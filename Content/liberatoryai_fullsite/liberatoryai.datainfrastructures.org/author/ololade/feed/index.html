<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Ololade Faniyi - Liberatory A.I.</title>
	<atom:link href="https://liberatoryai.datainfrastructures.org/author/ololade/feed/" rel="self" type="application/rss+xml" />
	<link>https://liberatoryai.datainfrastructures.org</link>
	<description>[rotating AI terms here]</description>
	<lastBuildDate>Thu, 01 May 2025 14:57:26 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.9.1</generator>
	<item>
		<title>African feminist approaches to liberatory AI</title>
		<link>https://liberatoryai.datainfrastructures.org/african-feminist-approaches-to-liberatory-ai/</link>
		
		<dc:creator><![CDATA[Ololade Faniyi]]></dc:creator>
		<pubDate>Thu, 01 May 2025 14:57:25 +0000</pubDate>
				<category><![CDATA[ways forward]]></category>
		<guid isPermaLink="false">https://liberatoryai.datainfrastructures.org/?p=289</guid>

					<description><![CDATA[<p>An African feminist liberatory approach recognizes technology as inherently political rather than neutral. Rather than accepting these embedded politics as inevitable, a liberatory approach would make them explicit and subject to democratic deliberation. Finally, and perhaps most importantly, an African feminist liberatory approach offers a fundamentally different vision of technological progress—one measured not by profit [&#8230;]</p>
<p>The post <a href="https://liberatoryai.datainfrastructures.org/african-feminist-approaches-to-liberatory-ai/">African feminist approaches to liberatory AI</a> first appeared on <a href="https://liberatoryai.datainfrastructures.org">Liberatory A.I.</a>.</p>]]></description>
										<content:encoded><![CDATA[<p>An African feminist liberatory approach recognizes technology as inherently political rather than neutral. Rather than accepting these embedded politics as inevitable, a liberatory approach would make them explicit and subject to democratic deliberation.</p>



<p>Finally, and perhaps most importantly, an African feminist liberatory approach offers a fundamentally different vision of technological progress—one measured not by profit or computational capacity but by how technology contributes to the collective. In contrast to the Techno-Optimist Manifesto&#8217;s individualistic vision, African feminist epistemologies offer frameworks for understanding technology as inherently relational.</p>



<p>Liberatory AI infrastructure is not merely theoretical—it is already emerging through the concrete actions of African feminists and technologists who are transforming how AI is governed, developed, and deployed.</p>



<p><a href="https://www.linkedin.com/posts/kauna-malgwi-104b5b86_at-long-last-eu-countries-adopt-the-platform-activity-7173281970402136064-vnfy/">Kauna Malgwi&#8217;s testimony</a> about content moderation conditions has had far-reaching impacts beyond Africa&#8217;s borders. Her advocacy helped lead to the European Union passing a directive protecting platform workers, demonstrating how the labor organizing of African women can reshape global technology governance. This cross-border influence reveals how African feminist resistance to exploitative tech practices creates ripple effects that benefit workers worldwide, fundamentally changing the narrative about whose imaginary can be embedded in policy and architecture of technology.</p>



<p>African women technologists are also directly shaping policy at national and regional levels. The expertise and advocacy of women like Dr Chinasa Okolo and more have contributed significantly to both Nigeria&#8217;s national AI strategy and the African Union&#8217;s continental approach. Rather than passively adapting to regulatory frameworks imported from the West or East, these women are ensuring that African priorities and values are centered on policy development.</p>



<p>Grassroots education initiatives are equally crucial in building liberatory infrastructure. My moderation of the <a href="https://youtu.be/0ce5JqrdngU?si=-1bqKn-TsM6emBW3">Liberation Alliance teach-in on digital colonialism and Afro-feminist futures</a> exemplifies how feminist collectives are contributing to citizen education and consciousness-raising. These spaces create critical literacy around technological systems, enabling communities to engage with technology from a position of knowledge rather than dependence.</p>



<p>Legal action and public accountability represent another scale of this emerging infrastructure. Former content moderators are seeking justice through lawsuits and public shaming of exploitative tech companies. These actions challenge the impunity with which multinational corporations have operated in African contexts, forcing recognition of their responsibilities toward African workers and users.</p>



<p>When viewed collectively, these initiatives constitute a distinct form of techno-resistance that recenters African women in who gets to talk about, critique, and rebuild technology. This resistance operates across multiple scales—from individual content moderators organizing for better working conditions to policy advocates shaping continental strategies.</p>



<p>We also see possibilities contained in community-led AI projects that demonstrate alternative approaches to technological development. <a href="https://www.technologyreview.com/2019/06/21/134820/ai-africa-machine-learning-ibm-google/">Charity Wayua&#8217;s AI tool </a>for identifying cassava diseases shows how AI can address challenges specific to African agricultural contexts, especially how artificial intelligence can be developed specifically to address local needs and improve livelihoods when designed with and for communities.&nbsp;</p>



<p>Projects like<a href="https://speech.igboapi.com/"> Ijemma Onwuzulike&#8217;s IgboSpeech</a>, the first Igbo voice-to-text AI model, exemplify liberatory AI in action. By building technological infrastructure for the Igbo language—creating not just a speech recognition system but a foundational API with over 5,000 words, nearly 30,000 Igbo sentences, and thousands of audio recordings—Onwuzulike demonstrates how AI can preserve and amplify indigenous languages, creating the technological foundation that would enable platforms like Duolingo to incorporate Igbo language learning. The Zambian feminist collective, Sistah Sistah, also launched their <a href="https://sistahsistah.org/wp-content/uploads/2024/11/Feminist-Ethics-AI-Toolkit_20241123_152905_0000.pdf">Feminist Ethics AI toolkit</a> in 2024, offering developers a review list to gauge their products&#8217; communal suitability.&nbsp; While still operating on the margins of mainstream technological development, these projects demonstrate tangible and possible futures of liberation.</p>



<p>What unites these diverse initiatives is their recognition of Africans—and particularly African women—not merely as consumers or low-skilled laborers in global technology supply chains, but as essential knowledge producers and innovators. By centering the experiences, needs, and expertise of those historically marginalized in technological development, these initiatives are reimagining the material conditions of technology &#8211; reimagining not just who benefits from AI but who creates it and for what purpose. By pushing against the false binary between the uncritical adoption of exploitative technologies and the rejection of technological development altogether, they create a third path: critical engagement that transforms technology to serve liberation.</p>



<p>The future of liberatory AI does not lie with amoral Silicon Valley entrepreneurs or Chinese state-affiliated corporations, but with the grassroots innovators, policy advocates, labor organizers, and community educators who are already building alternative technological infrastructures. Their work shows us that different technological futures are not only possible but already emerging.</p><p>The post <a href="https://liberatoryai.datainfrastructures.org/african-feminist-approaches-to-liberatory-ai/">African feminist approaches to liberatory AI</a> first appeared on <a href="https://liberatoryai.datainfrastructures.org">Liberatory A.I.</a>.</p>]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>AI must be built under humane conditions</title>
		<link>https://liberatoryai.datainfrastructures.org/ai-must-be-built-under-humane-conditions/</link>
		
		<dc:creator><![CDATA[Ololade Faniyi]]></dc:creator>
		<pubDate>Wed, 30 Apr 2025 20:51:05 +0000</pubDate>
				<category><![CDATA[ways forward]]></category>
		<guid isPermaLink="false">https://liberatoryai.datainfrastructures.org/?p=253</guid>

					<description><![CDATA[<p>A liberatory AI ecosystem would transform bad labor conditions by ensuring that those most affected by technological systems have a say in how they are designed and governed. AI is an African feminist issue. The convergence of automated systems, algorithmic governance, and digital infrastructure in African contexts has direct implications for African women&#8217;s lives, bodies, [&#8230;]</p>
<p>The post <a href="https://liberatoryai.datainfrastructures.org/ai-must-be-built-under-humane-conditions/">AI must be built under humane conditions</a> first appeared on <a href="https://liberatoryai.datainfrastructures.org">Liberatory A.I.</a>.</p>]]></description>
										<content:encoded><![CDATA[<p>A liberatory AI ecosystem would transform bad labor conditions by ensuring that those most affected by technological systems have a say in how they are designed and governed.</p>



<span id="more-253"></span>



<p>AI is an African feminist issue. The convergence of automated systems, algorithmic governance, and digital infrastructure in African contexts has direct implications for African women&#8217;s lives, bodies, and futures. As technological systems increasingly mediate social, political, and economic relations, they become inseparable from the broader struggles for liberation that have always been central to African feminist organizing.</p>



<p>An African feminist approach recognizes the embodied nature of technological systems. While corporate AI presents itself as disembodied and universal, African feminist thought insists on recognizing the physical bodies and lands that make technology possible. As the feminist historian Stephanie Camp reminds us, African women&#8217;s bodies were the scripts upon which the scripts of labor and enslavement was read and perpetuated, creating a coloniality/modernity where African women continue to pay the price for the indexing of humanity. A liberatory AI would acknowledge these embodied realities rather than obscuring them.</p>



<p>This embodied understanding leads to practical differences in how technology is developed and deployed. Content moderators would be recognized as tech workers rather than disposable labor. Data sovereignty would be understood as a crucial aspect of both personal and collective autonomy. The environmental impacts of technological infrastructure would be centered rather than externalized.</p>



<p>An African feminist approach to AI would transform tech governance by insisting on pluralistic, democratic control over technological systems. A liberatory AI ecosystem would transform this dynamic by ensuring that those most affected by technological systems have a say in how they are designed and governed. This would mean moving beyond corporate philanthropy or &#8220;ethical/responsible AI&#8221; initiatives that maintain existing power structures while making superficial adjustments.</p>



<p>Liberatory AI ecosystem must be grounded in the freedom dreams of those who have historically borne the costs of technological &#8220;progress.&#8221; Drawing from African feminist epistemologies offers us alternative frameworks for understanding and developing technologies that center relationality, care, freedom and plural frameworks of the human, rather than extraction, domination, and control.</p>



<p>African feminist scholar Filomina Chioma Steady provides a foundation for this reimagining when she positions her conception of feminism as emerging from what she terms &#8220;polarizations and conflicts—representing some of the worst and most chronic forms of human suffering&#8221;—and prompts us toward a broad struggle for social and humanistic transformation. This understanding allows us to envision a liberatory AI that critiques the racial, sexual, class, and cultural dimensions of technological oppression to produce equitable technologies through which humans are viewed as whole beings rather than data points to be extracted or bodies to be exploited.</p>



<p>What would this look like in practice? A liberatory AI ecosystem would acknowledge the full humanity of all people involved in its creation, deployment, and use. This means recognizing content moderators not as disposable labor but as essential tech workers deserving of fair compensation, psychological support, and dignity.&nbsp;</p>



<p>It recognizes that technological systems are never neutral but always encode particular ways of seeing and organizing the world. Rather than positioning the white, male, wealthy technologist as the universal subject of technological development, a liberatory AI would center multiple ways of being human. This means moving beyond what Alexander Weheliye describes as the &#8220;racializing assemblages&#8221; that discipline humanity into full humans, not-quite-humans, and nonhumans. Instead of reproducing these hierarchies, liberatory AI would be built on a &#8220;technological plural humanism&#8221;—recognition that different cultural contexts offer distinct and valuable approaches to technology development.</p>



<p>In the African context, this involves drawing on indigenous concepts of relationality and collective ownership. Many African societies have longstanding traditions that understand the individual as fundamentally embedded in community and the natural world. These epistemologies offer alternatives to the hyperindividualistic, extractive logics without soul that currently dominate AI development.</p>



<p>The digital articulations of African feminist freedom dreams are already pointing the way toward such alternatives. The Ugandan feminist tech collective, <a href="https://pollicy.org/">Pollicy</a>, for instance, builds its policy advocacies around the logic of digital kinship, where people must have access to their own data and technologies must be developed with and for communities rather than imposed upon them.</p>



<h3 class="wp-block-heading"><strong>Further Reading</strong></h3>



<p><strong>Further Reading (Academic)</strong></p>



<ul class="wp-block-list">
<li>Birhane, A. (2020). The Algorithmic Colonization of Africa. Script-ed, 17(2), 389-409.</li>



<li>Camp, S. M. H. (2005). Closer to Freedom: Enslaved Women and Everyday Resistance in the Plantation South. United States: University of North Carolina Press.</li>



<li>Jili, B. (2022). Chinese ICT and Smart City Initiatives in Kenya. Asia Policy 17(3), 40-50. <a href="https://dx.doi.org/10.1353/asp.2022.0051">https://dx.doi.org/10.1353/asp.2022.0051</a>.&nbsp;</li>



<li>Klein, L. &amp; D&#8217;Ignazio, C. (2024). Data Feminism for AI. ArXiv. <a href="https://doi.org/10.1145/3630106.3658543">https://doi.org/10.1145/3630106.3658543</a>&nbsp;</li>



<li>Mbembe, A. (2019). Necropolitics. Duke University Press.</li>



<li>Ogundipe, M. (1994). Re-creating Ourselves: African Women &amp; Critical Transformations. Africa World Press.</li>



<li>Steady, F. C. (1986). African Feminism: A Worldwide Perspective. In R. Terborg-Penn, S. Harley, &amp; A. Benton Rushing (Eds.), Women in Africa and the African Diaspora (pp. 3-24). Howard University Press.</li>



<li>Weheliye, A. G. (2014). Habeas Viscus: Racializing Assemblages, Biopolitics, and Black Feminist Theories of the Human. Duke University Press.</li>



<li>Wynter, S. (2003). Unsettling the Coloniality of Being/Power/Truth/Freedom: Towards the Human, After Man, Its Overrepresentation—An Argument. CR: The New Centennial Review, 3(3), 257-337.</li>



<li>Barrett, T., Okolo, C. T., Biira, B., Sherif, E., Zhang, A. X., &amp; Battle, L. (2025). African Data Ethics: A Discursive Framework for Black Decolonial Data Science. ArXiv. <a href="https://arxiv.org/abs/2502.16043">https://arxiv.org/abs/2502.16043</a>&nbsp;</li>
</ul>



<p><strong>Further Reading (Popular Press)</strong></p>



<ul class="wp-block-list">
<li>Benjamin, R. (2024). Imagination: A Manifesto (A Norton Short). United States: W. W. Norton.</li>



<li>Faniyi, O. (2024, February 27). An African Feminist Manifesto. The Republic. <a href="https://republic.com.ng/february-march-2024/an-african-feminist-manifesto/">https://republic.com.ng/february-march-2024/an-african-feminist-manifesto/</a>&nbsp;</li>



<li>Hao, K. (2019). The future of AI research is in Africa. MIT Technology Review. <a href="https://www.technologyreview.com/2019/06/21/134820/ai-africa-machine-learning-ibm-google/">https://www.technologyreview.com/2019/06/21/134820/ai-africa-machine-learning-ibm-google/</a>&nbsp;</li>



<li>Holland, A. (2024). Feminist Ethics AI Toolkit. Sistah Sistah</li>



<li>Jili, B. (2020, December 11). Surveillance tech in Africa stirs security concerns – Africa Center. Africa Center. <a href="https://africacenter.org/spotlight/surveillance-technology-in-africa-security-concerns/">https://africacenter.org/spotlight/surveillance-technology-in-africa-security-concerns/</a>&nbsp;</li>



<li>Perrigo, B. (2022, February 17). Inside Facebook’s African sweatshop. TIME. <a href="https://time.com/6147458/facebook-africa-content-moderation-employee-treatment/">https://time.com/6147458/facebook-africa-content-moderation-employee-treatment/</a>&nbsp;</li>
</ul><p>The post <a href="https://liberatoryai.datainfrastructures.org/ai-must-be-built-under-humane-conditions/">AI must be built under humane conditions</a> first appeared on <a href="https://liberatoryai.datainfrastructures.org">Liberatory A.I.</a>.</p>]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Corporate AI is built by exploited laborers.</title>
		<link>https://liberatoryai.datainfrastructures.org/corporate-ai-is-built-by-exploited-laborers/</link>
		
		<dc:creator><![CDATA[Ololade Faniyi]]></dc:creator>
		<pubDate>Wed, 30 Apr 2025 20:37:40 +0000</pubDate>
				<category><![CDATA[corporate AI landscape]]></category>
		<guid isPermaLink="false">https://liberatoryai.datainfrastructures.org/?p=248</guid>

					<description><![CDATA[<p>Corporate AI development depends on invisible labor, much of which is performed by workers in the Global South. This extractive reality stands in stark contrast to the techno-utopian promises of AI companies. My personal interactions with Kauna Malgwi, the Nigerian chairperson of the content moderator’s union, and my close watching and reading of the whistleblowing [&#8230;]</p>
<p>The post <a href="https://liberatoryai.datainfrastructures.org/corporate-ai-is-built-by-exploited-laborers/">Corporate AI is built by exploited laborers.</a> first appeared on <a href="https://liberatoryai.datainfrastructures.org">Liberatory A.I.</a>.</p>]]></description>
										<content:encoded><![CDATA[<p>Corporate AI development depends on invisible labor, much of which is performed by workers in the Global South. This extractive reality stands in stark contrast to the techno-utopian promises of AI companies. My personal interactions with Kauna Malgwi, the Nigerian chairperson of the content moderator’s union, and my close watching and reading of the whistleblowing expose at <a href="https://www.mozillafestival.org/en/highlights/mozfest-house-kenya/">MozFest</a>, <a href="https://www.bbc.com/news/av/world-africa-66514287">BBC Africa</a>, and <a href="https://www.youtube.com/watch?v=qZS50KXjAX0">60 Minutes</a> revealed the deception and exploitation at the heart of AI content moderation. Workers are recruited under false pretenses &#8211; told they would be &#8220;language annotators&#8221; for African languages, with no indication of the traumatic content they would be made to review.&nbsp;</p>



<p>These workers arrive at unassuming sub-contractor company buildings (Sama or TelePerformance and more), but once inside, they find themselves logging directly into BigTech systems like Open AI, Meta, TikTok, etc. Workers are coerced into signing non-disclosure agreements that prevent them from speaking about their experiences &#8211; a contractual silencing that whistleblowers have accurately described as &#8220;modern-day slavery.&#8221; They receive no psychological support despite being exposed to the most disturbing content imaginable: graphic violence, child abuse, and extreme hate speech. All this while being severely underpaid relative to the immense psychological toll of their work.</p>



<p>This human cost is devastating. Just days ago, a content moderator for TikTok was found dead in her apartment in Kenya. She had been deceased for three days before anyone discovered her. Her name was <a href="https://apnews.com/article/kenya-content-moderators-facebook-tik-tok-aa8cd8bd993c38d4701a64cfb7cd8ee6">Ladi Anzaki Olubunmi, </a>and her story exemplifies the disposability with which these workers are treated. There is an added cruel irony here: TikTok pays Global North creators through its Creator Fund but systematically excludes African creators from the same compensation—even as it relies on African workers like Ladi to moderate the very content that generates its profits. Sub-contractor companies like Teleperformance establish operations in Kenya, leveraging the country&#8217;s national position calling for tech investment to &#8220;provide jobs for Africans.&#8221; They recruit content moderators from across the continent with promises of work permits and annual tickets home. Yet these promises remain unfulfilled.</p>



<p>While Big tech giants exploit African labor through content moderation, Chinese companies deploy a different but equally extractive approach. Chinese &#8220;smart-safe cities&#8221; initiatives with scene analysis and facial recognition technologies are marketed across Africa as solutions to reduce crime. Bulelani Jili’s work has extensively documented this, and <a href="https://africacenter.org/spotlight/surveillance-technology-in-africa-security-concerns/">his findings</a> suggest that there is no clear evidence that these systems actually reduce crime rates. What is clear, however, is how authoritarian governments in Uganda and Zambia have weaponized these technologies to suppress anti-government opposition and dissenters.</p>



<p>The attraction of these systems to governments like Nigeria&#8217;s, Uganda’s, Zambia’s, and more becomes obvious: they extend state capacity for surveillance and control under the guise of public safety. These agreements are enabled by governmental greed and lust for power, offering new tools for monitoring and punishing dissent. At the same time, they extend Africa as a Chinese data territory, with people’s biometric and behavioral data flowing to Chinese companies and, by extension, the Chinese state—all without the consent of the citizens whose data is being harvested. This surveillance chain does not implicate just China, as similar safety-marketed surveillance tech from Israel, the United States, the United Kingdom and more connect several African countries to a <a href="https://www.surveillancewatch.io/">global surveillance industry</a>.</p>



<p>This dual exploitation—Western-Eastern extraction of labor, data, and surveillance extensions —represents two sides of the same colonial narrative. Ladi, denied a visa renewal and stranded in Kenya without the promised ticket home to Nigeria, died alone within this exploitative system. We may never get justice for her, as the insidious web of contractors, subcontractors, and multinational corporations diffuses responsibility and provides plausible deniability for tech giants.</p>



<p>This labor and data exploitation is not incidental but fundamental to how AI systems are built, maintained, and deployed globally. The racialized nature of this exploitation is also very familiar, as it follows centuries-old colonial patterns where Black and Brown bodies and data are extracted for wealth and power accumulation.</p>



<p>The pressure on African nations to align with competing techno-nationalist agendas creates an unending spiral of digital dependency. We see how Western and Eastern Big Tech corporations position themselves as saviors &#8220;bridging the digital divide&#8221; while actually extending colonial control. What emerges from these implementations are serious concerns about the intersection of state surveillance, data ownership, and labor and privacy rights.&nbsp;</p>



<p>The fundamental questions remain unaddressed: What data do the cameras, traffic surveillance systems, and phone decryption tools collect? How is this data perceived in authoritarian contexts—as an asset for the state or as something inevitably entangled with people&#8217;s rights? What are the implications of deploying technologies already demonstrated to exacerbate biases and heighten risks of misidentification, particularly within criminal justice systems?</p>



<p>In June 2024, Google posted images of African children playing football on the platform currently known as X. The caption of this now-deleted post shared that the most popular game in Africa was not, as some might think, &#8220;hide-and-seek with lions&#8221; but football. This post, on the back of Google’s own extraction, reflects the same tired narrative of exoticization and infantilization that accompanies technological engagement with the continent. Every time it seems like techno-critics might be too much of a killjoy about technology saviorism in Africa, we encounter content like this that further justifies our critique, especially when viewed through the lens of a humanistic African feminist thought. This post exemplifies why the myth of &#8220;bridging the digital divide&#8221; functions as nothing but a colonial strategy to keep Africa tied to the imperial imaginary of the West.&nbsp;</p>



<p>African nations thus find themselves caught between competing forms of digital colonialism, creating perpetual debt conditions—financial, technological, and political—that restrict African nations&#8217; autonomy while creating a path of debilitation of African workers in their savorist wake.&nbsp;</p>



<p>Corporate AI presents itself as automated, objective, and magical. Yet it depends entirely on human labor- specifically, the judgment of workers who are deliberately hidden, underpaid, and psychologically damaged by their labor. This is not merely a failure of corporate ethics but a structural feature of how AI wealth accumulation operates: by extracting value from racialized bodies kept invisible to end users.</p>



<p>The concrete manifestation of corporate AI&#8217;s extractive logic is perhaps most cohesively illustrated in Marc Andreessen&#8217;s &#8220;<a href="https://a16z.com/the-techno-optimist-manifesto/">The Techno-Optimist Manifesto</a>,&#8221; which champions a vision of technological progress that depends entirely on the creation of a&nbsp; white, male, wealthy super monohuman. This manifesto serves as a perfect case study of how technological discourse obscures the debilitating reality of AI development.</p>



<p>Andreessen&#8217;s opening claim that &#8220;Our civilization was built on technology&#8221; immediately raises the questions: Which civilization? Whose technology? And built on whose bodies? The manifesto&#8217;s universalizing &#8220;we&#8221; erases the differential impact of technological development across global populations.</p>



<p>This erasure is not accidental but structural. We have established how AI systems from Meta and OpenAI are quite literally built on the psychological trauma of African content moderators making $2/hour while being exposed to the worst content humanity produces. These workers bear the psychological burden of filtering graphic violence, child abuse, and hateful content so users can experience a &#8220;clean&#8221; online environment. Yet they remain invisible in techno-optimist narratives of progress.</p>



<p>The manifesto&#8217;s framing of technology as &#8220;lifting people out of poverty&#8221; obscures the reality that many technological supply chains depend on resource extraction that creates what Cameroonian historian Achille Mbembe terms &#8220;death-worlds&#8221;—zones where vast populations are subjected to conditions of living death. In the Democratic Republic of Congo, systematic sexual violence is used as a weapon of mineral control, as the techno-capital machine&#8217;s demand for cobalt and coltan drives conflict and exploitation. Yet this human cost of their extraction is conveniently absent from techno-optimist discourse.</p>



<p>This monohumanism represents what I identify as a third invention in Afro-Jamaican scholar <a href="https://muse.jhu.edu/article/51630">Sylvia Wynter&#8217;s question of the Human in our coloniality/modernity</a>—what we might call &#8216;Man3&#8217;—a conception shaped by our increasing entanglement with and fetishization of technology. We begin with the inevitable fact that the experiences we discuss are evidence of a racial capitalism whose very roots began with the invention of &#8216;Africa&#8217; with the transatlantic slave trade, through colonialism and the persistence of coloniality. Just as Wynter describes the evolution from Man1 (the Renaissance political subject) to Man2 (the biological, Darwinian subject), we now witness Big Tech elites creating technologies whose labor relies largely on the racialized bodies categorized under &#8216;Man2&#8217;—African and South Asian workers underpaid to do the arduous, emotionally taxing task of data labeling and content moderation.&nbsp;</p>



<p>Our everyday lives become territories of surveillance, controlled by various platforms from social media to work tools, health records, and transportation, to the scene recognition tools of the streets, increasingly separating us into those who adapt to machines and techno-hegemony and those who control these technologies—the data elites versus the data producers. The Techno-Optimist Manifesto reveals the extent to which this &#8216;Man3&#8217; paradigm has become normalized, presenting a vision of progress that requires the continued exploitation of racialized bodies while promising a techno-utopian future accessible only to those already privileged within global hierarchies and whose prescriptive statements define out coloniality/modernity.</p>



<p>This monohumanism operates through a closed loop: African language and stylistic choices are assimilated into AI systems through the labor of underpaid content moderators, only for those same people to find their own writing later flagged as &#8220;AI-generated&#8221; by detection systems, creating another cruel irony where the very people whose labor makes AI systems possible are summarily excluded.</p>



<p>The concrete infrastructure of corporate AI reveals precisely what Afro-Jamaican scholar Sylvia Wynter critiques—the overrepresentation of one vision of being human that makes other ways of being unthinkable. At this moment, the monohuman operates through Big Tech&#8217;s Euro-American-Chinese universalized imaginaries, while African bodies remain perpetual laboring bodies positioned outside technological progress except as sites of extraction.</p>



<p>When the manifesto proclaims that &#8220;technology opens the space of what it can mean to be human,&#8221; we must then ask: Whose humanity is being expanded, and whose is being erased? In the techno-capital machine, who cleans? Who mines? Whose bodies labor? Whose knowledge is extracted then discarded? Can technology solve the problem of its own colonial logic? Who, in this vision, gets to be human?</p>



<p>The material reality of corporate AI development answers these questions clearly. Until these questions are confronted, any techno-optimism that ignores the differential distribution of technology&#8217;s benefits and harms simply reproduces colonial patterns of exploitation under a new name.</p>



<p>A growing number of scholars, whistleblowers, and activists are bringing these issues to light, though their work often remains marginalized in mainstream tech discourse. Abeba Birhane&#8217;s work on &#8220;The Algorithmic Colonization of Africa&#8221; for instance critiques how AI and algorithmic systems reproduce colonial power dynamics on the continent. Birhane demonstrates how AI systems developed primarily in Western contexts are deployed across Africa with little regard for local needs, contexts, or potential harms. Her framework helps us understand that what we are witnessing is a new form of colonization operating through algorithms and data extraction.</p>



<p>Bulelani Jili&#8217;s research on Chinese Surveillance Technology in Africa also provides well-researched documentation of how Chinese tech companies are expanding their surveillance infrastructure across the continent. Jili&#8217;s work reveals how authoritarian governance models are embedded within the technologies themselves. He also questions the rhetoric promoting these systems, which emphasize crime prevention, accelerated emergency response, and technological modernization. Yet, as seen in the first implementation in Nairobi, Kenya, there is a troubling lack of empirical evidence supporting claims about the effectiveness of these surveillance technologies. In fact, reports from Huawei frequently contradict those from Kenya&#8217;s National Police Service, raising questions about who benefits from these systems.</p>



<p>From the work of Daniel Motaung, Kauna Malgwi, Mophat Okunyi, and more, whistleblowers have been bringing firsthand accounts of exploitation to public attention, connecting digital rights to mental health care and decolonization. Former content moderators have risked all to expose the traumatic working conditions at companies that contract with Meta, OpenAI, TikTok, and other platforms. Their testimonies have been featured in investigations by TIME magazine, BBC, and 60 Minutes. <a href="https://www.vanguardngr.com/2024/08/politicians-used-irts-tracker-to-monitor-enemies-mistresses-instead-of-kidnappers/">Reports from Nigeria</a> have also uncovered that politicians are weaponizing digital surveillance technologies to target their opponents and even spy on their mistresses, revealing how quickly surveillance tools shift from their stated purpose (crime reduction) to serving the personal and political interests of those in power.</p>



<p>While critical technology scholars, including Safiya Noble, Ruha Benjamin, Deb Raji, Joy Buolawumi and Timnit Gebru and more, have further developed frameworks for understanding how technological systems encode and amplify existing social hierarchies. Nonetheless, we need more holistic analysis that connects extractive labor practices, surveillance infrastructure, geopolitical technology competition, and the persistent devaluation of African lives, to see the full scope of how AI systems perpetuate coloniality. My own research aims to bridge these conversations by centering African feminist thought as not just a critique of existing systems but as a foundation for alternative frameworks for technological development.</p>



<h3 class="wp-block-heading"></h3>



<p><strong>Further Reading (Academic)</strong></p>



<ul class="wp-block-list">
<li>Birhane, A. (2020). The Algorithmic Colonization of Africa. Script-ed, 17(2), 389-409.</li>



<li>Camp, S. M. H. (2005). Closer to Freedom: Enslaved Women and Everyday Resistance in the Plantation South. United States: University of North Carolina Press.</li>



<li>Jili, B. (2022). Chinese ICT and Smart City Initiatives in Kenya. Asia Policy 17(3), 40-50. <a href="https://dx.doi.org/10.1353/asp.2022.0051">https://dx.doi.org/10.1353/asp.2022.0051</a>. </li>



<li>Klein, L. &amp; D&#8217;Ignazio, C. (2024). Data Feminism for AI. ArXiv. <a href="https://doi.org/10.1145/3630106.3658543">https://doi.org/10.1145/3630106.3658543</a> </li>



<li>Mbembe, A. (2019). Necropolitics. Duke University Press.</li>



<li>Ogundipe, M. (1994). Re-creating Ourselves: African Women &amp; Critical Transformations. Africa World Press.</li>



<li>Steady, F. C. (1986). African Feminism: A Worldwide Perspective. In R. Terborg-Penn, S. Harley, &amp; A. Benton Rushing (Eds.), Women in Africa and the African Diaspora (pp. 3-24). Howard University Press.</li>



<li>Weheliye, A. G. (2014). Habeas Viscus: Racializing Assemblages, Biopolitics, and Black Feminist Theories of the Human. Duke University Press.</li>



<li>Wynter, S. (2003). Unsettling the Coloniality of Being/Power/Truth/Freedom: Towards the Human, After Man, Its Overrepresentation—An Argument. CR: The New Centennial Review, 3(3), 257-337.</li>



<li>Barrett, T., Okolo, C. T., Biira, B., Sherif, E., Zhang, A. X., &amp; Battle, L. (2025). African Data Ethics: A Discursive Framework for Black Decolonial Data Science. ArXiv. <a href="https://arxiv.org/abs/2502.16043">https://arxiv.org/abs/2502.16043</a> </li>
</ul>



<p><strong>Further Reading (Popular Press)</strong></p>



<ul class="wp-block-list">
<li>Benjamin, R. (2024). Imagination: A Manifesto (A Norton Short). United States: W. W. Norton.</li>



<li>Faniyi, O. (2024, February 27). An African Feminist Manifesto. The Republic. <a href="https://republic.com.ng/february-march-2024/an-african-feminist-manifesto/">https://republic.com.ng/february-march-2024/an-african-feminist-manifesto/</a> </li>



<li>Hao, K. (2019). The future of AI research is in Africa. MIT Technology Review. <a href="https://www.technologyreview.com/2019/06/21/134820/ai-africa-machine-learning-ibm-google/">https://www.technologyreview.com/2019/06/21/134820/ai-africa-machine-learning-ibm-google/</a> </li>



<li>Holland, A. (2024). Feminist Ethics AI Toolkit. Sistah Sistah</li>



<li>Jili, B. (2020, December 11). Surveillance tech in Africa stirs security concerns – Africa Center. Africa Center. <a href="https://africacenter.org/spotlight/surveillance-technology-in-africa-security-concerns/">https://africacenter.org/spotlight/surveillance-technology-in-africa-security-concerns/</a> </li>



<li>Perrigo, B. (2022, February 17). Inside Facebook’s African sweatshop. TIME. <a href="https://time.com/6147458/facebook-africa-content-moderation-employee-treatment/">https://time.com/6147458/facebook-africa-content-moderation-employee-treatment/</a></li>
</ul><p>The post <a href="https://liberatoryai.datainfrastructures.org/corporate-ai-is-built-by-exploited-laborers/">Corporate AI is built by exploited laborers.</a> first appeared on <a href="https://liberatoryai.datainfrastructures.org">Liberatory A.I.</a>.</p>]]></content:encoded>
					
		
		
			</item>
	</channel>
</rss>
