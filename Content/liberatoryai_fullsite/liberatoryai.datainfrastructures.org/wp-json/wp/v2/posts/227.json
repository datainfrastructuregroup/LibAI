{"id":227,"date":"2025-04-30T20:02:29","date_gmt":"2025-04-30T20:02:29","guid":{"rendered":"https:\/\/liberatoryai.datainfrastructures.org\/?p=227"},"modified":"2025-04-30T20:12:25","modified_gmt":"2025-04-30T20:12:25","slug":"corporate-ai-is-colonialist","status":"publish","type":"post","link":"https:\/\/liberatoryai.datainfrastructures.org\/corporate-ai-is-colonialist\/","title":{"rendered":"Corporate AI is Colonialist"},"content":{"rendered":"\n<p>Corporate AI, especially LLMs, reinforce colonial and capitalist structures by privileging Western, male, and Global North perspectives while excluding localized <em>knowledges<\/em>. <\/p>\n\n\n\n<!--more-->\n\n\n\n<p>Corporations have developed and deployed (through markets) large language models (LLMs), particularly generative AI systems like ChatGPT, expanding their reach across geographic and political boundaries and broadening the range of languages and topics these models can process. On the one hand, LLMs developed by these corporations aim to represent and communicate with diverse realities. On the other, by prioritizing profit through broader market reach and scalability via larger models, they <em>strategically<\/em> promote a particular vision [LINK TO UNIVERSALITY]of the world, relying predominantly on English-language data and Western social perspectives about the world. This reliance prevents these models from capturing the nuances of the cultures, languages, and societies in which they operate.<\/p>\n\n\n\n<p>This <em>strategic flawed attempt<\/em> to universally represent the world and specific contexts while excluding local and situated contexts reveal a fundamental limitation of large language models (LLMs): the reproduction of stereotypes rooted in social structures, such as racism and sexism. \u200bWhile corporations often promote their AI systems as universally applicable to benefit \u201c<a href=\"https:\/\/openai.com\/about\/\">all of humanity<\/a>\u201d, large-scale models systematically encode the perspectives of specific and typically privileged social groups\u2013predominantly white, cisgender, Christian, English-speaking men from the global North. Even though this kind of human being has been historically constructed as a universal way of being in the world\u2013as demonstrated by centuries of colonization and the colonial consequences afterward (Grosfoguel 2008)\u2013, by privileging this profile, it is a particular and situated perspective that these LLMs embrace.<\/p>\n\n\n\n<p>Recent research illustrates how LLMs provide a limited perspective on different geopolitical regions, languages, and social groups. For example, Nyalleng Moorosi (2024) highlights the persistent limitations of large-scale AI models developed by Western tech companies, such as OpenAI, in processing African languages. ChatGPT, for instance, recognizes sentences in Hausa, Nigeria\u2019s most widely spoken language, only 10\u201320% of the time. This demonstrates a constraint imposed by the model\u2019s developers, as it lacks local linguistic and cultural contextualization.<\/p>\n\n\n\n<p>This exclusion of diverse geographic and cultural perspectives is also evident in text-to-image generative models, which fail to capture regional diversity and instead reinforce dominant narratives and stereotypes (Hall et al. 2024). Research on these models in Europe, Africa, and Southeast Asia highlights how both automated and human evaluations of generated images vary significantly by location (Hall et al. 2024). Annotators from different regions frequently disagree on what constitutes geographic representation, reinforcing the broader issue of AI systems reflecting the prejudices of those who design and train them rather than fostering a situated perspective.<\/p>\n\n\n\n<p>Additionally, a nearly universal gender gap in generative AI usage persists. <sup class=\"modern-footnotes-footnote \" data-mfn=\"1\" data-mfn-post-scope=\"000000000000056c0000000000000000_227\"><a href=\"javascript:void(0)\"  role=\"button\" aria-pressed=\"false\" aria-describedby=\"mfn-content-000000000000056c0000000000000000_227-1\">1<\/a><\/sup><span id=\"mfn-content-000000000000056c0000000000000000_227-1\" role=\"tooltip\" class=\"modern-footnotes-footnote__note\" tabindex=\"0\" data-mfn=\"1\">Many artificial general intelligence systems are continuously trained on data acquired through use, e.g. the text of Chat-GPT prompts.<\/span> Data from 18 studies covering more than 140,000 individuals worldwide reveal that this gap exists across regions, sectors, and occupations (Otis et al. 2025). This disparity risks creating a self-reinforcing cycle: women&#8217;s underrepresentation in generative AI usage results in systems trained on data that inadequately capture women&#8217;s preferences and needs. Consequently, even if achieving gender-equal usage of generative models is not a liberatory goal, these systems may be marketed as general and universal, but they ultimately reproduce harmful gendered stereotypes, generate lower-quality recommendations and outputs for women and gender minorities, and further widen existing gender disparities in technology implementation.<\/p>\n\n\n\n<p>By attempting to generalize the world, corporate AI fails to recognize the critical importance of context-situatedness. And by doing that, it denies its main marker: its own particularity and non-universality. Or, as Lauren Klein et al. (2025) state, it reflects a narrow definition of culture rooted in the terms of modernity.<\/p>\n\n\n\n<p><strong><em>Saying AI is colonialist implies that AI reinforces capitalism by also reproducing violent racial categories\u2014as colonial modernity historically does. <\/em><\/strong>These models, built on Western-centric datasets, embody <em>colonialidade do saber<\/em>\/knowledge coloniality (Quijano 2005), privileging certain worldviews while marginalizing non-Western and local epistemologies. <a href=\"https:\/\/www.brookings.edu\/articles\/how-language-gaps-constrain-generative-ai-development\/\">AI\u2019s reliance on English<\/a> clearly presents this exclusion, trying to make natural a narrow epistemology that frames Western knowledge\u2013such as through English-trained data\u2013as universal while distorting or erasing alternative ways of knowing. This is clear in the examples provided above, which highlighted how these prejudices manifest in AI\u2019s poor performance in processing African languages (Moorosi 2024) and its failure to accurately represent non-Western cultural contexts (Hall et al. 2024). This asymmetry determines whose perspectives are considered valid and whose realities are ignored.&nbsp;<\/p>\n\n\n\n<p>Neglection and removal of culture, in the last instance, is a way of dominating different cultures and, through this linguistic and epistemic hegemony, can be translated into material consequences, exacerbating global inequalities through the consolidation of <em>colonialidade do poder\/<\/em>power coloniality (Quijano 2005). AI development remains concentrated in Western tech corporations that not only dictate technological and ethical standards but also extract data work from the Global South without equitable returns. This is what happens, for example, in Brazil, where 64% of AI data training workers are women, with two-thirds being mothers seeking additional income (Tubaro et al. 2025). At the same time, the outputs of these models reinforce racialized and gendered hierarchies, echoing historical and colonial patterns of domination (Santino 2024). For Dan McQuillan (2022, 66), \u201cAI not only perpetuates racist discrimination but acts, at a deeper level, as a technology of racialization.\u201d Think, for example, about the well-known cases of facial recognition technologies that misidentify Black individuals at higher rates compared to white individuals, leading to arrests and surveillance (Buolamwini and Gebru 2018). These errors are not technical flaws but stem from how machine learning constructs and enforces categories of difference, \u201cforcing closeness in data space\u201d based on biased datasets that reflect existing social hierarchies (McQuillan 2022, 66). Even if efforts to improve facial recognition for marginalized groups do not necessarily lead to liberation, by presenting this systemic exclusion, AI <em>strategically <\/em>produces and sustains racialized systems of domination and exclusion, assigning different values and risks to individuals based on racial attributes that are different from the dominant, or so-called \u201cuniversal\u201d human beings\u2013usually white, men, from the global North.<\/p>\n\n\n\n<p>As Mar\u00eda Lugones (2014) argues, <em>colonialidade do g\u00eanero\/<\/em>gender coloniality combines these exclusions, as generative AI models systematically misrepresent or erase gender-diverse identities while perpetuating harmful gender stereotypes. This digital coloniality does not merely \u201cmirror\u201d existing prejudices\u2014it automates and scales them under the defense of <em>technological neutrality<\/em>. Os Keyes (2019) exemplify this problem in their text \u201cCounting the Countless.\u201d For them, the use of gender-recognition algorithms in facial recognition systems, which force individuals into rigid categories of \u201cmale\u201d or \u201cfemale\u201d based on biological essentialism, misrepresents and erases trans and nonbinary people. These systems require legibility within a binary framework, often linking access to public resources or safety (such as bathroom access or legal ID recognition) to conformity with those categories. This is a form of <em>gender coloniality<\/em> that automates, scales, and enforces a violent system of exclusion, based on a gendered approach, rooted in colonization\u2019s sexism and heteronormativity markers that appears neutral or scientific, but in the end, ignores situatedness to value a supposed universal, but also colonial, way of being.<\/p>\n\n\n\n<p>Beyond \u201cmisrepresentation,\u201d these dominant practices and prejudices have a material impact on thousands of people. For example, besides AI systems delivering lower-quality outputs in non-English contexts, studies have also revealed that LLMs exhibit broader social identity biases, such as favoring a group and showing negativity toward other groups (Hu et al. 2025). These prejudices can reinforce societal discrimination and contribute to issues like political polarization. The challenge is not only improving representation but questioning who controls knowledge production, whose perspectives are embedded in AI systems, and how these systems shape global power dynamics\u2013including authoritarianism\u2013in the current historical moment we live in.<\/p>\n\n\n\n<p><strong>Rooting the future of AI in our concrete collective experiences<\/strong><\/p>\n\n\n\n<p>I draw here on Rita Laura Segato (2025, 14) to argue that instead of embracing abstract utopias shaped by evolutionist and Eurocentric perspectives about the future\u2014utopias that can have an &#8220;authoritarian effect&#8221;\u2014we should instead look toward the concrete experiences of peoples who are still today \u201ccommunally and collectively organized.\u201d As Segato suggests, the inspiration for possible futures is not to be found in the illusion of a pre-designed future,<a href=\"https:\/\/www.newsweek.com\/blue-origin-jeff-bezos-moon-lander-concept-video-1423101\"> such as the colonizing dreams of Space<\/a>, but rather in concrete experiences. These experiences are rooted in the lives of those who, after hundreds of years of genocide, exploitation, and violence, have continued to resist.<\/p>\n\n\n\n<p>From solidarity economy practices (McQuillan 2022) to feminist data activism against feminicide (D\u2019Ignazio 2024), many real-world experiences offer concrete practices for social change in relation to AI. One such example is the work of the Stop LAPD Spying Coalition, which challenges police surveillance in the Skid Row community. Their 2023 report exposes how the State\u2019s &#8220;family policing&#8221; system uses AI and predictive analytics to punish mothers for systemic issues beyond their control, such as lack of housing or disability, reinforcing colonial patterns of domination (Stop LAPD Spying Coalition and Downtown Women\u2019s Action Coalition 2023). These examples remind us that building just futures for AI must begin by rooting our efforts in the community and situated struggles and solidarities that are already happening now.<\/p>\n\n\n\n<p><strong>References<\/strong><\/p>\n\n\n\n<p><a href=\"https:\/\/www.zotero.org\/google-docs\/?UsNwQn\">Buolamwini, Joy, and Timnit Gebru. 2018. \u201cGender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification.\u201d In <em>Conference on Fairness, Accountability and Transparency<\/em>, 77\u201391. PMLR.<\/a><\/p>\n\n\n\n<p>D\u2019Ignazio, Catherine. 2024. Counting Feminicide: Data Feminism in Action. MIT Pess, Cambridge.<\/p>\n\n\n\n<p>Grosfoguel, Ram\u00f3n. \u201cWorld-Systems Analysis in the Context of Transmodernity, Border Thinking, and Global Coloniality.\u201d <em>Review (Fernand Braudel Center)<\/em> 29, no. 2 (2006): 167\u201387. <a href=\"http:\/\/www.jstor.org\/stable\/40241659\">http:\/\/www.jstor.org\/stable\/40241659<\/a>.<\/p>\n\n\n\n<p>Hall, Melissa, Samuel J. Bell, Candace Ross, Adina Williams, Michal Drozdzal, and Adriana Romero Soriano. 2024. \u201cTowards Geographic Inclusion in the Evaluation of Text-to-Image Models.\u201d In <em>Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency (FAccT \u201924),<\/em> 585\u2013601. Rio de Janeiro, Brazil. New York: Association for Computing Machinery.<a href=\"https:\/\/doi.org\/10.1145\/3630106.3658927\"> https:\/\/doi.org\/10.1145\/3630106.3658927<\/a>.<\/p>\n\n\n\n<p>Hu, Tiancheng, Yara Kyrychenko, Steve Rathje, Nigel Collier, Sander van der Linden, and Jon Roozenbeek. 2025. \u201cGenerative Language Models Exhibit Social Identity Biases.\u201d <em>Nature Computational Science<\/em> 5: 65\u201375.<a href=\"https:\/\/www.nature.com\/articles\/s43588-024-00741-1\"> https:\/\/www.nature.com\/articles\/s43588-024-00741-1<\/a>.<\/p>\n\n\n\n<p>Keyes, Os. 2019. \u201cCounting the Countless: Why Data Science Is a Profound Threat for Queer People.\u201d <em>Real Life Magazine<\/em>, April 8, 2019.<a href=\"https:\/\/reallifemag.com\/counting-the-countless\/\"> https:\/\/reallifemag.com\/counting-the-countless\/<\/a>.<\/p>\n\n\n\n<p>Klein, Lauren, Meredith Martin, Andr\u00e9 Brock, Maria Antoniak, Melanie Walsh, Jessica Marie Johnson, Lauren Tilton, and David Mimno. 2025. \u201cProvocations from the Humanities for Generative AI Research.\u201d Preprint, <em>arXiv<\/em>, February 28, 2025.<a href=\"https:\/\/arxiv.org\/abs\/2502.19190\"> https:\/\/arxiv.org\/abs\/2502.19190<\/a>.<\/p>\n\n\n\n<p>Lugones, Mar\u00eda. 2014. \u201cRumo a um Feminismo Descolonial.\u201d <em>Estudos Feministas<\/em> 22, no. 3 (September\u2013December): 935\u2013952.<a href=\"https:\/\/periodicos.ufsc.br\/index.php\/ref\/article\/view\/36755\"> https:\/\/periodicos.ufsc.br\/index.php\/ref\/article\/view\/36755<\/a><\/p>\n\n\n\n<p>McQuillan, Dan. 2022. <em>Resisting AI: An Anti-Fascist Approach to Artificial Intelligence.<\/em> Policy Press.<a href=\"https:\/\/rojen.uk\/doc\/resisting-ai-an-anti-fascist-approach-to-artificial-intelligence.pdf\"> https:\/\/rojen.uk\/doc\/resisting-ai-an-anti-fascist-approach-to-artificial-intelligence.pdf<\/a><\/p>\n\n\n\n<p>Moorosi, Nyalleng. 2024. \u201cBetter Data Sets Won\u2019t Solve the Problem \u2014 We Need AI for Africa to Be Developed in Africa.\u201d <em>Nature<\/em> 636, no. 8042 (December): 276.<a href=\"https:\/\/doi.org\/10.1038\/d41586-024-03988-w\"> https:\/\/doi.org\/10.1038\/d41586-024-03988-w<\/a>.<\/p>\n\n\n\n<p><a href=\"https:\/\/www.zotero.org\/google-docs\/?UsNwQn\">Otis, Nicholas, Delecourt, Katelyn Cranney, and Rembrand Koning. 2025. \u201cGlobal Evidence on Gender Gaps and Generative AI.\u201d Harvard Business School. <\/a><a href=\"https:\/\/www.hbs.edu\/ris\/Publication%20Files\/25-023_8ee1f38f-d949-4b49-80c8-c7a736f2c27b.pdf\">https:\/\/www.hbs.edu\/ris\/Publication%20Files\/25-023_8ee1f38f-d949-4b49-80c8-c7a736f2c27b.pdf<\/a><a href=\"https:\/\/www.zotero.org\/google-docs\/?UsNwQn\">.<\/a><\/p>\n\n\n\n<p>Quijano, An\u00edbal. 2005. \u201cA Colonialidade do Poder, Eurocentrismo e Am\u00e9rica Latina.\u201d In <em>A Colonialidade do Saber: Eurocentrismo e Ci\u00eancias Sociais. Perspectivas Latino-Americanas<\/em>, 117\u2013142. Buenos Aires: CLACSO \u2013 Consejo Latinoamericano de Ciencias Sociales.<\/p>\n\n\n\n<p>Santino Regilme, Salvador. 2024. \u201cArtificial Intelligence Colonialism: Environmental Damage, Labor Exploitation, and Human Rights Crises in the Global South.\u201d <em>SAIS Review of International Affairs<\/em> 44, no. 2 (Fall\u2013Winter). Johns Hopkins University Press.<a href=\"https:\/\/muse.jhu.edu\/article\/950958\"> https:\/\/muse.jhu.edu\/article\/950958<\/a>.<\/p>\n\n\n\n<p>Segato, Rita Laura. 2025. <em>The War Against Women<\/em>. Critical South Series. Cambridge, UK: Polity Press.<\/p>\n\n\n\n<p>Stop LAPD Spying Coalition and Downtown Women\u2019s Action Coalition (DWAC). 2023. <em>DCF(S) Stands for Dividing and Conquering Families: How the Family Policing System Contributes to the Stalker State.<\/em> Available at:<a href=\"https:\/\/stoplapdspying.org\/dcfs\/\"> https:\/\/stoplapdspying.org\/dcfs\/<\/a>.<\/p>\n\n\n\n<p>Tubaro, Paola, Antonio A. Casilli, Mariana Fern\u00e1ndez Massi, Julieta Longo, Juana Torres Cierpe, and Matheus Viana Braz. 2025. &#8220;The Digital Labour of Artificial Intelligence in Latin America: A Comparison of Argentina, Brazil, and Venezuela.&#8221; The Political Economy of Artificial Intelligence in Latin America, published online February 19, 2025. <a href=\"https:\/\/doi.org\/10.1080\/14747731.2025.2465171\">https:\/\/doi.org\/10.1080\/14747731.2025.2465171<\/a>.<\/p>\n","protected":false},"excerpt":{"rendered":"<p>Corporate AI, especially LLMs, reinforce colonial and capitalist structures by privileging Western, male, and Global North perspectives while excluding localized knowledges.<\/p>\n","protected":false},"author":10,"featured_media":182,"comment_status":"closed","ping_status":"closed","sticky":false,"template":"","format":"standard","meta":{"inline_featured_image":false,"footnotes":""},"categories":[6],"tags":[],"coauthors":[25],"class_list":["post-227","post","type-post","status-publish","format-standard","has-post-thumbnail","hentry","category-corporate-ai-landscape"],"aioseo_notices":[],"_links":{"self":[{"href":"https:\/\/liberatoryai.datainfrastructures.org\/wp-json\/wp\/v2\/posts\/227","targetHints":{"allow":["GET"]}}],"collection":[{"href":"https:\/\/liberatoryai.datainfrastructures.org\/wp-json\/wp\/v2\/posts"}],"about":[{"href":"https:\/\/liberatoryai.datainfrastructures.org\/wp-json\/wp\/v2\/types\/post"}],"author":[{"embeddable":true,"href":"https:\/\/liberatoryai.datainfrastructures.org\/wp-json\/wp\/v2\/users\/10"}],"replies":[{"embeddable":true,"href":"https:\/\/liberatoryai.datainfrastructures.org\/wp-json\/wp\/v2\/comments?post=227"}],"version-history":[{"count":3,"href":"https:\/\/liberatoryai.datainfrastructures.org\/wp-json\/wp\/v2\/posts\/227\/revisions"}],"predecessor-version":[{"id":233,"href":"https:\/\/liberatoryai.datainfrastructures.org\/wp-json\/wp\/v2\/posts\/227\/revisions\/233"}],"wp:featuredmedia":[{"embeddable":true,"href":"https:\/\/liberatoryai.datainfrastructures.org\/wp-json\/wp\/v2\/media\/182"}],"wp:attachment":[{"href":"https:\/\/liberatoryai.datainfrastructures.org\/wp-json\/wp\/v2\/media?parent=227"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https:\/\/liberatoryai.datainfrastructures.org\/wp-json\/wp\/v2\/categories?post=227"},{"taxonomy":"post_tag","embeddable":true,"href":"https:\/\/liberatoryai.datainfrastructures.org\/wp-json\/wp\/v2\/tags?post=227"},{"taxonomy":"author","embeddable":true,"href":"https:\/\/liberatoryai.datainfrastructures.org\/wp-json\/wp\/v2\/coauthors?post=227"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}