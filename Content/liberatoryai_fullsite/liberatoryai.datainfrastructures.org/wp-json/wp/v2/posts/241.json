{"id":241,"date":"2025-04-30T20:30:53","date_gmt":"2025-04-30T20:30:53","guid":{"rendered":"https:\/\/liberatoryai.datainfrastructures.org\/?p=241"},"modified":"2025-04-30T20:34:18","modified_gmt":"2025-04-30T20:34:18","slug":"corporate-ai-threatens-democracy","status":"publish","type":"post","link":"https:\/\/liberatoryai.datainfrastructures.org\/corporate-ai-threatens-democracy\/","title":{"rendered":"Corporate AI threatens democracy"},"content":{"rendered":"\n<p>To reclaim our socio-digital futures, we must challenge corporate AI\u2019s capture of democratic politics and counter it by centering collective, solidary, and participatory forms of politics.<\/p>\n\n\n\n<!--more-->\n\n\n\n<p>Business influence on politics is commonly thought of as discreet, happening behind closed doors and away from public view. Culpepper (2011) has called this \u201cquiet politics\u201d. But lately, the politics of Big Tech corporations, who<a href=\"https:\/\/docs.google.com\/document\/d\/149rzy4aGwFk8R_WXRoYSSWArQumFHu5vMY8bmPLQ3Rw\/edit?tab=t.u9dbhnxznckc\"> control much of the AI pipeline<\/a>, has been anything but quiet. The widely shared photos of CEOs from Meta, Amazon, OpenAI, Apple, and Google standing behind Trump at his 2025 inauguration\u2014aptly captured in Barry Blitt\u2019s satirical illustration below\u2014is just one example of how this political influence has moved from back rooms to center stage. What this visibility reveals is a politics that is deeply particularistic or self-interested. Put simply, Corporate AI seeks to <strong>capture<\/strong> democratic political processes and imaginaries to advance its own interests\u2014controlling algorithmic decision-making, steering regulation, and influencing democratic elections to prioritize profit and industry power over societal concerns and welfare.<\/p>\n\n\n\n<figure class=\"wp-block-image\"><img decoding=\"async\" src=\"https:\/\/lh7-rt.googleusercontent.com\/docsz\/AD_4nXfjUMRU4dXky9UNTByG_2Jq1C8HPMit4xs0oTKWMVEL3v9WMaR9zIyaGZfNiWz1bY7q6cKXNJUPwkK6FEsQgQ5L1_Uk58CKkZNQoJ4g97kKGjt7k9gVnjx93Ocs29qgrdd9gLrj8A?key=xQZMTgOID_QH5hNfr6fxpkOd\" alt=\"\"\/><\/figure>\n\n\n\n<p class=\"has-text-align-center\"><em>Image credit: Barry Blitt for airmailweekly.<\/em><\/p>\n\n\n\n<p>The term \u201ccapture\u201d has been used by academics and commentators to describe various dynamics in AI development\u2014for instance, how \u201ctech oligarchs\u201d seek to capture state resources and institutions to support personal gain (Cohen, 2025), or how the AI industry has taken control over academic research agendas (Whittaker, 2021). The term also has a long history in research on regulatory politics, where \u201ccapture\u201d typically refers to the co-optation of regulatory bodies by the industries they are tasked with overseeing. For Carpenter and Moss (2014), capture is about consistently steering industry regulation, \u201cin law or application\u201d, away from the public interest.&nbsp;&nbsp;<\/p>\n\n\n\n<p>Building on these perspectives, the language of capture is helpful for describing how decision-making processes and institutions that should serve broad publics are shaped by Corporate AI to serve private interests instead. But the relationship between AI and democratic politics extends beyond industry regulation proper. <strong>Political capture<\/strong> by Corporate AI takes place across <strong>multiple sites of politics<\/strong> that configure how AI systems are built and governed\u2014and who benefits (or profits) from them in the long-term. As we will see below, political capture begins with the technical development of AI systems\u2014marked by opaqueness, data extraction, and centralized corporate control\u2014but stretches to broader dimensions of democratic governance: shaping electoral processes, evading regulation, influencing policy and judicial processes through lobbying and campaign financing, and working to redefine our political imaginaries.<\/p>\n\n\n\n<p>To grasp why Corporate AI\u2019s grip on politics is a problem, imagine a world in which a single superintelligence, wired into every person\u2019s brain, can immediately determine everyone\u2019s political preferences, eliminating the need for elections or government. That\u2019s pretty much the future that Andri Magnason sketches in the dystopian novel <em>LoveStar<\/em>. The catch: this superintelligence is corporate-controlled, and no one can tell whether the preferences identified by its \u201cDemocracy machine\u201d are real or manufactured. The result is little human agency and total corporate control, disguised as seamless efficiency.<\/p>\n\n\n\n<p>Unfortunately, the possibility of replacing democratic institutions and collective decision-making by efficient algorithms is a seductive political vision for many in Corporate AI. In the United States, this imaginary is already being pursued by Elon Musk\u2019s Department of Government Efficiency (DOGE), which hopes to <a href=\"https:\/\/www.theatlantic.com\/technology\/archive\/2025\/02\/doge-ai-plans\/681635\/\">replace civil servants with AI systems<\/a>. But this vision also transpires in the industry\u2019s privileging of efficiency at the expense of public accountability (Neff, 2024)<sup class=\"modern-footnotes-footnote \" data-mfn=\"1\" data-mfn-post-scope=\"000000000000056c0000000000000000_241\"><a href=\"javascript:void(0)\"  role=\"button\" aria-pressed=\"false\" aria-describedby=\"mfn-content-000000000000056c0000000000000000_241-1\">1<\/a><\/sup><span id=\"mfn-content-000000000000056c0000000000000000_241-1\" role=\"tooltip\" class=\"modern-footnotes-footnote__note\" tabindex=\"0\" data-mfn=\"1\">Inefficiencies, in fact, may actually support civic innovation and help build trust with different publics (Gordon and Mugar, 2020).<\/span> or in slogans such as \u201cmove fast and break things\u201d and \u201cask for forgiveness, not permission\u201d (Lalka, 2024), which, as Gardiner sums up (<a href=\"https:\/\/www.technologyreview.com\/2024\/12\/13\/1108459\/book-review-silicon-valley-democracy-techlash-rob-lalka-venture-alchemists-marietje-schaake-tech-coup\/\">2024<\/a>), celebrate innovation but can \u201coften mask a darker, more authoritarian ethos.\u201d As Cohen (2025, p. 9) writes, \u201ctechnology oligarchs have systematically pursued a particular vision of technological progress that aims to advance by leaving messy humanity and messy humans behind.\u201d This includes messy, unpredictable democracy.<\/p>\n\n\n\n<p>What\u2019s at stake, then, are the structures and processes through which we govern our societies. And Corporate AI is increasingly invested in reshaping these to serve its own interests. To understand how, it\u2019s useful to follow McQuillan\u2019s (2022, p. 2) framing of AI as a \u201clayered and interdependent arrangement\u201d comprising not just technology, but also institutions and ideology. Corporate AI operates politically across all these layers. Big Tech firms don\u2019t just hold concentrated market power; they also control the digital infrastructures and services that governments, communities, and other actors increasingly rely upon (Rahman, 2017; Cohen, 2025). This infrastructural dominance enables them to convert technical control into political leverage and influence. For example, by lobbying for public investment in AI research and development, these companies can shape state priorities in ways that deepen public dependency on their technologies and reinforce their own market power (Whittaker, 2021). At the same time, control over key infrastructures and services makes it easier for them to sidestep public oversight and regulation (Schaake, 2024)\u2014capturing political decision-making for themselves while shifting AI risks and harms onto society at large.&nbsp;<\/p>\n\n\n\n<p>How does Corporate AI wield power politically\u2014and with what implications for democratic processes and institutions? We can think of political capture as occurring across various sites of political decision-making.<\/p>\n\n\n\n<p>It begins at the scale of technology design and development, when <strong>decisions about how AI systems are built and trained<\/strong> are made. What and whose data are used, and with whose consent? Who gets to make decisions around safety, bias, or risk? Who governs and evaluates AI systems once they are developed? Corporate AI development has been marked by extractive and opaque data practices, with little public accountability. While a growing body of work seeks to counter these practices through participatory forms of AI development, open source models, or decentralized models of ownership, the current industry landscape remains characterized by anti-democratic logics of \u201ccentralization and control\u201d (Neff, 2024).<\/p>\n\n\n\n<p>But corporate efforts to shape AI politics go well beyond system design or deployment\u2014they cut into the core of democratic institutions and values. One clear example is <strong>direct investment in politics through lobbying and campaign financing<\/strong>\u2014what political scientists call instrumental business power.<sup class=\"modern-footnotes-footnote \" data-mfn=\"2\" data-mfn-post-scope=\"000000000000056c0000000000000000_241\"><a href=\"javascript:void(0)\"  role=\"button\" aria-pressed=\"false\" aria-describedby=\"mfn-content-000000000000056c0000000000000000_241-2\">2<\/a><\/sup><span id=\"mfn-content-000000000000056c0000000000000000_241-2\" role=\"tooltip\" class=\"modern-footnotes-footnote__note\" tabindex=\"0\" data-mfn=\"2\">For a recent discussion of corporate political spending in the US and how it undermines democracy, see Torres-Spelliscy\u2019s <em>Corporatocracy<\/em> (2024).<\/span> <a href=\"https:\/\/themarkup.org\/2020-in-review\/2020\/12\/24\/big-techs-year-of-big-political-spending\"> Big Tech\u2019s political spending in the U.S. has grown steadily<\/a> across local, state, and national levels.<sup class=\"modern-footnotes-footnote \" data-mfn=\"3\" data-mfn-post-scope=\"000000000000056c0000000000000000_241\"><a href=\"javascript:void(0)\"  role=\"button\" aria-pressed=\"false\" aria-describedby=\"mfn-content-000000000000056c0000000000000000_241-3\">3<\/a><\/sup><span id=\"mfn-content-000000000000056c0000000000000000_241-3\" role=\"tooltip\" class=\"modern-footnotes-footnote__note\" tabindex=\"0\" data-mfn=\"3\">While the tech industry once leaned Democratic, several major companies backed Trump in the 2024 election, signaling a shift in political alignment.<\/span> Amazon, for instance, increased its lobbying expenditures nearly twelve-fold between 2009 and 2022\u2014from US$1.81 million to US$21.38 million, according to data from the Senate Office of Public Records (available on Statista). In fact, lobbying by tech firms hit a record high in 2024, with \u201c<a href=\"https:\/\/issueone.org\/articles\/big-tech-spent-record-sums-on-lobbying-last-year\/\">one lobbyist for every two members of Congress<\/a>\u201d. Much of this political spending has focused on weakening or blocking regulation that might constrain corporate control and profits. And it&#8217;s not just legislatures\u2014tech billionaires are also targeting state courts,<a href=\"https:\/\/www.propublica.org\/article\/wisconsin-supreme-court-race-most-expensive-us-history-elon-musk\"> pouring money into judicial elections<\/a> like Wisconsin\u2019s race for a new state Supreme Court justice. The outcome of this race\u2014where the Musk-backed candidate lost\u2014offers a glimmer of hope that voters can resist overt attempts by corporate AI to buy political influence.<\/p>\n\n\n\n<p>Under Trump\u2019s second administration, we are also witnessing the direct<strong> capture of state institutions<\/strong> in ways that advance the interests of tech elites\u2014most notably, Elon Musk. DOGE, spearheaded by Musk, has launched efforts to<a href=\"https:\/\/abcnews.go.com\/Politics\/elon-musks-government-dismantling-fight-stop\/story?id=118576033\"> dismantle key federal agencies<\/a>, including USAID and the Department of Education. DOGE\u2019s restructuring approach closely<a href=\"https:\/\/www.motherjones.com\/politics\/2025\/02\/elon-musk-doge-private-equity\/\"> follows a private equity playbook<\/a>\u2014identifying government functions as inefficient, then hollowing them out under the guise of reform. This power grab has also enabled Musk to<a href=\"https:\/\/www.rollingstone.com\/politics\/politics-features\/trump-elon-musk-doge-weaken-regulators-1235284085\/\"> weaken regulatory bodies overseeing his companies<\/a>. Most strikingly, the Federal Aviation Administration has awarded Starlink a major federal contract, raising<a href=\"https:\/\/edition.cnn.com\/2025\/02\/25\/business\/musk-faa-starlink-contract\/index.html\"> conflict-of-interest concerns<\/a> given the agency\u2019s ongoing role in regulating Musk\u2019s ventures.<sup class=\"modern-footnotes-footnote \" data-mfn=\"4\" data-mfn-post-scope=\"000000000000056c0000000000000000_241\"><a href=\"javascript:void(0)\"  role=\"button\" aria-pressed=\"false\" aria-describedby=\"mfn-content-000000000000056c0000000000000000_241-4\">4<\/a><\/sup><span id=\"mfn-content-000000000000056c0000000000000000_241-4\" role=\"tooltip\" class=\"modern-footnotes-footnote__note\" tabindex=\"0\" data-mfn=\"4\">\u00a0Potential conflicts of interest have also been raised <a href=\"https:\/\/futurism.com\/elon-musk-conflict-interest-shutting-down-usaid\">in relation to USAID<\/a><\/span> This explicit convergence of public authority and private interest marks a troubling new phase in Corporate AI\u2019s capture of American politics.<\/p>\n\n\n\n<p>This story, however, extends far beyond the United States. As multinationals, Big Tech firms\u2014and the technologies they control\u2014are shaping politics across the world. In Brazil, Elon Musk\u2019s platform X (formerly Twitter) openly <a href=\"https:\/\/diplomatique.org.br\/big-techs-desafiam-a-democracia-e-favorecem-a-extrema-direita\/\">defied Supreme Court orders<\/a> to curb disinformation networks, with Musk even encouraging users to bypass judicial restrictions. He has also suggested the UK government be overthrown and signaled <a href=\"https:\/\/www.theguardian.com\/commentisfree\/2025\/jan\/14\/big-tech-picking-apart-europe-democracy-switch-off-algorithms\">alignment with far-right actors<\/a> in Europe, including public support for Germany\u2019s Alternative f\u00fcr Deutschland (AfD) political party. In Turkey, X <a href=\"https:\/\/www.politico.eu\/article\/musks-x-suspends-opposition-accounts-turkey-protest-civil-unrest-erdogan-imamoglu-istanbul-mayor\/\">suspended opposition accounts<\/a> amid mass protests, raising further concerns about authoritarian entanglements.<\/p>\n\n\n\n<p>These issues point to a deeper concern: the role of AI-powered social media platforms in <strong>shaping democratic processes and elections<\/strong>. With business models centered around economies of attention, platform algorithms often prioritize emotionally charged content to maximize user engagement, increasing the potential for <a href=\"https:\/\/www.science.org\/doi\/10.1126\/science.aap9559\">misinformation to spread<\/a>. In Brazil, such dynamics have visibly shaped electoral outcomes since 2018,<a href=\"https:\/\/diplomatique.org.br\/big-techs-desafiam-a-democracia-e-favorecem-a-extrema-direita\/\"> <\/a>with studies showing that manipulated content dominated WhatsApp groups and <a href=\"https:\/\/diplomatique.org.br\/big-techs-desafiam-a-democracia-e-favorecem-a-extrema-direita\/\">deepened political polarization<\/a>.<a href=\"https:\/\/www1.folha.uol.com.br\/paineldoleitor\/2025\/01\/as-big-techs-sao-uma-ameaca-para-a-democracia-brasileira-leitor.shtml\"> Meta\u2019s recent rollback of content moderation policies<\/a> has only intensified concerns over its impact on democratic processes. Beyond disinformation, unaccountable data practices and algorithmic systems are being weaponized to support the <strong>surveillance of populations and forms of authoritarian control<\/strong>. As Anne Applebaum (2024) shows in <em>Autocracy, Inc.<\/em>, autocratic regimes are not threatened by digital technologies\u2014they are empowered by them.<\/p>\n\n\n\n<p>Meanwhile, corporate leaders are increasingly open about their expectations regarding government responses. Meta\u2019s Zuckerberg, for example, has stated that he expects the U.S. government to <a href=\"https:\/\/www.theguardian.com\/commentisfree\/2025\/jan\/14\/big-tech-picking-apart-europe-democracy-switch-off-algorithms\">shield American tech giants from EU regulation<\/a>\u2014suggesting that the defense of corporate power should take precedence over democratic governance on the global stage.&nbsp;&nbsp;&nbsp;<\/p>\n\n\n\n<p>These interventions are not just about control over institutions or policy\u2014as noted earlier, they are also about capturing our political imagination. Corporate AI seeks to <strong>influence the production of knowledge and public discourse on AI<\/strong>. As Whittaker (2021) shows, industry funding has captured academic research, building expert communities that legitimize corporate interests. At the same time, tech leaders promote belief systems\u2014like long-termism\u2014that shift focus from present harms to speculative futures. As Benjamin (2024) and Gebru and Torres (2024) indicate, these ideologies sidestep issues like racism, sexism, and imperialism in favour of grand narratives about saving humanity. Underlying the struggle for democratic politics, then, is a <strong>struggle over our sense of political possibility<\/strong>. As Ruha Benjamin reminds us, domination doesn\u2019t always announce itself; sometimes, it works by narrowing what we believe is possible.<\/p>\n\n\n\n<p>As the discussion above makes clear, a growing body of interdisciplinary scholarship and public commentary is raising concerns about the anti-democratic implications of corporate AI. If you want to dig deeper, check out the Further Reading section, which includes references to all the sources that were drawn upon.&nbsp;<\/p>\n\n\n\n<p>While these critiques offer important insights into the layered relationships between Corporate AI and democracy, much of the English-language literature on this problem remains anchored in U.S. and Western European contexts, often framed through liberal-democratic ideals within a capitalist order. This framing risks limiting our capacity to confront the deeper challenges posed by Corporate AI\u2019s increasing concentration of power. In some analyses, for example, there is a disconnect: scholars go to great lengths to document how Big Tech routinely evades regulation and public accountability\u2014only to conclude that the solution lies in stronger regulation and oversight within liberal democratic frameworks. But if the very structures meant to hold power in check have already been captured or hollowed out, does this response truly hold up?<\/p>\n\n\n\n<p>If Corporate AI&#8217;s project of political capture is global\u2014and, increasingly, framed as civilizational\u2014then our analytical lenses and responses must be equally expansive, including a wider range of geographies, experiences, and perspectives on democratic politics. This means engaging with alternative imaginaries of democracy and resistance, especially those rooted in solidaristic, decolonial, anti-capitalist, and collective strategies. Inspired by Ruha Benjamin\u2019s manifesto on imagination, we must ask: what other democratic futures become visible when we look beyond the dominant frameworks? And how might these reorient our understanding of what meaningful, democratic politics and alternative economic systems could look like?<\/p>\n\n\n\n<p><strong>Further Reading <\/strong><\/p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Applebaum, A. (2024). <em>Autocracy, Inc: The dictators who want to run the World<\/em>. Random House.<\/li>\n\n\n\n<li>Benjamin, R. (2024). <em>Imagination: A Manifesto<\/em>. W. W. Norton &amp; Company.<\/li>\n\n\n\n<li>Carpenter, D., &amp; Moss, D. A. (2013). <em>Preventing Regulatory Capture: Special Interest Influence and How to Limit it<\/em>. Cambridge University Press.<\/li>\n\n\n\n<li>Cohen, J. E. (2025). <em>Oligarchy, State, and Cryptopia<\/em> (SSRN Scholarly Paper No. 5171050). Social Science Research Network.<a href=\"https:\/\/doi.org\/10.2139\/ssrn.5171050\"> https:\/\/doi.org\/10.2139\/ssrn.5171050<\/a><\/li>\n\n\n\n<li>Culpepper, P. D. (2010). <em>Quiet Politics and Business Power: Corporate Control in Europe and Japan<\/em>. Cambridge University Press.<\/li>\n\n\n\n<li>Gardiner, B. (2024). How Silicon Valley is disrupting democracy. <em>MIT Technology Review<\/em>. <a href=\"https:\/\/www.technologyreview.com\/2024\/12\/13\/1108459\/book-review-silicon-valley-democracy-techlash-rob-lalka-venture-alchemists-marietje-schaake-tech-coup\/\">https:\/\/www.technologyreview.com\/2024\/12\/13\/1108459\/book-review-silicon-valley-democracy-techlash-rob-lalka-venture-alchemists-marietje-schaake-tech-coup\/<\/a>\u00a0<\/li>\n\n\n\n<li>Gebru, T., &amp; Torres, \u00c9. P. (2024). The TESCREAL bundle: Eugenics and the promise of utopia through artificial general intelligence. <em>First Monday<\/em>.<a href=\"https:\/\/doi.org\/10.5210\/fm.v29i4.13636\"> https:\/\/doi.org\/10.5210\/fm.v29i4.13636<\/a><\/li>\n\n\n\n<li>Gordon, E., &amp; Mugar, G. (2020). <em>Meaningful inefficiencies: Civic design in an age of digital expediency<\/em>. Oxford University Press.<\/li>\n\n\n\n<li>McQuillan, D. (2022). <em>Resisting AI: An anti-fascist approach to artificial intelligence<\/em>. Policy Press.<\/li>\n\n\n\n<li>Neff, G. (2024). Can Democracy Survive AI? <em>Sociologica<\/em>, <em>18<\/em>(3), 137\u2013146.<a href=\"https:\/\/doi.org\/10.6092\/issn.1971-8853\/21108\"> https:\/\/doi.org\/10.6092\/issn.1971-8853\/21108<\/a><\/li>\n\n\n\n<li>Rahman, K. S. (2017). The New Utilities: Private Power, Social Infrastructure, and the Revival of the Public Utility Concept. <em>Cardozo Law Review<\/em>, <em>39<\/em>, 1621.<\/li>\n\n\n\n<li>Schaake, M. (2024). <em>The Tech Coup: How to Save Democracy from Silicon Valley<\/em>. Princeton University Press.<\/li>\n\n\n\n<li>Torres-Spelliscy, C. (2024). <em>Corporatocracy: How to Protect Democracy from Dark Money and Corrupt Politicians<\/em>. NYU Press.<\/li>\n\n\n\n<li>Whittaker, M. (2021). <em>The Steep Cost of Capture<\/em> (SSRN Scholarly Paper No. 4135581). Social Science Research Network.<a href=\"https:\/\/papers.ssrn.com\/abstract=4135581\"> https:\/\/papers.ssrn.com\/abstract=4135581<\/a><\/li>\n<\/ul>\n","protected":false},"excerpt":{"rendered":"<p>To reclaim our socio-digital futures, we must challenge corporate AI\u2019s capture of democratic politics and counter it by centering collective, solidary, and participatory forms of politics.<\/p>\n","protected":false},"author":6,"featured_media":184,"comment_status":"closed","ping_status":"closed","sticky":false,"template":"","format":"standard","meta":{"inline_featured_image":false,"footnotes":""},"categories":[6],"tags":[],"coauthors":[18],"class_list":["post-241","post","type-post","status-publish","format-standard","has-post-thumbnail","hentry","category-corporate-ai-landscape"],"aioseo_notices":[],"_links":{"self":[{"href":"https:\/\/liberatoryai.datainfrastructures.org\/wp-json\/wp\/v2\/posts\/241","targetHints":{"allow":["GET"]}}],"collection":[{"href":"https:\/\/liberatoryai.datainfrastructures.org\/wp-json\/wp\/v2\/posts"}],"about":[{"href":"https:\/\/liberatoryai.datainfrastructures.org\/wp-json\/wp\/v2\/types\/post"}],"author":[{"embeddable":true,"href":"https:\/\/liberatoryai.datainfrastructures.org\/wp-json\/wp\/v2\/users\/6"}],"replies":[{"embeddable":true,"href":"https:\/\/liberatoryai.datainfrastructures.org\/wp-json\/wp\/v2\/comments?post=241"}],"version-history":[{"count":4,"href":"https:\/\/liberatoryai.datainfrastructures.org\/wp-json\/wp\/v2\/posts\/241\/revisions"}],"predecessor-version":[{"id":247,"href":"https:\/\/liberatoryai.datainfrastructures.org\/wp-json\/wp\/v2\/posts\/241\/revisions\/247"}],"wp:featuredmedia":[{"embeddable":true,"href":"https:\/\/liberatoryai.datainfrastructures.org\/wp-json\/wp\/v2\/media\/184"}],"wp:attachment":[{"href":"https:\/\/liberatoryai.datainfrastructures.org\/wp-json\/wp\/v2\/media?parent=241"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https:\/\/liberatoryai.datainfrastructures.org\/wp-json\/wp\/v2\/categories?post=241"},{"taxonomy":"post_tag","embeddable":true,"href":"https:\/\/liberatoryai.datainfrastructures.org\/wp-json\/wp\/v2\/tags?post=241"},{"taxonomy":"author","embeddable":true,"href":"https:\/\/liberatoryai.datainfrastructures.org\/wp-json\/wp\/v2\/coauthors?post=241"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}