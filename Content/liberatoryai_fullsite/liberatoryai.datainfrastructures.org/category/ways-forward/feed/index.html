<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>ways forward - Liberatory A.I.</title>
	<atom:link href="https://liberatoryai.datainfrastructures.org/category/ways-forward/feed/" rel="self" type="application/rss+xml" />
	<link>https://liberatoryai.datainfrastructures.org</link>
	<description>[rotating AI terms here]</description>
	<lastBuildDate>Thu, 01 May 2025 14:57:26 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.9.1</generator>
	<item>
		<title>African feminist approaches to liberatory AI</title>
		<link>https://liberatoryai.datainfrastructures.org/african-feminist-approaches-to-liberatory-ai/</link>
		
		<dc:creator><![CDATA[Ololade Faniyi]]></dc:creator>
		<pubDate>Thu, 01 May 2025 14:57:25 +0000</pubDate>
				<category><![CDATA[ways forward]]></category>
		<guid isPermaLink="false">https://liberatoryai.datainfrastructures.org/?p=289</guid>

					<description><![CDATA[<p>An African feminist liberatory approach recognizes technology as inherently political rather than neutral. Rather than accepting these embedded politics as inevitable, a liberatory approach would make them explicit and subject to democratic deliberation. Finally, and perhaps most importantly, an African feminist liberatory approach offers a fundamentally different vision of technological progress—one measured not by profit [&#8230;]</p>
<p>The post <a href="https://liberatoryai.datainfrastructures.org/african-feminist-approaches-to-liberatory-ai/">African feminist approaches to liberatory AI</a> first appeared on <a href="https://liberatoryai.datainfrastructures.org">Liberatory A.I.</a>.</p>]]></description>
										<content:encoded><![CDATA[<p>An African feminist liberatory approach recognizes technology as inherently political rather than neutral. Rather than accepting these embedded politics as inevitable, a liberatory approach would make them explicit and subject to democratic deliberation.</p>



<p>Finally, and perhaps most importantly, an African feminist liberatory approach offers a fundamentally different vision of technological progress—one measured not by profit or computational capacity but by how technology contributes to the collective. In contrast to the Techno-Optimist Manifesto&#8217;s individualistic vision, African feminist epistemologies offer frameworks for understanding technology as inherently relational.</p>



<p>Liberatory AI infrastructure is not merely theoretical—it is already emerging through the concrete actions of African feminists and technologists who are transforming how AI is governed, developed, and deployed.</p>



<p><a href="https://www.linkedin.com/posts/kauna-malgwi-104b5b86_at-long-last-eu-countries-adopt-the-platform-activity-7173281970402136064-vnfy/">Kauna Malgwi&#8217;s testimony</a> about content moderation conditions has had far-reaching impacts beyond Africa&#8217;s borders. Her advocacy helped lead to the European Union passing a directive protecting platform workers, demonstrating how the labor organizing of African women can reshape global technology governance. This cross-border influence reveals how African feminist resistance to exploitative tech practices creates ripple effects that benefit workers worldwide, fundamentally changing the narrative about whose imaginary can be embedded in policy and architecture of technology.</p>



<p>African women technologists are also directly shaping policy at national and regional levels. The expertise and advocacy of women like Dr Chinasa Okolo and more have contributed significantly to both Nigeria&#8217;s national AI strategy and the African Union&#8217;s continental approach. Rather than passively adapting to regulatory frameworks imported from the West or East, these women are ensuring that African priorities and values are centered on policy development.</p>



<p>Grassroots education initiatives are equally crucial in building liberatory infrastructure. My moderation of the <a href="https://youtu.be/0ce5JqrdngU?si=-1bqKn-TsM6emBW3">Liberation Alliance teach-in on digital colonialism and Afro-feminist futures</a> exemplifies how feminist collectives are contributing to citizen education and consciousness-raising. These spaces create critical literacy around technological systems, enabling communities to engage with technology from a position of knowledge rather than dependence.</p>



<p>Legal action and public accountability represent another scale of this emerging infrastructure. Former content moderators are seeking justice through lawsuits and public shaming of exploitative tech companies. These actions challenge the impunity with which multinational corporations have operated in African contexts, forcing recognition of their responsibilities toward African workers and users.</p>



<p>When viewed collectively, these initiatives constitute a distinct form of techno-resistance that recenters African women in who gets to talk about, critique, and rebuild technology. This resistance operates across multiple scales—from individual content moderators organizing for better working conditions to policy advocates shaping continental strategies.</p>



<p>We also see possibilities contained in community-led AI projects that demonstrate alternative approaches to technological development. <a href="https://www.technologyreview.com/2019/06/21/134820/ai-africa-machine-learning-ibm-google/">Charity Wayua&#8217;s AI tool </a>for identifying cassava diseases shows how AI can address challenges specific to African agricultural contexts, especially how artificial intelligence can be developed specifically to address local needs and improve livelihoods when designed with and for communities.&nbsp;</p>



<p>Projects like<a href="https://speech.igboapi.com/"> Ijemma Onwuzulike&#8217;s IgboSpeech</a>, the first Igbo voice-to-text AI model, exemplify liberatory AI in action. By building technological infrastructure for the Igbo language—creating not just a speech recognition system but a foundational API with over 5,000 words, nearly 30,000 Igbo sentences, and thousands of audio recordings—Onwuzulike demonstrates how AI can preserve and amplify indigenous languages, creating the technological foundation that would enable platforms like Duolingo to incorporate Igbo language learning. The Zambian feminist collective, Sistah Sistah, also launched their <a href="https://sistahsistah.org/wp-content/uploads/2024/11/Feminist-Ethics-AI-Toolkit_20241123_152905_0000.pdf">Feminist Ethics AI toolkit</a> in 2024, offering developers a review list to gauge their products&#8217; communal suitability.&nbsp; While still operating on the margins of mainstream technological development, these projects demonstrate tangible and possible futures of liberation.</p>



<p>What unites these diverse initiatives is their recognition of Africans—and particularly African women—not merely as consumers or low-skilled laborers in global technology supply chains, but as essential knowledge producers and innovators. By centering the experiences, needs, and expertise of those historically marginalized in technological development, these initiatives are reimagining the material conditions of technology &#8211; reimagining not just who benefits from AI but who creates it and for what purpose. By pushing against the false binary between the uncritical adoption of exploitative technologies and the rejection of technological development altogether, they create a third path: critical engagement that transforms technology to serve liberation.</p>



<p>The future of liberatory AI does not lie with amoral Silicon Valley entrepreneurs or Chinese state-affiliated corporations, but with the grassroots innovators, policy advocates, labor organizers, and community educators who are already building alternative technological infrastructures. Their work shows us that different technological futures are not only possible but already emerging.</p><p>The post <a href="https://liberatoryai.datainfrastructures.org/african-feminist-approaches-to-liberatory-ai/">African feminist approaches to liberatory AI</a> first appeared on <a href="https://liberatoryai.datainfrastructures.org">Liberatory A.I.</a>.</p>]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Liberatory AI is place-based.</title>
		<link>https://liberatoryai.datainfrastructures.org/liberatory-ai-is-place-based/</link>
		
		<dc:creator><![CDATA[Amelia Lee Doğan]]></dc:creator>
		<pubDate>Thu, 01 May 2025 14:49:49 +0000</pubDate>
				<category><![CDATA[ways forward]]></category>
		<guid isPermaLink="false">https://liberatoryai.datainfrastructures.org/?p=284</guid>

					<description><![CDATA[<p>A liberatory AI ecosystem is grounded in space and place, this includes the infrastructure that is used to create and maintain it (ie: data centers) and the spaces and places it attempts to present. These places and the knowledges they produce are considered integral to the creations of this AI. Liberatory AI centers a place-based, [&#8230;]</p>
<p>The post <a href="https://liberatoryai.datainfrastructures.org/liberatory-ai-is-place-based/">Liberatory AI is place-based.</a> first appeared on <a href="https://liberatoryai.datainfrastructures.org">Liberatory A.I.</a>.</p>]]></description>
										<content:encoded><![CDATA[<p>A liberatory AI ecosystem is grounded in space and place, this includes the infrastructure that is used to create and maintain it (ie: data centers) and the spaces and places it attempts to present. These places and the knowledges they produce are considered integral to the creations of this AI. Liberatory AI centers a place-based, ecosystemic approach to computing. This means attending to the flourishing of human and other kin present in the places and lands the AI touches. Rida Qadri, attempts to do this by placing communities as experts in the representation. With participants from South Asia, Qadri and co-authors identified that many text to image generators failed to recognize cultural subjects and perpetuated Western imagery over South Asian contexts. The images also reinforced harmful cultural stereotypes when creating images of cities like Peshawar and Mumbai. Instead of the iconic cultural heritage of the cities, dusty and dirty images were generated. A liberatory AI would emphasize the place-based knowledge coming from Qadri’s participants who took pride in the places they were from.&nbsp;</p>



<p>By attending to the specificity of space and place, we are able to better care for different corners of the world. Paying attention to geographies allow us to imagine more possibilities and worlds rather than focus on making many tools doing the same, universal end goal. Recent work has highlighted how land-based and place-based education can put us more in conversation with Indigenous cosmologies and relationships We might learn from Āhau a Maori-led data platform that allows whānau (families) and tribal communities to share and record information in <a href="https://ahau.io/faqs.html">whānau-managed databases</a> that can communicate with a Pātaka server. The database management prioritizes privacy by storing data locally on the users’ device and for passing on history to descendents. Users can also configure cultural protocols to determine who in the community can access certain data. While these projects highlight the importance of sovereignty for tribal communities, they also demonstrate how developing technology from a place and space centered development attitude can create more relevant and values-aligned technologies for communities.&nbsp;</p>



<p>In a liberatory AI ecosystem, the places the AI was developed, the data is stored, and the infrastructure is present could be documented. This might in addition to already existing methods for accounting for models like model cards. This might also mean articulating how the developers of the AI tool are accountable to their local community. Being involved with people in their vicinity is necessary for developers to make sense of hyperlocal data and knowledge as researchers examining AI usage in citizen science contexts have pointed out. We must imagine a liberatory AI that allows us to account for the infrastructure of AI and the places it is used.</p>



<p><strong>Further Reading:</strong></p>



<ul class="wp-block-list">
<li><a href="https://www.tandfonline.com/doi/full/10.1080/13504622.2013.877708#d1e239">https://www.tandfonline.com/doi/full/10.1080/13504622.2013.877708#d1e239</a></li>



<li><a href="https://www.tandfonline.com/doi/full/10.1080/00131911.2023.2177260">https://www.tandfonline.com/doi/full/10.1080/00131911.2023.2177260</a></li>



<li>https://dl.acm.org/doi/abs/10.1145/3593013.3594016</li>
</ul><p>The post <a href="https://liberatoryai.datainfrastructures.org/liberatory-ai-is-place-based/">Liberatory AI is place-based.</a> first appeared on <a href="https://liberatoryai.datainfrastructures.org">Liberatory A.I.</a>.</p>]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>AI must be built under humane conditions</title>
		<link>https://liberatoryai.datainfrastructures.org/ai-must-be-built-under-humane-conditions/</link>
		
		<dc:creator><![CDATA[Ololade Faniyi]]></dc:creator>
		<pubDate>Wed, 30 Apr 2025 20:51:05 +0000</pubDate>
				<category><![CDATA[ways forward]]></category>
		<guid isPermaLink="false">https://liberatoryai.datainfrastructures.org/?p=253</guid>

					<description><![CDATA[<p>A liberatory AI ecosystem would transform bad labor conditions by ensuring that those most affected by technological systems have a say in how they are designed and governed. AI is an African feminist issue. The convergence of automated systems, algorithmic governance, and digital infrastructure in African contexts has direct implications for African women&#8217;s lives, bodies, [&#8230;]</p>
<p>The post <a href="https://liberatoryai.datainfrastructures.org/ai-must-be-built-under-humane-conditions/">AI must be built under humane conditions</a> first appeared on <a href="https://liberatoryai.datainfrastructures.org">Liberatory A.I.</a>.</p>]]></description>
										<content:encoded><![CDATA[<p>A liberatory AI ecosystem would transform bad labor conditions by ensuring that those most affected by technological systems have a say in how they are designed and governed.</p>



<span id="more-253"></span>



<p>AI is an African feminist issue. The convergence of automated systems, algorithmic governance, and digital infrastructure in African contexts has direct implications for African women&#8217;s lives, bodies, and futures. As technological systems increasingly mediate social, political, and economic relations, they become inseparable from the broader struggles for liberation that have always been central to African feminist organizing.</p>



<p>An African feminist approach recognizes the embodied nature of technological systems. While corporate AI presents itself as disembodied and universal, African feminist thought insists on recognizing the physical bodies and lands that make technology possible. As the feminist historian Stephanie Camp reminds us, African women&#8217;s bodies were the scripts upon which the scripts of labor and enslavement was read and perpetuated, creating a coloniality/modernity where African women continue to pay the price for the indexing of humanity. A liberatory AI would acknowledge these embodied realities rather than obscuring them.</p>



<p>This embodied understanding leads to practical differences in how technology is developed and deployed. Content moderators would be recognized as tech workers rather than disposable labor. Data sovereignty would be understood as a crucial aspect of both personal and collective autonomy. The environmental impacts of technological infrastructure would be centered rather than externalized.</p>



<p>An African feminist approach to AI would transform tech governance by insisting on pluralistic, democratic control over technological systems. A liberatory AI ecosystem would transform this dynamic by ensuring that those most affected by technological systems have a say in how they are designed and governed. This would mean moving beyond corporate philanthropy or &#8220;ethical/responsible AI&#8221; initiatives that maintain existing power structures while making superficial adjustments.</p>



<p>Liberatory AI ecosystem must be grounded in the freedom dreams of those who have historically borne the costs of technological &#8220;progress.&#8221; Drawing from African feminist epistemologies offers us alternative frameworks for understanding and developing technologies that center relationality, care, freedom and plural frameworks of the human, rather than extraction, domination, and control.</p>



<p>African feminist scholar Filomina Chioma Steady provides a foundation for this reimagining when she positions her conception of feminism as emerging from what she terms &#8220;polarizations and conflicts—representing some of the worst and most chronic forms of human suffering&#8221;—and prompts us toward a broad struggle for social and humanistic transformation. This understanding allows us to envision a liberatory AI that critiques the racial, sexual, class, and cultural dimensions of technological oppression to produce equitable technologies through which humans are viewed as whole beings rather than data points to be extracted or bodies to be exploited.</p>



<p>What would this look like in practice? A liberatory AI ecosystem would acknowledge the full humanity of all people involved in its creation, deployment, and use. This means recognizing content moderators not as disposable labor but as essential tech workers deserving of fair compensation, psychological support, and dignity.&nbsp;</p>



<p>It recognizes that technological systems are never neutral but always encode particular ways of seeing and organizing the world. Rather than positioning the white, male, wealthy technologist as the universal subject of technological development, a liberatory AI would center multiple ways of being human. This means moving beyond what Alexander Weheliye describes as the &#8220;racializing assemblages&#8221; that discipline humanity into full humans, not-quite-humans, and nonhumans. Instead of reproducing these hierarchies, liberatory AI would be built on a &#8220;technological plural humanism&#8221;—recognition that different cultural contexts offer distinct and valuable approaches to technology development.</p>



<p>In the African context, this involves drawing on indigenous concepts of relationality and collective ownership. Many African societies have longstanding traditions that understand the individual as fundamentally embedded in community and the natural world. These epistemologies offer alternatives to the hyperindividualistic, extractive logics without soul that currently dominate AI development.</p>



<p>The digital articulations of African feminist freedom dreams are already pointing the way toward such alternatives. The Ugandan feminist tech collective, <a href="https://pollicy.org/">Pollicy</a>, for instance, builds its policy advocacies around the logic of digital kinship, where people must have access to their own data and technologies must be developed with and for communities rather than imposed upon them.</p>



<h3 class="wp-block-heading"><strong>Further Reading</strong></h3>



<p><strong>Further Reading (Academic)</strong></p>



<ul class="wp-block-list">
<li>Birhane, A. (2020). The Algorithmic Colonization of Africa. Script-ed, 17(2), 389-409.</li>



<li>Camp, S. M. H. (2005). Closer to Freedom: Enslaved Women and Everyday Resistance in the Plantation South. United States: University of North Carolina Press.</li>



<li>Jili, B. (2022). Chinese ICT and Smart City Initiatives in Kenya. Asia Policy 17(3), 40-50. <a href="https://dx.doi.org/10.1353/asp.2022.0051">https://dx.doi.org/10.1353/asp.2022.0051</a>.&nbsp;</li>



<li>Klein, L. &amp; D&#8217;Ignazio, C. (2024). Data Feminism for AI. ArXiv. <a href="https://doi.org/10.1145/3630106.3658543">https://doi.org/10.1145/3630106.3658543</a>&nbsp;</li>



<li>Mbembe, A. (2019). Necropolitics. Duke University Press.</li>



<li>Ogundipe, M. (1994). Re-creating Ourselves: African Women &amp; Critical Transformations. Africa World Press.</li>



<li>Steady, F. C. (1986). African Feminism: A Worldwide Perspective. In R. Terborg-Penn, S. Harley, &amp; A. Benton Rushing (Eds.), Women in Africa and the African Diaspora (pp. 3-24). Howard University Press.</li>



<li>Weheliye, A. G. (2014). Habeas Viscus: Racializing Assemblages, Biopolitics, and Black Feminist Theories of the Human. Duke University Press.</li>



<li>Wynter, S. (2003). Unsettling the Coloniality of Being/Power/Truth/Freedom: Towards the Human, After Man, Its Overrepresentation—An Argument. CR: The New Centennial Review, 3(3), 257-337.</li>



<li>Barrett, T., Okolo, C. T., Biira, B., Sherif, E., Zhang, A. X., &amp; Battle, L. (2025). African Data Ethics: A Discursive Framework for Black Decolonial Data Science. ArXiv. <a href="https://arxiv.org/abs/2502.16043">https://arxiv.org/abs/2502.16043</a>&nbsp;</li>
</ul>



<p><strong>Further Reading (Popular Press)</strong></p>



<ul class="wp-block-list">
<li>Benjamin, R. (2024). Imagination: A Manifesto (A Norton Short). United States: W. W. Norton.</li>



<li>Faniyi, O. (2024, February 27). An African Feminist Manifesto. The Republic. <a href="https://republic.com.ng/february-march-2024/an-african-feminist-manifesto/">https://republic.com.ng/february-march-2024/an-african-feminist-manifesto/</a>&nbsp;</li>



<li>Hao, K. (2019). The future of AI research is in Africa. MIT Technology Review. <a href="https://www.technologyreview.com/2019/06/21/134820/ai-africa-machine-learning-ibm-google/">https://www.technologyreview.com/2019/06/21/134820/ai-africa-machine-learning-ibm-google/</a>&nbsp;</li>



<li>Holland, A. (2024). Feminist Ethics AI Toolkit. Sistah Sistah</li>



<li>Jili, B. (2020, December 11). Surveillance tech in Africa stirs security concerns – Africa Center. Africa Center. <a href="https://africacenter.org/spotlight/surveillance-technology-in-africa-security-concerns/">https://africacenter.org/spotlight/surveillance-technology-in-africa-security-concerns/</a>&nbsp;</li>



<li>Perrigo, B. (2022, February 17). Inside Facebook’s African sweatshop. TIME. <a href="https://time.com/6147458/facebook-africa-content-moderation-employee-treatment/">https://time.com/6147458/facebook-africa-content-moderation-employee-treatment/</a>&nbsp;</li>
</ul><p>The post <a href="https://liberatoryai.datainfrastructures.org/ai-must-be-built-under-humane-conditions/">AI must be built under humane conditions</a> first appeared on <a href="https://liberatoryai.datainfrastructures.org">Liberatory A.I.</a>.</p>]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Communities decide if AI is working for them. </title>
		<link>https://liberatoryai.datainfrastructures.org/communities-decide-if-ai-is-working-for-them/</link>
		
		<dc:creator><![CDATA[Yujia Gao]]></dc:creator>
		<pubDate>Wed, 30 Apr 2025 20:43:34 +0000</pubDate>
				<category><![CDATA[ways forward]]></category>
		<guid isPermaLink="false">https://liberatoryai.datainfrastructures.org/?p=250</guid>

					<description><![CDATA[<p>Liberatory AI evaluation facilitates the creation of more just, effective, and community-centered technology by shifting the power of assessment into the hands of those most impacted by these systems. In a liberatory AI framework, evaluation is not an afterthought, a marketing tool, or a pretense of accountability &#8211; it is the fundamental process through which [&#8230;]</p>
<p>The post <a href="https://liberatoryai.datainfrastructures.org/communities-decide-if-ai-is-working-for-them/">Communities decide if AI is working for them. </a> first appeared on <a href="https://liberatoryai.datainfrastructures.org">Liberatory A.I.</a>.</p>]]></description>
										<content:encoded><![CDATA[<p>Liberatory AI evaluation facilitates the creation of more just, effective, and community-centered technology by shifting the power of assessment into the hands of those most impacted by these systems.</p>



<span id="more-250"></span>



<p>In a liberatory AI framework, evaluation is not an afterthought, a marketing tool, or a pretense of accountability &#8211; it is the fundamental process through which communities collaboratively define what &#8220;good AI&#8221; looks like, who it serves, and how it aligns with their collective values. Instead of being shaped by opaque corporate interests, evaluation is driven by transparent, participatory methods that ensure AI systems remain responsive to the communities they impact.&nbsp;</p>



<p>For example, a community might evaluate an AI system based on how well it preserves cultural knowledge, promotes social cohesion, or addresses environmental concerns, all of which are often intentionally or unintentionally neglected in traditional technical evaluations. This approach acknowledges that communities have crucial lived experience and domain expertise about their own contexts that others lack, making them uniquely positioned to determine whether an AI system is truly serving their interests.</p>



<p>Liberatory AI evaluation is an ongoing process. It does not treat AI evaluation as a one-time step before deploying models. Instead, it is an iterative and participatory process where communities continuously give and integrate feedback into AI systems to ensure they reflect real-world conditions and community needs. Communities continuously provide feedback, refine success criteria, and hold AI developers accountable</p>



<p>Liberatory AI evaluation facilitates the creation of more just, effective, and community-centered technology by shifting the power of assessment into the hands of those most impacted by these systems. Instead of relying on corporate benchmarks that prioritize efficiency and profitability, this approach ensures that AI is held accountable to real human needs. When communities define what success looks like, AI systems are evaluated not by abstract performance metrics but by its tangible lives in the communities. This prevents the common scenario where technologies receive high numbers in controlled testing settings (e.g. benchmarks) yet fail miserably in real-world contexts, exacerbating harm rather than solving meaningful problems.</p>



<p>Unlike traditional AI evaluation, which applies one-size-fits-all benchmarks, liberatory AI evaluation recognizes that different communities have different values, histories, and aspirations. Success in AI should not be dictated by a single metric, but by criteria shaped by each community that interacts with the AI system. For example, a predictive policing model might achieve crime reduction according to a subjective benchmark dataset, but it fails to meet community needs when people experience it as invasive, discriminatory, and reinforcing existing power imbalance. </p>



<p>A liberatory approach also plays a crucial role in uncovering vulnerabilities and reducing harm. As discussed previously, many AI failures stem from evaluation practices that ignore the communities that the system fails on. For example, commercial facial recognition systems continue to be deployed despite well-documented failures in recognizing darker-skinned individuals. In a liberatory approach, AI is not deemed &#8220;successful&#8221; unless it works well for the people that it serves &#8211; not just those who resemble the datasets which it was trained on.&nbsp;</p>



<p>Beyond AI outcomes, community-driven evaluation also facilitates capacity building. The process of collaboratively defining evaluation metrics gives communities opportunities to gain technological literacy and agency, empowering them to engage, critique, and ultimately modify and own these systems. Rather than being passive recipients of technology imposed upon them, community members become active participants in shaping AI&#8217;s role in their lives.&nbsp;&nbsp;</p>



<p>To make liberatory AI evaluation a reality, we need an infrastructure that empowers communities to define, oversee, and enforce evaluation criteria &#8211; ensuring that AI systems are accountable to the people they impact, not just corporate interests. This requires both spaces for collective decision-making, accessible tools for auditing AI systems, and transparent documentation and accountability mechanisms.</p>



<p>Liberatory AI evaluation begins with community participation in shaping how AI systems are evaluated. This includes building collaborative spaces (e.g. workshops, focus groups, co-design sessions) that allows diverse community members to share their values, concerns, and priorities. This will be followed with collaborative processes to translate them into concrete measures. One real-world example of  this is Smith et al.&#8217;s study on fairness in recommendation systems, where researchers co-designed fairness metrics with content creators and dating app users. Participants shared how existing AI systems failed them, leading to the development of new, community-driven evaluation criteria that better reflected their lived experiences. This research demonstrates that AI evaluation is more effective and just when the people affected by these systems actively shape the metrics that define success.</p>



<p>To support the tracking, auditing, and evaluation processes, accessible tools that do not require specialized expertise should be in place. An important example of this is Wikibench, a community-driven AI evaluation framework for Wikipedia contributors to collaboratively curate, refine, and validate evaluation datasets. Their tools enable collective governance over evaluation criteria. Similar models could be employed to other domains &#8211; Imagine a world where workers co-create fairness metrics for hiring AI, moderators evaluate content moderation algorithms, etc.&nbsp;</p>



<p>Beyond community-driven evaluation and auditing tools, we also need transparent documentation systems that record AI models, datasets, evaluation suites, and the deliberative processes that they were developed through. Making these information public provides a basis for public and community audits that ensure the systems have met community metrics.  In situations of failures, there should exist mechanisms where communities can challenge these systems.</p>



<h3 class="wp-block-heading"><strong>Further Reading</strong></h3>



<ul class="wp-block-list">
<li>Smith, J.J., Satwani, A., Burke, R., &amp; Fiesler, C. (2024). Recommend Me? Designing Fairness Metrics with Providers. Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency.</li>
</ul><p>The post <a href="https://liberatoryai.datainfrastructures.org/communities-decide-if-ai-is-working-for-them/">Communities decide if AI is working for them. </a> first appeared on <a href="https://liberatoryai.datainfrastructures.org">Liberatory A.I.</a>.</p>]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>AI can work in harmony with the environment</title>
		<link>https://liberatoryai.datainfrastructures.org/ai-can-work-in-harmony-with-the-environment/</link>
		
		<dc:creator><![CDATA[Amelia Lee Doğan]]></dc:creator>
		<pubDate>Wed, 30 Apr 2025 20:21:48 +0000</pubDate>
				<category><![CDATA[ways forward]]></category>
		<guid isPermaLink="false">https://liberatoryai.datainfrastructures.org/?p=238</guid>

					<description><![CDATA[<p>AI development can work in alignment with environmental sustainability and ecological preservation. Liberatory AI is not just about avoiding harm; it is about actively creating systems that regenerate the planet and foster thriving communities. It is a vision of AI that is rooted in care, respect, and reciprocity—a vision that sees technology not as a [&#8230;]</p>
<p>The post <a href="https://liberatoryai.datainfrastructures.org/ai-can-work-in-harmony-with-the-environment/">AI can work in harmony with the environment</a> first appeared on <a href="https://liberatoryai.datainfrastructures.org">Liberatory A.I.</a>.</p>]]></description>
										<content:encoded><![CDATA[<p>AI development can work in alignment with environmental sustainability and ecological preservation.</p>



<span id="more-238"></span>



<p>Liberatory AI is not just about avoiding harm; it is about actively creating systems that regenerate the planet and foster thriving communities. It is a vision of AI that is rooted in care, respect, and reciprocity—a vision that sees technology not as a tool for domination but as a means of deepening our connection to the Earth and each other. By embracing this philosophy, we can create AI systems that are not only sustainable but also life-affirming, ensuring a future where both humans and the planet can flourish.</p>



<p>At its core, liberatory AI rejects the extractive logics that dominate corporate AI systems, which treat the Earth as a resource to be exploited and communities as collateral damage. Instead, it seeks to create AI systems that honor the interconnectedness of all life, and prioritize the flourishing of both human and non-human beings.</p>



<p>Liberatory AI begins with the understanding that the Earth is not an externality or a resource to be mined and discarded. It is <strong>a living, breathing ecosystem to which we are deeply connected</strong>. This means designing AI systems that work in harmony with the planet, rather than against it. For example, liberatory AI would prioritize renewable energy sources like solar, wind, and geothermal to power data centers, even if this presents technical challenges. The fluctuating nature of renewable energy might require innovative solutions, such as energy storage systems or decentralized computing, but these challenges are seen as opportunities to align AI development with the rhythms of the Earth, rather than forcing the planet to conform to the demands of technology. <sup class="modern-footnotes-footnote ">1</sup></p>



<p>Liberatory AI also honors the planetary limits of our home. It recognizes that elements&nbsp; like water, metals, and energy are finite and must be used thoughtfully. This means designing hardware that is durable, repairable, and recyclable, and creating systems that minimize waste. For example, the materials used to build data centers might be repurposed from existing structures, and the metals and components could be part of a circular economy. When a data center is no longer needed, its materials can be reused in other projects, ensuring that nothing is wasted and that the Earth is not burdened with more extraction.</p>



<p>We advocate for an AI that challenges the foundational core of corporate AI by rejecting the extractive logics that treat the Earth as a resource and exploit relationships. Instead, it embraces a relational way of being rooted in decolonial and Indigenous ways of relating to land. As scholar Kyle Whyte has pointed out, we are not only past the climate crisis tipping point but also past the<a href="https://wires.onlinelibrary.wiley.com/doi/10.1002/wcc.603"> relational tipping point</a>. This means that the crisis we face is not just about the physical consumption of resources but about the breakdown of our relationships with the Earth and each other. Liberatory AI seeks to (re)configure these relationships, recognizing the Earth as a living, sacred relative rather than a resource to be exploited.</p>



<h3 class="wp-block-heading"><strong>Further Reading</strong></h3>



<ul class="wp-block-list">
<li>Crawford, K. (2021). Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence. Yale University Press.</li>



<li>Escobar, A. (2018). Designs for the Pluriverse: Radical Interdependence, Autonomy, and the Making of Worlds. Duke University Press.</li>



<li>Shiva, V. (2015). Earth Democracy: Justice, Sustainability, and Peace. North Atlantic Books.</li>



<li><a href="https://www.unep.org/news-and-stories/story/ai-has-environmental-problem-heres-what-world-can-do-about">AI has an environmental problem. Here’s what the world can do about that.</a> </li>



<li><a href="https://www2.deloitte.com/us/en/insights/industry/technology/technology-media-and-telecom-predictions/2025/genai-power-consumption-creates-need-for-more-sustainable-data-centers.html">As generative AI asks for more power, data centers seek more reliable, cleaner energy solutions</a></li>



<li><a href="https://www.technologyreview.com/2024/09/26/1104516/three-mile-island-microsoft/">Why Microsoft made a deal to help restart Three Mile Island | MIT Technology Review</a></li>



<li><a href="https://oecd.ai/en/wonk/how-much-water-does-ai-consume">How much water does AI consume? The public deserves to know &#8211; OECD.AI</a> </li>



<li><a href="https://www.washingtonpost.com/technology/2024/09/18/energy-ai-use-electricity-water-data-centers/">A bottle of water per email: the hidden environmental costs of using AI chatbots</a> </li>



<li><a href="https://www.theatlantic.com/technology/archive/2024/09/microsoft-ai-oil-contracts/679804/">Microsoft’s Hypocrisy on AI</a></li>



<li><a href="https://www.washingtonpost.com/technology/2024/12/23/arizona-data-centers-navajo-power-aps-srp/">In the shadows of Arizona’s data center boom, thousands live without power</a></li>



<li><a href="https://commonplace.knowledgefutures.org/pub/0rpv3iuc/release/1">&#8220;This Has Nothing to Do With Clouds&#8221;: A Decolonial Approach to Data Centers in the Node Pole</a></li>
</ul><p>The post <a href="https://liberatoryai.datainfrastructures.org/ai-can-work-in-harmony-with-the-environment/">AI can work in harmony with the environment</a> first appeared on <a href="https://liberatoryai.datainfrastructures.org">Liberatory A.I.</a>.</p><div>1&nbsp;&nbsp;&nbsp;&nbsp;We’re mindful that the development of renewable energy can cause other ecological problems. A liberatory approach to AI considers these tensions.  <a href="https://www.nature.com/articles/s41467-020-17928-5">Read More</a> </div>]]></content:encoded>
					
		
		
			</item>
	</channel>
</rss>
