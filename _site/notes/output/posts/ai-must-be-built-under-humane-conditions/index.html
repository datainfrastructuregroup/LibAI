<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI must be built under humane conditions</title>
    <link rel="stylesheet" href="/css/style.css">
    <script type="module" src="/js/graph-visualization.js"></script>
</head>
<body>
    <div class="container">
        <header>
            <div class="header-title">
                <h1><a href="/" class="logo">Liberation + AI Think Tank</a></h1>
                <p class="subtitle">we are asking questions</p>
            </div>
            <nav>
                <a href="/">Home</a>
                <a href="/notes">All Entries</a>
                <a href="/contributors">Contributors</a>
                <a href="/about">About</a>
                <a href="/bibliography">Bibliography</a>
            </nav>
        </header>
        
        <main>
            
<article class="note">
    <header>
        <h1>AI must be built under humane conditions</h1>
        <div class="meta">
            <a href="/notes" class="back-link">← Back to all notes</a>
        </div>
        
        
        <div class="note-byline">
            
            <div class="byline-section">
                <span class="byline-label">Written by:</span>
                <span class="byline-content">
                    
                        
                        
                        
                            <a href="/notes/ololade-faniyi/">Ololade Faniyi</a>
                        
                    
                </span>
            </div>
            
            
            
            <div class="byline-section">
                <span class="byline-label">Additional contributions by:</span>
                <span class="byline-content">
                    
                        
                        
                        
                            <a href="/notes/null/"></a>
                        
                    
                </span>
            </div>
            
            
            
            <div class="byline-section">
                <span class="byline-label">Edited by:</span>
                <span class="byline-content">
                    
                        
                        
                        
                            <a href="/notes/null/"></a>
                        
                    
                </span>
            </div>
            
        </div>
        
    </header>
    
    <div class="content">
        <p>A liberatory AI ecosystem would transform bad labor conditions by ensuring that those most affected by technological systems have a say in how they are designed and governed.</p>
<p>AI is an African feminist issue. The convergence of automated systems, algorithmic governance, and digital infrastructure in African contexts has direct implications for African women’s lives, bodies, and futures. As technological systems increasingly mediate social, political, and economic relations, they become inseparable from the broader struggles for liberation that have always been central to African feminist organizing.</p>
<p>An African feminist approach recognizes the embodied nature of technological systems. While corporate AI presents itself as disembodied and universal, African feminist thought insists on recognizing the physical bodies and lands that make technology possible. As the feminist historian Stephanie Camp reminds us, African women’s bodies were the scripts upon which the scripts of labor and enslavement was read and perpetuated, creating a coloniality/modernity where African women continue to pay the price for the indexing of humanity. A liberatory AI would acknowledge these embodied realities rather than obscuring them.</p>
<p>This embodied understanding leads to practical differences in how technology is developed and deployed. Content moderators would be recognized as tech workers rather than disposable labor. Data sovereignty would be understood as a crucial aspect of both personal and collective autonomy. The environmental impacts of technological infrastructure would be centered rather than externalized.</p>
<p>An African feminist approach to AI would transform tech governance by insisting on pluralistic, democratic control over technological systems. A liberatory AI ecosystem would transform this dynamic by ensuring that those most affected by technological systems have a say in how they are designed and governed. This would mean moving beyond corporate philanthropy or “ethical/responsible AI” initiatives that maintain existing power structures while making superficial adjustments.</p>
<p>Liberatory AI ecosystem must be grounded in the freedom dreams of those who have historically borne the costs of technological “progress.” Drawing from African feminist epistemologies offers us alternative frameworks for understanding and developing technologies that center relationality, care, freedom and plural frameworks of the human, rather than extraction, domination, and control.</p>
<p>African feminist scholar Filomina Chioma Steady provides a foundation for this reimagining when she positions her conception of feminism as emerging from what she terms “polarizations and conflicts—representing some of the worst and most chronic forms of human suffering”—and prompts us toward a broad struggle for social and humanistic transformation. This understanding allows us to envision a liberatory AI that critiques the racial, sexual, class, and cultural dimensions of technological oppression to produce equitable technologies through which humans are viewed as whole beings rather than data points to be extracted or bodies to be exploited.</p>
<p>What would this look like in practice? A liberatory AI ecosystem would acknowledge the full humanity of all people involved in its creation, deployment, and use. This means recognizing content moderators not as disposable labor but as essential tech workers deserving of fair compensation, psychological support, and dignity.</p>
<p>It recognizes that technological systems are never neutral but always encode particular ways of seeing and organizing the world. Rather than positioning the white, male, wealthy technologist as the universal subject of technological development, a liberatory AI would center multiple ways of being human. This means moving beyond what Alexander Weheliye describes as the “racializing assemblages” that discipline humanity into full humans, not-quite-humans, and nonhumans. Instead of reproducing these hierarchies, liberatory AI would be built on a “technological plural humanism”—recognition that different cultural contexts offer distinct and valuable approaches to technology development.</p>
<p>In the African context, this involves drawing on indigenous concepts of relationality and collective ownership. Many African societies have longstanding traditions that understand the individual as fundamentally embedded in community and the natural world. These epistemologies offer alternatives to the hyperindividualistic, extractive logics without soul that currently dominate AI development.</p>
<p>The digital articulations of African feminist freedom dreams are already pointing the way toward such alternatives. The Ugandan feminist tech collective, <a href="https://pollicy.org/">Pollicy</a>, for instance, builds its policy advocacies around the logic of digital kinship, where people must have access to their own data and technologies must be developed with and for communities rather than imposed upon them.</p>
<h3><strong>Further Reading</strong></h3>
<p><strong>Further Reading (Academic)</strong></p>
<ul>
<li>Birhane, A. (2020). The Algorithmic Colonization of Africa. Script-ed, 17(2), 389-409.</li>
<li>Camp, S. M. H. (2005). Closer to Freedom: Enslaved Women and Everyday Resistance in the Plantation South. United States: University of North Carolina Press.</li>
<li>Jili, B. (2022). Chinese ICT and Smart City Initiatives in Kenya. Asia Policy 17(3), 40-50. <a href="https://dx.doi.org/10.1353/asp.2022.0051">https://dx.doi.org/10.1353/asp.2022.0051</a>.</li>
<li>Klein, L. &amp; D’Ignazio, C. (2024). Data Feminism for AI. ArXiv. <a href="https://doi.org/10.1145/3630106.3658543">https://doi.org/10.1145/3630106.3658543</a></li>
<li>Mbembe, A. (2019). Necropolitics. Duke University Press.</li>
<li>Ogundipe, M. (1994). Re-creating Ourselves: African Women &amp; Critical Transformations. Africa World Press.</li>
<li>Steady, F. C. (1986). African Feminism: A Worldwide Perspective. In R. Terborg-Penn, S. Harley, &amp; A. Benton Rushing (Eds.), Women in Africa and the African Diaspora (pp. 3-24). Howard University Press.</li>
<li>Weheliye, A. G. (2014). Habeas Viscus: Racializing Assemblages, Biopolitics, and Black Feminist Theories of the Human. Duke University Press.</li>
<li>Wynter, S. (2003). Unsettling the Coloniality of Being/Power/Truth/Freedom: Towards the Human, After Man, Its Overrepresentation—An Argument. CR: The New Centennial Review, 3(3), 257-337.</li>
<li>Barrett, T., Okolo, C. T., Biira, B., Sherif, E., Zhang, A. X., &amp; Battle, L. (2025). African Data Ethics: A Discursive Framework for Black Decolonial Data Science. ArXiv. <a href="https://arxiv.org/abs/2502.16043">https://arxiv.org/abs/2502.16043</a></li>
</ul>
<p><strong>Further Reading (Popular Press)</strong></p>
<ul>
<li>Benjamin, R. (2024). Imagination: A Manifesto (A Norton Short). United States: W. W. Norton.</li>
<li>Faniyi, O. (2024, February 27). An African Feminist Manifesto. The Republic. <a href="https://republic.com.ng/february-march-2024/an-african-feminist-manifesto/">https://republic.com.ng/february-march-2024/an-african-feminist-manifesto/</a></li>
<li>Hao, K. (2019). The future of AI research is in Africa. MIT Technology Review. <a href="https://www.technologyreview.com/2019/06/21/134820/ai-africa-machine-learning-ibm-google/">https://www.technologyreview.com/2019/06/21/134820/ai-africa-machine-learning-ibm-google/</a></li>
<li>Holland, A. (2024). Feminist Ethics AI Toolkit. Sistah Sistah</li>
<li>Jili, B. (2020, December 11). Surveillance tech in Africa stirs security concerns – Africa Center. Africa Center. <a href="https://africacenter.org/spotlight/surveillance-technology-in-africa-security-concerns/">https://africacenter.org/spotlight/surveillance-technology-in-africa-security-concerns/</a></li>
<li>Perrigo, B. (2022, February 17). Inside Facebook’s African sweatshop. TIME. <a href="https://time.com/6147458/facebook-africa-content-moderation-employee-treatment/">https://time.com/6147458/facebook-africa-content-moderation-employee-treatment/</a></li>
</ul>

    </div>
    
    <!-- Works Cited Section - Added by citations plugin -->
    
    <section class="works-cited">
        <h2>Works Cited</h2>
        
    </section>
    
    
    
    
    

</article>

        </main>
        
        <section class="graph-section">
            <h2>Knowledge Graph</h2>
            <div id="force-graph" class="force-graph-container"></div>
        </section>
        
        <footer>
            <p>Built with <3 by students at MIT and Smith College.</p>
        </footer>
    </div>
    <script src="/js/main.js"></script>
</body>
</html>
