#!/usr/bin/env node
import fs, { unwatchFile, watchFile, watch as watch$1, stat as stat$2 } from 'fs';
import * as sysPath from 'path';
import sysPath__default, { resolve as resolve$1, join as join$2 } from 'path';
import require$$0 from 'node:events';
import require$$1 from 'node:child_process';
import require$$2, { resolve, join as join$1, relative as relative$1, sep } from 'node:path';
import require$$3 from 'node:fs';
import require$$4 from 'node:process';
import { realpath as realpath$1, stat as stat$1, lstat as lstat$1, open, readdir as readdir$1 } from 'fs/promises';
import { EventEmitter } from 'events';
import { lstat, stat, readdir, realpath } from 'node:fs/promises';
import { Readable } from 'node:stream';
import { type as type$1 } from 'os';

// Custom error types for markdown graph processing
class MarkdownGraphError extends Error {
    constructor(message, cause) {
        super(message);
        this.name = "MarkdownGraphError";
        if (cause) {
            if (cause instanceof Error) {
                this.cause = cause;
            }
            else {
                this.cause = Error(JSON.stringify(cause));
            }
        }
    }
}
class FileNotFoundError extends MarkdownGraphError {
    constructor(filepath) {
        super(`File not found: ${filepath}`);
        this.name = "FileNotFoundError";
    }
}
class DirectoryNotFoundError extends MarkdownGraphError {
    constructor(directory, cause) {
        super(`Directory does not exist: ${directory}`, cause);
        this.name = "DirectoryNotFoundError";
    }
}
class MarkdownParsingError extends MarkdownGraphError {
    constructor(filename, cause) {
        super(`Failed to parse markdown in ${filename}: ${cause.message}`, cause);
        this.name = "MarkdownParsingError";
    }
}
class DocumentNotFoundError extends MarkdownGraphError {
    constructor(documentId, repositoryDescription) {
        super(`Cannot load document ${documentId}: does not exist in ${repositoryDescription}`);
        this.name = "DocumentNotFoundError";
    }
}
class RepositoryConfigurationError extends MarkdownGraphError {
    constructor(message) {
        super(message);
        this.name = "RepositoryConfigurationError";
    }
}

/**
 * Configuration management for markdown-graph CLI
 *
 * This module provides configuration loading and validation functionality,
 * supporting multiple configuration sources with proper precedence handling.
 */
const DEFAULT_CONFIG_NAMES = [
    "markdown-graph.config.json",
    ".markdown-graph.json",
    "package.json",
];
const DEFAULT_SEARCH_PATHS = [
    process.cwd(),
    sysPath__default.join(process.cwd(), ".config"),
    sysPath__default.dirname(process.cwd()),
];
/**
 * Load configuration from various sources in order of precedence:
 * 1. Explicit CLI options (highest precedence)
 * 2. Configuration file
 * 3. Default values (lowest precedence)
 */
function loadConfig(cliOptions = {}, configOptions = {}) {
    const fileConfig = loadConfigFromFile(configOptions);
    const defaultConfig = getDefaultConfig();
    // Merge configs in order of precedence
    return {
        ...defaultConfig,
        ...fileConfig,
        ...cliOptions,
    };
}
/**
 * Get default configuration values
 */
function getDefaultConfig() {
    return {
        outputFile: ".garden-graph.json",
        verbose: false,
        quiet: false,
        excludes: ["node_modules", "dist", ".git"],
        includeHidden: false,
    };
}
/**
 * Load configuration from a file
 */
function loadConfigFromFile(options = {}) {
    const configNames = options.name ? [options.name] : DEFAULT_CONFIG_NAMES;
    const searchPaths = options.searchPaths || DEFAULT_SEARCH_PATHS;
    for (const searchPath of searchPaths) {
        const foundConfig = tryLoadConfigInPath(searchPath, configNames);
        if (foundConfig) {
            return foundConfig;
        }
    }
    return {};
}
/**
 * Try to load configuration from a specific path
 */
function tryLoadConfigInPath(searchPath, configNames) {
    for (const configName of configNames) {
        const configPath = sysPath__default.join(searchPath, configName);
        if (fs.existsSync(configPath)) {
            try {
                return loadConfigFile(configPath, configName);
            }
            catch (error) {
                throw new RepositoryConfigurationError(`Failed to load config from ${configPath}: ${error instanceof Error ? error.message : error}`);
            }
        }
    }
    return null;
}
/**
 * Load and parse a specific configuration file
 */
function loadConfigFile(configPath, configName) {
    const content = fs.readFileSync(configPath, "utf8");
    const parsed = JSON.parse(content);
    if (configName === "package.json") {
        // Extract markdown-graph config from package.json
        return parsed["markdown-graph"] || {};
    }
    // Validate config structure
    if (typeof parsed !== "object" || parsed === null) {
        throw new Error("Configuration must be a JSON object");
    }
    return parsed;
}
/**
 * Validate configuration values
 */
function validateConfig(config) {
    if (config.targetDirectory && typeof config.targetDirectory !== "string") {
        throw new RepositoryConfigurationError("targetDirectory must be a string");
    }
    if (config.outputFile && typeof config.outputFile !== "string") {
        throw new RepositoryConfigurationError("outputFile must be a string");
    }
    if (config.excludes && !Array.isArray(config.excludes)) {
        throw new RepositoryConfigurationError("excludes must be an array of strings");
    }
    if (config.excludes?.some((exclude) => typeof exclude !== "string")) {
        throw new RepositoryConfigurationError("excludes must be an array of strings");
    }
    if (typeof config.verbose !== "boolean") {
        throw new RepositoryConfigurationError("verbose must be a boolean");
    }
    if (typeof config.quiet !== "boolean") {
        throw new RepositoryConfigurationError("quiet must be a boolean");
    }
    if (typeof config.includeHidden !== "boolean") {
        throw new RepositoryConfigurationError("includeHidden must be a boolean");
    }
}

function getDefaultExportFromCjs (x) {
	return x && x.__esModule && Object.prototype.hasOwnProperty.call(x, 'default') ? x['default'] : x;
}

var commander$1 = {};

var argument = {};

var error = {};

/**
 * CommanderError class
 */

var hasRequiredError;

function requireError () {
	if (hasRequiredError) return error;
	hasRequiredError = 1;
	class CommanderError extends Error {
	  /**
	   * Constructs the CommanderError class
	   * @param {number} exitCode suggested exit code which could be used with process.exit
	   * @param {string} code an id string representing the error
	   * @param {string} message human-readable description of the error
	   */
	  constructor(exitCode, code, message) {
	    super(message);
	    // properly capture stack trace in Node.js
	    Error.captureStackTrace(this, this.constructor);
	    this.name = this.constructor.name;
	    this.code = code;
	    this.exitCode = exitCode;
	    this.nestedError = undefined;
	  }
	}

	/**
	 * InvalidArgumentError class
	 */
	class InvalidArgumentError extends CommanderError {
	  /**
	   * Constructs the InvalidArgumentError class
	   * @param {string} [message] explanation of why argument is invalid
	   */
	  constructor(message) {
	    super(1, 'commander.invalidArgument', message);
	    // properly capture stack trace in Node.js
	    Error.captureStackTrace(this, this.constructor);
	    this.name = this.constructor.name;
	  }
	}

	error.CommanderError = CommanderError;
	error.InvalidArgumentError = InvalidArgumentError;
	return error;
}

var hasRequiredArgument;

function requireArgument () {
	if (hasRequiredArgument) return argument;
	hasRequiredArgument = 1;
	const { InvalidArgumentError } = requireError();

	class Argument {
	  /**
	   * Initialize a new command argument with the given name and description.
	   * The default is that the argument is required, and you can explicitly
	   * indicate this with <> around the name. Put [] around the name for an optional argument.
	   *
	   * @param {string} name
	   * @param {string} [description]
	   */

	  constructor(name, description) {
	    this.description = description || '';
	    this.variadic = false;
	    this.parseArg = undefined;
	    this.defaultValue = undefined;
	    this.defaultValueDescription = undefined;
	    this.argChoices = undefined;

	    switch (name[0]) {
	      case '<': // e.g. <required>
	        this.required = true;
	        this._name = name.slice(1, -1);
	        break;
	      case '[': // e.g. [optional]
	        this.required = false;
	        this._name = name.slice(1, -1);
	        break;
	      default:
	        this.required = true;
	        this._name = name;
	        break;
	    }

	    if (this._name.length > 3 && this._name.slice(-3) === '...') {
	      this.variadic = true;
	      this._name = this._name.slice(0, -3);
	    }
	  }

	  /**
	   * Return argument name.
	   *
	   * @return {string}
	   */

	  name() {
	    return this._name;
	  }

	  /**
	   * @package
	   */

	  _concatValue(value, previous) {
	    if (previous === this.defaultValue || !Array.isArray(previous)) {
	      return [value];
	    }

	    return previous.concat(value);
	  }

	  /**
	   * Set the default value, and optionally supply the description to be displayed in the help.
	   *
	   * @param {*} value
	   * @param {string} [description]
	   * @return {Argument}
	   */

	  default(value, description) {
	    this.defaultValue = value;
	    this.defaultValueDescription = description;
	    return this;
	  }

	  /**
	   * Set the custom handler for processing CLI command arguments into argument values.
	   *
	   * @param {Function} [fn]
	   * @return {Argument}
	   */

	  argParser(fn) {
	    this.parseArg = fn;
	    return this;
	  }

	  /**
	   * Only allow argument value to be one of choices.
	   *
	   * @param {string[]} values
	   * @return {Argument}
	   */

	  choices(values) {
	    this.argChoices = values.slice();
	    this.parseArg = (arg, previous) => {
	      if (!this.argChoices.includes(arg)) {
	        throw new InvalidArgumentError(
	          `Allowed choices are ${this.argChoices.join(', ')}.`,
	        );
	      }
	      if (this.variadic) {
	        return this._concatValue(arg, previous);
	      }
	      return arg;
	    };
	    return this;
	  }

	  /**
	   * Make argument required.
	   *
	   * @returns {Argument}
	   */
	  argRequired() {
	    this.required = true;
	    return this;
	  }

	  /**
	   * Make argument optional.
	   *
	   * @returns {Argument}
	   */
	  argOptional() {
	    this.required = false;
	    return this;
	  }
	}

	/**
	 * Takes an argument and returns its human readable equivalent for help usage.
	 *
	 * @param {Argument} arg
	 * @return {string}
	 * @private
	 */

	function humanReadableArgName(arg) {
	  const nameOutput = arg.name() + (arg.variadic === true ? '...' : '');

	  return arg.required ? '<' + nameOutput + '>' : '[' + nameOutput + ']';
	}

	argument.Argument = Argument;
	argument.humanReadableArgName = humanReadableArgName;
	return argument;
}

var command = {};

var help = {};

var hasRequiredHelp;

function requireHelp () {
	if (hasRequiredHelp) return help;
	hasRequiredHelp = 1;
	const { humanReadableArgName } = requireArgument();

	/**
	 * TypeScript import types for JSDoc, used by Visual Studio Code IntelliSense and `npm run typescript-checkJS`
	 * https://www.typescriptlang.org/docs/handbook/jsdoc-supported-types.html#import-types
	 * @typedef { import("./argument.js").Argument } Argument
	 * @typedef { import("./command.js").Command } Command
	 * @typedef { import("./option.js").Option } Option
	 */

	// Although this is a class, methods are static in style to allow override using subclass or just functions.
	class Help {
	  constructor() {
	    this.helpWidth = undefined;
	    this.minWidthToWrap = 40;
	    this.sortSubcommands = false;
	    this.sortOptions = false;
	    this.showGlobalOptions = false;
	  }

	  /**
	   * prepareContext is called by Commander after applying overrides from `Command.configureHelp()`
	   * and just before calling `formatHelp()`.
	   *
	   * Commander just uses the helpWidth and the rest is provided for optional use by more complex subclasses.
	   *
	   * @param {{ error?: boolean, helpWidth?: number, outputHasColors?: boolean }} contextOptions
	   */
	  prepareContext(contextOptions) {
	    this.helpWidth = this.helpWidth ?? contextOptions.helpWidth ?? 80;
	  }

	  /**
	   * Get an array of the visible subcommands. Includes a placeholder for the implicit help command, if there is one.
	   *
	   * @param {Command} cmd
	   * @returns {Command[]}
	   */

	  visibleCommands(cmd) {
	    const visibleCommands = cmd.commands.filter((cmd) => !cmd._hidden);
	    const helpCommand = cmd._getHelpCommand();
	    if (helpCommand && !helpCommand._hidden) {
	      visibleCommands.push(helpCommand);
	    }
	    if (this.sortSubcommands) {
	      visibleCommands.sort((a, b) => {
	        // @ts-ignore: because overloaded return type
	        return a.name().localeCompare(b.name());
	      });
	    }
	    return visibleCommands;
	  }

	  /**
	   * Compare options for sort.
	   *
	   * @param {Option} a
	   * @param {Option} b
	   * @returns {number}
	   */
	  compareOptions(a, b) {
	    const getSortKey = (option) => {
	      // WYSIWYG for order displayed in help. Short used for comparison if present. No special handling for negated.
	      return option.short
	        ? option.short.replace(/^-/, '')
	        : option.long.replace(/^--/, '');
	    };
	    return getSortKey(a).localeCompare(getSortKey(b));
	  }

	  /**
	   * Get an array of the visible options. Includes a placeholder for the implicit help option, if there is one.
	   *
	   * @param {Command} cmd
	   * @returns {Option[]}
	   */

	  visibleOptions(cmd) {
	    const visibleOptions = cmd.options.filter((option) => !option.hidden);
	    // Built-in help option.
	    const helpOption = cmd._getHelpOption();
	    if (helpOption && !helpOption.hidden) {
	      // Automatically hide conflicting flags. Bit dubious but a historical behaviour that is convenient for single-command programs.
	      const removeShort = helpOption.short && cmd._findOption(helpOption.short);
	      const removeLong = helpOption.long && cmd._findOption(helpOption.long);
	      if (!removeShort && !removeLong) {
	        visibleOptions.push(helpOption); // no changes needed
	      } else if (helpOption.long && !removeLong) {
	        visibleOptions.push(
	          cmd.createOption(helpOption.long, helpOption.description),
	        );
	      } else if (helpOption.short && !removeShort) {
	        visibleOptions.push(
	          cmd.createOption(helpOption.short, helpOption.description),
	        );
	      }
	    }
	    if (this.sortOptions) {
	      visibleOptions.sort(this.compareOptions);
	    }
	    return visibleOptions;
	  }

	  /**
	   * Get an array of the visible global options. (Not including help.)
	   *
	   * @param {Command} cmd
	   * @returns {Option[]}
	   */

	  visibleGlobalOptions(cmd) {
	    if (!this.showGlobalOptions) return [];

	    const globalOptions = [];
	    for (
	      let ancestorCmd = cmd.parent;
	      ancestorCmd;
	      ancestorCmd = ancestorCmd.parent
	    ) {
	      const visibleOptions = ancestorCmd.options.filter(
	        (option) => !option.hidden,
	      );
	      globalOptions.push(...visibleOptions);
	    }
	    if (this.sortOptions) {
	      globalOptions.sort(this.compareOptions);
	    }
	    return globalOptions;
	  }

	  /**
	   * Get an array of the arguments if any have a description.
	   *
	   * @param {Command} cmd
	   * @returns {Argument[]}
	   */

	  visibleArguments(cmd) {
	    // Side effect! Apply the legacy descriptions before the arguments are displayed.
	    if (cmd._argsDescription) {
	      cmd.registeredArguments.forEach((argument) => {
	        argument.description =
	          argument.description || cmd._argsDescription[argument.name()] || '';
	      });
	    }

	    // If there are any arguments with a description then return all the arguments.
	    if (cmd.registeredArguments.find((argument) => argument.description)) {
	      return cmd.registeredArguments;
	    }
	    return [];
	  }

	  /**
	   * Get the command term to show in the list of subcommands.
	   *
	   * @param {Command} cmd
	   * @returns {string}
	   */

	  subcommandTerm(cmd) {
	    // Legacy. Ignores custom usage string, and nested commands.
	    const args = cmd.registeredArguments
	      .map((arg) => humanReadableArgName(arg))
	      .join(' ');
	    return (
	      cmd._name +
	      (cmd._aliases[0] ? '|' + cmd._aliases[0] : '') +
	      (cmd.options.length ? ' [options]' : '') + // simplistic check for non-help option
	      (args ? ' ' + args : '')
	    );
	  }

	  /**
	   * Get the option term to show in the list of options.
	   *
	   * @param {Option} option
	   * @returns {string}
	   */

	  optionTerm(option) {
	    return option.flags;
	  }

	  /**
	   * Get the argument term to show in the list of arguments.
	   *
	   * @param {Argument} argument
	   * @returns {string}
	   */

	  argumentTerm(argument) {
	    return argument.name();
	  }

	  /**
	   * Get the longest command term length.
	   *
	   * @param {Command} cmd
	   * @param {Help} helper
	   * @returns {number}
	   */

	  longestSubcommandTermLength(cmd, helper) {
	    return helper.visibleCommands(cmd).reduce((max, command) => {
	      return Math.max(
	        max,
	        this.displayWidth(
	          helper.styleSubcommandTerm(helper.subcommandTerm(command)),
	        ),
	      );
	    }, 0);
	  }

	  /**
	   * Get the longest option term length.
	   *
	   * @param {Command} cmd
	   * @param {Help} helper
	   * @returns {number}
	   */

	  longestOptionTermLength(cmd, helper) {
	    return helper.visibleOptions(cmd).reduce((max, option) => {
	      return Math.max(
	        max,
	        this.displayWidth(helper.styleOptionTerm(helper.optionTerm(option))),
	      );
	    }, 0);
	  }

	  /**
	   * Get the longest global option term length.
	   *
	   * @param {Command} cmd
	   * @param {Help} helper
	   * @returns {number}
	   */

	  longestGlobalOptionTermLength(cmd, helper) {
	    return helper.visibleGlobalOptions(cmd).reduce((max, option) => {
	      return Math.max(
	        max,
	        this.displayWidth(helper.styleOptionTerm(helper.optionTerm(option))),
	      );
	    }, 0);
	  }

	  /**
	   * Get the longest argument term length.
	   *
	   * @param {Command} cmd
	   * @param {Help} helper
	   * @returns {number}
	   */

	  longestArgumentTermLength(cmd, helper) {
	    return helper.visibleArguments(cmd).reduce((max, argument) => {
	      return Math.max(
	        max,
	        this.displayWidth(
	          helper.styleArgumentTerm(helper.argumentTerm(argument)),
	        ),
	      );
	    }, 0);
	  }

	  /**
	   * Get the command usage to be displayed at the top of the built-in help.
	   *
	   * @param {Command} cmd
	   * @returns {string}
	   */

	  commandUsage(cmd) {
	    // Usage
	    let cmdName = cmd._name;
	    if (cmd._aliases[0]) {
	      cmdName = cmdName + '|' + cmd._aliases[0];
	    }
	    let ancestorCmdNames = '';
	    for (
	      let ancestorCmd = cmd.parent;
	      ancestorCmd;
	      ancestorCmd = ancestorCmd.parent
	    ) {
	      ancestorCmdNames = ancestorCmd.name() + ' ' + ancestorCmdNames;
	    }
	    return ancestorCmdNames + cmdName + ' ' + cmd.usage();
	  }

	  /**
	   * Get the description for the command.
	   *
	   * @param {Command} cmd
	   * @returns {string}
	   */

	  commandDescription(cmd) {
	    // @ts-ignore: because overloaded return type
	    return cmd.description();
	  }

	  /**
	   * Get the subcommand summary to show in the list of subcommands.
	   * (Fallback to description for backwards compatibility.)
	   *
	   * @param {Command} cmd
	   * @returns {string}
	   */

	  subcommandDescription(cmd) {
	    // @ts-ignore: because overloaded return type
	    return cmd.summary() || cmd.description();
	  }

	  /**
	   * Get the option description to show in the list of options.
	   *
	   * @param {Option} option
	   * @return {string}
	   */

	  optionDescription(option) {
	    const extraInfo = [];

	    if (option.argChoices) {
	      extraInfo.push(
	        // use stringify to match the display of the default value
	        `choices: ${option.argChoices.map((choice) => JSON.stringify(choice)).join(', ')}`,
	      );
	    }
	    if (option.defaultValue !== undefined) {
	      // default for boolean and negated more for programmer than end user,
	      // but show true/false for boolean option as may be for hand-rolled env or config processing.
	      const showDefault =
	        option.required ||
	        option.optional ||
	        (option.isBoolean() && typeof option.defaultValue === 'boolean');
	      if (showDefault) {
	        extraInfo.push(
	          `default: ${option.defaultValueDescription || JSON.stringify(option.defaultValue)}`,
	        );
	      }
	    }
	    // preset for boolean and negated are more for programmer than end user
	    if (option.presetArg !== undefined && option.optional) {
	      extraInfo.push(`preset: ${JSON.stringify(option.presetArg)}`);
	    }
	    if (option.envVar !== undefined) {
	      extraInfo.push(`env: ${option.envVar}`);
	    }
	    if (extraInfo.length > 0) {
	      const extraDescription = `(${extraInfo.join(', ')})`;
	      if (option.description) {
	        return `${option.description} ${extraDescription}`;
	      }
	      return extraDescription;
	    }

	    return option.description;
	  }

	  /**
	   * Get the argument description to show in the list of arguments.
	   *
	   * @param {Argument} argument
	   * @return {string}
	   */

	  argumentDescription(argument) {
	    const extraInfo = [];
	    if (argument.argChoices) {
	      extraInfo.push(
	        // use stringify to match the display of the default value
	        `choices: ${argument.argChoices.map((choice) => JSON.stringify(choice)).join(', ')}`,
	      );
	    }
	    if (argument.defaultValue !== undefined) {
	      extraInfo.push(
	        `default: ${argument.defaultValueDescription || JSON.stringify(argument.defaultValue)}`,
	      );
	    }
	    if (extraInfo.length > 0) {
	      const extraDescription = `(${extraInfo.join(', ')})`;
	      if (argument.description) {
	        return `${argument.description} ${extraDescription}`;
	      }
	      return extraDescription;
	    }
	    return argument.description;
	  }

	  /**
	   * Format a list of items, given a heading and an array of formatted items.
	   *
	   * @param {string} heading
	   * @param {string[]} items
	   * @param {Help} helper
	   * @returns string[]
	   */
	  formatItemList(heading, items, helper) {
	    if (items.length === 0) return [];

	    return [helper.styleTitle(heading), ...items, ''];
	  }

	  /**
	   * Group items by their help group heading.
	   *
	   * @param {Command[] | Option[]} unsortedItems
	   * @param {Command[] | Option[]} visibleItems
	   * @param {Function} getGroup
	   * @returns {Map<string, Command[] | Option[]>}
	   */
	  groupItems(unsortedItems, visibleItems, getGroup) {
	    const result = new Map();
	    // Add groups in order of appearance in unsortedItems.
	    unsortedItems.forEach((item) => {
	      const group = getGroup(item);
	      if (!result.has(group)) result.set(group, []);
	    });
	    // Add items in order of appearance in visibleItems.
	    visibleItems.forEach((item) => {
	      const group = getGroup(item);
	      if (!result.has(group)) {
	        result.set(group, []);
	      }
	      result.get(group).push(item);
	    });
	    return result;
	  }

	  /**
	   * Generate the built-in help text.
	   *
	   * @param {Command} cmd
	   * @param {Help} helper
	   * @returns {string}
	   */

	  formatHelp(cmd, helper) {
	    const termWidth = helper.padWidth(cmd, helper);
	    const helpWidth = helper.helpWidth ?? 80; // in case prepareContext() was not called

	    function callFormatItem(term, description) {
	      return helper.formatItem(term, termWidth, description, helper);
	    }

	    // Usage
	    let output = [
	      `${helper.styleTitle('Usage:')} ${helper.styleUsage(helper.commandUsage(cmd))}`,
	      '',
	    ];

	    // Description
	    const commandDescription = helper.commandDescription(cmd);
	    if (commandDescription.length > 0) {
	      output = output.concat([
	        helper.boxWrap(
	          helper.styleCommandDescription(commandDescription),
	          helpWidth,
	        ),
	        '',
	      ]);
	    }

	    // Arguments
	    const argumentList = helper.visibleArguments(cmd).map((argument) => {
	      return callFormatItem(
	        helper.styleArgumentTerm(helper.argumentTerm(argument)),
	        helper.styleArgumentDescription(helper.argumentDescription(argument)),
	      );
	    });
	    output = output.concat(
	      this.formatItemList('Arguments:', argumentList, helper),
	    );

	    // Options
	    const optionGroups = this.groupItems(
	      cmd.options,
	      helper.visibleOptions(cmd),
	      (option) => option.helpGroupHeading ?? 'Options:',
	    );
	    optionGroups.forEach((options, group) => {
	      const optionList = options.map((option) => {
	        return callFormatItem(
	          helper.styleOptionTerm(helper.optionTerm(option)),
	          helper.styleOptionDescription(helper.optionDescription(option)),
	        );
	      });
	      output = output.concat(this.formatItemList(group, optionList, helper));
	    });

	    if (helper.showGlobalOptions) {
	      const globalOptionList = helper
	        .visibleGlobalOptions(cmd)
	        .map((option) => {
	          return callFormatItem(
	            helper.styleOptionTerm(helper.optionTerm(option)),
	            helper.styleOptionDescription(helper.optionDescription(option)),
	          );
	        });
	      output = output.concat(
	        this.formatItemList('Global Options:', globalOptionList, helper),
	      );
	    }

	    // Commands
	    const commandGroups = this.groupItems(
	      cmd.commands,
	      helper.visibleCommands(cmd),
	      (sub) => sub.helpGroup() || 'Commands:',
	    );
	    commandGroups.forEach((commands, group) => {
	      const commandList = commands.map((sub) => {
	        return callFormatItem(
	          helper.styleSubcommandTerm(helper.subcommandTerm(sub)),
	          helper.styleSubcommandDescription(helper.subcommandDescription(sub)),
	        );
	      });
	      output = output.concat(this.formatItemList(group, commandList, helper));
	    });

	    return output.join('\n');
	  }

	  /**
	   * Return display width of string, ignoring ANSI escape sequences. Used in padding and wrapping calculations.
	   *
	   * @param {string} str
	   * @returns {number}
	   */
	  displayWidth(str) {
	    return stripColor(str).length;
	  }

	  /**
	   * Style the title for displaying in the help. Called with 'Usage:', 'Options:', etc.
	   *
	   * @param {string} str
	   * @returns {string}
	   */
	  styleTitle(str) {
	    return str;
	  }

	  styleUsage(str) {
	    // Usage has lots of parts the user might like to color separately! Assume default usage string which is formed like:
	    //    command subcommand [options] [command] <foo> [bar]
	    return str
	      .split(' ')
	      .map((word) => {
	        if (word === '[options]') return this.styleOptionText(word);
	        if (word === '[command]') return this.styleSubcommandText(word);
	        if (word[0] === '[' || word[0] === '<')
	          return this.styleArgumentText(word);
	        return this.styleCommandText(word); // Restrict to initial words?
	      })
	      .join(' ');
	  }
	  styleCommandDescription(str) {
	    return this.styleDescriptionText(str);
	  }
	  styleOptionDescription(str) {
	    return this.styleDescriptionText(str);
	  }
	  styleSubcommandDescription(str) {
	    return this.styleDescriptionText(str);
	  }
	  styleArgumentDescription(str) {
	    return this.styleDescriptionText(str);
	  }
	  styleDescriptionText(str) {
	    return str;
	  }
	  styleOptionTerm(str) {
	    return this.styleOptionText(str);
	  }
	  styleSubcommandTerm(str) {
	    // This is very like usage with lots of parts! Assume default string which is formed like:
	    //    subcommand [options] <foo> [bar]
	    return str
	      .split(' ')
	      .map((word) => {
	        if (word === '[options]') return this.styleOptionText(word);
	        if (word[0] === '[' || word[0] === '<')
	          return this.styleArgumentText(word);
	        return this.styleSubcommandText(word); // Restrict to initial words?
	      })
	      .join(' ');
	  }
	  styleArgumentTerm(str) {
	    return this.styleArgumentText(str);
	  }
	  styleOptionText(str) {
	    return str;
	  }
	  styleArgumentText(str) {
	    return str;
	  }
	  styleSubcommandText(str) {
	    return str;
	  }
	  styleCommandText(str) {
	    return str;
	  }

	  /**
	   * Calculate the pad width from the maximum term length.
	   *
	   * @param {Command} cmd
	   * @param {Help} helper
	   * @returns {number}
	   */

	  padWidth(cmd, helper) {
	    return Math.max(
	      helper.longestOptionTermLength(cmd, helper),
	      helper.longestGlobalOptionTermLength(cmd, helper),
	      helper.longestSubcommandTermLength(cmd, helper),
	      helper.longestArgumentTermLength(cmd, helper),
	    );
	  }

	  /**
	   * Detect manually wrapped and indented strings by checking for line break followed by whitespace.
	   *
	   * @param {string} str
	   * @returns {boolean}
	   */
	  preformatted(str) {
	    return /\n[^\S\r\n]/.test(str);
	  }

	  /**
	   * Format the "item", which consists of a term and description. Pad the term and wrap the description, indenting the following lines.
	   *
	   * So "TTT", 5, "DDD DDDD DD DDD" might be formatted for this.helpWidth=17 like so:
	   *   TTT  DDD DDDD
	   *        DD DDD
	   *
	   * @param {string} term
	   * @param {number} termWidth
	   * @param {string} description
	   * @param {Help} helper
	   * @returns {string}
	   */
	  formatItem(term, termWidth, description, helper) {
	    const itemIndent = 2;
	    const itemIndentStr = ' '.repeat(itemIndent);
	    if (!description) return itemIndentStr + term;

	    // Pad the term out to a consistent width, so descriptions are aligned.
	    const paddedTerm = term.padEnd(
	      termWidth + term.length - helper.displayWidth(term),
	    );

	    // Format the description.
	    const spacerWidth = 2; // between term and description
	    const helpWidth = this.helpWidth ?? 80; // in case prepareContext() was not called
	    const remainingWidth = helpWidth - termWidth - spacerWidth - itemIndent;
	    let formattedDescription;
	    if (
	      remainingWidth < this.minWidthToWrap ||
	      helper.preformatted(description)
	    ) {
	      formattedDescription = description;
	    } else {
	      const wrappedDescription = helper.boxWrap(description, remainingWidth);
	      formattedDescription = wrappedDescription.replace(
	        /\n/g,
	        '\n' + ' '.repeat(termWidth + spacerWidth),
	      );
	    }

	    // Construct and overall indent.
	    return (
	      itemIndentStr +
	      paddedTerm +
	      ' '.repeat(spacerWidth) +
	      formattedDescription.replace(/\n/g, `\n${itemIndentStr}`)
	    );
	  }

	  /**
	   * Wrap a string at whitespace, preserving existing line breaks.
	   * Wrapping is skipped if the width is less than `minWidthToWrap`.
	   *
	   * @param {string} str
	   * @param {number} width
	   * @returns {string}
	   */
	  boxWrap(str, width) {
	    if (width < this.minWidthToWrap) return str;

	    const rawLines = str.split(/\r\n|\n/);
	    // split up text by whitespace
	    const chunkPattern = /[\s]*[^\s]+/g;
	    const wrappedLines = [];
	    rawLines.forEach((line) => {
	      const chunks = line.match(chunkPattern);
	      if (chunks === null) {
	        wrappedLines.push('');
	        return;
	      }

	      let sumChunks = [chunks.shift()];
	      let sumWidth = this.displayWidth(sumChunks[0]);
	      chunks.forEach((chunk) => {
	        const visibleWidth = this.displayWidth(chunk);
	        // Accumulate chunks while they fit into width.
	        if (sumWidth + visibleWidth <= width) {
	          sumChunks.push(chunk);
	          sumWidth += visibleWidth;
	          return;
	        }
	        wrappedLines.push(sumChunks.join(''));

	        const nextChunk = chunk.trimStart(); // trim space at line break
	        sumChunks = [nextChunk];
	        sumWidth = this.displayWidth(nextChunk);
	      });
	      wrappedLines.push(sumChunks.join(''));
	    });

	    return wrappedLines.join('\n');
	  }
	}

	/**
	 * Strip style ANSI escape sequences from the string. In particular, SGR (Select Graphic Rendition) codes.
	 *
	 * @param {string} str
	 * @returns {string}
	 * @package
	 */

	function stripColor(str) {
	  // eslint-disable-next-line no-control-regex
	  const sgrPattern = /\x1b\[\d*(;\d*)*m/g;
	  return str.replace(sgrPattern, '');
	}

	help.Help = Help;
	help.stripColor = stripColor;
	return help;
}

var option = {};

var hasRequiredOption;

function requireOption () {
	if (hasRequiredOption) return option;
	hasRequiredOption = 1;
	const { InvalidArgumentError } = requireError();

	class Option {
	  /**
	   * Initialize a new `Option` with the given `flags` and `description`.
	   *
	   * @param {string} flags
	   * @param {string} [description]
	   */

	  constructor(flags, description) {
	    this.flags = flags;
	    this.description = description || '';

	    this.required = flags.includes('<'); // A value must be supplied when the option is specified.
	    this.optional = flags.includes('['); // A value is optional when the option is specified.
	    // variadic test ignores <value,...> et al which might be used to describe custom splitting of single argument
	    this.variadic = /\w\.\.\.[>\]]$/.test(flags); // The option can take multiple values.
	    this.mandatory = false; // The option must have a value after parsing, which usually means it must be specified on command line.
	    const optionFlags = splitOptionFlags(flags);
	    this.short = optionFlags.shortFlag; // May be a short flag, undefined, or even a long flag (if option has two long flags).
	    this.long = optionFlags.longFlag;
	    this.negate = false;
	    if (this.long) {
	      this.negate = this.long.startsWith('--no-');
	    }
	    this.defaultValue = undefined;
	    this.defaultValueDescription = undefined;
	    this.presetArg = undefined;
	    this.envVar = undefined;
	    this.parseArg = undefined;
	    this.hidden = false;
	    this.argChoices = undefined;
	    this.conflictsWith = [];
	    this.implied = undefined;
	    this.helpGroupHeading = undefined; // soft initialised when option added to command
	  }

	  /**
	   * Set the default value, and optionally supply the description to be displayed in the help.
	   *
	   * @param {*} value
	   * @param {string} [description]
	   * @return {Option}
	   */

	  default(value, description) {
	    this.defaultValue = value;
	    this.defaultValueDescription = description;
	    return this;
	  }

	  /**
	   * Preset to use when option used without option-argument, especially optional but also boolean and negated.
	   * The custom processing (parseArg) is called.
	   *
	   * @example
	   * new Option('--color').default('GREYSCALE').preset('RGB');
	   * new Option('--donate [amount]').preset('20').argParser(parseFloat);
	   *
	   * @param {*} arg
	   * @return {Option}
	   */

	  preset(arg) {
	    this.presetArg = arg;
	    return this;
	  }

	  /**
	   * Add option name(s) that conflict with this option.
	   * An error will be displayed if conflicting options are found during parsing.
	   *
	   * @example
	   * new Option('--rgb').conflicts('cmyk');
	   * new Option('--js').conflicts(['ts', 'jsx']);
	   *
	   * @param {(string | string[])} names
	   * @return {Option}
	   */

	  conflicts(names) {
	    this.conflictsWith = this.conflictsWith.concat(names);
	    return this;
	  }

	  /**
	   * Specify implied option values for when this option is set and the implied options are not.
	   *
	   * The custom processing (parseArg) is not called on the implied values.
	   *
	   * @example
	   * program
	   *   .addOption(new Option('--log', 'write logging information to file'))
	   *   .addOption(new Option('--trace', 'log extra details').implies({ log: 'trace.txt' }));
	   *
	   * @param {object} impliedOptionValues
	   * @return {Option}
	   */
	  implies(impliedOptionValues) {
	    let newImplied = impliedOptionValues;
	    if (typeof impliedOptionValues === 'string') {
	      // string is not documented, but easy mistake and we can do what user probably intended.
	      newImplied = { [impliedOptionValues]: true };
	    }
	    this.implied = Object.assign(this.implied || {}, newImplied);
	    return this;
	  }

	  /**
	   * Set environment variable to check for option value.
	   *
	   * An environment variable is only used if when processed the current option value is
	   * undefined, or the source of the current value is 'default' or 'config' or 'env'.
	   *
	   * @param {string} name
	   * @return {Option}
	   */

	  env(name) {
	    this.envVar = name;
	    return this;
	  }

	  /**
	   * Set the custom handler for processing CLI option arguments into option values.
	   *
	   * @param {Function} [fn]
	   * @return {Option}
	   */

	  argParser(fn) {
	    this.parseArg = fn;
	    return this;
	  }

	  /**
	   * Whether the option is mandatory and must have a value after parsing.
	   *
	   * @param {boolean} [mandatory=true]
	   * @return {Option}
	   */

	  makeOptionMandatory(mandatory = true) {
	    this.mandatory = !!mandatory;
	    return this;
	  }

	  /**
	   * Hide option in help.
	   *
	   * @param {boolean} [hide=true]
	   * @return {Option}
	   */

	  hideHelp(hide = true) {
	    this.hidden = !!hide;
	    return this;
	  }

	  /**
	   * @package
	   */

	  _concatValue(value, previous) {
	    if (previous === this.defaultValue || !Array.isArray(previous)) {
	      return [value];
	    }

	    return previous.concat(value);
	  }

	  /**
	   * Only allow option value to be one of choices.
	   *
	   * @param {string[]} values
	   * @return {Option}
	   */

	  choices(values) {
	    this.argChoices = values.slice();
	    this.parseArg = (arg, previous) => {
	      if (!this.argChoices.includes(arg)) {
	        throw new InvalidArgumentError(
	          `Allowed choices are ${this.argChoices.join(', ')}.`,
	        );
	      }
	      if (this.variadic) {
	        return this._concatValue(arg, previous);
	      }
	      return arg;
	    };
	    return this;
	  }

	  /**
	   * Return option name.
	   *
	   * @return {string}
	   */

	  name() {
	    if (this.long) {
	      return this.long.replace(/^--/, '');
	    }
	    return this.short.replace(/^-/, '');
	  }

	  /**
	   * Return option name, in a camelcase format that can be used
	   * as an object attribute key.
	   *
	   * @return {string}
	   */

	  attributeName() {
	    if (this.negate) {
	      return camelcase(this.name().replace(/^no-/, ''));
	    }
	    return camelcase(this.name());
	  }

	  /**
	   * Set the help group heading.
	   *
	   * @param {string} heading
	   * @return {Option}
	   */
	  helpGroup(heading) {
	    this.helpGroupHeading = heading;
	    return this;
	  }

	  /**
	   * Check if `arg` matches the short or long flag.
	   *
	   * @param {string} arg
	   * @return {boolean}
	   * @package
	   */

	  is(arg) {
	    return this.short === arg || this.long === arg;
	  }

	  /**
	   * Return whether a boolean option.
	   *
	   * Options are one of boolean, negated, required argument, or optional argument.
	   *
	   * @return {boolean}
	   * @package
	   */

	  isBoolean() {
	    return !this.required && !this.optional && !this.negate;
	  }
	}

	/**
	 * This class is to make it easier to work with dual options, without changing the existing
	 * implementation. We support separate dual options for separate positive and negative options,
	 * like `--build` and `--no-build`, which share a single option value. This works nicely for some
	 * use cases, but is tricky for others where we want separate behaviours despite
	 * the single shared option value.
	 */
	class DualOptions {
	  /**
	   * @param {Option[]} options
	   */
	  constructor(options) {
	    this.positiveOptions = new Map();
	    this.negativeOptions = new Map();
	    this.dualOptions = new Set();
	    options.forEach((option) => {
	      if (option.negate) {
	        this.negativeOptions.set(option.attributeName(), option);
	      } else {
	        this.positiveOptions.set(option.attributeName(), option);
	      }
	    });
	    this.negativeOptions.forEach((value, key) => {
	      if (this.positiveOptions.has(key)) {
	        this.dualOptions.add(key);
	      }
	    });
	  }

	  /**
	   * Did the value come from the option, and not from possible matching dual option?
	   *
	   * @param {*} value
	   * @param {Option} option
	   * @returns {boolean}
	   */
	  valueFromOption(value, option) {
	    const optionKey = option.attributeName();
	    if (!this.dualOptions.has(optionKey)) return true;

	    // Use the value to deduce if (probably) came from the option.
	    const preset = this.negativeOptions.get(optionKey).presetArg;
	    const negativeValue = preset !== undefined ? preset : false;
	    return option.negate === (negativeValue === value);
	  }
	}

	/**
	 * Convert string from kebab-case to camelCase.
	 *
	 * @param {string} str
	 * @return {string}
	 * @private
	 */

	function camelcase(str) {
	  return str.split('-').reduce((str, word) => {
	    return str + word[0].toUpperCase() + word.slice(1);
	  });
	}

	/**
	 * Split the short and long flag out of something like '-m,--mixed <value>'
	 *
	 * @private
	 */

	function splitOptionFlags(flags) {
	  let shortFlag;
	  let longFlag;
	  // short flag, single dash and single character
	  const shortFlagExp = /^-[^-]$/;
	  // long flag, double dash and at least one character
	  const longFlagExp = /^--[^-]/;

	  const flagParts = flags.split(/[ |,]+/).concat('guard');
	  // Normal is short and/or long.
	  if (shortFlagExp.test(flagParts[0])) shortFlag = flagParts.shift();
	  if (longFlagExp.test(flagParts[0])) longFlag = flagParts.shift();
	  // Long then short. Rarely used but fine.
	  if (!shortFlag && shortFlagExp.test(flagParts[0]))
	    shortFlag = flagParts.shift();
	  // Allow two long flags, like '--ws, --workspace'
	  // This is the supported way to have a shortish option flag.
	  if (!shortFlag && longFlagExp.test(flagParts[0])) {
	    shortFlag = longFlag;
	    longFlag = flagParts.shift();
	  }

	  // Check for unprocessed flag. Fail noisily rather than silently ignore.
	  if (flagParts[0].startsWith('-')) {
	    const unsupportedFlag = flagParts[0];
	    const baseError = `option creation failed due to '${unsupportedFlag}' in option flags '${flags}'`;
	    if (/^-[^-][^-]/.test(unsupportedFlag))
	      throw new Error(
	        `${baseError}
- a short flag is a single dash and a single character
  - either use a single dash and a single character (for a short flag)
  - or use a double dash for a long option (and can have two, like '--ws, --workspace')`,
	      );
	    if (shortFlagExp.test(unsupportedFlag))
	      throw new Error(`${baseError}
- too many short flags`);
	    if (longFlagExp.test(unsupportedFlag))
	      throw new Error(`${baseError}
- too many long flags`);

	    throw new Error(`${baseError}
- unrecognised flag format`);
	  }
	  if (shortFlag === undefined && longFlag === undefined)
	    throw new Error(
	      `option creation failed due to no flags found in '${flags}'.`,
	    );

	  return { shortFlag, longFlag };
	}

	option.Option = Option;
	option.DualOptions = DualOptions;
	return option;
}

var suggestSimilar = {};

var hasRequiredSuggestSimilar;

function requireSuggestSimilar () {
	if (hasRequiredSuggestSimilar) return suggestSimilar;
	hasRequiredSuggestSimilar = 1;
	const maxDistance = 3;

	function editDistance(a, b) {
	  // https://en.wikipedia.org/wiki/Damerauâ€“Levenshtein_distance
	  // Calculating optimal string alignment distance, no substring is edited more than once.
	  // (Simple implementation.)

	  // Quick early exit, return worst case.
	  if (Math.abs(a.length - b.length) > maxDistance)
	    return Math.max(a.length, b.length);

	  // distance between prefix substrings of a and b
	  const d = [];

	  // pure deletions turn a into empty string
	  for (let i = 0; i <= a.length; i++) {
	    d[i] = [i];
	  }
	  // pure insertions turn empty string into b
	  for (let j = 0; j <= b.length; j++) {
	    d[0][j] = j;
	  }

	  // fill matrix
	  for (let j = 1; j <= b.length; j++) {
	    for (let i = 1; i <= a.length; i++) {
	      let cost = 1;
	      if (a[i - 1] === b[j - 1]) {
	        cost = 0;
	      } else {
	        cost = 1;
	      }
	      d[i][j] = Math.min(
	        d[i - 1][j] + 1, // deletion
	        d[i][j - 1] + 1, // insertion
	        d[i - 1][j - 1] + cost, // substitution
	      );
	      // transposition
	      if (i > 1 && j > 1 && a[i - 1] === b[j - 2] && a[i - 2] === b[j - 1]) {
	        d[i][j] = Math.min(d[i][j], d[i - 2][j - 2] + 1);
	      }
	    }
	  }

	  return d[a.length][b.length];
	}

	/**
	 * Find close matches, restricted to same number of edits.
	 *
	 * @param {string} word
	 * @param {string[]} candidates
	 * @returns {string}
	 */

	function suggestSimilar$1(word, candidates) {
	  if (!candidates || candidates.length === 0) return '';
	  // remove possible duplicates
	  candidates = Array.from(new Set(candidates));

	  const searchingOptions = word.startsWith('--');
	  if (searchingOptions) {
	    word = word.slice(2);
	    candidates = candidates.map((candidate) => candidate.slice(2));
	  }

	  let similar = [];
	  let bestDistance = maxDistance;
	  const minSimilarity = 0.4;
	  candidates.forEach((candidate) => {
	    if (candidate.length <= 1) return; // no one character guesses

	    const distance = editDistance(word, candidate);
	    const length = Math.max(word.length, candidate.length);
	    const similarity = (length - distance) / length;
	    if (similarity > minSimilarity) {
	      if (distance < bestDistance) {
	        // better edit distance, throw away previous worse matches
	        bestDistance = distance;
	        similar = [candidate];
	      } else if (distance === bestDistance) {
	        similar.push(candidate);
	      }
	    }
	  });

	  similar.sort((a, b) => a.localeCompare(b));
	  if (searchingOptions) {
	    similar = similar.map((candidate) => `--${candidate}`);
	  }

	  if (similar.length > 1) {
	    return `\n(Did you mean one of ${similar.join(', ')}?)`;
	  }
	  if (similar.length === 1) {
	    return `\n(Did you mean ${similar[0]}?)`;
	  }
	  return '';
	}

	suggestSimilar.suggestSimilar = suggestSimilar$1;
	return suggestSimilar;
}

var hasRequiredCommand;

function requireCommand () {
	if (hasRequiredCommand) return command;
	hasRequiredCommand = 1;
	const EventEmitter = require$$0.EventEmitter;
	const childProcess = require$$1;
	const path = require$$2;
	const fs = require$$3;
	const process = require$$4;

	const { Argument, humanReadableArgName } = requireArgument();
	const { CommanderError } = requireError();
	const { Help, stripColor } = requireHelp();
	const { Option, DualOptions } = requireOption();
	const { suggestSimilar } = requireSuggestSimilar();

	class Command extends EventEmitter {
	  /**
	   * Initialize a new `Command`.
	   *
	   * @param {string} [name]
	   */

	  constructor(name) {
	    super();
	    /** @type {Command[]} */
	    this.commands = [];
	    /** @type {Option[]} */
	    this.options = [];
	    this.parent = null;
	    this._allowUnknownOption = false;
	    this._allowExcessArguments = false;
	    /** @type {Argument[]} */
	    this.registeredArguments = [];
	    this._args = this.registeredArguments; // deprecated old name
	    /** @type {string[]} */
	    this.args = []; // cli args with options removed
	    this.rawArgs = [];
	    this.processedArgs = []; // like .args but after custom processing and collecting variadic
	    this._scriptPath = null;
	    this._name = name || '';
	    this._optionValues = {};
	    this._optionValueSources = {}; // default, env, cli etc
	    this._storeOptionsAsProperties = false;
	    this._actionHandler = null;
	    this._executableHandler = false;
	    this._executableFile = null; // custom name for executable
	    this._executableDir = null; // custom search directory for subcommands
	    this._defaultCommandName = null;
	    this._exitCallback = null;
	    this._aliases = [];
	    this._combineFlagAndOptionalValue = true;
	    this._description = '';
	    this._summary = '';
	    this._argsDescription = undefined; // legacy
	    this._enablePositionalOptions = false;
	    this._passThroughOptions = false;
	    this._lifeCycleHooks = {}; // a hash of arrays
	    /** @type {(boolean | string)} */
	    this._showHelpAfterError = false;
	    this._showSuggestionAfterError = true;
	    this._savedState = null; // used in save/restoreStateBeforeParse

	    // see configureOutput() for docs
	    this._outputConfiguration = {
	      writeOut: (str) => process.stdout.write(str),
	      writeErr: (str) => process.stderr.write(str),
	      outputError: (str, write) => write(str),
	      getOutHelpWidth: () =>
	        process.stdout.isTTY ? process.stdout.columns : undefined,
	      getErrHelpWidth: () =>
	        process.stderr.isTTY ? process.stderr.columns : undefined,
	      getOutHasColors: () =>
	        useColor() ?? (process.stdout.isTTY && process.stdout.hasColors?.()),
	      getErrHasColors: () =>
	        useColor() ?? (process.stderr.isTTY && process.stderr.hasColors?.()),
	      stripColor: (str) => stripColor(str),
	    };

	    this._hidden = false;
	    /** @type {(Option | null | undefined)} */
	    this._helpOption = undefined; // Lazy created on demand. May be null if help option is disabled.
	    this._addImplicitHelpCommand = undefined; // undecided whether true or false yet, not inherited
	    /** @type {Command} */
	    this._helpCommand = undefined; // lazy initialised, inherited
	    this._helpConfiguration = {};
	    /** @type {string | undefined} */
	    this._helpGroupHeading = undefined; // soft initialised when added to parent
	    /** @type {string | undefined} */
	    this._defaultCommandGroup = undefined;
	    /** @type {string | undefined} */
	    this._defaultOptionGroup = undefined;
	  }

	  /**
	   * Copy settings that are useful to have in common across root command and subcommands.
	   *
	   * (Used internally when adding a command using `.command()` so subcommands inherit parent settings.)
	   *
	   * @param {Command} sourceCommand
	   * @return {Command} `this` command for chaining
	   */
	  copyInheritedSettings(sourceCommand) {
	    this._outputConfiguration = sourceCommand._outputConfiguration;
	    this._helpOption = sourceCommand._helpOption;
	    this._helpCommand = sourceCommand._helpCommand;
	    this._helpConfiguration = sourceCommand._helpConfiguration;
	    this._exitCallback = sourceCommand._exitCallback;
	    this._storeOptionsAsProperties = sourceCommand._storeOptionsAsProperties;
	    this._combineFlagAndOptionalValue =
	      sourceCommand._combineFlagAndOptionalValue;
	    this._allowExcessArguments = sourceCommand._allowExcessArguments;
	    this._enablePositionalOptions = sourceCommand._enablePositionalOptions;
	    this._showHelpAfterError = sourceCommand._showHelpAfterError;
	    this._showSuggestionAfterError = sourceCommand._showSuggestionAfterError;

	    return this;
	  }

	  /**
	   * @returns {Command[]}
	   * @private
	   */

	  _getCommandAndAncestors() {
	    const result = [];
	    // eslint-disable-next-line @typescript-eslint/no-this-alias
	    for (let command = this; command; command = command.parent) {
	      result.push(command);
	    }
	    return result;
	  }

	  /**
	   * Define a command.
	   *
	   * There are two styles of command: pay attention to where to put the description.
	   *
	   * @example
	   * // Command implemented using action handler (description is supplied separately to `.command`)
	   * program
	   *   .command('clone <source> [destination]')
	   *   .description('clone a repository into a newly created directory')
	   *   .action((source, destination) => {
	   *     console.log('clone command called');
	   *   });
	   *
	   * // Command implemented using separate executable file (description is second parameter to `.command`)
	   * program
	   *   .command('start <service>', 'start named service')
	   *   .command('stop [service]', 'stop named service, or all if no name supplied');
	   *
	   * @param {string} nameAndArgs - command name and arguments, args are `<required>` or `[optional]` and last may also be `variadic...`
	   * @param {(object | string)} [actionOptsOrExecDesc] - configuration options (for action), or description (for executable)
	   * @param {object} [execOpts] - configuration options (for executable)
	   * @return {Command} returns new command for action handler, or `this` for executable command
	   */

	  command(nameAndArgs, actionOptsOrExecDesc, execOpts) {
	    let desc = actionOptsOrExecDesc;
	    let opts = execOpts;
	    if (typeof desc === 'object' && desc !== null) {
	      opts = desc;
	      desc = null;
	    }
	    opts = opts || {};
	    const [, name, args] = nameAndArgs.match(/([^ ]+) *(.*)/);

	    const cmd = this.createCommand(name);
	    if (desc) {
	      cmd.description(desc);
	      cmd._executableHandler = true;
	    }
	    if (opts.isDefault) this._defaultCommandName = cmd._name;
	    cmd._hidden = !!(opts.noHelp || opts.hidden); // noHelp is deprecated old name for hidden
	    cmd._executableFile = opts.executableFile || null; // Custom name for executable file, set missing to null to match constructor
	    if (args) cmd.arguments(args);
	    this._registerCommand(cmd);
	    cmd.parent = this;
	    cmd.copyInheritedSettings(this);

	    if (desc) return this;
	    return cmd;
	  }

	  /**
	   * Factory routine to create a new unattached command.
	   *
	   * See .command() for creating an attached subcommand, which uses this routine to
	   * create the command. You can override createCommand to customise subcommands.
	   *
	   * @param {string} [name]
	   * @return {Command} new command
	   */

	  createCommand(name) {
	    return new Command(name);
	  }

	  /**
	   * You can customise the help with a subclass of Help by overriding createHelp,
	   * or by overriding Help properties using configureHelp().
	   *
	   * @return {Help}
	   */

	  createHelp() {
	    return Object.assign(new Help(), this.configureHelp());
	  }

	  /**
	   * You can customise the help by overriding Help properties using configureHelp(),
	   * or with a subclass of Help by overriding createHelp().
	   *
	   * @param {object} [configuration] - configuration options
	   * @return {(Command | object)} `this` command for chaining, or stored configuration
	   */

	  configureHelp(configuration) {
	    if (configuration === undefined) return this._helpConfiguration;

	    this._helpConfiguration = configuration;
	    return this;
	  }

	  /**
	   * The default output goes to stdout and stderr. You can customise this for special
	   * applications. You can also customise the display of errors by overriding outputError.
	   *
	   * The configuration properties are all functions:
	   *
	   *     // change how output being written, defaults to stdout and stderr
	   *     writeOut(str)
	   *     writeErr(str)
	   *     // change how output being written for errors, defaults to writeErr
	   *     outputError(str, write) // used for displaying errors and not used for displaying help
	   *     // specify width for wrapping help
	   *     getOutHelpWidth()
	   *     getErrHelpWidth()
	   *     // color support, currently only used with Help
	   *     getOutHasColors()
	   *     getErrHasColors()
	   *     stripColor() // used to remove ANSI escape codes if output does not have colors
	   *
	   * @param {object} [configuration] - configuration options
	   * @return {(Command | object)} `this` command for chaining, or stored configuration
	   */

	  configureOutput(configuration) {
	    if (configuration === undefined) return this._outputConfiguration;

	    this._outputConfiguration = Object.assign(
	      {},
	      this._outputConfiguration,
	      configuration,
	    );
	    return this;
	  }

	  /**
	   * Display the help or a custom message after an error occurs.
	   *
	   * @param {(boolean|string)} [displayHelp]
	   * @return {Command} `this` command for chaining
	   */
	  showHelpAfterError(displayHelp = true) {
	    if (typeof displayHelp !== 'string') displayHelp = !!displayHelp;
	    this._showHelpAfterError = displayHelp;
	    return this;
	  }

	  /**
	   * Display suggestion of similar commands for unknown commands, or options for unknown options.
	   *
	   * @param {boolean} [displaySuggestion]
	   * @return {Command} `this` command for chaining
	   */
	  showSuggestionAfterError(displaySuggestion = true) {
	    this._showSuggestionAfterError = !!displaySuggestion;
	    return this;
	  }

	  /**
	   * Add a prepared subcommand.
	   *
	   * See .command() for creating an attached subcommand which inherits settings from its parent.
	   *
	   * @param {Command} cmd - new subcommand
	   * @param {object} [opts] - configuration options
	   * @return {Command} `this` command for chaining
	   */

	  addCommand(cmd, opts) {
	    if (!cmd._name) {
	      throw new Error(`Command passed to .addCommand() must have a name
- specify the name in Command constructor or using .name()`);
	    }

	    opts = opts || {};
	    if (opts.isDefault) this._defaultCommandName = cmd._name;
	    if (opts.noHelp || opts.hidden) cmd._hidden = true; // modifying passed command due to existing implementation

	    this._registerCommand(cmd);
	    cmd.parent = this;
	    cmd._checkForBrokenPassThrough();

	    return this;
	  }

	  /**
	   * Factory routine to create a new unattached argument.
	   *
	   * See .argument() for creating an attached argument, which uses this routine to
	   * create the argument. You can override createArgument to return a custom argument.
	   *
	   * @param {string} name
	   * @param {string} [description]
	   * @return {Argument} new argument
	   */

	  createArgument(name, description) {
	    return new Argument(name, description);
	  }

	  /**
	   * Define argument syntax for command.
	   *
	   * The default is that the argument is required, and you can explicitly
	   * indicate this with <> around the name. Put [] around the name for an optional argument.
	   *
	   * @example
	   * program.argument('<input-file>');
	   * program.argument('[output-file]');
	   *
	   * @param {string} name
	   * @param {string} [description]
	   * @param {(Function|*)} [parseArg] - custom argument processing function or default value
	   * @param {*} [defaultValue]
	   * @return {Command} `this` command for chaining
	   */
	  argument(name, description, parseArg, defaultValue) {
	    const argument = this.createArgument(name, description);
	    if (typeof parseArg === 'function') {
	      argument.default(defaultValue).argParser(parseArg);
	    } else {
	      argument.default(parseArg);
	    }
	    this.addArgument(argument);
	    return this;
	  }

	  /**
	   * Define argument syntax for command, adding multiple at once (without descriptions).
	   *
	   * See also .argument().
	   *
	   * @example
	   * program.arguments('<cmd> [env]');
	   *
	   * @param {string} names
	   * @return {Command} `this` command for chaining
	   */

	  arguments(names) {
	    names
	      .trim()
	      .split(/ +/)
	      .forEach((detail) => {
	        this.argument(detail);
	      });
	    return this;
	  }

	  /**
	   * Define argument syntax for command, adding a prepared argument.
	   *
	   * @param {Argument} argument
	   * @return {Command} `this` command for chaining
	   */
	  addArgument(argument) {
	    const previousArgument = this.registeredArguments.slice(-1)[0];
	    if (previousArgument && previousArgument.variadic) {
	      throw new Error(
	        `only the last argument can be variadic '${previousArgument.name()}'`,
	      );
	    }
	    if (
	      argument.required &&
	      argument.defaultValue !== undefined &&
	      argument.parseArg === undefined
	    ) {
	      throw new Error(
	        `a default value for a required argument is never used: '${argument.name()}'`,
	      );
	    }
	    this.registeredArguments.push(argument);
	    return this;
	  }

	  /**
	   * Customise or override default help command. By default a help command is automatically added if your command has subcommands.
	   *
	   * @example
	   *    program.helpCommand('help [cmd]');
	   *    program.helpCommand('help [cmd]', 'show help');
	   *    program.helpCommand(false); // suppress default help command
	   *    program.helpCommand(true); // add help command even if no subcommands
	   *
	   * @param {string|boolean} enableOrNameAndArgs - enable with custom name and/or arguments, or boolean to override whether added
	   * @param {string} [description] - custom description
	   * @return {Command} `this` command for chaining
	   */

	  helpCommand(enableOrNameAndArgs, description) {
	    if (typeof enableOrNameAndArgs === 'boolean') {
	      this._addImplicitHelpCommand = enableOrNameAndArgs;
	      if (enableOrNameAndArgs && this._defaultCommandGroup) {
	        // make the command to store the group
	        this._initCommandGroup(this._getHelpCommand());
	      }
	      return this;
	    }

	    const nameAndArgs = enableOrNameAndArgs ?? 'help [command]';
	    const [, helpName, helpArgs] = nameAndArgs.match(/([^ ]+) *(.*)/);
	    const helpDescription = description ?? 'display help for command';

	    const helpCommand = this.createCommand(helpName);
	    helpCommand.helpOption(false);
	    if (helpArgs) helpCommand.arguments(helpArgs);
	    if (helpDescription) helpCommand.description(helpDescription);

	    this._addImplicitHelpCommand = true;
	    this._helpCommand = helpCommand;
	    // init group unless lazy create
	    if (enableOrNameAndArgs || description) this._initCommandGroup(helpCommand);

	    return this;
	  }

	  /**
	   * Add prepared custom help command.
	   *
	   * @param {(Command|string|boolean)} helpCommand - custom help command, or deprecated enableOrNameAndArgs as for `.helpCommand()`
	   * @param {string} [deprecatedDescription] - deprecated custom description used with custom name only
	   * @return {Command} `this` command for chaining
	   */
	  addHelpCommand(helpCommand, deprecatedDescription) {
	    // If not passed an object, call through to helpCommand for backwards compatibility,
	    // as addHelpCommand was originally used like helpCommand is now.
	    if (typeof helpCommand !== 'object') {
	      this.helpCommand(helpCommand, deprecatedDescription);
	      return this;
	    }

	    this._addImplicitHelpCommand = true;
	    this._helpCommand = helpCommand;
	    this._initCommandGroup(helpCommand);
	    return this;
	  }

	  /**
	   * Lazy create help command.
	   *
	   * @return {(Command|null)}
	   * @package
	   */
	  _getHelpCommand() {
	    const hasImplicitHelpCommand =
	      this._addImplicitHelpCommand ??
	      (this.commands.length &&
	        !this._actionHandler &&
	        !this._findCommand('help'));

	    if (hasImplicitHelpCommand) {
	      if (this._helpCommand === undefined) {
	        this.helpCommand(undefined, undefined); // use default name and description
	      }
	      return this._helpCommand;
	    }
	    return null;
	  }

	  /**
	   * Add hook for life cycle event.
	   *
	   * @param {string} event
	   * @param {Function} listener
	   * @return {Command} `this` command for chaining
	   */

	  hook(event, listener) {
	    const allowedValues = ['preSubcommand', 'preAction', 'postAction'];
	    if (!allowedValues.includes(event)) {
	      throw new Error(`Unexpected value for event passed to hook : '${event}'.
Expecting one of '${allowedValues.join("', '")}'`);
	    }
	    if (this._lifeCycleHooks[event]) {
	      this._lifeCycleHooks[event].push(listener);
	    } else {
	      this._lifeCycleHooks[event] = [listener];
	    }
	    return this;
	  }

	  /**
	   * Register callback to use as replacement for calling process.exit.
	   *
	   * @param {Function} [fn] optional callback which will be passed a CommanderError, defaults to throwing
	   * @return {Command} `this` command for chaining
	   */

	  exitOverride(fn) {
	    if (fn) {
	      this._exitCallback = fn;
	    } else {
	      this._exitCallback = (err) => {
	        if (err.code !== 'commander.executeSubCommandAsync') {
	          throw err;
	        }
	      };
	    }
	    return this;
	  }

	  /**
	   * Call process.exit, and _exitCallback if defined.
	   *
	   * @param {number} exitCode exit code for using with process.exit
	   * @param {string} code an id string representing the error
	   * @param {string} message human-readable description of the error
	   * @return never
	   * @private
	   */

	  _exit(exitCode, code, message) {
	    if (this._exitCallback) {
	      this._exitCallback(new CommanderError(exitCode, code, message));
	      // Expecting this line is not reached.
	    }
	    process.exit(exitCode);
	  }

	  /**
	   * Register callback `fn` for the command.
	   *
	   * @example
	   * program
	   *   .command('serve')
	   *   .description('start service')
	   *   .action(function() {
	   *      // do work here
	   *   });
	   *
	   * @param {Function} fn
	   * @return {Command} `this` command for chaining
	   */

	  action(fn) {
	    const listener = (args) => {
	      // The .action callback takes an extra parameter which is the command or options.
	      const expectedArgsCount = this.registeredArguments.length;
	      const actionArgs = args.slice(0, expectedArgsCount);
	      if (this._storeOptionsAsProperties) {
	        actionArgs[expectedArgsCount] = this; // backwards compatible "options"
	      } else {
	        actionArgs[expectedArgsCount] = this.opts();
	      }
	      actionArgs.push(this);

	      return fn.apply(this, actionArgs);
	    };
	    this._actionHandler = listener;
	    return this;
	  }

	  /**
	   * Factory routine to create a new unattached option.
	   *
	   * See .option() for creating an attached option, which uses this routine to
	   * create the option. You can override createOption to return a custom option.
	   *
	   * @param {string} flags
	   * @param {string} [description]
	   * @return {Option} new option
	   */

	  createOption(flags, description) {
	    return new Option(flags, description);
	  }

	  /**
	   * Wrap parseArgs to catch 'commander.invalidArgument'.
	   *
	   * @param {(Option | Argument)} target
	   * @param {string} value
	   * @param {*} previous
	   * @param {string} invalidArgumentMessage
	   * @private
	   */

	  _callParseArg(target, value, previous, invalidArgumentMessage) {
	    try {
	      return target.parseArg(value, previous);
	    } catch (err) {
	      if (err.code === 'commander.invalidArgument') {
	        const message = `${invalidArgumentMessage} ${err.message}`;
	        this.error(message, { exitCode: err.exitCode, code: err.code });
	      }
	      throw err;
	    }
	  }

	  /**
	   * Check for option flag conflicts.
	   * Register option if no conflicts found, or throw on conflict.
	   *
	   * @param {Option} option
	   * @private
	   */

	  _registerOption(option) {
	    const matchingOption =
	      (option.short && this._findOption(option.short)) ||
	      (option.long && this._findOption(option.long));
	    if (matchingOption) {
	      const matchingFlag =
	        option.long && this._findOption(option.long)
	          ? option.long
	          : option.short;
	      throw new Error(`Cannot add option '${option.flags}'${this._name && ` to command '${this._name}'`} due to conflicting flag '${matchingFlag}'
-  already used by option '${matchingOption.flags}'`);
	    }

	    this._initOptionGroup(option);
	    this.options.push(option);
	  }

	  /**
	   * Check for command name and alias conflicts with existing commands.
	   * Register command if no conflicts found, or throw on conflict.
	   *
	   * @param {Command} command
	   * @private
	   */

	  _registerCommand(command) {
	    const knownBy = (cmd) => {
	      return [cmd.name()].concat(cmd.aliases());
	    };

	    const alreadyUsed = knownBy(command).find((name) =>
	      this._findCommand(name),
	    );
	    if (alreadyUsed) {
	      const existingCmd = knownBy(this._findCommand(alreadyUsed)).join('|');
	      const newCmd = knownBy(command).join('|');
	      throw new Error(
	        `cannot add command '${newCmd}' as already have command '${existingCmd}'`,
	      );
	    }

	    this._initCommandGroup(command);
	    this.commands.push(command);
	  }

	  /**
	   * Add an option.
	   *
	   * @param {Option} option
	   * @return {Command} `this` command for chaining
	   */
	  addOption(option) {
	    this._registerOption(option);

	    const oname = option.name();
	    const name = option.attributeName();

	    // store default value
	    if (option.negate) {
	      // --no-foo is special and defaults foo to true, unless a --foo option is already defined
	      const positiveLongFlag = option.long.replace(/^--no-/, '--');
	      if (!this._findOption(positiveLongFlag)) {
	        this.setOptionValueWithSource(
	          name,
	          option.defaultValue === undefined ? true : option.defaultValue,
	          'default',
	        );
	      }
	    } else if (option.defaultValue !== undefined) {
	      this.setOptionValueWithSource(name, option.defaultValue, 'default');
	    }

	    // handler for cli and env supplied values
	    const handleOptionValue = (val, invalidValueMessage, valueSource) => {
	      // val is null for optional option used without an optional-argument.
	      // val is undefined for boolean and negated option.
	      if (val == null && option.presetArg !== undefined) {
	        val = option.presetArg;
	      }

	      // custom processing
	      const oldValue = this.getOptionValue(name);
	      if (val !== null && option.parseArg) {
	        val = this._callParseArg(option, val, oldValue, invalidValueMessage);
	      } else if (val !== null && option.variadic) {
	        val = option._concatValue(val, oldValue);
	      }

	      // Fill-in appropriate missing values. Long winded but easy to follow.
	      if (val == null) {
	        if (option.negate) {
	          val = false;
	        } else if (option.isBoolean() || option.optional) {
	          val = true;
	        } else {
	          val = ''; // not normal, parseArg might have failed or be a mock function for testing
	        }
	      }
	      this.setOptionValueWithSource(name, val, valueSource);
	    };

	    this.on('option:' + oname, (val) => {
	      const invalidValueMessage = `error: option '${option.flags}' argument '${val}' is invalid.`;
	      handleOptionValue(val, invalidValueMessage, 'cli');
	    });

	    if (option.envVar) {
	      this.on('optionEnv:' + oname, (val) => {
	        const invalidValueMessage = `error: option '${option.flags}' value '${val}' from env '${option.envVar}' is invalid.`;
	        handleOptionValue(val, invalidValueMessage, 'env');
	      });
	    }

	    return this;
	  }

	  /**
	   * Internal implementation shared by .option() and .requiredOption()
	   *
	   * @return {Command} `this` command for chaining
	   * @private
	   */
	  _optionEx(config, flags, description, fn, defaultValue) {
	    if (typeof flags === 'object' && flags instanceof Option) {
	      throw new Error(
	        'To add an Option object use addOption() instead of option() or requiredOption()',
	      );
	    }
	    const option = this.createOption(flags, description);
	    option.makeOptionMandatory(!!config.mandatory);
	    if (typeof fn === 'function') {
	      option.default(defaultValue).argParser(fn);
	    } else if (fn instanceof RegExp) {
	      // deprecated
	      const regex = fn;
	      fn = (val, def) => {
	        const m = regex.exec(val);
	        return m ? m[0] : def;
	      };
	      option.default(defaultValue).argParser(fn);
	    } else {
	      option.default(fn);
	    }

	    return this.addOption(option);
	  }

	  /**
	   * Define option with `flags`, `description`, and optional argument parsing function or `defaultValue` or both.
	   *
	   * The `flags` string contains the short and/or long flags, separated by comma, a pipe or space. A required
	   * option-argument is indicated by `<>` and an optional option-argument by `[]`.
	   *
	   * See the README for more details, and see also addOption() and requiredOption().
	   *
	   * @example
	   * program
	   *     .option('-p, --pepper', 'add pepper')
	   *     .option('--pt, --pizza-type <TYPE>', 'type of pizza') // required option-argument
	   *     .option('-c, --cheese [CHEESE]', 'add extra cheese', 'mozzarella') // optional option-argument with default
	   *     .option('-t, --tip <VALUE>', 'add tip to purchase cost', parseFloat) // custom parse function
	   *
	   * @param {string} flags
	   * @param {string} [description]
	   * @param {(Function|*)} [parseArg] - custom option processing function or default value
	   * @param {*} [defaultValue]
	   * @return {Command} `this` command for chaining
	   */

	  option(flags, description, parseArg, defaultValue) {
	    return this._optionEx({}, flags, description, parseArg, defaultValue);
	  }

	  /**
	   * Add a required option which must have a value after parsing. This usually means
	   * the option must be specified on the command line. (Otherwise the same as .option().)
	   *
	   * The `flags` string contains the short and/or long flags, separated by comma, a pipe or space.
	   *
	   * @param {string} flags
	   * @param {string} [description]
	   * @param {(Function|*)} [parseArg] - custom option processing function or default value
	   * @param {*} [defaultValue]
	   * @return {Command} `this` command for chaining
	   */

	  requiredOption(flags, description, parseArg, defaultValue) {
	    return this._optionEx(
	      { mandatory: true },
	      flags,
	      description,
	      parseArg,
	      defaultValue,
	    );
	  }

	  /**
	   * Alter parsing of short flags with optional values.
	   *
	   * @example
	   * // for `.option('-f,--flag [value]'):
	   * program.combineFlagAndOptionalValue(true);  // `-f80` is treated like `--flag=80`, this is the default behaviour
	   * program.combineFlagAndOptionalValue(false) // `-fb` is treated like `-f -b`
	   *
	   * @param {boolean} [combine] - if `true` or omitted, an optional value can be specified directly after the flag.
	   * @return {Command} `this` command for chaining
	   */
	  combineFlagAndOptionalValue(combine = true) {
	    this._combineFlagAndOptionalValue = !!combine;
	    return this;
	  }

	  /**
	   * Allow unknown options on the command line.
	   *
	   * @param {boolean} [allowUnknown] - if `true` or omitted, no error will be thrown for unknown options.
	   * @return {Command} `this` command for chaining
	   */
	  allowUnknownOption(allowUnknown = true) {
	    this._allowUnknownOption = !!allowUnknown;
	    return this;
	  }

	  /**
	   * Allow excess command-arguments on the command line. Pass false to make excess arguments an error.
	   *
	   * @param {boolean} [allowExcess] - if `true` or omitted, no error will be thrown for excess arguments.
	   * @return {Command} `this` command for chaining
	   */
	  allowExcessArguments(allowExcess = true) {
	    this._allowExcessArguments = !!allowExcess;
	    return this;
	  }

	  /**
	   * Enable positional options. Positional means global options are specified before subcommands which lets
	   * subcommands reuse the same option names, and also enables subcommands to turn on passThroughOptions.
	   * The default behaviour is non-positional and global options may appear anywhere on the command line.
	   *
	   * @param {boolean} [positional]
	   * @return {Command} `this` command for chaining
	   */
	  enablePositionalOptions(positional = true) {
	    this._enablePositionalOptions = !!positional;
	    return this;
	  }

	  /**
	   * Pass through options that come after command-arguments rather than treat them as command-options,
	   * so actual command-options come before command-arguments. Turning this on for a subcommand requires
	   * positional options to have been enabled on the program (parent commands).
	   * The default behaviour is non-positional and options may appear before or after command-arguments.
	   *
	   * @param {boolean} [passThrough] for unknown options.
	   * @return {Command} `this` command for chaining
	   */
	  passThroughOptions(passThrough = true) {
	    this._passThroughOptions = !!passThrough;
	    this._checkForBrokenPassThrough();
	    return this;
	  }

	  /**
	   * @private
	   */

	  _checkForBrokenPassThrough() {
	    if (
	      this.parent &&
	      this._passThroughOptions &&
	      !this.parent._enablePositionalOptions
	    ) {
	      throw new Error(
	        `passThroughOptions cannot be used for '${this._name}' without turning on enablePositionalOptions for parent command(s)`,
	      );
	    }
	  }

	  /**
	   * Whether to store option values as properties on command object,
	   * or store separately (specify false). In both cases the option values can be accessed using .opts().
	   *
	   * @param {boolean} [storeAsProperties=true]
	   * @return {Command} `this` command for chaining
	   */

	  storeOptionsAsProperties(storeAsProperties = true) {
	    if (this.options.length) {
	      throw new Error('call .storeOptionsAsProperties() before adding options');
	    }
	    if (Object.keys(this._optionValues).length) {
	      throw new Error(
	        'call .storeOptionsAsProperties() before setting option values',
	      );
	    }
	    this._storeOptionsAsProperties = !!storeAsProperties;
	    return this;
	  }

	  /**
	   * Retrieve option value.
	   *
	   * @param {string} key
	   * @return {object} value
	   */

	  getOptionValue(key) {
	    if (this._storeOptionsAsProperties) {
	      return this[key];
	    }
	    return this._optionValues[key];
	  }

	  /**
	   * Store option value.
	   *
	   * @param {string} key
	   * @param {object} value
	   * @return {Command} `this` command for chaining
	   */

	  setOptionValue(key, value) {
	    return this.setOptionValueWithSource(key, value, undefined);
	  }

	  /**
	   * Store option value and where the value came from.
	   *
	   * @param {string} key
	   * @param {object} value
	   * @param {string} source - expected values are default/config/env/cli/implied
	   * @return {Command} `this` command for chaining
	   */

	  setOptionValueWithSource(key, value, source) {
	    if (this._storeOptionsAsProperties) {
	      this[key] = value;
	    } else {
	      this._optionValues[key] = value;
	    }
	    this._optionValueSources[key] = source;
	    return this;
	  }

	  /**
	   * Get source of option value.
	   * Expected values are default | config | env | cli | implied
	   *
	   * @param {string} key
	   * @return {string}
	   */

	  getOptionValueSource(key) {
	    return this._optionValueSources[key];
	  }

	  /**
	   * Get source of option value. See also .optsWithGlobals().
	   * Expected values are default | config | env | cli | implied
	   *
	   * @param {string} key
	   * @return {string}
	   */

	  getOptionValueSourceWithGlobals(key) {
	    // global overwrites local, like optsWithGlobals
	    let source;
	    this._getCommandAndAncestors().forEach((cmd) => {
	      if (cmd.getOptionValueSource(key) !== undefined) {
	        source = cmd.getOptionValueSource(key);
	      }
	    });
	    return source;
	  }

	  /**
	   * Get user arguments from implied or explicit arguments.
	   * Side-effects: set _scriptPath if args included script. Used for default program name, and subcommand searches.
	   *
	   * @private
	   */

	  _prepareUserArgs(argv, parseOptions) {
	    if (argv !== undefined && !Array.isArray(argv)) {
	      throw new Error('first parameter to parse must be array or undefined');
	    }
	    parseOptions = parseOptions || {};

	    // auto-detect argument conventions if nothing supplied
	    if (argv === undefined && parseOptions.from === undefined) {
	      if (process.versions?.electron) {
	        parseOptions.from = 'electron';
	      }
	      // check node specific options for scenarios where user CLI args follow executable without scriptname
	      const execArgv = process.execArgv ?? [];
	      if (
	        execArgv.includes('-e') ||
	        execArgv.includes('--eval') ||
	        execArgv.includes('-p') ||
	        execArgv.includes('--print')
	      ) {
	        parseOptions.from = 'eval'; // internal usage, not documented
	      }
	    }

	    // default to using process.argv
	    if (argv === undefined) {
	      argv = process.argv;
	    }
	    this.rawArgs = argv.slice();

	    // extract the user args and scriptPath
	    let userArgs;
	    switch (parseOptions.from) {
	      case undefined:
	      case 'node':
	        this._scriptPath = argv[1];
	        userArgs = argv.slice(2);
	        break;
	      case 'electron':
	        // @ts-ignore: because defaultApp is an unknown property
	        if (process.defaultApp) {
	          this._scriptPath = argv[1];
	          userArgs = argv.slice(2);
	        } else {
	          userArgs = argv.slice(1);
	        }
	        break;
	      case 'user':
	        userArgs = argv.slice(0);
	        break;
	      case 'eval':
	        userArgs = argv.slice(1);
	        break;
	      default:
	        throw new Error(
	          `unexpected parse option { from: '${parseOptions.from}' }`,
	        );
	    }

	    // Find default name for program from arguments.
	    if (!this._name && this._scriptPath)
	      this.nameFromFilename(this._scriptPath);
	    this._name = this._name || 'program';

	    return userArgs;
	  }

	  /**
	   * Parse `argv`, setting options and invoking commands when defined.
	   *
	   * Use parseAsync instead of parse if any of your action handlers are async.
	   *
	   * Call with no parameters to parse `process.argv`. Detects Electron and special node options like `node --eval`. Easy mode!
	   *
	   * Or call with an array of strings to parse, and optionally where the user arguments start by specifying where the arguments are `from`:
	   * - `'node'`: default, `argv[0]` is the application and `argv[1]` is the script being run, with user arguments after that
	   * - `'electron'`: `argv[0]` is the application and `argv[1]` varies depending on whether the electron application is packaged
	   * - `'user'`: just user arguments
	   *
	   * @example
	   * program.parse(); // parse process.argv and auto-detect electron and special node flags
	   * program.parse(process.argv); // assume argv[0] is app and argv[1] is script
	   * program.parse(my-args, { from: 'user' }); // just user supplied arguments, nothing special about argv[0]
	   *
	   * @param {string[]} [argv] - optional, defaults to process.argv
	   * @param {object} [parseOptions] - optionally specify style of options with from: node/user/electron
	   * @param {string} [parseOptions.from] - where the args are from: 'node', 'user', 'electron'
	   * @return {Command} `this` command for chaining
	   */

	  parse(argv, parseOptions) {
	    this._prepareForParse();
	    const userArgs = this._prepareUserArgs(argv, parseOptions);
	    this._parseCommand([], userArgs);

	    return this;
	  }

	  /**
	   * Parse `argv`, setting options and invoking commands when defined.
	   *
	   * Call with no parameters to parse `process.argv`. Detects Electron and special node options like `node --eval`. Easy mode!
	   *
	   * Or call with an array of strings to parse, and optionally where the user arguments start by specifying where the arguments are `from`:
	   * - `'node'`: default, `argv[0]` is the application and `argv[1]` is the script being run, with user arguments after that
	   * - `'electron'`: `argv[0]` is the application and `argv[1]` varies depending on whether the electron application is packaged
	   * - `'user'`: just user arguments
	   *
	   * @example
	   * await program.parseAsync(); // parse process.argv and auto-detect electron and special node flags
	   * await program.parseAsync(process.argv); // assume argv[0] is app and argv[1] is script
	   * await program.parseAsync(my-args, { from: 'user' }); // just user supplied arguments, nothing special about argv[0]
	   *
	   * @param {string[]} [argv]
	   * @param {object} [parseOptions]
	   * @param {string} parseOptions.from - where the args are from: 'node', 'user', 'electron'
	   * @return {Promise}
	   */

	  async parseAsync(argv, parseOptions) {
	    this._prepareForParse();
	    const userArgs = this._prepareUserArgs(argv, parseOptions);
	    await this._parseCommand([], userArgs);

	    return this;
	  }

	  _prepareForParse() {
	    if (this._savedState === null) {
	      this.saveStateBeforeParse();
	    } else {
	      this.restoreStateBeforeParse();
	    }
	  }

	  /**
	   * Called the first time parse is called to save state and allow a restore before subsequent calls to parse.
	   * Not usually called directly, but available for subclasses to save their custom state.
	   *
	   * This is called in a lazy way. Only commands used in parsing chain will have state saved.
	   */
	  saveStateBeforeParse() {
	    this._savedState = {
	      // name is stable if supplied by author, but may be unspecified for root command and deduced during parsing
	      _name: this._name,
	      // option values before parse have default values (including false for negated options)
	      // shallow clones
	      _optionValues: { ...this._optionValues },
	      _optionValueSources: { ...this._optionValueSources },
	    };
	  }

	  /**
	   * Restore state before parse for calls after the first.
	   * Not usually called directly, but available for subclasses to save their custom state.
	   *
	   * This is called in a lazy way. Only commands used in parsing chain will have state restored.
	   */
	  restoreStateBeforeParse() {
	    if (this._storeOptionsAsProperties)
	      throw new Error(`Can not call parse again when storeOptionsAsProperties is true.
- either make a new Command for each call to parse, or stop storing options as properties`);

	    // clear state from _prepareUserArgs
	    this._name = this._savedState._name;
	    this._scriptPath = null;
	    this.rawArgs = [];
	    // clear state from setOptionValueWithSource
	    this._optionValues = { ...this._savedState._optionValues };
	    this._optionValueSources = { ...this._savedState._optionValueSources };
	    // clear state from _parseCommand
	    this.args = [];
	    // clear state from _processArguments
	    this.processedArgs = [];
	  }

	  /**
	   * Throw if expected executable is missing. Add lots of help for author.
	   *
	   * @param {string} executableFile
	   * @param {string} executableDir
	   * @param {string} subcommandName
	   */
	  _checkForMissingExecutable(executableFile, executableDir, subcommandName) {
	    if (fs.existsSync(executableFile)) return;

	    const executableDirMessage = executableDir
	      ? `searched for local subcommand relative to directory '${executableDir}'`
	      : 'no directory for search for local subcommand, use .executableDir() to supply a custom directory';
	    const executableMissing = `'${executableFile}' does not exist
 - if '${subcommandName}' is not meant to be an executable command, remove description parameter from '.command()' and use '.description()' instead
 - if the default executable name is not suitable, use the executableFile option to supply a custom name or path
 - ${executableDirMessage}`;
	    throw new Error(executableMissing);
	  }

	  /**
	   * Execute a sub-command executable.
	   *
	   * @private
	   */

	  _executeSubCommand(subcommand, args) {
	    args = args.slice();
	    let launchWithNode = false; // Use node for source targets so do not need to get permissions correct, and on Windows.
	    const sourceExt = ['.js', '.ts', '.tsx', '.mjs', '.cjs'];

	    function findFile(baseDir, baseName) {
	      // Look for specified file
	      const localBin = path.resolve(baseDir, baseName);
	      if (fs.existsSync(localBin)) return localBin;

	      // Stop looking if candidate already has an expected extension.
	      if (sourceExt.includes(path.extname(baseName))) return undefined;

	      // Try all the extensions.
	      const foundExt = sourceExt.find((ext) =>
	        fs.existsSync(`${localBin}${ext}`),
	      );
	      if (foundExt) return `${localBin}${foundExt}`;

	      return undefined;
	    }

	    // Not checking for help first. Unlikely to have mandatory and executable, and can't robustly test for help flags in external command.
	    this._checkForMissingMandatoryOptions();
	    this._checkForConflictingOptions();

	    // executableFile and executableDir might be full path, or just a name
	    let executableFile =
	      subcommand._executableFile || `${this._name}-${subcommand._name}`;
	    let executableDir = this._executableDir || '';
	    if (this._scriptPath) {
	      let resolvedScriptPath; // resolve possible symlink for installed npm binary
	      try {
	        resolvedScriptPath = fs.realpathSync(this._scriptPath);
	      } catch {
	        resolvedScriptPath = this._scriptPath;
	      }
	      executableDir = path.resolve(
	        path.dirname(resolvedScriptPath),
	        executableDir,
	      );
	    }

	    // Look for a local file in preference to a command in PATH.
	    if (executableDir) {
	      let localFile = findFile(executableDir, executableFile);

	      // Legacy search using prefix of script name instead of command name
	      if (!localFile && !subcommand._executableFile && this._scriptPath) {
	        const legacyName = path.basename(
	          this._scriptPath,
	          path.extname(this._scriptPath),
	        );
	        if (legacyName !== this._name) {
	          localFile = findFile(
	            executableDir,
	            `${legacyName}-${subcommand._name}`,
	          );
	        }
	      }
	      executableFile = localFile || executableFile;
	    }

	    launchWithNode = sourceExt.includes(path.extname(executableFile));

	    let proc;
	    if (process.platform !== 'win32') {
	      if (launchWithNode) {
	        args.unshift(executableFile);
	        // add executable arguments to spawn
	        args = incrementNodeInspectorPort(process.execArgv).concat(args);

	        proc = childProcess.spawn(process.argv[0], args, { stdio: 'inherit' });
	      } else {
	        proc = childProcess.spawn(executableFile, args, { stdio: 'inherit' });
	      }
	    } else {
	      this._checkForMissingExecutable(
	        executableFile,
	        executableDir,
	        subcommand._name,
	      );
	      args.unshift(executableFile);
	      // add executable arguments to spawn
	      args = incrementNodeInspectorPort(process.execArgv).concat(args);
	      proc = childProcess.spawn(process.execPath, args, { stdio: 'inherit' });
	    }

	    if (!proc.killed) {
	      // testing mainly to avoid leak warnings during unit tests with mocked spawn
	      const signals = ['SIGUSR1', 'SIGUSR2', 'SIGTERM', 'SIGINT', 'SIGHUP'];
	      signals.forEach((signal) => {
	        process.on(signal, () => {
	          if (proc.killed === false && proc.exitCode === null) {
	            // @ts-ignore because signals not typed to known strings
	            proc.kill(signal);
	          }
	        });
	      });
	    }

	    // By default terminate process when spawned process terminates.
	    const exitCallback = this._exitCallback;
	    proc.on('close', (code) => {
	      code = code ?? 1; // code is null if spawned process terminated due to a signal
	      if (!exitCallback) {
	        process.exit(code);
	      } else {
	        exitCallback(
	          new CommanderError(
	            code,
	            'commander.executeSubCommandAsync',
	            '(close)',
	          ),
	        );
	      }
	    });
	    proc.on('error', (err) => {
	      // @ts-ignore: because err.code is an unknown property
	      if (err.code === 'ENOENT') {
	        this._checkForMissingExecutable(
	          executableFile,
	          executableDir,
	          subcommand._name,
	        );
	        // @ts-ignore: because err.code is an unknown property
	      } else if (err.code === 'EACCES') {
	        throw new Error(`'${executableFile}' not executable`);
	      }
	      if (!exitCallback) {
	        process.exit(1);
	      } else {
	        const wrappedError = new CommanderError(
	          1,
	          'commander.executeSubCommandAsync',
	          '(error)',
	        );
	        wrappedError.nestedError = err;
	        exitCallback(wrappedError);
	      }
	    });

	    // Store the reference to the child process
	    this.runningCommand = proc;
	  }

	  /**
	   * @private
	   */

	  _dispatchSubcommand(commandName, operands, unknown) {
	    const subCommand = this._findCommand(commandName);
	    if (!subCommand) this.help({ error: true });

	    subCommand._prepareForParse();
	    let promiseChain;
	    promiseChain = this._chainOrCallSubCommandHook(
	      promiseChain,
	      subCommand,
	      'preSubcommand',
	    );
	    promiseChain = this._chainOrCall(promiseChain, () => {
	      if (subCommand._executableHandler) {
	        this._executeSubCommand(subCommand, operands.concat(unknown));
	      } else {
	        return subCommand._parseCommand(operands, unknown);
	      }
	    });
	    return promiseChain;
	  }

	  /**
	   * Invoke help directly if possible, or dispatch if necessary.
	   * e.g. help foo
	   *
	   * @private
	   */

	  _dispatchHelpCommand(subcommandName) {
	    if (!subcommandName) {
	      this.help();
	    }
	    const subCommand = this._findCommand(subcommandName);
	    if (subCommand && !subCommand._executableHandler) {
	      subCommand.help();
	    }

	    // Fallback to parsing the help flag to invoke the help.
	    return this._dispatchSubcommand(
	      subcommandName,
	      [],
	      [this._getHelpOption()?.long ?? this._getHelpOption()?.short ?? '--help'],
	    );
	  }

	  /**
	   * Check this.args against expected this.registeredArguments.
	   *
	   * @private
	   */

	  _checkNumberOfArguments() {
	    // too few
	    this.registeredArguments.forEach((arg, i) => {
	      if (arg.required && this.args[i] == null) {
	        this.missingArgument(arg.name());
	      }
	    });
	    // too many
	    if (
	      this.registeredArguments.length > 0 &&
	      this.registeredArguments[this.registeredArguments.length - 1].variadic
	    ) {
	      return;
	    }
	    if (this.args.length > this.registeredArguments.length) {
	      this._excessArguments(this.args);
	    }
	  }

	  /**
	   * Process this.args using this.registeredArguments and save as this.processedArgs!
	   *
	   * @private
	   */

	  _processArguments() {
	    const myParseArg = (argument, value, previous) => {
	      // Extra processing for nice error message on parsing failure.
	      let parsedValue = value;
	      if (value !== null && argument.parseArg) {
	        const invalidValueMessage = `error: command-argument value '${value}' is invalid for argument '${argument.name()}'.`;
	        parsedValue = this._callParseArg(
	          argument,
	          value,
	          previous,
	          invalidValueMessage,
	        );
	      }
	      return parsedValue;
	    };

	    this._checkNumberOfArguments();

	    const processedArgs = [];
	    this.registeredArguments.forEach((declaredArg, index) => {
	      let value = declaredArg.defaultValue;
	      if (declaredArg.variadic) {
	        // Collect together remaining arguments for passing together as an array.
	        if (index < this.args.length) {
	          value = this.args.slice(index);
	          if (declaredArg.parseArg) {
	            value = value.reduce((processed, v) => {
	              return myParseArg(declaredArg, v, processed);
	            }, declaredArg.defaultValue);
	          }
	        } else if (value === undefined) {
	          value = [];
	        }
	      } else if (index < this.args.length) {
	        value = this.args[index];
	        if (declaredArg.parseArg) {
	          value = myParseArg(declaredArg, value, declaredArg.defaultValue);
	        }
	      }
	      processedArgs[index] = value;
	    });
	    this.processedArgs = processedArgs;
	  }

	  /**
	   * Once we have a promise we chain, but call synchronously until then.
	   *
	   * @param {(Promise|undefined)} promise
	   * @param {Function} fn
	   * @return {(Promise|undefined)}
	   * @private
	   */

	  _chainOrCall(promise, fn) {
	    // thenable
	    if (promise && promise.then && typeof promise.then === 'function') {
	      // already have a promise, chain callback
	      return promise.then(() => fn());
	    }
	    // callback might return a promise
	    return fn();
	  }

	  /**
	   *
	   * @param {(Promise|undefined)} promise
	   * @param {string} event
	   * @return {(Promise|undefined)}
	   * @private
	   */

	  _chainOrCallHooks(promise, event) {
	    let result = promise;
	    const hooks = [];
	    this._getCommandAndAncestors()
	      .reverse()
	      .filter((cmd) => cmd._lifeCycleHooks[event] !== undefined)
	      .forEach((hookedCommand) => {
	        hookedCommand._lifeCycleHooks[event].forEach((callback) => {
	          hooks.push({ hookedCommand, callback });
	        });
	      });
	    if (event === 'postAction') {
	      hooks.reverse();
	    }

	    hooks.forEach((hookDetail) => {
	      result = this._chainOrCall(result, () => {
	        return hookDetail.callback(hookDetail.hookedCommand, this);
	      });
	    });
	    return result;
	  }

	  /**
	   *
	   * @param {(Promise|undefined)} promise
	   * @param {Command} subCommand
	   * @param {string} event
	   * @return {(Promise|undefined)}
	   * @private
	   */

	  _chainOrCallSubCommandHook(promise, subCommand, event) {
	    let result = promise;
	    if (this._lifeCycleHooks[event] !== undefined) {
	      this._lifeCycleHooks[event].forEach((hook) => {
	        result = this._chainOrCall(result, () => {
	          return hook(this, subCommand);
	        });
	      });
	    }
	    return result;
	  }

	  /**
	   * Process arguments in context of this command.
	   * Returns action result, in case it is a promise.
	   *
	   * @private
	   */

	  _parseCommand(operands, unknown) {
	    const parsed = this.parseOptions(unknown);
	    this._parseOptionsEnv(); // after cli, so parseArg not called on both cli and env
	    this._parseOptionsImplied();
	    operands = operands.concat(parsed.operands);
	    unknown = parsed.unknown;
	    this.args = operands.concat(unknown);

	    if (operands && this._findCommand(operands[0])) {
	      return this._dispatchSubcommand(operands[0], operands.slice(1), unknown);
	    }
	    if (
	      this._getHelpCommand() &&
	      operands[0] === this._getHelpCommand().name()
	    ) {
	      return this._dispatchHelpCommand(operands[1]);
	    }
	    if (this._defaultCommandName) {
	      this._outputHelpIfRequested(unknown); // Run the help for default command from parent rather than passing to default command
	      return this._dispatchSubcommand(
	        this._defaultCommandName,
	        operands,
	        unknown,
	      );
	    }
	    if (
	      this.commands.length &&
	      this.args.length === 0 &&
	      !this._actionHandler &&
	      !this._defaultCommandName
	    ) {
	      // probably missing subcommand and no handler, user needs help (and exit)
	      this.help({ error: true });
	    }

	    this._outputHelpIfRequested(parsed.unknown);
	    this._checkForMissingMandatoryOptions();
	    this._checkForConflictingOptions();

	    // We do not always call this check to avoid masking a "better" error, like unknown command.
	    const checkForUnknownOptions = () => {
	      if (parsed.unknown.length > 0) {
	        this.unknownOption(parsed.unknown[0]);
	      }
	    };

	    const commandEvent = `command:${this.name()}`;
	    if (this._actionHandler) {
	      checkForUnknownOptions();
	      this._processArguments();

	      let promiseChain;
	      promiseChain = this._chainOrCallHooks(promiseChain, 'preAction');
	      promiseChain = this._chainOrCall(promiseChain, () =>
	        this._actionHandler(this.processedArgs),
	      );
	      if (this.parent) {
	        promiseChain = this._chainOrCall(promiseChain, () => {
	          this.parent.emit(commandEvent, operands, unknown); // legacy
	        });
	      }
	      promiseChain = this._chainOrCallHooks(promiseChain, 'postAction');
	      return promiseChain;
	    }
	    if (this.parent && this.parent.listenerCount(commandEvent)) {
	      checkForUnknownOptions();
	      this._processArguments();
	      this.parent.emit(commandEvent, operands, unknown); // legacy
	    } else if (operands.length) {
	      if (this._findCommand('*')) {
	        // legacy default command
	        return this._dispatchSubcommand('*', operands, unknown);
	      }
	      if (this.listenerCount('command:*')) {
	        // skip option check, emit event for possible misspelling suggestion
	        this.emit('command:*', operands, unknown);
	      } else if (this.commands.length) {
	        this.unknownCommand();
	      } else {
	        checkForUnknownOptions();
	        this._processArguments();
	      }
	    } else if (this.commands.length) {
	      checkForUnknownOptions();
	      // This command has subcommands and nothing hooked up at this level, so display help (and exit).
	      this.help({ error: true });
	    } else {
	      checkForUnknownOptions();
	      this._processArguments();
	      // fall through for caller to handle after calling .parse()
	    }
	  }

	  /**
	   * Find matching command.
	   *
	   * @private
	   * @return {Command | undefined}
	   */
	  _findCommand(name) {
	    if (!name) return undefined;
	    return this.commands.find(
	      (cmd) => cmd._name === name || cmd._aliases.includes(name),
	    );
	  }

	  /**
	   * Return an option matching `arg` if any.
	   *
	   * @param {string} arg
	   * @return {Option}
	   * @package
	   */

	  _findOption(arg) {
	    return this.options.find((option) => option.is(arg));
	  }

	  /**
	   * Display an error message if a mandatory option does not have a value.
	   * Called after checking for help flags in leaf subcommand.
	   *
	   * @private
	   */

	  _checkForMissingMandatoryOptions() {
	    // Walk up hierarchy so can call in subcommand after checking for displaying help.
	    this._getCommandAndAncestors().forEach((cmd) => {
	      cmd.options.forEach((anOption) => {
	        if (
	          anOption.mandatory &&
	          cmd.getOptionValue(anOption.attributeName()) === undefined
	        ) {
	          cmd.missingMandatoryOptionValue(anOption);
	        }
	      });
	    });
	  }

	  /**
	   * Display an error message if conflicting options are used together in this.
	   *
	   * @private
	   */
	  _checkForConflictingLocalOptions() {
	    const definedNonDefaultOptions = this.options.filter((option) => {
	      const optionKey = option.attributeName();
	      if (this.getOptionValue(optionKey) === undefined) {
	        return false;
	      }
	      return this.getOptionValueSource(optionKey) !== 'default';
	    });

	    const optionsWithConflicting = definedNonDefaultOptions.filter(
	      (option) => option.conflictsWith.length > 0,
	    );

	    optionsWithConflicting.forEach((option) => {
	      const conflictingAndDefined = definedNonDefaultOptions.find((defined) =>
	        option.conflictsWith.includes(defined.attributeName()),
	      );
	      if (conflictingAndDefined) {
	        this._conflictingOption(option, conflictingAndDefined);
	      }
	    });
	  }

	  /**
	   * Display an error message if conflicting options are used together.
	   * Called after checking for help flags in leaf subcommand.
	   *
	   * @private
	   */
	  _checkForConflictingOptions() {
	    // Walk up hierarchy so can call in subcommand after checking for displaying help.
	    this._getCommandAndAncestors().forEach((cmd) => {
	      cmd._checkForConflictingLocalOptions();
	    });
	  }

	  /**
	   * Parse options from `argv` removing known options,
	   * and return argv split into operands and unknown arguments.
	   *
	   * Side effects: modifies command by storing options. Does not reset state if called again.
	   *
	   * Examples:
	   *
	   *     argv => operands, unknown
	   *     --known kkk op => [op], []
	   *     op --known kkk => [op], []
	   *     sub --unknown uuu op => [sub], [--unknown uuu op]
	   *     sub -- --unknown uuu op => [sub --unknown uuu op], []
	   *
	   * @param {string[]} argv
	   * @return {{operands: string[], unknown: string[]}}
	   */

	  parseOptions(argv) {
	    const operands = []; // operands, not options or values
	    const unknown = []; // first unknown option and remaining unknown args
	    let dest = operands;
	    const args = argv.slice();

	    function maybeOption(arg) {
	      return arg.length > 1 && arg[0] === '-';
	    }

	    const negativeNumberArg = (arg) => {
	      // return false if not a negative number
	      if (!/^-\d*\.?\d+(e[+-]?\d+)?$/.test(arg)) return false;
	      // negative number is ok unless digit used as an option in command hierarchy
	      return !this._getCommandAndAncestors().some((cmd) =>
	        cmd.options
	          .map((opt) => opt.short)
	          .some((short) => /^-\d$/.test(short)),
	      );
	    };

	    // parse options
	    let activeVariadicOption = null;
	    while (args.length) {
	      const arg = args.shift();

	      // literal
	      if (arg === '--') {
	        if (dest === unknown) dest.push(arg);
	        dest.push(...args);
	        break;
	      }

	      if (
	        activeVariadicOption &&
	        (!maybeOption(arg) || negativeNumberArg(arg))
	      ) {
	        this.emit(`option:${activeVariadicOption.name()}`, arg);
	        continue;
	      }
	      activeVariadicOption = null;

	      if (maybeOption(arg)) {
	        const option = this._findOption(arg);
	        // recognised option, call listener to assign value with possible custom processing
	        if (option) {
	          if (option.required) {
	            const value = args.shift();
	            if (value === undefined) this.optionMissingArgument(option);
	            this.emit(`option:${option.name()}`, value);
	          } else if (option.optional) {
	            let value = null;
	            // historical behaviour is optional value is following arg unless an option
	            if (
	              args.length > 0 &&
	              (!maybeOption(args[0]) || negativeNumberArg(args[0]))
	            ) {
	              value = args.shift();
	            }
	            this.emit(`option:${option.name()}`, value);
	          } else {
	            // boolean flag
	            this.emit(`option:${option.name()}`);
	          }
	          activeVariadicOption = option.variadic ? option : null;
	          continue;
	        }
	      }

	      // Look for combo options following single dash, eat first one if known.
	      if (arg.length > 2 && arg[0] === '-' && arg[1] !== '-') {
	        const option = this._findOption(`-${arg[1]}`);
	        if (option) {
	          if (
	            option.required ||
	            (option.optional && this._combineFlagAndOptionalValue)
	          ) {
	            // option with value following in same argument
	            this.emit(`option:${option.name()}`, arg.slice(2));
	          } else {
	            // boolean option, emit and put back remainder of arg for further processing
	            this.emit(`option:${option.name()}`);
	            args.unshift(`-${arg.slice(2)}`);
	          }
	          continue;
	        }
	      }

	      // Look for known long flag with value, like --foo=bar
	      if (/^--[^=]+=/.test(arg)) {
	        const index = arg.indexOf('=');
	        const option = this._findOption(arg.slice(0, index));
	        if (option && (option.required || option.optional)) {
	          this.emit(`option:${option.name()}`, arg.slice(index + 1));
	          continue;
	        }
	      }

	      // Not a recognised option by this command.
	      // Might be a command-argument, or subcommand option, or unknown option, or help command or option.

	      // An unknown option means further arguments also classified as unknown so can be reprocessed by subcommands.
	      // A negative number in a leaf command is not an unknown option.
	      if (
	        dest === operands &&
	        maybeOption(arg) &&
	        !(this.commands.length === 0 && negativeNumberArg(arg))
	      ) {
	        dest = unknown;
	      }

	      // If using positionalOptions, stop processing our options at subcommand.
	      if (
	        (this._enablePositionalOptions || this._passThroughOptions) &&
	        operands.length === 0 &&
	        unknown.length === 0
	      ) {
	        if (this._findCommand(arg)) {
	          operands.push(arg);
	          if (args.length > 0) unknown.push(...args);
	          break;
	        } else if (
	          this._getHelpCommand() &&
	          arg === this._getHelpCommand().name()
	        ) {
	          operands.push(arg);
	          if (args.length > 0) operands.push(...args);
	          break;
	        } else if (this._defaultCommandName) {
	          unknown.push(arg);
	          if (args.length > 0) unknown.push(...args);
	          break;
	        }
	      }

	      // If using passThroughOptions, stop processing options at first command-argument.
	      if (this._passThroughOptions) {
	        dest.push(arg);
	        if (args.length > 0) dest.push(...args);
	        break;
	      }

	      // add arg
	      dest.push(arg);
	    }

	    return { operands, unknown };
	  }

	  /**
	   * Return an object containing local option values as key-value pairs.
	   *
	   * @return {object}
	   */
	  opts() {
	    if (this._storeOptionsAsProperties) {
	      // Preserve original behaviour so backwards compatible when still using properties
	      const result = {};
	      const len = this.options.length;

	      for (let i = 0; i < len; i++) {
	        const key = this.options[i].attributeName();
	        result[key] =
	          key === this._versionOptionName ? this._version : this[key];
	      }
	      return result;
	    }

	    return this._optionValues;
	  }

	  /**
	   * Return an object containing merged local and global option values as key-value pairs.
	   *
	   * @return {object}
	   */
	  optsWithGlobals() {
	    // globals overwrite locals
	    return this._getCommandAndAncestors().reduce(
	      (combinedOptions, cmd) => Object.assign(combinedOptions, cmd.opts()),
	      {},
	    );
	  }

	  /**
	   * Display error message and exit (or call exitOverride).
	   *
	   * @param {string} message
	   * @param {object} [errorOptions]
	   * @param {string} [errorOptions.code] - an id string representing the error
	   * @param {number} [errorOptions.exitCode] - used with process.exit
	   */
	  error(message, errorOptions) {
	    // output handling
	    this._outputConfiguration.outputError(
	      `${message}\n`,
	      this._outputConfiguration.writeErr,
	    );
	    if (typeof this._showHelpAfterError === 'string') {
	      this._outputConfiguration.writeErr(`${this._showHelpAfterError}\n`);
	    } else if (this._showHelpAfterError) {
	      this._outputConfiguration.writeErr('\n');
	      this.outputHelp({ error: true });
	    }

	    // exit handling
	    const config = errorOptions || {};
	    const exitCode = config.exitCode || 1;
	    const code = config.code || 'commander.error';
	    this._exit(exitCode, code, message);
	  }

	  /**
	   * Apply any option related environment variables, if option does
	   * not have a value from cli or client code.
	   *
	   * @private
	   */
	  _parseOptionsEnv() {
	    this.options.forEach((option) => {
	      if (option.envVar && option.envVar in process.env) {
	        const optionKey = option.attributeName();
	        // Priority check. Do not overwrite cli or options from unknown source (client-code).
	        if (
	          this.getOptionValue(optionKey) === undefined ||
	          ['default', 'config', 'env'].includes(
	            this.getOptionValueSource(optionKey),
	          )
	        ) {
	          if (option.required || option.optional) {
	            // option can take a value
	            // keep very simple, optional always takes value
	            this.emit(`optionEnv:${option.name()}`, process.env[option.envVar]);
	          } else {
	            // boolean
	            // keep very simple, only care that envVar defined and not the value
	            this.emit(`optionEnv:${option.name()}`);
	          }
	        }
	      }
	    });
	  }

	  /**
	   * Apply any implied option values, if option is undefined or default value.
	   *
	   * @private
	   */
	  _parseOptionsImplied() {
	    const dualHelper = new DualOptions(this.options);
	    const hasCustomOptionValue = (optionKey) => {
	      return (
	        this.getOptionValue(optionKey) !== undefined &&
	        !['default', 'implied'].includes(this.getOptionValueSource(optionKey))
	      );
	    };
	    this.options
	      .filter(
	        (option) =>
	          option.implied !== undefined &&
	          hasCustomOptionValue(option.attributeName()) &&
	          dualHelper.valueFromOption(
	            this.getOptionValue(option.attributeName()),
	            option,
	          ),
	      )
	      .forEach((option) => {
	        Object.keys(option.implied)
	          .filter((impliedKey) => !hasCustomOptionValue(impliedKey))
	          .forEach((impliedKey) => {
	            this.setOptionValueWithSource(
	              impliedKey,
	              option.implied[impliedKey],
	              'implied',
	            );
	          });
	      });
	  }

	  /**
	   * Argument `name` is missing.
	   *
	   * @param {string} name
	   * @private
	   */

	  missingArgument(name) {
	    const message = `error: missing required argument '${name}'`;
	    this.error(message, { code: 'commander.missingArgument' });
	  }

	  /**
	   * `Option` is missing an argument.
	   *
	   * @param {Option} option
	   * @private
	   */

	  optionMissingArgument(option) {
	    const message = `error: option '${option.flags}' argument missing`;
	    this.error(message, { code: 'commander.optionMissingArgument' });
	  }

	  /**
	   * `Option` does not have a value, and is a mandatory option.
	   *
	   * @param {Option} option
	   * @private
	   */

	  missingMandatoryOptionValue(option) {
	    const message = `error: required option '${option.flags}' not specified`;
	    this.error(message, { code: 'commander.missingMandatoryOptionValue' });
	  }

	  /**
	   * `Option` conflicts with another option.
	   *
	   * @param {Option} option
	   * @param {Option} conflictingOption
	   * @private
	   */
	  _conflictingOption(option, conflictingOption) {
	    // The calling code does not know whether a negated option is the source of the
	    // value, so do some work to take an educated guess.
	    const findBestOptionFromValue = (option) => {
	      const optionKey = option.attributeName();
	      const optionValue = this.getOptionValue(optionKey);
	      const negativeOption = this.options.find(
	        (target) => target.negate && optionKey === target.attributeName(),
	      );
	      const positiveOption = this.options.find(
	        (target) => !target.negate && optionKey === target.attributeName(),
	      );
	      if (
	        negativeOption &&
	        ((negativeOption.presetArg === undefined && optionValue === false) ||
	          (negativeOption.presetArg !== undefined &&
	            optionValue === negativeOption.presetArg))
	      ) {
	        return negativeOption;
	      }
	      return positiveOption || option;
	    };

	    const getErrorMessage = (option) => {
	      const bestOption = findBestOptionFromValue(option);
	      const optionKey = bestOption.attributeName();
	      const source = this.getOptionValueSource(optionKey);
	      if (source === 'env') {
	        return `environment variable '${bestOption.envVar}'`;
	      }
	      return `option '${bestOption.flags}'`;
	    };

	    const message = `error: ${getErrorMessage(option)} cannot be used with ${getErrorMessage(conflictingOption)}`;
	    this.error(message, { code: 'commander.conflictingOption' });
	  }

	  /**
	   * Unknown option `flag`.
	   *
	   * @param {string} flag
	   * @private
	   */

	  unknownOption(flag) {
	    if (this._allowUnknownOption) return;
	    let suggestion = '';

	    if (flag.startsWith('--') && this._showSuggestionAfterError) {
	      // Looping to pick up the global options too
	      let candidateFlags = [];
	      // eslint-disable-next-line @typescript-eslint/no-this-alias
	      let command = this;
	      do {
	        const moreFlags = command
	          .createHelp()
	          .visibleOptions(command)
	          .filter((option) => option.long)
	          .map((option) => option.long);
	        candidateFlags = candidateFlags.concat(moreFlags);
	        command = command.parent;
	      } while (command && !command._enablePositionalOptions);
	      suggestion = suggestSimilar(flag, candidateFlags);
	    }

	    const message = `error: unknown option '${flag}'${suggestion}`;
	    this.error(message, { code: 'commander.unknownOption' });
	  }

	  /**
	   * Excess arguments, more than expected.
	   *
	   * @param {string[]} receivedArgs
	   * @private
	   */

	  _excessArguments(receivedArgs) {
	    if (this._allowExcessArguments) return;

	    const expected = this.registeredArguments.length;
	    const s = expected === 1 ? '' : 's';
	    const forSubcommand = this.parent ? ` for '${this.name()}'` : '';
	    const message = `error: too many arguments${forSubcommand}. Expected ${expected} argument${s} but got ${receivedArgs.length}.`;
	    this.error(message, { code: 'commander.excessArguments' });
	  }

	  /**
	   * Unknown command.
	   *
	   * @private
	   */

	  unknownCommand() {
	    const unknownName = this.args[0];
	    let suggestion = '';

	    if (this._showSuggestionAfterError) {
	      const candidateNames = [];
	      this.createHelp()
	        .visibleCommands(this)
	        .forEach((command) => {
	          candidateNames.push(command.name());
	          // just visible alias
	          if (command.alias()) candidateNames.push(command.alias());
	        });
	      suggestion = suggestSimilar(unknownName, candidateNames);
	    }

	    const message = `error: unknown command '${unknownName}'${suggestion}`;
	    this.error(message, { code: 'commander.unknownCommand' });
	  }

	  /**
	   * Get or set the program version.
	   *
	   * This method auto-registers the "-V, --version" option which will print the version number.
	   *
	   * You can optionally supply the flags and description to override the defaults.
	   *
	   * @param {string} [str]
	   * @param {string} [flags]
	   * @param {string} [description]
	   * @return {(this | string | undefined)} `this` command for chaining, or version string if no arguments
	   */

	  version(str, flags, description) {
	    if (str === undefined) return this._version;
	    this._version = str;
	    flags = flags || '-V, --version';
	    description = description || 'output the version number';
	    const versionOption = this.createOption(flags, description);
	    this._versionOptionName = versionOption.attributeName();
	    this._registerOption(versionOption);

	    this.on('option:' + versionOption.name(), () => {
	      this._outputConfiguration.writeOut(`${str}\n`);
	      this._exit(0, 'commander.version', str);
	    });
	    return this;
	  }

	  /**
	   * Set the description.
	   *
	   * @param {string} [str]
	   * @param {object} [argsDescription]
	   * @return {(string|Command)}
	   */
	  description(str, argsDescription) {
	    if (str === undefined && argsDescription === undefined)
	      return this._description;
	    this._description = str;
	    if (argsDescription) {
	      this._argsDescription = argsDescription;
	    }
	    return this;
	  }

	  /**
	   * Set the summary. Used when listed as subcommand of parent.
	   *
	   * @param {string} [str]
	   * @return {(string|Command)}
	   */
	  summary(str) {
	    if (str === undefined) return this._summary;
	    this._summary = str;
	    return this;
	  }

	  /**
	   * Set an alias for the command.
	   *
	   * You may call more than once to add multiple aliases. Only the first alias is shown in the auto-generated help.
	   *
	   * @param {string} [alias]
	   * @return {(string|Command)}
	   */

	  alias(alias) {
	    if (alias === undefined) return this._aliases[0]; // just return first, for backwards compatibility

	    /** @type {Command} */
	    // eslint-disable-next-line @typescript-eslint/no-this-alias
	    let command = this;
	    if (
	      this.commands.length !== 0 &&
	      this.commands[this.commands.length - 1]._executableHandler
	    ) {
	      // assume adding alias for last added executable subcommand, rather than this
	      command = this.commands[this.commands.length - 1];
	    }

	    if (alias === command._name)
	      throw new Error("Command alias can't be the same as its name");
	    const matchingCommand = this.parent?._findCommand(alias);
	    if (matchingCommand) {
	      // c.f. _registerCommand
	      const existingCmd = [matchingCommand.name()]
	        .concat(matchingCommand.aliases())
	        .join('|');
	      throw new Error(
	        `cannot add alias '${alias}' to command '${this.name()}' as already have command '${existingCmd}'`,
	      );
	    }

	    command._aliases.push(alias);
	    return this;
	  }

	  /**
	   * Set aliases for the command.
	   *
	   * Only the first alias is shown in the auto-generated help.
	   *
	   * @param {string[]} [aliases]
	   * @return {(string[]|Command)}
	   */

	  aliases(aliases) {
	    // Getter for the array of aliases is the main reason for having aliases() in addition to alias().
	    if (aliases === undefined) return this._aliases;

	    aliases.forEach((alias) => this.alias(alias));
	    return this;
	  }

	  /**
	   * Set / get the command usage `str`.
	   *
	   * @param {string} [str]
	   * @return {(string|Command)}
	   */

	  usage(str) {
	    if (str === undefined) {
	      if (this._usage) return this._usage;

	      const args = this.registeredArguments.map((arg) => {
	        return humanReadableArgName(arg);
	      });
	      return []
	        .concat(
	          this.options.length || this._helpOption !== null ? '[options]' : [],
	          this.commands.length ? '[command]' : [],
	          this.registeredArguments.length ? args : [],
	        )
	        .join(' ');
	    }

	    this._usage = str;
	    return this;
	  }

	  /**
	   * Get or set the name of the command.
	   *
	   * @param {string} [str]
	   * @return {(string|Command)}
	   */

	  name(str) {
	    if (str === undefined) return this._name;
	    this._name = str;
	    return this;
	  }

	  /**
	   * Set/get the help group heading for this subcommand in parent command's help.
	   *
	   * @param {string} [heading]
	   * @return {Command | string}
	   */

	  helpGroup(heading) {
	    if (heading === undefined) return this._helpGroupHeading ?? '';
	    this._helpGroupHeading = heading;
	    return this;
	  }

	  /**
	   * Set/get the default help group heading for subcommands added to this command.
	   * (This does not override a group set directly on the subcommand using .helpGroup().)
	   *
	   * @example
	   * program.commandsGroup('Development Commands:);
	   * program.command('watch')...
	   * program.command('lint')...
	   * ...
	   *
	   * @param {string} [heading]
	   * @returns {Command | string}
	   */
	  commandsGroup(heading) {
	    if (heading === undefined) return this._defaultCommandGroup ?? '';
	    this._defaultCommandGroup = heading;
	    return this;
	  }

	  /**
	   * Set/get the default help group heading for options added to this command.
	   * (This does not override a group set directly on the option using .helpGroup().)
	   *
	   * @example
	   * program
	   *   .optionsGroup('Development Options:')
	   *   .option('-d, --debug', 'output extra debugging')
	   *   .option('-p, --profile', 'output profiling information')
	   *
	   * @param {string} [heading]
	   * @returns {Command | string}
	   */
	  optionsGroup(heading) {
	    if (heading === undefined) return this._defaultOptionGroup ?? '';
	    this._defaultOptionGroup = heading;
	    return this;
	  }

	  /**
	   * @param {Option} option
	   * @private
	   */
	  _initOptionGroup(option) {
	    if (this._defaultOptionGroup && !option.helpGroupHeading)
	      option.helpGroup(this._defaultOptionGroup);
	  }

	  /**
	   * @param {Command} cmd
	   * @private
	   */
	  _initCommandGroup(cmd) {
	    if (this._defaultCommandGroup && !cmd.helpGroup())
	      cmd.helpGroup(this._defaultCommandGroup);
	  }

	  /**
	   * Set the name of the command from script filename, such as process.argv[1],
	   * or require.main.filename, or __filename.
	   *
	   * (Used internally and public although not documented in README.)
	   *
	   * @example
	   * program.nameFromFilename(require.main.filename);
	   *
	   * @param {string} filename
	   * @return {Command}
	   */

	  nameFromFilename(filename) {
	    this._name = path.basename(filename, path.extname(filename));

	    return this;
	  }

	  /**
	   * Get or set the directory for searching for executable subcommands of this command.
	   *
	   * @example
	   * program.executableDir(__dirname);
	   * // or
	   * program.executableDir('subcommands');
	   *
	   * @param {string} [path]
	   * @return {(string|null|Command)}
	   */

	  executableDir(path) {
	    if (path === undefined) return this._executableDir;
	    this._executableDir = path;
	    return this;
	  }

	  /**
	   * Return program help documentation.
	   *
	   * @param {{ error: boolean }} [contextOptions] - pass {error:true} to wrap for stderr instead of stdout
	   * @return {string}
	   */

	  helpInformation(contextOptions) {
	    const helper = this.createHelp();
	    const context = this._getOutputContext(contextOptions);
	    helper.prepareContext({
	      error: context.error,
	      helpWidth: context.helpWidth,
	      outputHasColors: context.hasColors,
	    });
	    const text = helper.formatHelp(this, helper);
	    if (context.hasColors) return text;
	    return this._outputConfiguration.stripColor(text);
	  }

	  /**
	   * @typedef HelpContext
	   * @type {object}
	   * @property {boolean} error
	   * @property {number} helpWidth
	   * @property {boolean} hasColors
	   * @property {function} write - includes stripColor if needed
	   *
	   * @returns {HelpContext}
	   * @private
	   */

	  _getOutputContext(contextOptions) {
	    contextOptions = contextOptions || {};
	    const error = !!contextOptions.error;
	    let baseWrite;
	    let hasColors;
	    let helpWidth;
	    if (error) {
	      baseWrite = (str) => this._outputConfiguration.writeErr(str);
	      hasColors = this._outputConfiguration.getErrHasColors();
	      helpWidth = this._outputConfiguration.getErrHelpWidth();
	    } else {
	      baseWrite = (str) => this._outputConfiguration.writeOut(str);
	      hasColors = this._outputConfiguration.getOutHasColors();
	      helpWidth = this._outputConfiguration.getOutHelpWidth();
	    }
	    const write = (str) => {
	      if (!hasColors) str = this._outputConfiguration.stripColor(str);
	      return baseWrite(str);
	    };
	    return { error, write, hasColors, helpWidth };
	  }

	  /**
	   * Output help information for this command.
	   *
	   * Outputs built-in help, and custom text added using `.addHelpText()`.
	   *
	   * @param {{ error: boolean } | Function} [contextOptions] - pass {error:true} to write to stderr instead of stdout
	   */

	  outputHelp(contextOptions) {
	    let deprecatedCallback;
	    if (typeof contextOptions === 'function') {
	      deprecatedCallback = contextOptions;
	      contextOptions = undefined;
	    }

	    const outputContext = this._getOutputContext(contextOptions);
	    /** @type {HelpTextEventContext} */
	    const eventContext = {
	      error: outputContext.error,
	      write: outputContext.write,
	      command: this,
	    };

	    this._getCommandAndAncestors()
	      .reverse()
	      .forEach((command) => command.emit('beforeAllHelp', eventContext));
	    this.emit('beforeHelp', eventContext);

	    let helpInformation = this.helpInformation({ error: outputContext.error });
	    if (deprecatedCallback) {
	      helpInformation = deprecatedCallback(helpInformation);
	      if (
	        typeof helpInformation !== 'string' &&
	        !Buffer.isBuffer(helpInformation)
	      ) {
	        throw new Error('outputHelp callback must return a string or a Buffer');
	      }
	    }
	    outputContext.write(helpInformation);

	    if (this._getHelpOption()?.long) {
	      this.emit(this._getHelpOption().long); // deprecated
	    }
	    this.emit('afterHelp', eventContext);
	    this._getCommandAndAncestors().forEach((command) =>
	      command.emit('afterAllHelp', eventContext),
	    );
	  }

	  /**
	   * You can pass in flags and a description to customise the built-in help option.
	   * Pass in false to disable the built-in help option.
	   *
	   * @example
	   * program.helpOption('-?, --help' 'show help'); // customise
	   * program.helpOption(false); // disable
	   *
	   * @param {(string | boolean)} flags
	   * @param {string} [description]
	   * @return {Command} `this` command for chaining
	   */

	  helpOption(flags, description) {
	    // Support enabling/disabling built-in help option.
	    if (typeof flags === 'boolean') {
	      if (flags) {
	        if (this._helpOption === null) this._helpOption = undefined; // reenable
	        if (this._defaultOptionGroup) {
	          // make the option to store the group
	          this._initOptionGroup(this._getHelpOption());
	        }
	      } else {
	        this._helpOption = null; // disable
	      }
	      return this;
	    }

	    // Customise flags and description.
	    this._helpOption = this.createOption(
	      flags ?? '-h, --help',
	      description ?? 'display help for command',
	    );
	    // init group unless lazy create
	    if (flags || description) this._initOptionGroup(this._helpOption);

	    return this;
	  }

	  /**
	   * Lazy create help option.
	   * Returns null if has been disabled with .helpOption(false).
	   *
	   * @returns {(Option | null)} the help option
	   * @package
	   */
	  _getHelpOption() {
	    // Lazy create help option on demand.
	    if (this._helpOption === undefined) {
	      this.helpOption(undefined, undefined);
	    }
	    return this._helpOption;
	  }

	  /**
	   * Supply your own option to use for the built-in help option.
	   * This is an alternative to using helpOption() to customise the flags and description etc.
	   *
	   * @param {Option} option
	   * @return {Command} `this` command for chaining
	   */
	  addHelpOption(option) {
	    this._helpOption = option;
	    this._initOptionGroup(option);
	    return this;
	  }

	  /**
	   * Output help information and exit.
	   *
	   * Outputs built-in help, and custom text added using `.addHelpText()`.
	   *
	   * @param {{ error: boolean }} [contextOptions] - pass {error:true} to write to stderr instead of stdout
	   */

	  help(contextOptions) {
	    this.outputHelp(contextOptions);
	    let exitCode = Number(process.exitCode ?? 0); // process.exitCode does allow a string or an integer, but we prefer just a number
	    if (
	      exitCode === 0 &&
	      contextOptions &&
	      typeof contextOptions !== 'function' &&
	      contextOptions.error
	    ) {
	      exitCode = 1;
	    }
	    // message: do not have all displayed text available so only passing placeholder.
	    this._exit(exitCode, 'commander.help', '(outputHelp)');
	  }

	  /**
	   * // Do a little typing to coordinate emit and listener for the help text events.
	   * @typedef HelpTextEventContext
	   * @type {object}
	   * @property {boolean} error
	   * @property {Command} command
	   * @property {function} write
	   */

	  /**
	   * Add additional text to be displayed with the built-in help.
	   *
	   * Position is 'before' or 'after' to affect just this command,
	   * and 'beforeAll' or 'afterAll' to affect this command and all its subcommands.
	   *
	   * @param {string} position - before or after built-in help
	   * @param {(string | Function)} text - string to add, or a function returning a string
	   * @return {Command} `this` command for chaining
	   */

	  addHelpText(position, text) {
	    const allowedValues = ['beforeAll', 'before', 'after', 'afterAll'];
	    if (!allowedValues.includes(position)) {
	      throw new Error(`Unexpected value for position to addHelpText.
Expecting one of '${allowedValues.join("', '")}'`);
	    }

	    const helpEvent = `${position}Help`;
	    this.on(helpEvent, (/** @type {HelpTextEventContext} */ context) => {
	      let helpStr;
	      if (typeof text === 'function') {
	        helpStr = text({ error: context.error, command: context.command });
	      } else {
	        helpStr = text;
	      }
	      // Ignore falsy value when nothing to output.
	      if (helpStr) {
	        context.write(`${helpStr}\n`);
	      }
	    });
	    return this;
	  }

	  /**
	   * Output help information if help flags specified
	   *
	   * @param {Array} args - array of options to search for help flags
	   * @private
	   */

	  _outputHelpIfRequested(args) {
	    const helpOption = this._getHelpOption();
	    const helpRequested = helpOption && args.find((arg) => helpOption.is(arg));
	    if (helpRequested) {
	      this.outputHelp();
	      // (Do not have all displayed text available so only passing placeholder.)
	      this._exit(0, 'commander.helpDisplayed', '(outputHelp)');
	    }
	  }
	}

	/**
	 * Scan arguments and increment port number for inspect calls (to avoid conflicts when spawning new command).
	 *
	 * @param {string[]} args - array of arguments from node.execArgv
	 * @returns {string[]}
	 * @private
	 */

	function incrementNodeInspectorPort(args) {
	  // Testing for these options:
	  //  --inspect[=[host:]port]
	  //  --inspect-brk[=[host:]port]
	  //  --inspect-port=[host:]port
	  return args.map((arg) => {
	    if (!arg.startsWith('--inspect')) {
	      return arg;
	    }
	    let debugOption;
	    let debugHost = '127.0.0.1';
	    let debugPort = '9229';
	    let match;
	    if ((match = arg.match(/^(--inspect(-brk)?)$/)) !== null) {
	      // e.g. --inspect
	      debugOption = match[1];
	    } else if (
	      (match = arg.match(/^(--inspect(-brk|-port)?)=([^:]+)$/)) !== null
	    ) {
	      debugOption = match[1];
	      if (/^\d+$/.test(match[3])) {
	        // e.g. --inspect=1234
	        debugPort = match[3];
	      } else {
	        // e.g. --inspect=localhost
	        debugHost = match[3];
	      }
	    } else if (
	      (match = arg.match(/^(--inspect(-brk|-port)?)=([^:]+):(\d+)$/)) !== null
	    ) {
	      // e.g. --inspect=localhost:1234
	      debugOption = match[1];
	      debugHost = match[3];
	      debugPort = match[4];
	    }

	    if (debugOption && debugPort !== '0') {
	      return `${debugOption}=${debugHost}:${parseInt(debugPort) + 1}`;
	    }
	    return arg;
	  });
	}

	/**
	 * @returns {boolean | undefined}
	 * @package
	 */
	function useColor() {
	  // Test for common conventions.
	  // NB: the observed behaviour is in combination with how author adds color! For example:
	  //   - we do not test NODE_DISABLE_COLORS, but util:styletext does
	  //   - we do test NO_COLOR, but Chalk does not
	  //
	  // References:
	  // https://no-color.org
	  // https://bixense.com/clicolors/
	  // https://github.com/nodejs/node/blob/0a00217a5f67ef4a22384cfc80eb6dd9a917fdc1/lib/internal/tty.js#L109
	  // https://github.com/chalk/supports-color/blob/c214314a14bcb174b12b3014b2b0a8de375029ae/index.js#L33
	  // (https://force-color.org recent web page from 2023, does not match major javascript implementations)

	  if (
	    process.env.NO_COLOR ||
	    process.env.FORCE_COLOR === '0' ||
	    process.env.FORCE_COLOR === 'false'
	  )
	    return false;
	  if (process.env.FORCE_COLOR || process.env.CLICOLOR_FORCE !== undefined)
	    return true;
	  return undefined;
	}

	command.Command = Command;
	command.useColor = useColor; // exporting for tests
	return command;
}

var hasRequiredCommander;

function requireCommander () {
	if (hasRequiredCommander) return commander$1;
	hasRequiredCommander = 1;
	const { Argument } = requireArgument();
	const { Command } = requireCommand();
	const { CommanderError, InvalidArgumentError } = requireError();
	const { Help } = requireHelp();
	const { Option } = requireOption();

	commander$1.program = new Command();

	commander$1.createCommand = (name) => new Command(name);
	commander$1.createOption = (flags, description) => new Option(flags, description);
	commander$1.createArgument = (name, description) => new Argument(name, description);

	/**
	 * Expose classes
	 */

	commander$1.Command = Command;
	commander$1.Option = Option;
	commander$1.Argument = Argument;
	commander$1.Help = Help;

	commander$1.CommanderError = CommanderError;
	commander$1.InvalidArgumentError = InvalidArgumentError;
	commander$1.InvalidOptionArgumentError = InvalidArgumentError; // Deprecated
	return commander$1;
}

var commanderExports = requireCommander();
var commander = /*@__PURE__*/getDefaultExportFromCjs(commanderExports);

// wrapper to provide named exports for ESM.
const {
  program,
  createCommand,
  createArgument,
  createOption,
  CommanderError,
  InvalidArgumentError,
  InvalidOptionArgumentError, // deprecated old name
  Command,
  Argument,
  Option,
  Help,
} = commander;

const EntryTypes = {
    FILE_TYPE: 'files',
    DIR_TYPE: 'directories',
    FILE_DIR_TYPE: 'files_directories',
    EVERYTHING_TYPE: 'all',
};
const defaultOptions = {
    root: '.',
    fileFilter: (_entryInfo) => true,
    directoryFilter: (_entryInfo) => true,
    type: EntryTypes.FILE_TYPE,
    lstat: false,
    depth: 2147483648,
    alwaysStat: false,
    highWaterMark: 4096,
};
Object.freeze(defaultOptions);
const RECURSIVE_ERROR_CODE = 'READDIRP_RECURSIVE_ERROR';
const NORMAL_FLOW_ERRORS = new Set(['ENOENT', 'EPERM', 'EACCES', 'ELOOP', RECURSIVE_ERROR_CODE]);
const ALL_TYPES = [
    EntryTypes.DIR_TYPE,
    EntryTypes.EVERYTHING_TYPE,
    EntryTypes.FILE_DIR_TYPE,
    EntryTypes.FILE_TYPE,
];
const DIR_TYPES = new Set([
    EntryTypes.DIR_TYPE,
    EntryTypes.EVERYTHING_TYPE,
    EntryTypes.FILE_DIR_TYPE,
]);
const FILE_TYPES = new Set([
    EntryTypes.EVERYTHING_TYPE,
    EntryTypes.FILE_DIR_TYPE,
    EntryTypes.FILE_TYPE,
]);
const isNormalFlowError = (error) => NORMAL_FLOW_ERRORS.has(error.code);
const wantBigintFsStats = process.platform === 'win32';
const emptyFn = (_entryInfo) => true;
const normalizeFilter = (filter) => {
    if (filter === undefined)
        return emptyFn;
    if (typeof filter === 'function')
        return filter;
    if (typeof filter === 'string') {
        const fl = filter.trim();
        return (entry) => entry.basename === fl;
    }
    if (Array.isArray(filter)) {
        const trItems = filter.map((item) => item.trim());
        return (entry) => trItems.some((f) => entry.basename === f);
    }
    return emptyFn;
};
/** Readable readdir stream, emitting new files as they're being listed. */
class ReaddirpStream extends Readable {
    constructor(options = {}) {
        super({
            objectMode: true,
            autoDestroy: true,
            highWaterMark: options.highWaterMark,
        });
        const opts = { ...defaultOptions, ...options };
        const { root, type } = opts;
        this._fileFilter = normalizeFilter(opts.fileFilter);
        this._directoryFilter = normalizeFilter(opts.directoryFilter);
        const statMethod = opts.lstat ? lstat : stat;
        // Use bigint stats if it's windows and stat() supports options (node 10+).
        if (wantBigintFsStats) {
            this._stat = (path) => statMethod(path, { bigint: true });
        }
        else {
            this._stat = statMethod;
        }
        this._maxDepth = opts.depth ?? defaultOptions.depth;
        this._wantsDir = type ? DIR_TYPES.has(type) : false;
        this._wantsFile = type ? FILE_TYPES.has(type) : false;
        this._wantsEverything = type === EntryTypes.EVERYTHING_TYPE;
        this._root = resolve(root);
        this._isDirent = !opts.alwaysStat;
        this._statsProp = this._isDirent ? 'dirent' : 'stats';
        this._rdOptions = { encoding: 'utf8', withFileTypes: this._isDirent };
        // Launch stream with one parent, the root dir.
        this.parents = [this._exploreDir(root, 1)];
        this.reading = false;
        this.parent = undefined;
    }
    async _read(batch) {
        if (this.reading)
            return;
        this.reading = true;
        try {
            while (!this.destroyed && batch > 0) {
                const par = this.parent;
                const fil = par && par.files;
                if (fil && fil.length > 0) {
                    const { path, depth } = par;
                    const slice = fil.splice(0, batch).map((dirent) => this._formatEntry(dirent, path));
                    const awaited = await Promise.all(slice);
                    for (const entry of awaited) {
                        if (!entry)
                            continue;
                        if (this.destroyed)
                            return;
                        const entryType = await this._getEntryType(entry);
                        if (entryType === 'directory' && this._directoryFilter(entry)) {
                            if (depth <= this._maxDepth) {
                                this.parents.push(this._exploreDir(entry.fullPath, depth + 1));
                            }
                            if (this._wantsDir) {
                                this.push(entry);
                                batch--;
                            }
                        }
                        else if ((entryType === 'file' || this._includeAsFile(entry)) &&
                            this._fileFilter(entry)) {
                            if (this._wantsFile) {
                                this.push(entry);
                                batch--;
                            }
                        }
                    }
                }
                else {
                    const parent = this.parents.pop();
                    if (!parent) {
                        this.push(null);
                        break;
                    }
                    this.parent = await parent;
                    if (this.destroyed)
                        return;
                }
            }
        }
        catch (error) {
            this.destroy(error);
        }
        finally {
            this.reading = false;
        }
    }
    async _exploreDir(path, depth) {
        let files;
        try {
            files = await readdir(path, this._rdOptions);
        }
        catch (error) {
            this._onError(error);
        }
        return { files, depth, path };
    }
    async _formatEntry(dirent, path) {
        let entry;
        const basename = this._isDirent ? dirent.name : dirent;
        try {
            const fullPath = resolve(join$1(path, basename));
            entry = { path: relative$1(this._root, fullPath), fullPath, basename };
            entry[this._statsProp] = this._isDirent ? dirent : await this._stat(fullPath);
        }
        catch (err) {
            this._onError(err);
            return;
        }
        return entry;
    }
    _onError(err) {
        if (isNormalFlowError(err) && !this.destroyed) {
            this.emit('warn', err);
        }
        else {
            this.destroy(err);
        }
    }
    async _getEntryType(entry) {
        // entry may be undefined, because a warning or an error were emitted
        // and the statsProp is undefined
        if (!entry && this._statsProp in entry) {
            return '';
        }
        const stats = entry[this._statsProp];
        if (stats.isFile())
            return 'file';
        if (stats.isDirectory())
            return 'directory';
        if (stats && stats.isSymbolicLink()) {
            const full = entry.fullPath;
            try {
                const entryRealPath = await realpath(full);
                const entryRealPathStats = await lstat(entryRealPath);
                if (entryRealPathStats.isFile()) {
                    return 'file';
                }
                if (entryRealPathStats.isDirectory()) {
                    const len = entryRealPath.length;
                    if (full.startsWith(entryRealPath) && full.substr(len, 1) === sep) {
                        const recursiveError = new Error(`Circular symlink detected: "${full}" points to "${entryRealPath}"`);
                        // @ts-ignore
                        recursiveError.code = RECURSIVE_ERROR_CODE;
                        return this._onError(recursiveError);
                    }
                    return 'directory';
                }
            }
            catch (error) {
                this._onError(error);
                return '';
            }
        }
    }
    _includeAsFile(entry) {
        const stats = entry && entry[this._statsProp];
        return stats && this._wantsEverything && !stats.isDirectory();
    }
}
/**
 * Streaming version: Reads all files and directories in given root recursively.
 * Consumes ~constant small amount of RAM.
 * @param root Root directory
 * @param options Options to specify root (start directory), filters and recursion depth
 */
function readdirp(root, options = {}) {
    // @ts-ignore
    let type = options.entryType || options.type;
    if (type === 'both')
        type = EntryTypes.FILE_DIR_TYPE; // backwards-compatibility
    if (type)
        options.type = type;
    if (!root) {
        throw new Error('readdirp: root argument is required. Usage: readdirp(root, options)');
    }
    else if (typeof root !== 'string') {
        throw new TypeError('readdirp: root argument must be a string. Usage: readdirp(root, options)');
    }
    else if (type && !ALL_TYPES.includes(type)) {
        throw new Error(`readdirp: Invalid type passed. Use one of ${ALL_TYPES.join(', ')}`);
    }
    options.root = root;
    return new ReaddirpStream(options);
}

const STR_DATA = 'data';
const STR_END = 'end';
const STR_CLOSE = 'close';
const EMPTY_FN = () => { };
const pl = process.platform;
const isWindows = pl === 'win32';
const isMacos = pl === 'darwin';
const isLinux = pl === 'linux';
const isFreeBSD = pl === 'freebsd';
const isIBMi = type$1() === 'OS400';
const EVENTS = {
    ALL: 'all',
    READY: 'ready',
    ADD: 'add',
    CHANGE: 'change',
    ADD_DIR: 'addDir',
    UNLINK: 'unlink',
    UNLINK_DIR: 'unlinkDir',
    RAW: 'raw',
    ERROR: 'error',
};
const EV = EVENTS;
const THROTTLE_MODE_WATCH = 'watch';
const statMethods = { lstat: lstat$1, stat: stat$1 };
const KEY_LISTENERS = 'listeners';
const KEY_ERR = 'errHandlers';
const KEY_RAW = 'rawEmitters';
const HANDLER_KEYS = [KEY_LISTENERS, KEY_ERR, KEY_RAW];
// prettier-ignore
const binaryExtensions = new Set([
    '3dm', '3ds', '3g2', '3gp', '7z', 'a', 'aac', 'adp', 'afdesign', 'afphoto', 'afpub', 'ai',
    'aif', 'aiff', 'alz', 'ape', 'apk', 'appimage', 'ar', 'arj', 'asf', 'au', 'avi',
    'bak', 'baml', 'bh', 'bin', 'bk', 'bmp', 'btif', 'bz2', 'bzip2',
    'cab', 'caf', 'cgm', 'class', 'cmx', 'cpio', 'cr2', 'cur', 'dat', 'dcm', 'deb', 'dex', 'djvu',
    'dll', 'dmg', 'dng', 'doc', 'docm', 'docx', 'dot', 'dotm', 'dra', 'DS_Store', 'dsk', 'dts',
    'dtshd', 'dvb', 'dwg', 'dxf',
    'ecelp4800', 'ecelp7470', 'ecelp9600', 'egg', 'eol', 'eot', 'epub', 'exe',
    'f4v', 'fbs', 'fh', 'fla', 'flac', 'flatpak', 'fli', 'flv', 'fpx', 'fst', 'fvt',
    'g3', 'gh', 'gif', 'graffle', 'gz', 'gzip',
    'h261', 'h263', 'h264', 'icns', 'ico', 'ief', 'img', 'ipa', 'iso',
    'jar', 'jpeg', 'jpg', 'jpgv', 'jpm', 'jxr', 'key', 'ktx',
    'lha', 'lib', 'lvp', 'lz', 'lzh', 'lzma', 'lzo',
    'm3u', 'm4a', 'm4v', 'mar', 'mdi', 'mht', 'mid', 'midi', 'mj2', 'mka', 'mkv', 'mmr', 'mng',
    'mobi', 'mov', 'movie', 'mp3',
    'mp4', 'mp4a', 'mpeg', 'mpg', 'mpga', 'mxu',
    'nef', 'npx', 'numbers', 'nupkg',
    'o', 'odp', 'ods', 'odt', 'oga', 'ogg', 'ogv', 'otf', 'ott',
    'pages', 'pbm', 'pcx', 'pdb', 'pdf', 'pea', 'pgm', 'pic', 'png', 'pnm', 'pot', 'potm',
    'potx', 'ppa', 'ppam',
    'ppm', 'pps', 'ppsm', 'ppsx', 'ppt', 'pptm', 'pptx', 'psd', 'pya', 'pyc', 'pyo', 'pyv',
    'qt',
    'rar', 'ras', 'raw', 'resources', 'rgb', 'rip', 'rlc', 'rmf', 'rmvb', 'rpm', 'rtf', 'rz',
    's3m', 's7z', 'scpt', 'sgi', 'shar', 'snap', 'sil', 'sketch', 'slk', 'smv', 'snk', 'so',
    'stl', 'suo', 'sub', 'swf',
    'tar', 'tbz', 'tbz2', 'tga', 'tgz', 'thmx', 'tif', 'tiff', 'tlz', 'ttc', 'ttf', 'txz',
    'udf', 'uvh', 'uvi', 'uvm', 'uvp', 'uvs', 'uvu',
    'viv', 'vob',
    'war', 'wav', 'wax', 'wbmp', 'wdp', 'weba', 'webm', 'webp', 'whl', 'wim', 'wm', 'wma',
    'wmv', 'wmx', 'woff', 'woff2', 'wrm', 'wvx',
    'xbm', 'xif', 'xla', 'xlam', 'xls', 'xlsb', 'xlsm', 'xlsx', 'xlt', 'xltm', 'xltx', 'xm',
    'xmind', 'xpi', 'xpm', 'xwd', 'xz',
    'z', 'zip', 'zipx',
]);
const isBinaryPath = (filePath) => binaryExtensions.has(sysPath.extname(filePath).slice(1).toLowerCase());
// TODO: emit errors properly. Example: EMFILE on Macos.
const foreach = (val, fn) => {
    if (val instanceof Set) {
        val.forEach(fn);
    }
    else {
        fn(val);
    }
};
const addAndConvert = (main, prop, item) => {
    let container = main[prop];
    if (!(container instanceof Set)) {
        main[prop] = container = new Set([container]);
    }
    container.add(item);
};
const clearItem = (cont) => (key) => {
    const set = cont[key];
    if (set instanceof Set) {
        set.clear();
    }
    else {
        delete cont[key];
    }
};
const delFromSet = (main, prop, item) => {
    const container = main[prop];
    if (container instanceof Set) {
        container.delete(item);
    }
    else if (container === item) {
        delete main[prop];
    }
};
const isEmptySet = (val) => (val instanceof Set ? val.size === 0 : !val);
const FsWatchInstances = new Map();
/**
 * Instantiates the fs_watch interface
 * @param path to be watched
 * @param options to be passed to fs_watch
 * @param listener main event handler
 * @param errHandler emits info about errors
 * @param emitRaw emits raw event data
 * @returns {NativeFsWatcher}
 */
function createFsWatchInstance(path, options, listener, errHandler, emitRaw) {
    const handleEvent = (rawEvent, evPath) => {
        listener(path);
        emitRaw(rawEvent, evPath, { watchedPath: path });
        // emit based on events occurring for files from a directory's watcher in
        // case the file's watcher misses it (and rely on throttling to de-dupe)
        if (evPath && path !== evPath) {
            fsWatchBroadcast(sysPath.resolve(path, evPath), KEY_LISTENERS, sysPath.join(path, evPath));
        }
    };
    try {
        return watch$1(path, {
            persistent: options.persistent,
        }, handleEvent);
    }
    catch (error) {
        errHandler(error);
        return undefined;
    }
}
/**
 * Helper for passing fs_watch event data to a collection of listeners
 * @param fullPath absolute path bound to fs_watch instance
 */
const fsWatchBroadcast = (fullPath, listenerType, val1, val2, val3) => {
    const cont = FsWatchInstances.get(fullPath);
    if (!cont)
        return;
    foreach(cont[listenerType], (listener) => {
        listener(val1, val2, val3);
    });
};
/**
 * Instantiates the fs_watch interface or binds listeners
 * to an existing one covering the same file system entry
 * @param path
 * @param fullPath absolute path
 * @param options to be passed to fs_watch
 * @param handlers container for event listener functions
 */
const setFsWatchListener = (path, fullPath, options, handlers) => {
    const { listener, errHandler, rawEmitter } = handlers;
    let cont = FsWatchInstances.get(fullPath);
    let watcher;
    if (!options.persistent) {
        watcher = createFsWatchInstance(path, options, listener, errHandler, rawEmitter);
        if (!watcher)
            return;
        return watcher.close.bind(watcher);
    }
    if (cont) {
        addAndConvert(cont, KEY_LISTENERS, listener);
        addAndConvert(cont, KEY_ERR, errHandler);
        addAndConvert(cont, KEY_RAW, rawEmitter);
    }
    else {
        watcher = createFsWatchInstance(path, options, fsWatchBroadcast.bind(null, fullPath, KEY_LISTENERS), errHandler, // no need to use broadcast here
        fsWatchBroadcast.bind(null, fullPath, KEY_RAW));
        if (!watcher)
            return;
        watcher.on(EV.ERROR, async (error) => {
            const broadcastErr = fsWatchBroadcast.bind(null, fullPath, KEY_ERR);
            if (cont)
                cont.watcherUnusable = true; // documented since Node 10.4.1
            // Workaround for https://github.com/joyent/node/issues/4337
            if (isWindows && error.code === 'EPERM') {
                try {
                    const fd = await open(path, 'r');
                    await fd.close();
                    broadcastErr(error);
                }
                catch (err) {
                    // do nothing
                }
            }
            else {
                broadcastErr(error);
            }
        });
        cont = {
            listeners: listener,
            errHandlers: errHandler,
            rawEmitters: rawEmitter,
            watcher,
        };
        FsWatchInstances.set(fullPath, cont);
    }
    // const index = cont.listeners.indexOf(listener);
    // removes this instance's listeners and closes the underlying fs_watch
    // instance if there are no more listeners left
    return () => {
        delFromSet(cont, KEY_LISTENERS, listener);
        delFromSet(cont, KEY_ERR, errHandler);
        delFromSet(cont, KEY_RAW, rawEmitter);
        if (isEmptySet(cont.listeners)) {
            // Check to protect against issue gh-730.
            // if (cont.watcherUnusable) {
            cont.watcher.close();
            // }
            FsWatchInstances.delete(fullPath);
            HANDLER_KEYS.forEach(clearItem(cont));
            // @ts-ignore
            cont.watcher = undefined;
            Object.freeze(cont);
        }
    };
};
// fs_watchFile helpers
// object to hold per-process fs_watchFile instances
// (may be shared across chokidar FSWatcher instances)
const FsWatchFileInstances = new Map();
/**
 * Instantiates the fs_watchFile interface or binds listeners
 * to an existing one covering the same file system entry
 * @param path to be watched
 * @param fullPath absolute path
 * @param options options to be passed to fs_watchFile
 * @param handlers container for event listener functions
 * @returns closer
 */
const setFsWatchFileListener = (path, fullPath, options, handlers) => {
    const { listener, rawEmitter } = handlers;
    let cont = FsWatchFileInstances.get(fullPath);
    // let listeners = new Set();
    // let rawEmitters = new Set();
    const copts = cont && cont.options;
    if (copts && (copts.persistent < options.persistent || copts.interval > options.interval)) {
        // "Upgrade" the watcher to persistence or a quicker interval.
        // This creates some unlikely edge case issues if the user mixes
        // settings in a very weird way, but solving for those cases
        // doesn't seem worthwhile for the added complexity.
        // listeners = cont.listeners;
        // rawEmitters = cont.rawEmitters;
        unwatchFile(fullPath);
        cont = undefined;
    }
    if (cont) {
        addAndConvert(cont, KEY_LISTENERS, listener);
        addAndConvert(cont, KEY_RAW, rawEmitter);
    }
    else {
        // TODO
        // listeners.add(listener);
        // rawEmitters.add(rawEmitter);
        cont = {
            listeners: listener,
            rawEmitters: rawEmitter,
            options,
            watcher: watchFile(fullPath, options, (curr, prev) => {
                foreach(cont.rawEmitters, (rawEmitter) => {
                    rawEmitter(EV.CHANGE, fullPath, { curr, prev });
                });
                const currmtime = curr.mtimeMs;
                if (curr.size !== prev.size || currmtime > prev.mtimeMs || currmtime === 0) {
                    foreach(cont.listeners, (listener) => listener(path, curr));
                }
            }),
        };
        FsWatchFileInstances.set(fullPath, cont);
    }
    // const index = cont.listeners.indexOf(listener);
    // Removes this instance's listeners and closes the underlying fs_watchFile
    // instance if there are no more listeners left.
    return () => {
        delFromSet(cont, KEY_LISTENERS, listener);
        delFromSet(cont, KEY_RAW, rawEmitter);
        if (isEmptySet(cont.listeners)) {
            FsWatchFileInstances.delete(fullPath);
            unwatchFile(fullPath);
            cont.options = cont.watcher = undefined;
            Object.freeze(cont);
        }
    };
};
/**
 * @mixin
 */
class NodeFsHandler {
    constructor(fsW) {
        this.fsw = fsW;
        this._boundHandleError = (error) => fsW._handleError(error);
    }
    /**
     * Watch file for changes with fs_watchFile or fs_watch.
     * @param path to file or dir
     * @param listener on fs change
     * @returns closer for the watcher instance
     */
    _watchWithNodeFs(path, listener) {
        const opts = this.fsw.options;
        const directory = sysPath.dirname(path);
        const basename = sysPath.basename(path);
        const parent = this.fsw._getWatchedDir(directory);
        parent.add(basename);
        const absolutePath = sysPath.resolve(path);
        const options = {
            persistent: opts.persistent,
        };
        if (!listener)
            listener = EMPTY_FN;
        let closer;
        if (opts.usePolling) {
            const enableBin = opts.interval !== opts.binaryInterval;
            options.interval = enableBin && isBinaryPath(basename) ? opts.binaryInterval : opts.interval;
            closer = setFsWatchFileListener(path, absolutePath, options, {
                listener,
                rawEmitter: this.fsw._emitRaw,
            });
        }
        else {
            closer = setFsWatchListener(path, absolutePath, options, {
                listener,
                errHandler: this._boundHandleError,
                rawEmitter: this.fsw._emitRaw,
            });
        }
        return closer;
    }
    /**
     * Watch a file and emit add event if warranted.
     * @returns closer for the watcher instance
     */
    _handleFile(file, stats, initialAdd) {
        if (this.fsw.closed) {
            return;
        }
        const dirname = sysPath.dirname(file);
        const basename = sysPath.basename(file);
        const parent = this.fsw._getWatchedDir(dirname);
        // stats is always present
        let prevStats = stats;
        // if the file is already being watched, do nothing
        if (parent.has(basename))
            return;
        const listener = async (path, newStats) => {
            if (!this.fsw._throttle(THROTTLE_MODE_WATCH, file, 5))
                return;
            if (!newStats || newStats.mtimeMs === 0) {
                try {
                    const newStats = await stat$1(file);
                    if (this.fsw.closed)
                        return;
                    // Check that change event was not fired because of changed only accessTime.
                    const at = newStats.atimeMs;
                    const mt = newStats.mtimeMs;
                    if (!at || at <= mt || mt !== prevStats.mtimeMs) {
                        this.fsw._emit(EV.CHANGE, file, newStats);
                    }
                    if ((isMacos || isLinux || isFreeBSD) && prevStats.ino !== newStats.ino) {
                        this.fsw._closeFile(path);
                        prevStats = newStats;
                        const closer = this._watchWithNodeFs(file, listener);
                        if (closer)
                            this.fsw._addPathCloser(path, closer);
                    }
                    else {
                        prevStats = newStats;
                    }
                }
                catch (error) {
                    // Fix issues where mtime is null but file is still present
                    this.fsw._remove(dirname, basename);
                }
                // add is about to be emitted if file not already tracked in parent
            }
            else if (parent.has(basename)) {
                // Check that change event was not fired because of changed only accessTime.
                const at = newStats.atimeMs;
                const mt = newStats.mtimeMs;
                if (!at || at <= mt || mt !== prevStats.mtimeMs) {
                    this.fsw._emit(EV.CHANGE, file, newStats);
                }
                prevStats = newStats;
            }
        };
        // kick off the watcher
        const closer = this._watchWithNodeFs(file, listener);
        // emit an add event if we're supposed to
        if (!(initialAdd && this.fsw.options.ignoreInitial) && this.fsw._isntIgnored(file)) {
            if (!this.fsw._throttle(EV.ADD, file, 0))
                return;
            this.fsw._emit(EV.ADD, file, stats);
        }
        return closer;
    }
    /**
     * Handle symlinks encountered while reading a dir.
     * @param entry returned by readdirp
     * @param directory path of dir being read
     * @param path of this item
     * @param item basename of this item
     * @returns true if no more processing is needed for this entry.
     */
    async _handleSymlink(entry, directory, path, item) {
        if (this.fsw.closed) {
            return;
        }
        const full = entry.fullPath;
        const dir = this.fsw._getWatchedDir(directory);
        if (!this.fsw.options.followSymlinks) {
            // watch symlink directly (don't follow) and detect changes
            this.fsw._incrReadyCount();
            let linkPath;
            try {
                linkPath = await realpath$1(path);
            }
            catch (e) {
                this.fsw._emitReady();
                return true;
            }
            if (this.fsw.closed)
                return;
            if (dir.has(item)) {
                if (this.fsw._symlinkPaths.get(full) !== linkPath) {
                    this.fsw._symlinkPaths.set(full, linkPath);
                    this.fsw._emit(EV.CHANGE, path, entry.stats);
                }
            }
            else {
                dir.add(item);
                this.fsw._symlinkPaths.set(full, linkPath);
                this.fsw._emit(EV.ADD, path, entry.stats);
            }
            this.fsw._emitReady();
            return true;
        }
        // don't follow the same symlink more than once
        if (this.fsw._symlinkPaths.has(full)) {
            return true;
        }
        this.fsw._symlinkPaths.set(full, true);
    }
    _handleRead(directory, initialAdd, wh, target, dir, depth, throttler) {
        // Normalize the directory name on Windows
        directory = sysPath.join(directory, '');
        throttler = this.fsw._throttle('readdir', directory, 1000);
        if (!throttler)
            return;
        const previous = this.fsw._getWatchedDir(wh.path);
        const current = new Set();
        let stream = this.fsw._readdirp(directory, {
            fileFilter: (entry) => wh.filterPath(entry),
            directoryFilter: (entry) => wh.filterDir(entry),
        });
        if (!stream)
            return;
        stream
            .on(STR_DATA, async (entry) => {
            if (this.fsw.closed) {
                stream = undefined;
                return;
            }
            const item = entry.path;
            let path = sysPath.join(directory, item);
            current.add(item);
            if (entry.stats.isSymbolicLink() &&
                (await this._handleSymlink(entry, directory, path, item))) {
                return;
            }
            if (this.fsw.closed) {
                stream = undefined;
                return;
            }
            // Files that present in current directory snapshot
            // but absent in previous are added to watch list and
            // emit `add` event.
            if (item === target || (!target && !previous.has(item))) {
                this.fsw._incrReadyCount();
                // ensure relativeness of path is preserved in case of watcher reuse
                path = sysPath.join(dir, sysPath.relative(dir, path));
                this._addToNodeFs(path, initialAdd, wh, depth + 1);
            }
        })
            .on(EV.ERROR, this._boundHandleError);
        return new Promise((resolve, reject) => {
            if (!stream)
                return reject();
            stream.once(STR_END, () => {
                if (this.fsw.closed) {
                    stream = undefined;
                    return;
                }
                const wasThrottled = throttler ? throttler.clear() : false;
                resolve(undefined);
                // Files that absent in current directory snapshot
                // but present in previous emit `remove` event
                // and are removed from @watched[directory].
                previous
                    .getChildren()
                    .filter((item) => {
                    return item !== directory && !current.has(item);
                })
                    .forEach((item) => {
                    this.fsw._remove(directory, item);
                });
                stream = undefined;
                // one more time for any missed in case changes came in extremely quickly
                if (wasThrottled)
                    this._handleRead(directory, false, wh, target, dir, depth, throttler);
            });
        });
    }
    /**
     * Read directory to add / remove files from `@watched` list and re-read it on change.
     * @param dir fs path
     * @param stats
     * @param initialAdd
     * @param depth relative to user-supplied path
     * @param target child path targeted for watch
     * @param wh Common watch helpers for this path
     * @param realpath
     * @returns closer for the watcher instance.
     */
    async _handleDir(dir, stats, initialAdd, depth, target, wh, realpath) {
        const parentDir = this.fsw._getWatchedDir(sysPath.dirname(dir));
        const tracked = parentDir.has(sysPath.basename(dir));
        if (!(initialAdd && this.fsw.options.ignoreInitial) && !target && !tracked) {
            this.fsw._emit(EV.ADD_DIR, dir, stats);
        }
        // ensure dir is tracked (harmless if redundant)
        parentDir.add(sysPath.basename(dir));
        this.fsw._getWatchedDir(dir);
        let throttler;
        let closer;
        const oDepth = this.fsw.options.depth;
        if ((oDepth == null || depth <= oDepth) && !this.fsw._symlinkPaths.has(realpath)) {
            if (!target) {
                await this._handleRead(dir, initialAdd, wh, target, dir, depth, throttler);
                if (this.fsw.closed)
                    return;
            }
            closer = this._watchWithNodeFs(dir, (dirPath, stats) => {
                // if current directory is removed, do nothing
                if (stats && stats.mtimeMs === 0)
                    return;
                this._handleRead(dirPath, false, wh, target, dir, depth, throttler);
            });
        }
        return closer;
    }
    /**
     * Handle added file, directory, or glob pattern.
     * Delegates call to _handleFile / _handleDir after checks.
     * @param path to file or ir
     * @param initialAdd was the file added at watch instantiation?
     * @param priorWh depth relative to user-supplied path
     * @param depth Child path actually targeted for watch
     * @param target Child path actually targeted for watch
     */
    async _addToNodeFs(path, initialAdd, priorWh, depth, target) {
        const ready = this.fsw._emitReady;
        if (this.fsw._isIgnored(path) || this.fsw.closed) {
            ready();
            return false;
        }
        const wh = this.fsw._getWatchHelpers(path);
        if (priorWh) {
            wh.filterPath = (entry) => priorWh.filterPath(entry);
            wh.filterDir = (entry) => priorWh.filterDir(entry);
        }
        // evaluate what is at the path we're being asked to watch
        try {
            const stats = await statMethods[wh.statMethod](wh.watchPath);
            if (this.fsw.closed)
                return;
            if (this.fsw._isIgnored(wh.watchPath, stats)) {
                ready();
                return false;
            }
            const follow = this.fsw.options.followSymlinks;
            let closer;
            if (stats.isDirectory()) {
                const absPath = sysPath.resolve(path);
                const targetPath = follow ? await realpath$1(path) : path;
                if (this.fsw.closed)
                    return;
                closer = await this._handleDir(wh.watchPath, stats, initialAdd, depth, target, wh, targetPath);
                if (this.fsw.closed)
                    return;
                // preserve this symlink's target path
                if (absPath !== targetPath && targetPath !== undefined) {
                    this.fsw._symlinkPaths.set(absPath, targetPath);
                }
            }
            else if (stats.isSymbolicLink()) {
                const targetPath = follow ? await realpath$1(path) : path;
                if (this.fsw.closed)
                    return;
                const parent = sysPath.dirname(wh.watchPath);
                this.fsw._getWatchedDir(parent).add(wh.watchPath);
                this.fsw._emit(EV.ADD, wh.watchPath, stats);
                closer = await this._handleDir(parent, stats, initialAdd, depth, path, wh, targetPath);
                if (this.fsw.closed)
                    return;
                // preserve this symlink's target path
                if (targetPath !== undefined) {
                    this.fsw._symlinkPaths.set(sysPath.resolve(path), targetPath);
                }
            }
            else {
                closer = this._handleFile(wh.watchPath, stats, initialAdd);
            }
            ready();
            if (closer)
                this.fsw._addPathCloser(path, closer);
            return false;
        }
        catch (error) {
            if (this.fsw._handleError(error)) {
                ready();
                return path;
            }
        }
    }
}

/*! chokidar - MIT License (c) 2012 Paul Miller (paulmillr.com) */
const SLASH = '/';
const SLASH_SLASH = '//';
const ONE_DOT = '.';
const TWO_DOTS = '..';
const STRING_TYPE = 'string';
const BACK_SLASH_RE = /\\/g;
const DOUBLE_SLASH_RE = /\/\//;
const DOT_RE = /\..*\.(sw[px])$|~$|\.subl.*\.tmp/;
const REPLACER_RE = /^\.[/\\]/;
function arrify(item) {
    return Array.isArray(item) ? item : [item];
}
const isMatcherObject = (matcher) => typeof matcher === 'object' && matcher !== null && !(matcher instanceof RegExp);
function createPattern(matcher) {
    if (typeof matcher === 'function')
        return matcher;
    if (typeof matcher === 'string')
        return (string) => matcher === string;
    if (matcher instanceof RegExp)
        return (string) => matcher.test(string);
    if (typeof matcher === 'object' && matcher !== null) {
        return (string) => {
            if (matcher.path === string)
                return true;
            if (matcher.recursive) {
                const relative = sysPath.relative(matcher.path, string);
                if (!relative) {
                    return false;
                }
                return !relative.startsWith('..') && !sysPath.isAbsolute(relative);
            }
            return false;
        };
    }
    return () => false;
}
function normalizePath(path) {
    if (typeof path !== 'string')
        throw new Error('string expected');
    path = sysPath.normalize(path);
    path = path.replace(/\\/g, '/');
    let prepend = false;
    if (path.startsWith('//'))
        prepend = true;
    const DOUBLE_SLASH_RE = /\/\//;
    while (path.match(DOUBLE_SLASH_RE))
        path = path.replace(DOUBLE_SLASH_RE, '/');
    if (prepend)
        path = '/' + path;
    return path;
}
function matchPatterns(patterns, testString, stats) {
    const path = normalizePath(testString);
    for (let index = 0; index < patterns.length; index++) {
        const pattern = patterns[index];
        if (pattern(path, stats)) {
            return true;
        }
    }
    return false;
}
function anymatch(matchers, testString) {
    if (matchers == null) {
        throw new TypeError('anymatch: specify first argument');
    }
    // Early cache for matchers.
    const matchersArray = arrify(matchers);
    const patterns = matchersArray.map((matcher) => createPattern(matcher));
    {
        return (testString, stats) => {
            return matchPatterns(patterns, testString, stats);
        };
    }
}
const unifyPaths = (paths_) => {
    const paths = arrify(paths_).flat();
    if (!paths.every((p) => typeof p === STRING_TYPE)) {
        throw new TypeError(`Non-string provided as watch path: ${paths}`);
    }
    return paths.map(normalizePathToUnix);
};
// If SLASH_SLASH occurs at the beginning of path, it is not replaced
//     because "//StoragePC/DrivePool/Movies" is a valid network path
const toUnix = (string) => {
    let str = string.replace(BACK_SLASH_RE, SLASH);
    let prepend = false;
    if (str.startsWith(SLASH_SLASH)) {
        prepend = true;
    }
    while (str.match(DOUBLE_SLASH_RE)) {
        str = str.replace(DOUBLE_SLASH_RE, SLASH);
    }
    if (prepend) {
        str = SLASH + str;
    }
    return str;
};
// Our version of upath.normalize
// TODO: this is not equal to path-normalize module - investigate why
const normalizePathToUnix = (path) => toUnix(sysPath.normalize(toUnix(path)));
// TODO: refactor
const normalizeIgnored = (cwd = '') => (path) => {
    if (typeof path === 'string') {
        return normalizePathToUnix(sysPath.isAbsolute(path) ? path : sysPath.join(cwd, path));
    }
    else {
        return path;
    }
};
const getAbsolutePath = (path, cwd) => {
    if (sysPath.isAbsolute(path)) {
        return path;
    }
    return sysPath.join(cwd, path);
};
const EMPTY_SET = Object.freeze(new Set());
/**
 * Directory entry.
 */
class DirEntry {
    constructor(dir, removeWatcher) {
        this.path = dir;
        this._removeWatcher = removeWatcher;
        this.items = new Set();
    }
    add(item) {
        const { items } = this;
        if (!items)
            return;
        if (item !== ONE_DOT && item !== TWO_DOTS)
            items.add(item);
    }
    async remove(item) {
        const { items } = this;
        if (!items)
            return;
        items.delete(item);
        if (items.size > 0)
            return;
        const dir = this.path;
        try {
            await readdir$1(dir);
        }
        catch (err) {
            if (this._removeWatcher) {
                this._removeWatcher(sysPath.dirname(dir), sysPath.basename(dir));
            }
        }
    }
    has(item) {
        const { items } = this;
        if (!items)
            return;
        return items.has(item);
    }
    getChildren() {
        const { items } = this;
        if (!items)
            return [];
        return [...items.values()];
    }
    dispose() {
        this.items.clear();
        this.path = '';
        this._removeWatcher = EMPTY_FN;
        this.items = EMPTY_SET;
        Object.freeze(this);
    }
}
const STAT_METHOD_F = 'stat';
const STAT_METHOD_L = 'lstat';
class WatchHelper {
    constructor(path, follow, fsw) {
        this.fsw = fsw;
        const watchPath = path;
        this.path = path = path.replace(REPLACER_RE, '');
        this.watchPath = watchPath;
        this.fullWatchPath = sysPath.resolve(watchPath);
        this.dirParts = [];
        this.dirParts.forEach((parts) => {
            if (parts.length > 1)
                parts.pop();
        });
        this.followSymlinks = follow;
        this.statMethod = follow ? STAT_METHOD_F : STAT_METHOD_L;
    }
    entryPath(entry) {
        return sysPath.join(this.watchPath, sysPath.relative(this.watchPath, entry.fullPath));
    }
    filterPath(entry) {
        const { stats } = entry;
        if (stats && stats.isSymbolicLink())
            return this.filterDir(entry);
        const resolvedPath = this.entryPath(entry);
        // TODO: what if stats is undefined? remove !
        return this.fsw._isntIgnored(resolvedPath, stats) && this.fsw._hasReadPermissions(stats);
    }
    filterDir(entry) {
        return this.fsw._isntIgnored(this.entryPath(entry), entry.stats);
    }
}
/**
 * Watches files & directories for changes. Emitted events:
 * `add`, `addDir`, `change`, `unlink`, `unlinkDir`, `all`, `error`
 *
 *     new FSWatcher()
 *       .add(directories)
 *       .on('add', path => log('File', path, 'was added'))
 */
class FSWatcher extends EventEmitter {
    // Not indenting methods for history sake; for now.
    constructor(_opts = {}) {
        super();
        this.closed = false;
        this._closers = new Map();
        this._ignoredPaths = new Set();
        this._throttled = new Map();
        this._streams = new Set();
        this._symlinkPaths = new Map();
        this._watched = new Map();
        this._pendingWrites = new Map();
        this._pendingUnlinks = new Map();
        this._readyCount = 0;
        this._readyEmitted = false;
        const awf = _opts.awaitWriteFinish;
        const DEF_AWF = { stabilityThreshold: 2000, pollInterval: 100 };
        const opts = {
            // Defaults
            persistent: true,
            ignoreInitial: false,
            ignorePermissionErrors: false,
            interval: 100,
            binaryInterval: 300,
            followSymlinks: true,
            usePolling: false,
            // useAsync: false,
            atomic: true, // NOTE: overwritten later (depends on usePolling)
            ..._opts,
            // Change format
            ignored: _opts.ignored ? arrify(_opts.ignored) : arrify([]),
            awaitWriteFinish: awf === true ? DEF_AWF : typeof awf === 'object' ? { ...DEF_AWF, ...awf } : false,
        };
        // Always default to polling on IBM i because fs.watch() is not available on IBM i.
        if (isIBMi)
            opts.usePolling = true;
        // Editor atomic write normalization enabled by default with fs.watch
        if (opts.atomic === undefined)
            opts.atomic = !opts.usePolling;
        // opts.atomic = typeof _opts.atomic === 'number' ? _opts.atomic : 100;
        // Global override. Useful for developers, who need to force polling for all
        // instances of chokidar, regardless of usage / dependency depth
        const envPoll = process.env.CHOKIDAR_USEPOLLING;
        if (envPoll !== undefined) {
            const envLower = envPoll.toLowerCase();
            if (envLower === 'false' || envLower === '0')
                opts.usePolling = false;
            else if (envLower === 'true' || envLower === '1')
                opts.usePolling = true;
            else
                opts.usePolling = !!envLower;
        }
        const envInterval = process.env.CHOKIDAR_INTERVAL;
        if (envInterval)
            opts.interval = Number.parseInt(envInterval, 10);
        // This is done to emit ready only once, but each 'add' will increase that?
        let readyCalls = 0;
        this._emitReady = () => {
            readyCalls++;
            if (readyCalls >= this._readyCount) {
                this._emitReady = EMPTY_FN;
                this._readyEmitted = true;
                // use process.nextTick to allow time for listener to be bound
                process.nextTick(() => this.emit(EVENTS.READY));
            }
        };
        this._emitRaw = (...args) => this.emit(EVENTS.RAW, ...args);
        this._boundRemove = this._remove.bind(this);
        this.options = opts;
        this._nodeFsHandler = new NodeFsHandler(this);
        // Youâ€™re frozen when your heartâ€™s not open.
        Object.freeze(opts);
    }
    _addIgnoredPath(matcher) {
        if (isMatcherObject(matcher)) {
            // return early if we already have a deeply equal matcher object
            for (const ignored of this._ignoredPaths) {
                if (isMatcherObject(ignored) &&
                    ignored.path === matcher.path &&
                    ignored.recursive === matcher.recursive) {
                    return;
                }
            }
        }
        this._ignoredPaths.add(matcher);
    }
    _removeIgnoredPath(matcher) {
        this._ignoredPaths.delete(matcher);
        // now find any matcher objects with the matcher as path
        if (typeof matcher === 'string') {
            for (const ignored of this._ignoredPaths) {
                // TODO (43081j): make this more efficient.
                // probably just make a `this._ignoredDirectories` or some
                // such thing.
                if (isMatcherObject(ignored) && ignored.path === matcher) {
                    this._ignoredPaths.delete(ignored);
                }
            }
        }
    }
    // Public methods
    /**
     * Adds paths to be watched on an existing FSWatcher instance.
     * @param paths_ file or file list. Other arguments are unused
     */
    add(paths_, _origAdd, _internal) {
        const { cwd } = this.options;
        this.closed = false;
        this._closePromise = undefined;
        let paths = unifyPaths(paths_);
        if (cwd) {
            paths = paths.map((path) => {
                const absPath = getAbsolutePath(path, cwd);
                // Check `path` instead of `absPath` because the cwd portion can't be a glob
                return absPath;
            });
        }
        paths.forEach((path) => {
            this._removeIgnoredPath(path);
        });
        this._userIgnored = undefined;
        if (!this._readyCount)
            this._readyCount = 0;
        this._readyCount += paths.length;
        Promise.all(paths.map(async (path) => {
            const res = await this._nodeFsHandler._addToNodeFs(path, !_internal, undefined, 0, _origAdd);
            if (res)
                this._emitReady();
            return res;
        })).then((results) => {
            if (this.closed)
                return;
            results.forEach((item) => {
                if (item)
                    this.add(sysPath.dirname(item), sysPath.basename(_origAdd || item));
            });
        });
        return this;
    }
    /**
     * Close watchers or start ignoring events from specified paths.
     */
    unwatch(paths_) {
        if (this.closed)
            return this;
        const paths = unifyPaths(paths_);
        const { cwd } = this.options;
        paths.forEach((path) => {
            // convert to absolute path unless relative path already matches
            if (!sysPath.isAbsolute(path) && !this._closers.has(path)) {
                if (cwd)
                    path = sysPath.join(cwd, path);
                path = sysPath.resolve(path);
            }
            this._closePath(path);
            this._addIgnoredPath(path);
            if (this._watched.has(path)) {
                this._addIgnoredPath({
                    path,
                    recursive: true,
                });
            }
            // reset the cached userIgnored anymatch fn
            // to make ignoredPaths changes effective
            this._userIgnored = undefined;
        });
        return this;
    }
    /**
     * Close watchers and remove all listeners from watched paths.
     */
    close() {
        if (this._closePromise) {
            return this._closePromise;
        }
        this.closed = true;
        // Memory management.
        this.removeAllListeners();
        const closers = [];
        this._closers.forEach((closerList) => closerList.forEach((closer) => {
            const promise = closer();
            if (promise instanceof Promise)
                closers.push(promise);
        }));
        this._streams.forEach((stream) => stream.destroy());
        this._userIgnored = undefined;
        this._readyCount = 0;
        this._readyEmitted = false;
        this._watched.forEach((dirent) => dirent.dispose());
        this._closers.clear();
        this._watched.clear();
        this._streams.clear();
        this._symlinkPaths.clear();
        this._throttled.clear();
        this._closePromise = closers.length
            ? Promise.all(closers).then(() => undefined)
            : Promise.resolve();
        return this._closePromise;
    }
    /**
     * Expose list of watched paths
     * @returns for chaining
     */
    getWatched() {
        const watchList = {};
        this._watched.forEach((entry, dir) => {
            const key = this.options.cwd ? sysPath.relative(this.options.cwd, dir) : dir;
            const index = key || ONE_DOT;
            watchList[index] = entry.getChildren().sort();
        });
        return watchList;
    }
    emitWithAll(event, args) {
        this.emit(event, ...args);
        if (event !== EVENTS.ERROR)
            this.emit(EVENTS.ALL, event, ...args);
    }
    // Common helpers
    // --------------
    /**
     * Normalize and emit events.
     * Calling _emit DOES NOT MEAN emit() would be called!
     * @param event Type of event
     * @param path File or directory path
     * @param stats arguments to be passed with event
     * @returns the error if defined, otherwise the value of the FSWatcher instance's `closed` flag
     */
    async _emit(event, path, stats) {
        if (this.closed)
            return;
        const opts = this.options;
        if (isWindows)
            path = sysPath.normalize(path);
        if (opts.cwd)
            path = sysPath.relative(opts.cwd, path);
        const args = [path];
        if (stats != null)
            args.push(stats);
        const awf = opts.awaitWriteFinish;
        let pw;
        if (awf && (pw = this._pendingWrites.get(path))) {
            pw.lastChange = new Date();
            return this;
        }
        if (opts.atomic) {
            if (event === EVENTS.UNLINK) {
                this._pendingUnlinks.set(path, [event, ...args]);
                setTimeout(() => {
                    this._pendingUnlinks.forEach((entry, path) => {
                        this.emit(...entry);
                        this.emit(EVENTS.ALL, ...entry);
                        this._pendingUnlinks.delete(path);
                    });
                }, typeof opts.atomic === 'number' ? opts.atomic : 100);
                return this;
            }
            if (event === EVENTS.ADD && this._pendingUnlinks.has(path)) {
                event = EVENTS.CHANGE;
                this._pendingUnlinks.delete(path);
            }
        }
        if (awf && (event === EVENTS.ADD || event === EVENTS.CHANGE) && this._readyEmitted) {
            const awfEmit = (err, stats) => {
                if (err) {
                    event = EVENTS.ERROR;
                    args[0] = err;
                    this.emitWithAll(event, args);
                }
                else if (stats) {
                    // if stats doesn't exist the file must have been deleted
                    if (args.length > 1) {
                        args[1] = stats;
                    }
                    else {
                        args.push(stats);
                    }
                    this.emitWithAll(event, args);
                }
            };
            this._awaitWriteFinish(path, awf.stabilityThreshold, event, awfEmit);
            return this;
        }
        if (event === EVENTS.CHANGE) {
            const isThrottled = !this._throttle(EVENTS.CHANGE, path, 50);
            if (isThrottled)
                return this;
        }
        if (opts.alwaysStat &&
            stats === undefined &&
            (event === EVENTS.ADD || event === EVENTS.ADD_DIR || event === EVENTS.CHANGE)) {
            const fullPath = opts.cwd ? sysPath.join(opts.cwd, path) : path;
            let stats;
            try {
                stats = await stat$1(fullPath);
            }
            catch (err) {
                // do nothing
            }
            // Suppress event when fs_stat fails, to avoid sending undefined 'stat'
            if (!stats || this.closed)
                return;
            args.push(stats);
        }
        this.emitWithAll(event, args);
        return this;
    }
    /**
     * Common handler for errors
     * @returns The error if defined, otherwise the value of the FSWatcher instance's `closed` flag
     */
    _handleError(error) {
        const code = error && error.code;
        if (error &&
            code !== 'ENOENT' &&
            code !== 'ENOTDIR' &&
            (!this.options.ignorePermissionErrors || (code !== 'EPERM' && code !== 'EACCES'))) {
            this.emit(EVENTS.ERROR, error);
        }
        return error || this.closed;
    }
    /**
     * Helper utility for throttling
     * @param actionType type being throttled
     * @param path being acted upon
     * @param timeout duration of time to suppress duplicate actions
     * @returns tracking object or false if action should be suppressed
     */
    _throttle(actionType, path, timeout) {
        if (!this._throttled.has(actionType)) {
            this._throttled.set(actionType, new Map());
        }
        const action = this._throttled.get(actionType);
        if (!action)
            throw new Error('invalid throttle');
        const actionPath = action.get(path);
        if (actionPath) {
            actionPath.count++;
            return false;
        }
        // eslint-disable-next-line prefer-const
        let timeoutObject;
        const clear = () => {
            const item = action.get(path);
            const count = item ? item.count : 0;
            action.delete(path);
            clearTimeout(timeoutObject);
            if (item)
                clearTimeout(item.timeoutObject);
            return count;
        };
        timeoutObject = setTimeout(clear, timeout);
        const thr = { timeoutObject, clear, count: 0 };
        action.set(path, thr);
        return thr;
    }
    _incrReadyCount() {
        return this._readyCount++;
    }
    /**
     * Awaits write operation to finish.
     * Polls a newly created file for size variations. When files size does not change for 'threshold' milliseconds calls callback.
     * @param path being acted upon
     * @param threshold Time in milliseconds a file size must be fixed before acknowledging write OP is finished
     * @param event
     * @param awfEmit Callback to be called when ready for event to be emitted.
     */
    _awaitWriteFinish(path, threshold, event, awfEmit) {
        const awf = this.options.awaitWriteFinish;
        if (typeof awf !== 'object')
            return;
        const pollInterval = awf.pollInterval;
        let timeoutHandler;
        let fullPath = path;
        if (this.options.cwd && !sysPath.isAbsolute(path)) {
            fullPath = sysPath.join(this.options.cwd, path);
        }
        const now = new Date();
        const writes = this._pendingWrites;
        function awaitWriteFinishFn(prevStat) {
            stat$2(fullPath, (err, curStat) => {
                if (err || !writes.has(path)) {
                    if (err && err.code !== 'ENOENT')
                        awfEmit(err);
                    return;
                }
                const now = Number(new Date());
                if (prevStat && curStat.size !== prevStat.size) {
                    writes.get(path).lastChange = now;
                }
                const pw = writes.get(path);
                const df = now - pw.lastChange;
                if (df >= threshold) {
                    writes.delete(path);
                    awfEmit(undefined, curStat);
                }
                else {
                    timeoutHandler = setTimeout(awaitWriteFinishFn, pollInterval, curStat);
                }
            });
        }
        if (!writes.has(path)) {
            writes.set(path, {
                lastChange: now,
                cancelWait: () => {
                    writes.delete(path);
                    clearTimeout(timeoutHandler);
                    return event;
                },
            });
            timeoutHandler = setTimeout(awaitWriteFinishFn, pollInterval);
        }
    }
    /**
     * Determines whether user has asked to ignore this path.
     */
    _isIgnored(path, stats) {
        if (this.options.atomic && DOT_RE.test(path))
            return true;
        if (!this._userIgnored) {
            const { cwd } = this.options;
            const ign = this.options.ignored;
            const ignored = (ign || []).map(normalizeIgnored(cwd));
            const ignoredPaths = [...this._ignoredPaths];
            const list = [...ignoredPaths.map(normalizeIgnored(cwd)), ...ignored];
            this._userIgnored = anymatch(list);
        }
        return this._userIgnored(path, stats);
    }
    _isntIgnored(path, stat) {
        return !this._isIgnored(path, stat);
    }
    /**
     * Provides a set of common helpers and properties relating to symlink handling.
     * @param path file or directory pattern being watched
     */
    _getWatchHelpers(path) {
        return new WatchHelper(path, this.options.followSymlinks, this);
    }
    // Directory helpers
    // -----------------
    /**
     * Provides directory tracking objects
     * @param directory path of the directory
     */
    _getWatchedDir(directory) {
        const dir = sysPath.resolve(directory);
        if (!this._watched.has(dir))
            this._watched.set(dir, new DirEntry(dir, this._boundRemove));
        return this._watched.get(dir);
    }
    // File helpers
    // ------------
    /**
     * Check for read permissions: https://stackoverflow.com/a/11781404/1358405
     */
    _hasReadPermissions(stats) {
        if (this.options.ignorePermissionErrors)
            return true;
        return Boolean(Number(stats.mode) & 0o400);
    }
    /**
     * Handles emitting unlink events for
     * files and directories, and via recursion, for
     * files and directories within directories that are unlinked
     * @param directory within which the following item is located
     * @param item      base path of item/directory
     */
    _remove(directory, item, isDirectory) {
        // if what is being deleted is a directory, get that directory's paths
        // for recursive deleting and cleaning of watched object
        // if it is not a directory, nestedDirectoryChildren will be empty array
        const path = sysPath.join(directory, item);
        const fullPath = sysPath.resolve(path);
        isDirectory =
            isDirectory != null ? isDirectory : this._watched.has(path) || this._watched.has(fullPath);
        // prevent duplicate handling in case of arriving here nearly simultaneously
        // via multiple paths (such as _handleFile and _handleDir)
        if (!this._throttle('remove', path, 100))
            return;
        // if the only watched file is removed, watch for its return
        if (!isDirectory && this._watched.size === 1) {
            this.add(directory, item, true);
        }
        // This will create a new entry in the watched object in either case
        // so we got to do the directory check beforehand
        const wp = this._getWatchedDir(path);
        const nestedDirectoryChildren = wp.getChildren();
        // Recursively remove children directories / files.
        nestedDirectoryChildren.forEach((nested) => this._remove(path, nested));
        // Check if item was on the watched list and remove it
        const parent = this._getWatchedDir(directory);
        const wasTracked = parent.has(item);
        parent.remove(item);
        // Fixes issue #1042 -> Relative paths were detected and added as symlinks
        // (https://github.com/paulmillr/chokidar/blob/e1753ddbc9571bdc33b4a4af172d52cb6e611c10/lib/nodefs-handler.js#L612),
        // but never removed from the map in case the path was deleted.
        // This leads to an incorrect state if the path was recreated:
        // https://github.com/paulmillr/chokidar/blob/e1753ddbc9571bdc33b4a4af172d52cb6e611c10/lib/nodefs-handler.js#L553
        if (this._symlinkPaths.has(fullPath)) {
            this._symlinkPaths.delete(fullPath);
        }
        // If we wait for this file to be fully written, cancel the wait.
        let relPath = path;
        if (this.options.cwd)
            relPath = sysPath.relative(this.options.cwd, path);
        if (this.options.awaitWriteFinish && this._pendingWrites.has(relPath)) {
            const event = this._pendingWrites.get(relPath).cancelWait();
            if (event === EVENTS.ADD)
                return;
        }
        // The Entry will either be a directory that just got removed
        // or a bogus entry to a file, in either case we have to remove it
        this._watched.delete(path);
        this._watched.delete(fullPath);
        const eventName = isDirectory ? EVENTS.UNLINK_DIR : EVENTS.UNLINK;
        if (wasTracked && !this._isIgnored(path))
            this._emit(eventName, path);
        // Avoid conflicts if we later create another file with the same name
        this._closePath(path);
    }
    /**
     * Closes all watchers for a path
     */
    _closePath(path) {
        this._closeFile(path);
        const dir = sysPath.dirname(path);
        this._getWatchedDir(dir).remove(sysPath.basename(path));
    }
    /**
     * Closes only file-specific watchers
     */
    _closeFile(path) {
        const closers = this._closers.get(path);
        if (!closers)
            return;
        closers.forEach((closer) => closer());
        this._closers.delete(path);
    }
    _addPathCloser(path, closer) {
        if (!closer)
            return;
        let list = this._closers.get(path);
        if (!list) {
            list = [];
            this._closers.set(path, list);
        }
        list.push(closer);
    }
    _readdirp(root, opts) {
        if (this.closed)
            return;
        const options = { type: EVENTS.ALL, alwaysStat: true, lstat: true, ...opts, depth: 0 };
        let stream = readdirp(root, options);
        this._streams.add(stream);
        stream.once(STR_CLOSE, () => {
            stream = undefined;
        });
        stream.once(STR_END, () => {
            if (stream) {
                this._streams.delete(stream);
                stream = undefined;
            }
        });
        return stream;
    }
}
/**
 * Instantiates watcher with paths to be tracked.
 * @param paths file / directory paths
 * @param options opts, such as `atomic`, `awaitWriteFinish`, `ignored`, and others
 * @returns an instance of FSWatcher for chaining.
 * @example
 * const watcher = watch('.').on('all', (event, path) => { console.log(event, path); });
 * watch('.', { atomic: true, awaitWriteFinish: true, ignored: (f, stats) => stats?.isFile() && !f.endsWith('.js') })
 */
function watch(paths, options = {}) {
    const watcher = new FSWatcher(options);
    watcher.add(paths);
    return watcher;
}

var kindOf;
var hasRequiredKindOf;

function requireKindOf () {
	if (hasRequiredKindOf) return kindOf;
	hasRequiredKindOf = 1;
	var toString = Object.prototype.toString;

	kindOf = function kindOf(val) {
	  if (val === void 0) return 'undefined';
	  if (val === null) return 'null';

	  var type = typeof val;
	  if (type === 'boolean') return 'boolean';
	  if (type === 'string') return 'string';
	  if (type === 'number') return 'number';
	  if (type === 'symbol') return 'symbol';
	  if (type === 'function') {
	    return isGeneratorFn(val) ? 'generatorfunction' : 'function';
	  }

	  if (isArray(val)) return 'array';
	  if (isBuffer(val)) return 'buffer';
	  if (isArguments(val)) return 'arguments';
	  if (isDate(val)) return 'date';
	  if (isError(val)) return 'error';
	  if (isRegexp(val)) return 'regexp';

	  switch (ctorName(val)) {
	    case 'Symbol': return 'symbol';
	    case 'Promise': return 'promise';

	    // Set, Map, WeakSet, WeakMap
	    case 'WeakMap': return 'weakmap';
	    case 'WeakSet': return 'weakset';
	    case 'Map': return 'map';
	    case 'Set': return 'set';

	    // 8-bit typed arrays
	    case 'Int8Array': return 'int8array';
	    case 'Uint8Array': return 'uint8array';
	    case 'Uint8ClampedArray': return 'uint8clampedarray';

	    // 16-bit typed arrays
	    case 'Int16Array': return 'int16array';
	    case 'Uint16Array': return 'uint16array';

	    // 32-bit typed arrays
	    case 'Int32Array': return 'int32array';
	    case 'Uint32Array': return 'uint32array';
	    case 'Float32Array': return 'float32array';
	    case 'Float64Array': return 'float64array';
	  }

	  if (isGeneratorObj(val)) {
	    return 'generator';
	  }

	  // Non-plain objects
	  type = toString.call(val);
	  switch (type) {
	    case '[object Object]': return 'object';
	    // iterators
	    case '[object Map Iterator]': return 'mapiterator';
	    case '[object Set Iterator]': return 'setiterator';
	    case '[object String Iterator]': return 'stringiterator';
	    case '[object Array Iterator]': return 'arrayiterator';
	  }

	  // other
	  return type.slice(8, -1).toLowerCase().replace(/\s/g, '');
	};

	function ctorName(val) {
	  return typeof val.constructor === 'function' ? val.constructor.name : null;
	}

	function isArray(val) {
	  if (Array.isArray) return Array.isArray(val);
	  return val instanceof Array;
	}

	function isError(val) {
	  return val instanceof Error || (typeof val.message === 'string' && val.constructor && typeof val.constructor.stackTraceLimit === 'number');
	}

	function isDate(val) {
	  if (val instanceof Date) return true;
	  return typeof val.toDateString === 'function'
	    && typeof val.getDate === 'function'
	    && typeof val.setDate === 'function';
	}

	function isRegexp(val) {
	  if (val instanceof RegExp) return true;
	  return typeof val.flags === 'string'
	    && typeof val.ignoreCase === 'boolean'
	    && typeof val.multiline === 'boolean'
	    && typeof val.global === 'boolean';
	}

	function isGeneratorFn(name, val) {
	  return ctorName(name) === 'GeneratorFunction';
	}

	function isGeneratorObj(val) {
	  return typeof val.throw === 'function'
	    && typeof val.return === 'function'
	    && typeof val.next === 'function';
	}

	function isArguments(val) {
	  try {
	    if (typeof val.length === 'number' && typeof val.callee === 'function') {
	      return true;
	    }
	  } catch (err) {
	    if (err.message.indexOf('callee') !== -1) {
	      return true;
	    }
	  }
	  return false;
	}

	/**
	 * If you need to support Safari 5-7 (8-10 yr-old browser),
	 * take a look at https://github.com/feross/is-buffer
	 */

	function isBuffer(val) {
	  if (val.constructor && typeof val.constructor.isBuffer === 'function') {
	    return val.constructor.isBuffer(val);
	  }
	  return false;
	}
	return kindOf;
}

/*!
 * is-extendable <https://github.com/jonschlinkert/is-extendable>
 *
 * Copyright (c) 2015, Jon Schlinkert.
 * Licensed under the MIT License.
 */

var isExtendable;
var hasRequiredIsExtendable;

function requireIsExtendable () {
	if (hasRequiredIsExtendable) return isExtendable;
	hasRequiredIsExtendable = 1;

	isExtendable = function isExtendable(val) {
	  return typeof val !== 'undefined' && val !== null
	    && (typeof val === 'object' || typeof val === 'function');
	};
	return isExtendable;
}

var extendShallow;
var hasRequiredExtendShallow;

function requireExtendShallow () {
	if (hasRequiredExtendShallow) return extendShallow;
	hasRequiredExtendShallow = 1;

	var isObject = requireIsExtendable();

	extendShallow = function extend(o/*, objects*/) {
	  if (!isObject(o)) { o = {}; }

	  var len = arguments.length;
	  for (var i = 1; i < len; i++) {
	    var obj = arguments[i];

	    if (isObject(obj)) {
	      assign(o, obj);
	    }
	  }
	  return o;
	};

	function assign(a, b) {
	  for (var key in b) {
	    if (hasOwn(b, key)) {
	      a[key] = b[key];
	    }
	  }
	}

	/**
	 * Returns true if the given `key` is an own property of `obj`.
	 */

	function hasOwn(obj, key) {
	  return Object.prototype.hasOwnProperty.call(obj, key);
	}
	return extendShallow;
}

var sectionMatter;
var hasRequiredSectionMatter;

function requireSectionMatter () {
	if (hasRequiredSectionMatter) return sectionMatter;
	hasRequiredSectionMatter = 1;

	var typeOf = requireKindOf();
	var extend = requireExtendShallow();

	/**
	 * Parse sections in `input` with the given `options`.
	 *
	 * ```js
	 * var sections = require('{%= name %}');
	 * var result = sections(input, options);
	 * // { content: 'Content before sections', sections: [] }
	 * ```
	 * @param {String|Buffer|Object} `input` If input is an object, it's `content` property must be a string or buffer.
	 * @param {Object} options
	 * @return {Object} Returns an object with a `content` string and an array of `sections` objects.
	 * @api public
	 */

	sectionMatter = function(input, options) {
	  if (typeof options === 'function') {
	    options = { parse: options };
	  }

	  var file = toObject(input);
	  var defaults = {section_delimiter: '---', parse: identity};
	  var opts = extend({}, defaults, options);
	  var delim = opts.section_delimiter;
	  var lines = file.content.split(/\r?\n/);
	  var sections = null;
	  var section = createSection();
	  var content = [];
	  var stack = [];

	  function initSections(val) {
	    file.content = val;
	    sections = [];
	    content = [];
	  }

	  function closeSection(val) {
	    if (stack.length) {
	      section.key = getKey(stack[0], delim);
	      section.content = val;
	      opts.parse(section, sections);
	      sections.push(section);
	      section = createSection();
	      content = [];
	      stack = [];
	    }
	  }

	  for (var i = 0; i < lines.length; i++) {
	    var line = lines[i];
	    var len = stack.length;
	    var ln = line.trim();

	    if (isDelimiter(ln, delim)) {
	      if (ln.length === 3 && i !== 0) {
	        if (len === 0 || len === 2) {
	          content.push(line);
	          continue;
	        }
	        stack.push(ln);
	        section.data = content.join('\n');
	        content = [];
	        continue;
	      }

	      if (sections === null) {
	        initSections(content.join('\n'));
	      }

	      if (len === 2) {
	        closeSection(content.join('\n'));
	      }

	      stack.push(ln);
	      continue;
	    }

	    content.push(line);
	  }

	  if (sections === null) {
	    initSections(content.join('\n'));
	  } else {
	    closeSection(content.join('\n'));
	  }

	  file.sections = sections;
	  return file;
	};

	function isDelimiter(line, delim) {
	  if (line.slice(0, delim.length) !== delim) {
	    return false;
	  }
	  if (line.charAt(delim.length + 1) === delim.slice(-1)) {
	    return false;
	  }
	  return true;
	}

	function toObject(input) {
	  if (typeOf(input) !== 'object') {
	    input = { content: input };
	  }

	  if (typeof input.content !== 'string' && !isBuffer(input.content)) {
	    throw new TypeError('expected a buffer or string');
	  }

	  input.content = input.content.toString();
	  input.sections = [];
	  return input;
	}

	function getKey(val, delim) {
	  return val ? val.slice(delim.length).trim() : '';
	}

	function createSection() {
	  return { key: '', data: '', content: '' };
	}

	function identity(val) {
	  return val;
	}

	function isBuffer(val) {
	  if (val && val.constructor && typeof val.constructor.isBuffer === 'function') {
	    return val.constructor.isBuffer(val);
	  }
	  return false;
	}
	return sectionMatter;
}

var engines = {exports: {}};

var jsYaml$1 = {};

var loader = {};

var common = {};

var hasRequiredCommon;

function requireCommon () {
	if (hasRequiredCommon) return common;
	hasRequiredCommon = 1;


	function isNothing(subject) {
	  return (typeof subject === 'undefined') || (subject === null);
	}


	function isObject(subject) {
	  return (typeof subject === 'object') && (subject !== null);
	}


	function toArray(sequence) {
	  if (Array.isArray(sequence)) return sequence;
	  else if (isNothing(sequence)) return [];

	  return [ sequence ];
	}


	function extend(target, source) {
	  var index, length, key, sourceKeys;

	  if (source) {
	    sourceKeys = Object.keys(source);

	    for (index = 0, length = sourceKeys.length; index < length; index += 1) {
	      key = sourceKeys[index];
	      target[key] = source[key];
	    }
	  }

	  return target;
	}


	function repeat(string, count) {
	  var result = '', cycle;

	  for (cycle = 0; cycle < count; cycle += 1) {
	    result += string;
	  }

	  return result;
	}


	function isNegativeZero(number) {
	  return (number === 0) && (Number.NEGATIVE_INFINITY === 1 / number);
	}


	common.isNothing      = isNothing;
	common.isObject       = isObject;
	common.toArray        = toArray;
	common.repeat         = repeat;
	common.isNegativeZero = isNegativeZero;
	common.extend         = extend;
	return common;
}

var exception;
var hasRequiredException;

function requireException () {
	if (hasRequiredException) return exception;
	hasRequiredException = 1;

	function YAMLException(reason, mark) {
	  // Super constructor
	  Error.call(this);

	  this.name = 'YAMLException';
	  this.reason = reason;
	  this.mark = mark;
	  this.message = (this.reason || '(unknown reason)') + (this.mark ? ' ' + this.mark.toString() : '');

	  // Include stack trace in error object
	  if (Error.captureStackTrace) {
	    // Chrome and NodeJS
	    Error.captureStackTrace(this, this.constructor);
	  } else {
	    // FF, IE 10+ and Safari 6+. Fallback for others
	    this.stack = (new Error()).stack || '';
	  }
	}


	// Inherit from Error
	YAMLException.prototype = Object.create(Error.prototype);
	YAMLException.prototype.constructor = YAMLException;


	YAMLException.prototype.toString = function toString(compact) {
	  var result = this.name + ': ';

	  result += this.reason || '(unknown reason)';

	  if (!compact && this.mark) {
	    result += ' ' + this.mark.toString();
	  }

	  return result;
	};


	exception = YAMLException;
	return exception;
}

var mark;
var hasRequiredMark;

function requireMark () {
	if (hasRequiredMark) return mark;
	hasRequiredMark = 1;


	var common = requireCommon();


	function Mark(name, buffer, position, line, column) {
	  this.name     = name;
	  this.buffer   = buffer;
	  this.position = position;
	  this.line     = line;
	  this.column   = column;
	}


	Mark.prototype.getSnippet = function getSnippet(indent, maxLength) {
	  var head, start, tail, end, snippet;

	  if (!this.buffer) return null;

	  indent = indent || 4;
	  maxLength = maxLength || 75;

	  head = '';
	  start = this.position;

	  while (start > 0 && '\x00\r\n\x85\u2028\u2029'.indexOf(this.buffer.charAt(start - 1)) === -1) {
	    start -= 1;
	    if (this.position - start > (maxLength / 2 - 1)) {
	      head = ' ... ';
	      start += 5;
	      break;
	    }
	  }

	  tail = '';
	  end = this.position;

	  while (end < this.buffer.length && '\x00\r\n\x85\u2028\u2029'.indexOf(this.buffer.charAt(end)) === -1) {
	    end += 1;
	    if (end - this.position > (maxLength / 2 - 1)) {
	      tail = ' ... ';
	      end -= 5;
	      break;
	    }
	  }

	  snippet = this.buffer.slice(start, end);

	  return common.repeat(' ', indent) + head + snippet + tail + '\n' +
	         common.repeat(' ', indent + this.position - start + head.length) + '^';
	};


	Mark.prototype.toString = function toString(compact) {
	  var snippet, where = '';

	  if (this.name) {
	    where += 'in "' + this.name + '" ';
	  }

	  where += 'at line ' + (this.line + 1) + ', column ' + (this.column + 1);

	  if (!compact) {
	    snippet = this.getSnippet();

	    if (snippet) {
	      where += ':\n' + snippet;
	    }
	  }

	  return where;
	};


	mark = Mark;
	return mark;
}

var type;
var hasRequiredType;

function requireType () {
	if (hasRequiredType) return type;
	hasRequiredType = 1;

	var YAMLException = requireException();

	var TYPE_CONSTRUCTOR_OPTIONS = [
	  'kind',
	  'resolve',
	  'construct',
	  'instanceOf',
	  'predicate',
	  'represent',
	  'defaultStyle',
	  'styleAliases'
	];

	var YAML_NODE_KINDS = [
	  'scalar',
	  'sequence',
	  'mapping'
	];

	function compileStyleAliases(map) {
	  var result = {};

	  if (map !== null) {
	    Object.keys(map).forEach(function (style) {
	      map[style].forEach(function (alias) {
	        result[String(alias)] = style;
	      });
	    });
	  }

	  return result;
	}

	function Type(tag, options) {
	  options = options || {};

	  Object.keys(options).forEach(function (name) {
	    if (TYPE_CONSTRUCTOR_OPTIONS.indexOf(name) === -1) {
	      throw new YAMLException('Unknown option "' + name + '" is met in definition of "' + tag + '" YAML type.');
	    }
	  });

	  // TODO: Add tag format check.
	  this.tag          = tag;
	  this.kind         = options['kind']         || null;
	  this.resolve      = options['resolve']      || function () { return true; };
	  this.construct    = options['construct']    || function (data) { return data; };
	  this.instanceOf   = options['instanceOf']   || null;
	  this.predicate    = options['predicate']    || null;
	  this.represent    = options['represent']    || null;
	  this.defaultStyle = options['defaultStyle'] || null;
	  this.styleAliases = compileStyleAliases(options['styleAliases'] || null);

	  if (YAML_NODE_KINDS.indexOf(this.kind) === -1) {
	    throw new YAMLException('Unknown kind "' + this.kind + '" is specified for "' + tag + '" YAML type.');
	  }
	}

	type = Type;
	return type;
}

var schema;
var hasRequiredSchema;

function requireSchema () {
	if (hasRequiredSchema) return schema;
	hasRequiredSchema = 1;

	/*eslint-disable max-len*/

	var common        = requireCommon();
	var YAMLException = requireException();
	var Type          = requireType();


	function compileList(schema, name, result) {
	  var exclude = [];

	  schema.include.forEach(function (includedSchema) {
	    result = compileList(includedSchema, name, result);
	  });

	  schema[name].forEach(function (currentType) {
	    result.forEach(function (previousType, previousIndex) {
	      if (previousType.tag === currentType.tag && previousType.kind === currentType.kind) {
	        exclude.push(previousIndex);
	      }
	    });

	    result.push(currentType);
	  });

	  return result.filter(function (type, index) {
	    return exclude.indexOf(index) === -1;
	  });
	}


	function compileMap(/* lists... */) {
	  var result = {
	        scalar: {},
	        sequence: {},
	        mapping: {},
	        fallback: {}
	      }, index, length;

	  function collectType(type) {
	    result[type.kind][type.tag] = result['fallback'][type.tag] = type;
	  }

	  for (index = 0, length = arguments.length; index < length; index += 1) {
	    arguments[index].forEach(collectType);
	  }
	  return result;
	}


	function Schema(definition) {
	  this.include  = definition.include  || [];
	  this.implicit = definition.implicit || [];
	  this.explicit = definition.explicit || [];

	  this.implicit.forEach(function (type) {
	    if (type.loadKind && type.loadKind !== 'scalar') {
	      throw new YAMLException('There is a non-scalar type in the implicit list of a schema. Implicit resolving of such types is not supported.');
	    }
	  });

	  this.compiledImplicit = compileList(this, 'implicit', []);
	  this.compiledExplicit = compileList(this, 'explicit', []);
	  this.compiledTypeMap  = compileMap(this.compiledImplicit, this.compiledExplicit);
	}


	Schema.DEFAULT = null;


	Schema.create = function createSchema() {
	  var schemas, types;

	  switch (arguments.length) {
	    case 1:
	      schemas = Schema.DEFAULT;
	      types = arguments[0];
	      break;

	    case 2:
	      schemas = arguments[0];
	      types = arguments[1];
	      break;

	    default:
	      throw new YAMLException('Wrong number of arguments for Schema.create function');
	  }

	  schemas = common.toArray(schemas);
	  types = common.toArray(types);

	  if (!schemas.every(function (schema) { return schema instanceof Schema; })) {
	    throw new YAMLException('Specified list of super schemas (or a single Schema object) contains a non-Schema object.');
	  }

	  if (!types.every(function (type) { return type instanceof Type; })) {
	    throw new YAMLException('Specified list of YAML types (or a single Type object) contains a non-Type object.');
	  }

	  return new Schema({
	    include: schemas,
	    explicit: types
	  });
	};


	schema = Schema;
	return schema;
}

var str;
var hasRequiredStr;

function requireStr () {
	if (hasRequiredStr) return str;
	hasRequiredStr = 1;

	var Type = requireType();

	str = new Type('tag:yaml.org,2002:str', {
	  kind: 'scalar',
	  construct: function (data) { return data !== null ? data : ''; }
	});
	return str;
}

var seq$1;
var hasRequiredSeq;

function requireSeq () {
	if (hasRequiredSeq) return seq$1;
	hasRequiredSeq = 1;

	var Type = requireType();

	seq$1 = new Type('tag:yaml.org,2002:seq', {
	  kind: 'sequence',
	  construct: function (data) { return data !== null ? data : []; }
	});
	return seq$1;
}

var map$1;
var hasRequiredMap;

function requireMap () {
	if (hasRequiredMap) return map$1;
	hasRequiredMap = 1;

	var Type = requireType();

	map$1 = new Type('tag:yaml.org,2002:map', {
	  kind: 'mapping',
	  construct: function (data) { return data !== null ? data : {}; }
	});
	return map$1;
}

var failsafe;
var hasRequiredFailsafe;

function requireFailsafe () {
	if (hasRequiredFailsafe) return failsafe;
	hasRequiredFailsafe = 1;


	var Schema = requireSchema();


	failsafe = new Schema({
	  explicit: [
	    requireStr(),
	    requireSeq(),
	    requireMap()
	  ]
	});
	return failsafe;
}

var _null;
var hasRequired_null;

function require_null () {
	if (hasRequired_null) return _null;
	hasRequired_null = 1;

	var Type = requireType();

	function resolveYamlNull(data) {
	  if (data === null) return true;

	  var max = data.length;

	  return (max === 1 && data === '~') ||
	         (max === 4 && (data === 'null' || data === 'Null' || data === 'NULL'));
	}

	function constructYamlNull() {
	  return null;
	}

	function isNull(object) {
	  return object === null;
	}

	_null = new Type('tag:yaml.org,2002:null', {
	  kind: 'scalar',
	  resolve: resolveYamlNull,
	  construct: constructYamlNull,
	  predicate: isNull,
	  represent: {
	    canonical: function () { return '~';    },
	    lowercase: function () { return 'null'; },
	    uppercase: function () { return 'NULL'; },
	    camelcase: function () { return 'Null'; }
	  },
	  defaultStyle: 'lowercase'
	});
	return _null;
}

var bool;
var hasRequiredBool;

function requireBool () {
	if (hasRequiredBool) return bool;
	hasRequiredBool = 1;

	var Type = requireType();

	function resolveYamlBoolean(data) {
	  if (data === null) return false;

	  var max = data.length;

	  return (max === 4 && (data === 'true' || data === 'True' || data === 'TRUE')) ||
	         (max === 5 && (data === 'false' || data === 'False' || data === 'FALSE'));
	}

	function constructYamlBoolean(data) {
	  return data === 'true' ||
	         data === 'True' ||
	         data === 'TRUE';
	}

	function isBoolean(object) {
	  return Object.prototype.toString.call(object) === '[object Boolean]';
	}

	bool = new Type('tag:yaml.org,2002:bool', {
	  kind: 'scalar',
	  resolve: resolveYamlBoolean,
	  construct: constructYamlBoolean,
	  predicate: isBoolean,
	  represent: {
	    lowercase: function (object) { return object ? 'true' : 'false'; },
	    uppercase: function (object) { return object ? 'TRUE' : 'FALSE'; },
	    camelcase: function (object) { return object ? 'True' : 'False'; }
	  },
	  defaultStyle: 'lowercase'
	});
	return bool;
}

var int;
var hasRequiredInt;

function requireInt () {
	if (hasRequiredInt) return int;
	hasRequiredInt = 1;

	var common = requireCommon();
	var Type   = requireType();

	function isHexCode(c) {
	  return ((0x30/* 0 */ <= c) && (c <= 0x39/* 9 */)) ||
	         ((0x41/* A */ <= c) && (c <= 0x46/* F */)) ||
	         ((0x61/* a */ <= c) && (c <= 0x66/* f */));
	}

	function isOctCode(c) {
	  return ((0x30/* 0 */ <= c) && (c <= 0x37/* 7 */));
	}

	function isDecCode(c) {
	  return ((0x30/* 0 */ <= c) && (c <= 0x39/* 9 */));
	}

	function resolveYamlInteger(data) {
	  if (data === null) return false;

	  var max = data.length,
	      index = 0,
	      hasDigits = false,
	      ch;

	  if (!max) return false;

	  ch = data[index];

	  // sign
	  if (ch === '-' || ch === '+') {
	    ch = data[++index];
	  }

	  if (ch === '0') {
	    // 0
	    if (index + 1 === max) return true;
	    ch = data[++index];

	    // base 2, base 8, base 16

	    if (ch === 'b') {
	      // base 2
	      index++;

	      for (; index < max; index++) {
	        ch = data[index];
	        if (ch === '_') continue;
	        if (ch !== '0' && ch !== '1') return false;
	        hasDigits = true;
	      }
	      return hasDigits && ch !== '_';
	    }


	    if (ch === 'x') {
	      // base 16
	      index++;

	      for (; index < max; index++) {
	        ch = data[index];
	        if (ch === '_') continue;
	        if (!isHexCode(data.charCodeAt(index))) return false;
	        hasDigits = true;
	      }
	      return hasDigits && ch !== '_';
	    }

	    // base 8
	    for (; index < max; index++) {
	      ch = data[index];
	      if (ch === '_') continue;
	      if (!isOctCode(data.charCodeAt(index))) return false;
	      hasDigits = true;
	    }
	    return hasDigits && ch !== '_';
	  }

	  // base 10 (except 0) or base 60

	  // value should not start with `_`;
	  if (ch === '_') return false;

	  for (; index < max; index++) {
	    ch = data[index];
	    if (ch === '_') continue;
	    if (ch === ':') break;
	    if (!isDecCode(data.charCodeAt(index))) {
	      return false;
	    }
	    hasDigits = true;
	  }

	  // Should have digits and should not end with `_`
	  if (!hasDigits || ch === '_') return false;

	  // if !base60 - done;
	  if (ch !== ':') return true;

	  // base60 almost not used, no needs to optimize
	  return /^(:[0-5]?[0-9])+$/.test(data.slice(index));
	}

	function constructYamlInteger(data) {
	  var value = data, sign = 1, ch, base, digits = [];

	  if (value.indexOf('_') !== -1) {
	    value = value.replace(/_/g, '');
	  }

	  ch = value[0];

	  if (ch === '-' || ch === '+') {
	    if (ch === '-') sign = -1;
	    value = value.slice(1);
	    ch = value[0];
	  }

	  if (value === '0') return 0;

	  if (ch === '0') {
	    if (value[1] === 'b') return sign * parseInt(value.slice(2), 2);
	    if (value[1] === 'x') return sign * parseInt(value, 16);
	    return sign * parseInt(value, 8);
	  }

	  if (value.indexOf(':') !== -1) {
	    value.split(':').forEach(function (v) {
	      digits.unshift(parseInt(v, 10));
	    });

	    value = 0;
	    base = 1;

	    digits.forEach(function (d) {
	      value += (d * base);
	      base *= 60;
	    });

	    return sign * value;

	  }

	  return sign * parseInt(value, 10);
	}

	function isInteger(object) {
	  return (Object.prototype.toString.call(object)) === '[object Number]' &&
	         (object % 1 === 0 && !common.isNegativeZero(object));
	}

	int = new Type('tag:yaml.org,2002:int', {
	  kind: 'scalar',
	  resolve: resolveYamlInteger,
	  construct: constructYamlInteger,
	  predicate: isInteger,
	  represent: {
	    binary:      function (obj) { return obj >= 0 ? '0b' + obj.toString(2) : '-0b' + obj.toString(2).slice(1); },
	    octal:       function (obj) { return obj >= 0 ? '0'  + obj.toString(8) : '-0'  + obj.toString(8).slice(1); },
	    decimal:     function (obj) { return obj.toString(10); },
	    /* eslint-disable max-len */
	    hexadecimal: function (obj) { return obj >= 0 ? '0x' + obj.toString(16).toUpperCase() :  '-0x' + obj.toString(16).toUpperCase().slice(1); }
	  },
	  defaultStyle: 'decimal',
	  styleAliases: {
	    binary:      [ 2,  'bin' ],
	    octal:       [ 8,  'oct' ],
	    decimal:     [ 10, 'dec' ],
	    hexadecimal: [ 16, 'hex' ]
	  }
	});
	return int;
}

var float;
var hasRequiredFloat;

function requireFloat () {
	if (hasRequiredFloat) return float;
	hasRequiredFloat = 1;

	var common = requireCommon();
	var Type   = requireType();

	var YAML_FLOAT_PATTERN = new RegExp(
	  // 2.5e4, 2.5 and integers
	  '^(?:[-+]?(?:0|[1-9][0-9_]*)(?:\\.[0-9_]*)?(?:[eE][-+]?[0-9]+)?' +
	  // .2e4, .2
	  // special case, seems not from spec
	  '|\\.[0-9_]+(?:[eE][-+]?[0-9]+)?' +
	  // 20:59
	  '|[-+]?[0-9][0-9_]*(?::[0-5]?[0-9])+\\.[0-9_]*' +
	  // .inf
	  '|[-+]?\\.(?:inf|Inf|INF)' +
	  // .nan
	  '|\\.(?:nan|NaN|NAN))$');

	function resolveYamlFloat(data) {
	  if (data === null) return false;

	  if (!YAML_FLOAT_PATTERN.test(data) ||
	      // Quick hack to not allow integers end with `_`
	      // Probably should update regexp & check speed
	      data[data.length - 1] === '_') {
	    return false;
	  }

	  return true;
	}

	function constructYamlFloat(data) {
	  var value, sign, base, digits;

	  value  = data.replace(/_/g, '').toLowerCase();
	  sign   = value[0] === '-' ? -1 : 1;
	  digits = [];

	  if ('+-'.indexOf(value[0]) >= 0) {
	    value = value.slice(1);
	  }

	  if (value === '.inf') {
	    return (sign === 1) ? Number.POSITIVE_INFINITY : Number.NEGATIVE_INFINITY;

	  } else if (value === '.nan') {
	    return NaN;

	  } else if (value.indexOf(':') >= 0) {
	    value.split(':').forEach(function (v) {
	      digits.unshift(parseFloat(v, 10));
	    });

	    value = 0.0;
	    base = 1;

	    digits.forEach(function (d) {
	      value += d * base;
	      base *= 60;
	    });

	    return sign * value;

	  }
	  return sign * parseFloat(value, 10);
	}


	var SCIENTIFIC_WITHOUT_DOT = /^[-+]?[0-9]+e/;

	function representYamlFloat(object, style) {
	  var res;

	  if (isNaN(object)) {
	    switch (style) {
	      case 'lowercase': return '.nan';
	      case 'uppercase': return '.NAN';
	      case 'camelcase': return '.NaN';
	    }
	  } else if (Number.POSITIVE_INFINITY === object) {
	    switch (style) {
	      case 'lowercase': return '.inf';
	      case 'uppercase': return '.INF';
	      case 'camelcase': return '.Inf';
	    }
	  } else if (Number.NEGATIVE_INFINITY === object) {
	    switch (style) {
	      case 'lowercase': return '-.inf';
	      case 'uppercase': return '-.INF';
	      case 'camelcase': return '-.Inf';
	    }
	  } else if (common.isNegativeZero(object)) {
	    return '-0.0';
	  }

	  res = object.toString(10);

	  // JS stringifier can build scientific format without dots: 5e-100,
	  // while YAML requres dot: 5.e-100. Fix it with simple hack

	  return SCIENTIFIC_WITHOUT_DOT.test(res) ? res.replace('e', '.e') : res;
	}

	function isFloat(object) {
	  return (Object.prototype.toString.call(object) === '[object Number]') &&
	         (object % 1 !== 0 || common.isNegativeZero(object));
	}

	float = new Type('tag:yaml.org,2002:float', {
	  kind: 'scalar',
	  resolve: resolveYamlFloat,
	  construct: constructYamlFloat,
	  predicate: isFloat,
	  represent: representYamlFloat,
	  defaultStyle: 'lowercase'
	});
	return float;
}

var json;
var hasRequiredJson;

function requireJson () {
	if (hasRequiredJson) return json;
	hasRequiredJson = 1;


	var Schema = requireSchema();


	json = new Schema({
	  include: [
	    requireFailsafe()
	  ],
	  implicit: [
	    require_null(),
	    requireBool(),
	    requireInt(),
	    requireFloat()
	  ]
	});
	return json;
}

var core;
var hasRequiredCore;

function requireCore () {
	if (hasRequiredCore) return core;
	hasRequiredCore = 1;


	var Schema = requireSchema();


	core = new Schema({
	  include: [
	    requireJson()
	  ]
	});
	return core;
}

var timestamp;
var hasRequiredTimestamp;

function requireTimestamp () {
	if (hasRequiredTimestamp) return timestamp;
	hasRequiredTimestamp = 1;

	var Type = requireType();

	var YAML_DATE_REGEXP = new RegExp(
	  '^([0-9][0-9][0-9][0-9])'          + // [1] year
	  '-([0-9][0-9])'                    + // [2] month
	  '-([0-9][0-9])$');                   // [3] day

	var YAML_TIMESTAMP_REGEXP = new RegExp(
	  '^([0-9][0-9][0-9][0-9])'          + // [1] year
	  '-([0-9][0-9]?)'                   + // [2] month
	  '-([0-9][0-9]?)'                   + // [3] day
	  '(?:[Tt]|[ \\t]+)'                 + // ...
	  '([0-9][0-9]?)'                    + // [4] hour
	  ':([0-9][0-9])'                    + // [5] minute
	  ':([0-9][0-9])'                    + // [6] second
	  '(?:\\.([0-9]*))?'                 + // [7] fraction
	  '(?:[ \\t]*(Z|([-+])([0-9][0-9]?)' + // [8] tz [9] tz_sign [10] tz_hour
	  '(?::([0-9][0-9]))?))?$');           // [11] tz_minute

	function resolveYamlTimestamp(data) {
	  if (data === null) return false;
	  if (YAML_DATE_REGEXP.exec(data) !== null) return true;
	  if (YAML_TIMESTAMP_REGEXP.exec(data) !== null) return true;
	  return false;
	}

	function constructYamlTimestamp(data) {
	  var match, year, month, day, hour, minute, second, fraction = 0,
	      delta = null, tz_hour, tz_minute, date;

	  match = YAML_DATE_REGEXP.exec(data);
	  if (match === null) match = YAML_TIMESTAMP_REGEXP.exec(data);

	  if (match === null) throw new Error('Date resolve error');

	  // match: [1] year [2] month [3] day

	  year = +(match[1]);
	  month = +(match[2]) - 1; // JS month starts with 0
	  day = +(match[3]);

	  if (!match[4]) { // no hour
	    return new Date(Date.UTC(year, month, day));
	  }

	  // match: [4] hour [5] minute [6] second [7] fraction

	  hour = +(match[4]);
	  minute = +(match[5]);
	  second = +(match[6]);

	  if (match[7]) {
	    fraction = match[7].slice(0, 3);
	    while (fraction.length < 3) { // milli-seconds
	      fraction += '0';
	    }
	    fraction = +fraction;
	  }

	  // match: [8] tz [9] tz_sign [10] tz_hour [11] tz_minute

	  if (match[9]) {
	    tz_hour = +(match[10]);
	    tz_minute = +(match[11] || 0);
	    delta = (tz_hour * 60 + tz_minute) * 60000; // delta in mili-seconds
	    if (match[9] === '-') delta = -delta;
	  }

	  date = new Date(Date.UTC(year, month, day, hour, minute, second, fraction));

	  if (delta) date.setTime(date.getTime() - delta);

	  return date;
	}

	function representYamlTimestamp(object /*, style*/) {
	  return object.toISOString();
	}

	timestamp = new Type('tag:yaml.org,2002:timestamp', {
	  kind: 'scalar',
	  resolve: resolveYamlTimestamp,
	  construct: constructYamlTimestamp,
	  instanceOf: Date,
	  represent: representYamlTimestamp
	});
	return timestamp;
}

var merge$1;
var hasRequiredMerge;

function requireMerge () {
	if (hasRequiredMerge) return merge$1;
	hasRequiredMerge = 1;

	var Type = requireType();

	function resolveYamlMerge(data) {
	  return data === '<<' || data === null;
	}

	merge$1 = new Type('tag:yaml.org,2002:merge', {
	  kind: 'scalar',
	  resolve: resolveYamlMerge
	});
	return merge$1;
}

function commonjsRequire(path) {
	throw new Error('Could not dynamically require "' + path + '". Please configure the dynamicRequireTargets or/and ignoreDynamicRequires option of @rollup/plugin-commonjs appropriately for this require call to work.');
}

var binary;
var hasRequiredBinary;

function requireBinary () {
	if (hasRequiredBinary) return binary;
	hasRequiredBinary = 1;

	/*eslint-disable no-bitwise*/

	var NodeBuffer;

	try {
	  // A trick for browserified version, to not include `Buffer` shim
	  var _require = commonjsRequire;
	  NodeBuffer = _require('buffer').Buffer;
	} catch (__) {}

	var Type       = requireType();


	// [ 64, 65, 66 ] -> [ padding, CR, LF ]
	var BASE64_MAP = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=\n\r';


	function resolveYamlBinary(data) {
	  if (data === null) return false;

	  var code, idx, bitlen = 0, max = data.length, map = BASE64_MAP;

	  // Convert one by one.
	  for (idx = 0; idx < max; idx++) {
	    code = map.indexOf(data.charAt(idx));

	    // Skip CR/LF
	    if (code > 64) continue;

	    // Fail on illegal characters
	    if (code < 0) return false;

	    bitlen += 6;
	  }

	  // If there are any bits left, source was corrupted
	  return (bitlen % 8) === 0;
	}

	function constructYamlBinary(data) {
	  var idx, tailbits,
	      input = data.replace(/[\r\n=]/g, ''), // remove CR/LF & padding to simplify scan
	      max = input.length,
	      map = BASE64_MAP,
	      bits = 0,
	      result = [];

	  // Collect by 6*4 bits (3 bytes)

	  for (idx = 0; idx < max; idx++) {
	    if ((idx % 4 === 0) && idx) {
	      result.push((bits >> 16) & 0xFF);
	      result.push((bits >> 8) & 0xFF);
	      result.push(bits & 0xFF);
	    }

	    bits = (bits << 6) | map.indexOf(input.charAt(idx));
	  }

	  // Dump tail

	  tailbits = (max % 4) * 6;

	  if (tailbits === 0) {
	    result.push((bits >> 16) & 0xFF);
	    result.push((bits >> 8) & 0xFF);
	    result.push(bits & 0xFF);
	  } else if (tailbits === 18) {
	    result.push((bits >> 10) & 0xFF);
	    result.push((bits >> 2) & 0xFF);
	  } else if (tailbits === 12) {
	    result.push((bits >> 4) & 0xFF);
	  }

	  // Wrap into Buffer for NodeJS and leave Array for browser
	  if (NodeBuffer) {
	    // Support node 6.+ Buffer API when available
	    return NodeBuffer.from ? NodeBuffer.from(result) : new NodeBuffer(result);
	  }

	  return result;
	}

	function representYamlBinary(object /*, style*/) {
	  var result = '', bits = 0, idx, tail,
	      max = object.length,
	      map = BASE64_MAP;

	  // Convert every three bytes to 4 ASCII characters.

	  for (idx = 0; idx < max; idx++) {
	    if ((idx % 3 === 0) && idx) {
	      result += map[(bits >> 18) & 0x3F];
	      result += map[(bits >> 12) & 0x3F];
	      result += map[(bits >> 6) & 0x3F];
	      result += map[bits & 0x3F];
	    }

	    bits = (bits << 8) + object[idx];
	  }

	  // Dump tail

	  tail = max % 3;

	  if (tail === 0) {
	    result += map[(bits >> 18) & 0x3F];
	    result += map[(bits >> 12) & 0x3F];
	    result += map[(bits >> 6) & 0x3F];
	    result += map[bits & 0x3F];
	  } else if (tail === 2) {
	    result += map[(bits >> 10) & 0x3F];
	    result += map[(bits >> 4) & 0x3F];
	    result += map[(bits << 2) & 0x3F];
	    result += map[64];
	  } else if (tail === 1) {
	    result += map[(bits >> 2) & 0x3F];
	    result += map[(bits << 4) & 0x3F];
	    result += map[64];
	    result += map[64];
	  }

	  return result;
	}

	function isBinary(object) {
	  return NodeBuffer && NodeBuffer.isBuffer(object);
	}

	binary = new Type('tag:yaml.org,2002:binary', {
	  kind: 'scalar',
	  resolve: resolveYamlBinary,
	  construct: constructYamlBinary,
	  predicate: isBinary,
	  represent: representYamlBinary
	});
	return binary;
}

var omap;
var hasRequiredOmap;

function requireOmap () {
	if (hasRequiredOmap) return omap;
	hasRequiredOmap = 1;

	var Type = requireType();

	var _hasOwnProperty = Object.prototype.hasOwnProperty;
	var _toString       = Object.prototype.toString;

	function resolveYamlOmap(data) {
	  if (data === null) return true;

	  var objectKeys = [], index, length, pair, pairKey, pairHasKey,
	      object = data;

	  for (index = 0, length = object.length; index < length; index += 1) {
	    pair = object[index];
	    pairHasKey = false;

	    if (_toString.call(pair) !== '[object Object]') return false;

	    for (pairKey in pair) {
	      if (_hasOwnProperty.call(pair, pairKey)) {
	        if (!pairHasKey) pairHasKey = true;
	        else return false;
	      }
	    }

	    if (!pairHasKey) return false;

	    if (objectKeys.indexOf(pairKey) === -1) objectKeys.push(pairKey);
	    else return false;
	  }

	  return true;
	}

	function constructYamlOmap(data) {
	  return data !== null ? data : [];
	}

	omap = new Type('tag:yaml.org,2002:omap', {
	  kind: 'sequence',
	  resolve: resolveYamlOmap,
	  construct: constructYamlOmap
	});
	return omap;
}

var pairs$2;
var hasRequiredPairs;

function requirePairs () {
	if (hasRequiredPairs) return pairs$2;
	hasRequiredPairs = 1;

	var Type = requireType();

	var _toString = Object.prototype.toString;

	function resolveYamlPairs(data) {
	  if (data === null) return true;

	  var index, length, pair, keys, result,
	      object = data;

	  result = new Array(object.length);

	  for (index = 0, length = object.length; index < length; index += 1) {
	    pair = object[index];

	    if (_toString.call(pair) !== '[object Object]') return false;

	    keys = Object.keys(pair);

	    if (keys.length !== 1) return false;

	    result[index] = [ keys[0], pair[keys[0]] ];
	  }

	  return true;
	}

	function constructYamlPairs(data) {
	  if (data === null) return [];

	  var index, length, pair, keys, result,
	      object = data;

	  result = new Array(object.length);

	  for (index = 0, length = object.length; index < length; index += 1) {
	    pair = object[index];

	    keys = Object.keys(pair);

	    result[index] = [ keys[0], pair[keys[0]] ];
	  }

	  return result;
	}

	pairs$2 = new Type('tag:yaml.org,2002:pairs', {
	  kind: 'sequence',
	  resolve: resolveYamlPairs,
	  construct: constructYamlPairs
	});
	return pairs$2;
}

var set;
var hasRequiredSet;

function requireSet () {
	if (hasRequiredSet) return set;
	hasRequiredSet = 1;

	var Type = requireType();

	var _hasOwnProperty = Object.prototype.hasOwnProperty;

	function resolveYamlSet(data) {
	  if (data === null) return true;

	  var key, object = data;

	  for (key in object) {
	    if (_hasOwnProperty.call(object, key)) {
	      if (object[key] !== null) return false;
	    }
	  }

	  return true;
	}

	function constructYamlSet(data) {
	  return data !== null ? data : {};
	}

	set = new Type('tag:yaml.org,2002:set', {
	  kind: 'mapping',
	  resolve: resolveYamlSet,
	  construct: constructYamlSet
	});
	return set;
}

var default_safe;
var hasRequiredDefault_safe;

function requireDefault_safe () {
	if (hasRequiredDefault_safe) return default_safe;
	hasRequiredDefault_safe = 1;


	var Schema = requireSchema();


	default_safe = new Schema({
	  include: [
	    requireCore()
	  ],
	  implicit: [
	    requireTimestamp(),
	    requireMerge()
	  ],
	  explicit: [
	    requireBinary(),
	    requireOmap(),
	    requirePairs(),
	    requireSet()
	  ]
	});
	return default_safe;
}

var _undefined;
var hasRequired_undefined;

function require_undefined () {
	if (hasRequired_undefined) return _undefined;
	hasRequired_undefined = 1;

	var Type = requireType();

	function resolveJavascriptUndefined() {
	  return true;
	}

	function constructJavascriptUndefined() {
	  /*eslint-disable no-undefined*/
	  return undefined;
	}

	function representJavascriptUndefined() {
	  return '';
	}

	function isUndefined(object) {
	  return typeof object === 'undefined';
	}

	_undefined = new Type('tag:yaml.org,2002:js/undefined', {
	  kind: 'scalar',
	  resolve: resolveJavascriptUndefined,
	  construct: constructJavascriptUndefined,
	  predicate: isUndefined,
	  represent: representJavascriptUndefined
	});
	return _undefined;
}

var regexp;
var hasRequiredRegexp;

function requireRegexp () {
	if (hasRequiredRegexp) return regexp;
	hasRequiredRegexp = 1;

	var Type = requireType();

	function resolveJavascriptRegExp(data) {
	  if (data === null) return false;
	  if (data.length === 0) return false;

	  var regexp = data,
	      tail   = /\/([gim]*)$/.exec(data),
	      modifiers = '';

	  // if regexp starts with '/' it can have modifiers and must be properly closed
	  // `/foo/gim` - modifiers tail can be maximum 3 chars
	  if (regexp[0] === '/') {
	    if (tail) modifiers = tail[1];

	    if (modifiers.length > 3) return false;
	    // if expression starts with /, is should be properly terminated
	    if (regexp[regexp.length - modifiers.length - 1] !== '/') return false;
	  }

	  return true;
	}

	function constructJavascriptRegExp(data) {
	  var regexp = data,
	      tail   = /\/([gim]*)$/.exec(data),
	      modifiers = '';

	  // `/foo/gim` - tail can be maximum 4 chars
	  if (regexp[0] === '/') {
	    if (tail) modifiers = tail[1];
	    regexp = regexp.slice(1, regexp.length - modifiers.length - 1);
	  }

	  return new RegExp(regexp, modifiers);
	}

	function representJavascriptRegExp(object /*, style*/) {
	  var result = '/' + object.source + '/';

	  if (object.global) result += 'g';
	  if (object.multiline) result += 'm';
	  if (object.ignoreCase) result += 'i';

	  return result;
	}

	function isRegExp(object) {
	  return Object.prototype.toString.call(object) === '[object RegExp]';
	}

	regexp = new Type('tag:yaml.org,2002:js/regexp', {
	  kind: 'scalar',
	  resolve: resolveJavascriptRegExp,
	  construct: constructJavascriptRegExp,
	  predicate: isRegExp,
	  represent: representJavascriptRegExp
	});
	return regexp;
}

var _function;
var hasRequired_function;

function require_function () {
	if (hasRequired_function) return _function;
	hasRequired_function = 1;

	var esprima;

	// Browserified version does not have esprima
	//
	// 1. For node.js just require module as deps
	// 2. For browser try to require mudule via external AMD system.
	//    If not found - try to fallback to window.esprima. If not
	//    found too - then fail to parse.
	//
	try {
	  // workaround to exclude package from browserify list.
	  var _require = commonjsRequire;
	  esprima = _require('esprima');
	} catch (_) {
	  /* eslint-disable no-redeclare */
	  /* global window */
	  if (typeof window !== 'undefined') esprima = window.esprima;
	}

	var Type = requireType();

	function resolveJavascriptFunction(data) {
	  if (data === null) return false;

	  try {
	    var source = '(' + data + ')',
	        ast    = esprima.parse(source, { range: true });

	    if (ast.type                    !== 'Program'             ||
	        ast.body.length             !== 1                     ||
	        ast.body[0].type            !== 'ExpressionStatement' ||
	        (ast.body[0].expression.type !== 'ArrowFunctionExpression' &&
	          ast.body[0].expression.type !== 'FunctionExpression')) {
	      return false;
	    }

	    return true;
	  } catch (err) {
	    return false;
	  }
	}

	function constructJavascriptFunction(data) {
	  /*jslint evil:true*/

	  var source = '(' + data + ')',
	      ast    = esprima.parse(source, { range: true }),
	      params = [],
	      body;

	  if (ast.type                    !== 'Program'             ||
	      ast.body.length             !== 1                     ||
	      ast.body[0].type            !== 'ExpressionStatement' ||
	      (ast.body[0].expression.type !== 'ArrowFunctionExpression' &&
	        ast.body[0].expression.type !== 'FunctionExpression')) {
	    throw new Error('Failed to resolve function');
	  }

	  ast.body[0].expression.params.forEach(function (param) {
	    params.push(param.name);
	  });

	  body = ast.body[0].expression.body.range;

	  // Esprima's ranges include the first '{' and the last '}' characters on
	  // function expressions. So cut them out.
	  if (ast.body[0].expression.body.type === 'BlockStatement') {
	    /*eslint-disable no-new-func*/
	    return new Function(params, source.slice(body[0] + 1, body[1] - 1));
	  }
	  // ES6 arrow functions can omit the BlockStatement. In that case, just return
	  // the body.
	  /*eslint-disable no-new-func*/
	  return new Function(params, 'return ' + source.slice(body[0], body[1]));
	}

	function representJavascriptFunction(object /*, style*/) {
	  return object.toString();
	}

	function isFunction(object) {
	  return Object.prototype.toString.call(object) === '[object Function]';
	}

	_function = new Type('tag:yaml.org,2002:js/function', {
	  kind: 'scalar',
	  resolve: resolveJavascriptFunction,
	  construct: constructJavascriptFunction,
	  predicate: isFunction,
	  represent: representJavascriptFunction
	});
	return _function;
}

var default_full;
var hasRequiredDefault_full;

function requireDefault_full () {
	if (hasRequiredDefault_full) return default_full;
	hasRequiredDefault_full = 1;


	var Schema = requireSchema();


	default_full = Schema.DEFAULT = new Schema({
	  include: [
	    requireDefault_safe()
	  ],
	  explicit: [
	    require_undefined(),
	    requireRegexp(),
	    require_function()
	  ]
	});
	return default_full;
}

var hasRequiredLoader;

function requireLoader () {
	if (hasRequiredLoader) return loader;
	hasRequiredLoader = 1;

	/*eslint-disable max-len,no-use-before-define*/

	var common              = requireCommon();
	var YAMLException       = requireException();
	var Mark                = requireMark();
	var DEFAULT_SAFE_SCHEMA = requireDefault_safe();
	var DEFAULT_FULL_SCHEMA = requireDefault_full();


	var _hasOwnProperty = Object.prototype.hasOwnProperty;


	var CONTEXT_FLOW_IN   = 1;
	var CONTEXT_FLOW_OUT  = 2;
	var CONTEXT_BLOCK_IN  = 3;
	var CONTEXT_BLOCK_OUT = 4;


	var CHOMPING_CLIP  = 1;
	var CHOMPING_STRIP = 2;
	var CHOMPING_KEEP  = 3;


	var PATTERN_NON_PRINTABLE         = /[\x00-\x08\x0B\x0C\x0E-\x1F\x7F-\x84\x86-\x9F\uFFFE\uFFFF]|[\uD800-\uDBFF](?![\uDC00-\uDFFF])|(?:[^\uD800-\uDBFF]|^)[\uDC00-\uDFFF]/;
	var PATTERN_NON_ASCII_LINE_BREAKS = /[\x85\u2028\u2029]/;
	var PATTERN_FLOW_INDICATORS       = /[,\[\]\{\}]/;
	var PATTERN_TAG_HANDLE            = /^(?:!|!!|![a-z\-]+!)$/i;
	var PATTERN_TAG_URI               = /^(?:!|[^,\[\]\{\}])(?:%[0-9a-f]{2}|[0-9a-z\-#;\/\?:@&=\+\$,_\.!~\*'\(\)\[\]])*$/i;


	function _class(obj) { return Object.prototype.toString.call(obj); }

	function is_EOL(c) {
	  return (c === 0x0A/* LF */) || (c === 0x0D/* CR */);
	}

	function is_WHITE_SPACE(c) {
	  return (c === 0x09/* Tab */) || (c === 0x20/* Space */);
	}

	function is_WS_OR_EOL(c) {
	  return (c === 0x09/* Tab */) ||
	         (c === 0x20/* Space */) ||
	         (c === 0x0A/* LF */) ||
	         (c === 0x0D/* CR */);
	}

	function is_FLOW_INDICATOR(c) {
	  return c === 0x2C/* , */ ||
	         c === 0x5B/* [ */ ||
	         c === 0x5D/* ] */ ||
	         c === 0x7B/* { */ ||
	         c === 0x7D/* } */;
	}

	function fromHexCode(c) {
	  var lc;

	  if ((0x30/* 0 */ <= c) && (c <= 0x39/* 9 */)) {
	    return c - 0x30;
	  }

	  /*eslint-disable no-bitwise*/
	  lc = c | 0x20;

	  if ((0x61/* a */ <= lc) && (lc <= 0x66/* f */)) {
	    return lc - 0x61 + 10;
	  }

	  return -1;
	}

	function escapedHexLen(c) {
	  if (c === 0x78/* x */) { return 2; }
	  if (c === 0x75/* u */) { return 4; }
	  if (c === 0x55/* U */) { return 8; }
	  return 0;
	}

	function fromDecimalCode(c) {
	  if ((0x30/* 0 */ <= c) && (c <= 0x39/* 9 */)) {
	    return c - 0x30;
	  }

	  return -1;
	}

	function simpleEscapeSequence(c) {
	  /* eslint-disable indent */
	  return (c === 0x30/* 0 */) ? '\x00' :
	        (c === 0x61/* a */) ? '\x07' :
	        (c === 0x62/* b */) ? '\x08' :
	        (c === 0x74/* t */) ? '\x09' :
	        (c === 0x09/* Tab */) ? '\x09' :
	        (c === 0x6E/* n */) ? '\x0A' :
	        (c === 0x76/* v */) ? '\x0B' :
	        (c === 0x66/* f */) ? '\x0C' :
	        (c === 0x72/* r */) ? '\x0D' :
	        (c === 0x65/* e */) ? '\x1B' :
	        (c === 0x20/* Space */) ? ' ' :
	        (c === 0x22/* " */) ? '\x22' :
	        (c === 0x2F/* / */) ? '/' :
	        (c === 0x5C/* \ */) ? '\x5C' :
	        (c === 0x4E/* N */) ? '\x85' :
	        (c === 0x5F/* _ */) ? '\xA0' :
	        (c === 0x4C/* L */) ? '\u2028' :
	        (c === 0x50/* P */) ? '\u2029' : '';
	}

	function charFromCodepoint(c) {
	  if (c <= 0xFFFF) {
	    return String.fromCharCode(c);
	  }
	  // Encode UTF-16 surrogate pair
	  // https://en.wikipedia.org/wiki/UTF-16#Code_points_U.2B010000_to_U.2B10FFFF
	  return String.fromCharCode(
	    ((c - 0x010000) >> 10) + 0xD800,
	    ((c - 0x010000) & 0x03FF) + 0xDC00
	  );
	}

	var simpleEscapeCheck = new Array(256); // integer, for fast access
	var simpleEscapeMap = new Array(256);
	for (var i = 0; i < 256; i++) {
	  simpleEscapeCheck[i] = simpleEscapeSequence(i) ? 1 : 0;
	  simpleEscapeMap[i] = simpleEscapeSequence(i);
	}


	function State(input, options) {
	  this.input = input;

	  this.filename  = options['filename']  || null;
	  this.schema    = options['schema']    || DEFAULT_FULL_SCHEMA;
	  this.onWarning = options['onWarning'] || null;
	  this.legacy    = options['legacy']    || false;
	  this.json      = options['json']      || false;
	  this.listener  = options['listener']  || null;

	  this.implicitTypes = this.schema.compiledImplicit;
	  this.typeMap       = this.schema.compiledTypeMap;

	  this.length     = input.length;
	  this.position   = 0;
	  this.line       = 0;
	  this.lineStart  = 0;
	  this.lineIndent = 0;

	  this.documents = [];

	  /*
	  this.version;
	  this.checkLineBreaks;
	  this.tagMap;
	  this.anchorMap;
	  this.tag;
	  this.anchor;
	  this.kind;
	  this.result;*/

	}


	function generateError(state, message) {
	  return new YAMLException(
	    message,
	    new Mark(state.filename, state.input, state.position, state.line, (state.position - state.lineStart)));
	}

	function throwError(state, message) {
	  throw generateError(state, message);
	}

	function throwWarning(state, message) {
	  if (state.onWarning) {
	    state.onWarning.call(null, generateError(state, message));
	  }
	}


	var directiveHandlers = {

	  YAML: function handleYamlDirective(state, name, args) {

	    var match, major, minor;

	    if (state.version !== null) {
	      throwError(state, 'duplication of %YAML directive');
	    }

	    if (args.length !== 1) {
	      throwError(state, 'YAML directive accepts exactly one argument');
	    }

	    match = /^([0-9]+)\.([0-9]+)$/.exec(args[0]);

	    if (match === null) {
	      throwError(state, 'ill-formed argument of the YAML directive');
	    }

	    major = parseInt(match[1], 10);
	    minor = parseInt(match[2], 10);

	    if (major !== 1) {
	      throwError(state, 'unacceptable YAML version of the document');
	    }

	    state.version = args[0];
	    state.checkLineBreaks = (minor < 2);

	    if (minor !== 1 && minor !== 2) {
	      throwWarning(state, 'unsupported YAML version of the document');
	    }
	  },

	  TAG: function handleTagDirective(state, name, args) {

	    var handle, prefix;

	    if (args.length !== 2) {
	      throwError(state, 'TAG directive accepts exactly two arguments');
	    }

	    handle = args[0];
	    prefix = args[1];

	    if (!PATTERN_TAG_HANDLE.test(handle)) {
	      throwError(state, 'ill-formed tag handle (first argument) of the TAG directive');
	    }

	    if (_hasOwnProperty.call(state.tagMap, handle)) {
	      throwError(state, 'there is a previously declared suffix for "' + handle + '" tag handle');
	    }

	    if (!PATTERN_TAG_URI.test(prefix)) {
	      throwError(state, 'ill-formed tag prefix (second argument) of the TAG directive');
	    }

	    state.tagMap[handle] = prefix;
	  }
	};


	function captureSegment(state, start, end, checkJson) {
	  var _position, _length, _character, _result;

	  if (start < end) {
	    _result = state.input.slice(start, end);

	    if (checkJson) {
	      for (_position = 0, _length = _result.length; _position < _length; _position += 1) {
	        _character = _result.charCodeAt(_position);
	        if (!(_character === 0x09 ||
	              (0x20 <= _character && _character <= 0x10FFFF))) {
	          throwError(state, 'expected valid JSON character');
	        }
	      }
	    } else if (PATTERN_NON_PRINTABLE.test(_result)) {
	      throwError(state, 'the stream contains non-printable characters');
	    }

	    state.result += _result;
	  }
	}

	function mergeMappings(state, destination, source, overridableKeys) {
	  var sourceKeys, key, index, quantity;

	  if (!common.isObject(source)) {
	    throwError(state, 'cannot merge mappings; the provided source object is unacceptable');
	  }

	  sourceKeys = Object.keys(source);

	  for (index = 0, quantity = sourceKeys.length; index < quantity; index += 1) {
	    key = sourceKeys[index];

	    if (!_hasOwnProperty.call(destination, key)) {
	      destination[key] = source[key];
	      overridableKeys[key] = true;
	    }
	  }
	}

	function storeMappingPair(state, _result, overridableKeys, keyTag, keyNode, valueNode, startLine, startPos) {
	  var index, quantity;

	  // The output is a plain object here, so keys can only be strings.
	  // We need to convert keyNode to a string, but doing so can hang the process
	  // (deeply nested arrays that explode exponentially using aliases).
	  if (Array.isArray(keyNode)) {
	    keyNode = Array.prototype.slice.call(keyNode);

	    for (index = 0, quantity = keyNode.length; index < quantity; index += 1) {
	      if (Array.isArray(keyNode[index])) {
	        throwError(state, 'nested arrays are not supported inside keys');
	      }

	      if (typeof keyNode === 'object' && _class(keyNode[index]) === '[object Object]') {
	        keyNode[index] = '[object Object]';
	      }
	    }
	  }

	  // Avoid code execution in load() via toString property
	  // (still use its own toString for arrays, timestamps,
	  // and whatever user schema extensions happen to have @@toStringTag)
	  if (typeof keyNode === 'object' && _class(keyNode) === '[object Object]') {
	    keyNode = '[object Object]';
	  }


	  keyNode = String(keyNode);

	  if (_result === null) {
	    _result = {};
	  }

	  if (keyTag === 'tag:yaml.org,2002:merge') {
	    if (Array.isArray(valueNode)) {
	      for (index = 0, quantity = valueNode.length; index < quantity; index += 1) {
	        mergeMappings(state, _result, valueNode[index], overridableKeys);
	      }
	    } else {
	      mergeMappings(state, _result, valueNode, overridableKeys);
	    }
	  } else {
	    if (!state.json &&
	        !_hasOwnProperty.call(overridableKeys, keyNode) &&
	        _hasOwnProperty.call(_result, keyNode)) {
	      state.line = startLine || state.line;
	      state.position = startPos || state.position;
	      throwError(state, 'duplicated mapping key');
	    }
	    _result[keyNode] = valueNode;
	    delete overridableKeys[keyNode];
	  }

	  return _result;
	}

	function readLineBreak(state) {
	  var ch;

	  ch = state.input.charCodeAt(state.position);

	  if (ch === 0x0A/* LF */) {
	    state.position++;
	  } else if (ch === 0x0D/* CR */) {
	    state.position++;
	    if (state.input.charCodeAt(state.position) === 0x0A/* LF */) {
	      state.position++;
	    }
	  } else {
	    throwError(state, 'a line break is expected');
	  }

	  state.line += 1;
	  state.lineStart = state.position;
	}

	function skipSeparationSpace(state, allowComments, checkIndent) {
	  var lineBreaks = 0,
	      ch = state.input.charCodeAt(state.position);

	  while (ch !== 0) {
	    while (is_WHITE_SPACE(ch)) {
	      ch = state.input.charCodeAt(++state.position);
	    }

	    if (allowComments && ch === 0x23/* # */) {
	      do {
	        ch = state.input.charCodeAt(++state.position);
	      } while (ch !== 0x0A/* LF */ && ch !== 0x0D/* CR */ && ch !== 0);
	    }

	    if (is_EOL(ch)) {
	      readLineBreak(state);

	      ch = state.input.charCodeAt(state.position);
	      lineBreaks++;
	      state.lineIndent = 0;

	      while (ch === 0x20/* Space */) {
	        state.lineIndent++;
	        ch = state.input.charCodeAt(++state.position);
	      }
	    } else {
	      break;
	    }
	  }

	  if (checkIndent !== -1 && lineBreaks !== 0 && state.lineIndent < checkIndent) {
	    throwWarning(state, 'deficient indentation');
	  }

	  return lineBreaks;
	}

	function testDocumentSeparator(state) {
	  var _position = state.position,
	      ch;

	  ch = state.input.charCodeAt(_position);

	  // Condition state.position === state.lineStart is tested
	  // in parent on each call, for efficiency. No needs to test here again.
	  if ((ch === 0x2D/* - */ || ch === 0x2E/* . */) &&
	      ch === state.input.charCodeAt(_position + 1) &&
	      ch === state.input.charCodeAt(_position + 2)) {

	    _position += 3;

	    ch = state.input.charCodeAt(_position);

	    if (ch === 0 || is_WS_OR_EOL(ch)) {
	      return true;
	    }
	  }

	  return false;
	}

	function writeFoldedLines(state, count) {
	  if (count === 1) {
	    state.result += ' ';
	  } else if (count > 1) {
	    state.result += common.repeat('\n', count - 1);
	  }
	}


	function readPlainScalar(state, nodeIndent, withinFlowCollection) {
	  var preceding,
	      following,
	      captureStart,
	      captureEnd,
	      hasPendingContent,
	      _line,
	      _lineStart,
	      _lineIndent,
	      _kind = state.kind,
	      _result = state.result,
	      ch;

	  ch = state.input.charCodeAt(state.position);

	  if (is_WS_OR_EOL(ch)      ||
	      is_FLOW_INDICATOR(ch) ||
	      ch === 0x23/* # */    ||
	      ch === 0x26/* & */    ||
	      ch === 0x2A/* * */    ||
	      ch === 0x21/* ! */    ||
	      ch === 0x7C/* | */    ||
	      ch === 0x3E/* > */    ||
	      ch === 0x27/* ' */    ||
	      ch === 0x22/* " */    ||
	      ch === 0x25/* % */    ||
	      ch === 0x40/* @ */    ||
	      ch === 0x60/* ` */) {
	    return false;
	  }

	  if (ch === 0x3F/* ? */ || ch === 0x2D/* - */) {
	    following = state.input.charCodeAt(state.position + 1);

	    if (is_WS_OR_EOL(following) ||
	        withinFlowCollection && is_FLOW_INDICATOR(following)) {
	      return false;
	    }
	  }

	  state.kind = 'scalar';
	  state.result = '';
	  captureStart = captureEnd = state.position;
	  hasPendingContent = false;

	  while (ch !== 0) {
	    if (ch === 0x3A/* : */) {
	      following = state.input.charCodeAt(state.position + 1);

	      if (is_WS_OR_EOL(following) ||
	          withinFlowCollection && is_FLOW_INDICATOR(following)) {
	        break;
	      }

	    } else if (ch === 0x23/* # */) {
	      preceding = state.input.charCodeAt(state.position - 1);

	      if (is_WS_OR_EOL(preceding)) {
	        break;
	      }

	    } else if ((state.position === state.lineStart && testDocumentSeparator(state)) ||
	               withinFlowCollection && is_FLOW_INDICATOR(ch)) {
	      break;

	    } else if (is_EOL(ch)) {
	      _line = state.line;
	      _lineStart = state.lineStart;
	      _lineIndent = state.lineIndent;
	      skipSeparationSpace(state, false, -1);

	      if (state.lineIndent >= nodeIndent) {
	        hasPendingContent = true;
	        ch = state.input.charCodeAt(state.position);
	        continue;
	      } else {
	        state.position = captureEnd;
	        state.line = _line;
	        state.lineStart = _lineStart;
	        state.lineIndent = _lineIndent;
	        break;
	      }
	    }

	    if (hasPendingContent) {
	      captureSegment(state, captureStart, captureEnd, false);
	      writeFoldedLines(state, state.line - _line);
	      captureStart = captureEnd = state.position;
	      hasPendingContent = false;
	    }

	    if (!is_WHITE_SPACE(ch)) {
	      captureEnd = state.position + 1;
	    }

	    ch = state.input.charCodeAt(++state.position);
	  }

	  captureSegment(state, captureStart, captureEnd, false);

	  if (state.result) {
	    return true;
	  }

	  state.kind = _kind;
	  state.result = _result;
	  return false;
	}

	function readSingleQuotedScalar(state, nodeIndent) {
	  var ch,
	      captureStart, captureEnd;

	  ch = state.input.charCodeAt(state.position);

	  if (ch !== 0x27/* ' */) {
	    return false;
	  }

	  state.kind = 'scalar';
	  state.result = '';
	  state.position++;
	  captureStart = captureEnd = state.position;

	  while ((ch = state.input.charCodeAt(state.position)) !== 0) {
	    if (ch === 0x27/* ' */) {
	      captureSegment(state, captureStart, state.position, true);
	      ch = state.input.charCodeAt(++state.position);

	      if (ch === 0x27/* ' */) {
	        captureStart = state.position;
	        state.position++;
	        captureEnd = state.position;
	      } else {
	        return true;
	      }

	    } else if (is_EOL(ch)) {
	      captureSegment(state, captureStart, captureEnd, true);
	      writeFoldedLines(state, skipSeparationSpace(state, false, nodeIndent));
	      captureStart = captureEnd = state.position;

	    } else if (state.position === state.lineStart && testDocumentSeparator(state)) {
	      throwError(state, 'unexpected end of the document within a single quoted scalar');

	    } else {
	      state.position++;
	      captureEnd = state.position;
	    }
	  }

	  throwError(state, 'unexpected end of the stream within a single quoted scalar');
	}

	function readDoubleQuotedScalar(state, nodeIndent) {
	  var captureStart,
	      captureEnd,
	      hexLength,
	      hexResult,
	      tmp,
	      ch;

	  ch = state.input.charCodeAt(state.position);

	  if (ch !== 0x22/* " */) {
	    return false;
	  }

	  state.kind = 'scalar';
	  state.result = '';
	  state.position++;
	  captureStart = captureEnd = state.position;

	  while ((ch = state.input.charCodeAt(state.position)) !== 0) {
	    if (ch === 0x22/* " */) {
	      captureSegment(state, captureStart, state.position, true);
	      state.position++;
	      return true;

	    } else if (ch === 0x5C/* \ */) {
	      captureSegment(state, captureStart, state.position, true);
	      ch = state.input.charCodeAt(++state.position);

	      if (is_EOL(ch)) {
	        skipSeparationSpace(state, false, nodeIndent);

	        // TODO: rework to inline fn with no type cast?
	      } else if (ch < 256 && simpleEscapeCheck[ch]) {
	        state.result += simpleEscapeMap[ch];
	        state.position++;

	      } else if ((tmp = escapedHexLen(ch)) > 0) {
	        hexLength = tmp;
	        hexResult = 0;

	        for (; hexLength > 0; hexLength--) {
	          ch = state.input.charCodeAt(++state.position);

	          if ((tmp = fromHexCode(ch)) >= 0) {
	            hexResult = (hexResult << 4) + tmp;

	          } else {
	            throwError(state, 'expected hexadecimal character');
	          }
	        }

	        state.result += charFromCodepoint(hexResult);

	        state.position++;

	      } else {
	        throwError(state, 'unknown escape sequence');
	      }

	      captureStart = captureEnd = state.position;

	    } else if (is_EOL(ch)) {
	      captureSegment(state, captureStart, captureEnd, true);
	      writeFoldedLines(state, skipSeparationSpace(state, false, nodeIndent));
	      captureStart = captureEnd = state.position;

	    } else if (state.position === state.lineStart && testDocumentSeparator(state)) {
	      throwError(state, 'unexpected end of the document within a double quoted scalar');

	    } else {
	      state.position++;
	      captureEnd = state.position;
	    }
	  }

	  throwError(state, 'unexpected end of the stream within a double quoted scalar');
	}

	function readFlowCollection(state, nodeIndent) {
	  var readNext = true,
	      _line,
	      _tag     = state.tag,
	      _result,
	      _anchor  = state.anchor,
	      following,
	      terminator,
	      isPair,
	      isExplicitPair,
	      isMapping,
	      overridableKeys = {},
	      keyNode,
	      keyTag,
	      valueNode,
	      ch;

	  ch = state.input.charCodeAt(state.position);

	  if (ch === 0x5B/* [ */) {
	    terminator = 0x5D;/* ] */
	    isMapping = false;
	    _result = [];
	  } else if (ch === 0x7B/* { */) {
	    terminator = 0x7D;/* } */
	    isMapping = true;
	    _result = {};
	  } else {
	    return false;
	  }

	  if (state.anchor !== null) {
	    state.anchorMap[state.anchor] = _result;
	  }

	  ch = state.input.charCodeAt(++state.position);

	  while (ch !== 0) {
	    skipSeparationSpace(state, true, nodeIndent);

	    ch = state.input.charCodeAt(state.position);

	    if (ch === terminator) {
	      state.position++;
	      state.tag = _tag;
	      state.anchor = _anchor;
	      state.kind = isMapping ? 'mapping' : 'sequence';
	      state.result = _result;
	      return true;
	    } else if (!readNext) {
	      throwError(state, 'missed comma between flow collection entries');
	    }

	    keyTag = keyNode = valueNode = null;
	    isPair = isExplicitPair = false;

	    if (ch === 0x3F/* ? */) {
	      following = state.input.charCodeAt(state.position + 1);

	      if (is_WS_OR_EOL(following)) {
	        isPair = isExplicitPair = true;
	        state.position++;
	        skipSeparationSpace(state, true, nodeIndent);
	      }
	    }

	    _line = state.line;
	    composeNode(state, nodeIndent, CONTEXT_FLOW_IN, false, true);
	    keyTag = state.tag;
	    keyNode = state.result;
	    skipSeparationSpace(state, true, nodeIndent);

	    ch = state.input.charCodeAt(state.position);

	    if ((isExplicitPair || state.line === _line) && ch === 0x3A/* : */) {
	      isPair = true;
	      ch = state.input.charCodeAt(++state.position);
	      skipSeparationSpace(state, true, nodeIndent);
	      composeNode(state, nodeIndent, CONTEXT_FLOW_IN, false, true);
	      valueNode = state.result;
	    }

	    if (isMapping) {
	      storeMappingPair(state, _result, overridableKeys, keyTag, keyNode, valueNode);
	    } else if (isPair) {
	      _result.push(storeMappingPair(state, null, overridableKeys, keyTag, keyNode, valueNode));
	    } else {
	      _result.push(keyNode);
	    }

	    skipSeparationSpace(state, true, nodeIndent);

	    ch = state.input.charCodeAt(state.position);

	    if (ch === 0x2C/* , */) {
	      readNext = true;
	      ch = state.input.charCodeAt(++state.position);
	    } else {
	      readNext = false;
	    }
	  }

	  throwError(state, 'unexpected end of the stream within a flow collection');
	}

	function readBlockScalar(state, nodeIndent) {
	  var captureStart,
	      folding,
	      chomping       = CHOMPING_CLIP,
	      didReadContent = false,
	      detectedIndent = false,
	      textIndent     = nodeIndent,
	      emptyLines     = 0,
	      atMoreIndented = false,
	      tmp,
	      ch;

	  ch = state.input.charCodeAt(state.position);

	  if (ch === 0x7C/* | */) {
	    folding = false;
	  } else if (ch === 0x3E/* > */) {
	    folding = true;
	  } else {
	    return false;
	  }

	  state.kind = 'scalar';
	  state.result = '';

	  while (ch !== 0) {
	    ch = state.input.charCodeAt(++state.position);

	    if (ch === 0x2B/* + */ || ch === 0x2D/* - */) {
	      if (CHOMPING_CLIP === chomping) {
	        chomping = (ch === 0x2B/* + */) ? CHOMPING_KEEP : CHOMPING_STRIP;
	      } else {
	        throwError(state, 'repeat of a chomping mode identifier');
	      }

	    } else if ((tmp = fromDecimalCode(ch)) >= 0) {
	      if (tmp === 0) {
	        throwError(state, 'bad explicit indentation width of a block scalar; it cannot be less than one');
	      } else if (!detectedIndent) {
	        textIndent = nodeIndent + tmp - 1;
	        detectedIndent = true;
	      } else {
	        throwError(state, 'repeat of an indentation width identifier');
	      }

	    } else {
	      break;
	    }
	  }

	  if (is_WHITE_SPACE(ch)) {
	    do { ch = state.input.charCodeAt(++state.position); }
	    while (is_WHITE_SPACE(ch));

	    if (ch === 0x23/* # */) {
	      do { ch = state.input.charCodeAt(++state.position); }
	      while (!is_EOL(ch) && (ch !== 0));
	    }
	  }

	  while (ch !== 0) {
	    readLineBreak(state);
	    state.lineIndent = 0;

	    ch = state.input.charCodeAt(state.position);

	    while ((!detectedIndent || state.lineIndent < textIndent) &&
	           (ch === 0x20/* Space */)) {
	      state.lineIndent++;
	      ch = state.input.charCodeAt(++state.position);
	    }

	    if (!detectedIndent && state.lineIndent > textIndent) {
	      textIndent = state.lineIndent;
	    }

	    if (is_EOL(ch)) {
	      emptyLines++;
	      continue;
	    }

	    // End of the scalar.
	    if (state.lineIndent < textIndent) {

	      // Perform the chomping.
	      if (chomping === CHOMPING_KEEP) {
	        state.result += common.repeat('\n', didReadContent ? 1 + emptyLines : emptyLines);
	      } else if (chomping === CHOMPING_CLIP) {
	        if (didReadContent) { // i.e. only if the scalar is not empty.
	          state.result += '\n';
	        }
	      }

	      // Break this `while` cycle and go to the funciton's epilogue.
	      break;
	    }

	    // Folded style: use fancy rules to handle line breaks.
	    if (folding) {

	      // Lines starting with white space characters (more-indented lines) are not folded.
	      if (is_WHITE_SPACE(ch)) {
	        atMoreIndented = true;
	        // except for the first content line (cf. Example 8.1)
	        state.result += common.repeat('\n', didReadContent ? 1 + emptyLines : emptyLines);

	      // End of more-indented block.
	      } else if (atMoreIndented) {
	        atMoreIndented = false;
	        state.result += common.repeat('\n', emptyLines + 1);

	      // Just one line break - perceive as the same line.
	      } else if (emptyLines === 0) {
	        if (didReadContent) { // i.e. only if we have already read some scalar content.
	          state.result += ' ';
	        }

	      // Several line breaks - perceive as different lines.
	      } else {
	        state.result += common.repeat('\n', emptyLines);
	      }

	    // Literal style: just add exact number of line breaks between content lines.
	    } else {
	      // Keep all line breaks except the header line break.
	      state.result += common.repeat('\n', didReadContent ? 1 + emptyLines : emptyLines);
	    }

	    didReadContent = true;
	    detectedIndent = true;
	    emptyLines = 0;
	    captureStart = state.position;

	    while (!is_EOL(ch) && (ch !== 0)) {
	      ch = state.input.charCodeAt(++state.position);
	    }

	    captureSegment(state, captureStart, state.position, false);
	  }

	  return true;
	}

	function readBlockSequence(state, nodeIndent) {
	  var _line,
	      _tag      = state.tag,
	      _anchor   = state.anchor,
	      _result   = [],
	      following,
	      detected  = false,
	      ch;

	  if (state.anchor !== null) {
	    state.anchorMap[state.anchor] = _result;
	  }

	  ch = state.input.charCodeAt(state.position);

	  while (ch !== 0) {

	    if (ch !== 0x2D/* - */) {
	      break;
	    }

	    following = state.input.charCodeAt(state.position + 1);

	    if (!is_WS_OR_EOL(following)) {
	      break;
	    }

	    detected = true;
	    state.position++;

	    if (skipSeparationSpace(state, true, -1)) {
	      if (state.lineIndent <= nodeIndent) {
	        _result.push(null);
	        ch = state.input.charCodeAt(state.position);
	        continue;
	      }
	    }

	    _line = state.line;
	    composeNode(state, nodeIndent, CONTEXT_BLOCK_IN, false, true);
	    _result.push(state.result);
	    skipSeparationSpace(state, true, -1);

	    ch = state.input.charCodeAt(state.position);

	    if ((state.line === _line || state.lineIndent > nodeIndent) && (ch !== 0)) {
	      throwError(state, 'bad indentation of a sequence entry');
	    } else if (state.lineIndent < nodeIndent) {
	      break;
	    }
	  }

	  if (detected) {
	    state.tag = _tag;
	    state.anchor = _anchor;
	    state.kind = 'sequence';
	    state.result = _result;
	    return true;
	  }
	  return false;
	}

	function readBlockMapping(state, nodeIndent, flowIndent) {
	  var following,
	      allowCompact,
	      _line,
	      _pos,
	      _tag          = state.tag,
	      _anchor       = state.anchor,
	      _result       = {},
	      overridableKeys = {},
	      keyTag        = null,
	      keyNode       = null,
	      valueNode     = null,
	      atExplicitKey = false,
	      detected      = false,
	      ch;

	  if (state.anchor !== null) {
	    state.anchorMap[state.anchor] = _result;
	  }

	  ch = state.input.charCodeAt(state.position);

	  while (ch !== 0) {
	    following = state.input.charCodeAt(state.position + 1);
	    _line = state.line; // Save the current line.
	    _pos = state.position;

	    //
	    // Explicit notation case. There are two separate blocks:
	    // first for the key (denoted by "?") and second for the value (denoted by ":")
	    //
	    if ((ch === 0x3F/* ? */ || ch === 0x3A/* : */) && is_WS_OR_EOL(following)) {

	      if (ch === 0x3F/* ? */) {
	        if (atExplicitKey) {
	          storeMappingPair(state, _result, overridableKeys, keyTag, keyNode, null);
	          keyTag = keyNode = valueNode = null;
	        }

	        detected = true;
	        atExplicitKey = true;
	        allowCompact = true;

	      } else if (atExplicitKey) {
	        // i.e. 0x3A/* : */ === character after the explicit key.
	        atExplicitKey = false;
	        allowCompact = true;

	      } else {
	        throwError(state, 'incomplete explicit mapping pair; a key node is missed; or followed by a non-tabulated empty line');
	      }

	      state.position += 1;
	      ch = following;

	    //
	    // Implicit notation case. Flow-style node as the key first, then ":", and the value.
	    //
	    } else if (composeNode(state, flowIndent, CONTEXT_FLOW_OUT, false, true)) {

	      if (state.line === _line) {
	        ch = state.input.charCodeAt(state.position);

	        while (is_WHITE_SPACE(ch)) {
	          ch = state.input.charCodeAt(++state.position);
	        }

	        if (ch === 0x3A/* : */) {
	          ch = state.input.charCodeAt(++state.position);

	          if (!is_WS_OR_EOL(ch)) {
	            throwError(state, 'a whitespace character is expected after the key-value separator within a block mapping');
	          }

	          if (atExplicitKey) {
	            storeMappingPair(state, _result, overridableKeys, keyTag, keyNode, null);
	            keyTag = keyNode = valueNode = null;
	          }

	          detected = true;
	          atExplicitKey = false;
	          allowCompact = false;
	          keyTag = state.tag;
	          keyNode = state.result;

	        } else if (detected) {
	          throwError(state, 'can not read an implicit mapping pair; a colon is missed');

	        } else {
	          state.tag = _tag;
	          state.anchor = _anchor;
	          return true; // Keep the result of `composeNode`.
	        }

	      } else if (detected) {
	        throwError(state, 'can not read a block mapping entry; a multiline key may not be an implicit key');

	      } else {
	        state.tag = _tag;
	        state.anchor = _anchor;
	        return true; // Keep the result of `composeNode`.
	      }

	    } else {
	      break; // Reading is done. Go to the epilogue.
	    }

	    //
	    // Common reading code for both explicit and implicit notations.
	    //
	    if (state.line === _line || state.lineIndent > nodeIndent) {
	      if (composeNode(state, nodeIndent, CONTEXT_BLOCK_OUT, true, allowCompact)) {
	        if (atExplicitKey) {
	          keyNode = state.result;
	        } else {
	          valueNode = state.result;
	        }
	      }

	      if (!atExplicitKey) {
	        storeMappingPair(state, _result, overridableKeys, keyTag, keyNode, valueNode, _line, _pos);
	        keyTag = keyNode = valueNode = null;
	      }

	      skipSeparationSpace(state, true, -1);
	      ch = state.input.charCodeAt(state.position);
	    }

	    if (state.lineIndent > nodeIndent && (ch !== 0)) {
	      throwError(state, 'bad indentation of a mapping entry');
	    } else if (state.lineIndent < nodeIndent) {
	      break;
	    }
	  }

	  //
	  // Epilogue.
	  //

	  // Special case: last mapping's node contains only the key in explicit notation.
	  if (atExplicitKey) {
	    storeMappingPair(state, _result, overridableKeys, keyTag, keyNode, null);
	  }

	  // Expose the resulting mapping.
	  if (detected) {
	    state.tag = _tag;
	    state.anchor = _anchor;
	    state.kind = 'mapping';
	    state.result = _result;
	  }

	  return detected;
	}

	function readTagProperty(state) {
	  var _position,
	      isVerbatim = false,
	      isNamed    = false,
	      tagHandle,
	      tagName,
	      ch;

	  ch = state.input.charCodeAt(state.position);

	  if (ch !== 0x21/* ! */) return false;

	  if (state.tag !== null) {
	    throwError(state, 'duplication of a tag property');
	  }

	  ch = state.input.charCodeAt(++state.position);

	  if (ch === 0x3C/* < */) {
	    isVerbatim = true;
	    ch = state.input.charCodeAt(++state.position);

	  } else if (ch === 0x21/* ! */) {
	    isNamed = true;
	    tagHandle = '!!';
	    ch = state.input.charCodeAt(++state.position);

	  } else {
	    tagHandle = '!';
	  }

	  _position = state.position;

	  if (isVerbatim) {
	    do { ch = state.input.charCodeAt(++state.position); }
	    while (ch !== 0 && ch !== 0x3E/* > */);

	    if (state.position < state.length) {
	      tagName = state.input.slice(_position, state.position);
	      ch = state.input.charCodeAt(++state.position);
	    } else {
	      throwError(state, 'unexpected end of the stream within a verbatim tag');
	    }
	  } else {
	    while (ch !== 0 && !is_WS_OR_EOL(ch)) {

	      if (ch === 0x21/* ! */) {
	        if (!isNamed) {
	          tagHandle = state.input.slice(_position - 1, state.position + 1);

	          if (!PATTERN_TAG_HANDLE.test(tagHandle)) {
	            throwError(state, 'named tag handle cannot contain such characters');
	          }

	          isNamed = true;
	          _position = state.position + 1;
	        } else {
	          throwError(state, 'tag suffix cannot contain exclamation marks');
	        }
	      }

	      ch = state.input.charCodeAt(++state.position);
	    }

	    tagName = state.input.slice(_position, state.position);

	    if (PATTERN_FLOW_INDICATORS.test(tagName)) {
	      throwError(state, 'tag suffix cannot contain flow indicator characters');
	    }
	  }

	  if (tagName && !PATTERN_TAG_URI.test(tagName)) {
	    throwError(state, 'tag name cannot contain such characters: ' + tagName);
	  }

	  if (isVerbatim) {
	    state.tag = tagName;

	  } else if (_hasOwnProperty.call(state.tagMap, tagHandle)) {
	    state.tag = state.tagMap[tagHandle] + tagName;

	  } else if (tagHandle === '!') {
	    state.tag = '!' + tagName;

	  } else if (tagHandle === '!!') {
	    state.tag = 'tag:yaml.org,2002:' + tagName;

	  } else {
	    throwError(state, 'undeclared tag handle "' + tagHandle + '"');
	  }

	  return true;
	}

	function readAnchorProperty(state) {
	  var _position,
	      ch;

	  ch = state.input.charCodeAt(state.position);

	  if (ch !== 0x26/* & */) return false;

	  if (state.anchor !== null) {
	    throwError(state, 'duplication of an anchor property');
	  }

	  ch = state.input.charCodeAt(++state.position);
	  _position = state.position;

	  while (ch !== 0 && !is_WS_OR_EOL(ch) && !is_FLOW_INDICATOR(ch)) {
	    ch = state.input.charCodeAt(++state.position);
	  }

	  if (state.position === _position) {
	    throwError(state, 'name of an anchor node must contain at least one character');
	  }

	  state.anchor = state.input.slice(_position, state.position);
	  return true;
	}

	function readAlias(state) {
	  var _position, alias,
	      ch;

	  ch = state.input.charCodeAt(state.position);

	  if (ch !== 0x2A/* * */) return false;

	  ch = state.input.charCodeAt(++state.position);
	  _position = state.position;

	  while (ch !== 0 && !is_WS_OR_EOL(ch) && !is_FLOW_INDICATOR(ch)) {
	    ch = state.input.charCodeAt(++state.position);
	  }

	  if (state.position === _position) {
	    throwError(state, 'name of an alias node must contain at least one character');
	  }

	  alias = state.input.slice(_position, state.position);

	  if (!_hasOwnProperty.call(state.anchorMap, alias)) {
	    throwError(state, 'unidentified alias "' + alias + '"');
	  }

	  state.result = state.anchorMap[alias];
	  skipSeparationSpace(state, true, -1);
	  return true;
	}

	function composeNode(state, parentIndent, nodeContext, allowToSeek, allowCompact) {
	  var allowBlockStyles,
	      allowBlockScalars,
	      allowBlockCollections,
	      indentStatus = 1, // 1: this>parent, 0: this=parent, -1: this<parent
	      atNewLine  = false,
	      hasContent = false,
	      typeIndex,
	      typeQuantity,
	      type,
	      flowIndent,
	      blockIndent;

	  if (state.listener !== null) {
	    state.listener('open', state);
	  }

	  state.tag    = null;
	  state.anchor = null;
	  state.kind   = null;
	  state.result = null;

	  allowBlockStyles = allowBlockScalars = allowBlockCollections =
	    CONTEXT_BLOCK_OUT === nodeContext ||
	    CONTEXT_BLOCK_IN  === nodeContext;

	  if (allowToSeek) {
	    if (skipSeparationSpace(state, true, -1)) {
	      atNewLine = true;

	      if (state.lineIndent > parentIndent) {
	        indentStatus = 1;
	      } else if (state.lineIndent === parentIndent) {
	        indentStatus = 0;
	      } else if (state.lineIndent < parentIndent) {
	        indentStatus = -1;
	      }
	    }
	  }

	  if (indentStatus === 1) {
	    while (readTagProperty(state) || readAnchorProperty(state)) {
	      if (skipSeparationSpace(state, true, -1)) {
	        atNewLine = true;
	        allowBlockCollections = allowBlockStyles;

	        if (state.lineIndent > parentIndent) {
	          indentStatus = 1;
	        } else if (state.lineIndent === parentIndent) {
	          indentStatus = 0;
	        } else if (state.lineIndent < parentIndent) {
	          indentStatus = -1;
	        }
	      } else {
	        allowBlockCollections = false;
	      }
	    }
	  }

	  if (allowBlockCollections) {
	    allowBlockCollections = atNewLine || allowCompact;
	  }

	  if (indentStatus === 1 || CONTEXT_BLOCK_OUT === nodeContext) {
	    if (CONTEXT_FLOW_IN === nodeContext || CONTEXT_FLOW_OUT === nodeContext) {
	      flowIndent = parentIndent;
	    } else {
	      flowIndent = parentIndent + 1;
	    }

	    blockIndent = state.position - state.lineStart;

	    if (indentStatus === 1) {
	      if (allowBlockCollections &&
	          (readBlockSequence(state, blockIndent) ||
	           readBlockMapping(state, blockIndent, flowIndent)) ||
	          readFlowCollection(state, flowIndent)) {
	        hasContent = true;
	      } else {
	        if ((allowBlockScalars && readBlockScalar(state, flowIndent)) ||
	            readSingleQuotedScalar(state, flowIndent) ||
	            readDoubleQuotedScalar(state, flowIndent)) {
	          hasContent = true;

	        } else if (readAlias(state)) {
	          hasContent = true;

	          if (state.tag !== null || state.anchor !== null) {
	            throwError(state, 'alias node should not have any properties');
	          }

	        } else if (readPlainScalar(state, flowIndent, CONTEXT_FLOW_IN === nodeContext)) {
	          hasContent = true;

	          if (state.tag === null) {
	            state.tag = '?';
	          }
	        }

	        if (state.anchor !== null) {
	          state.anchorMap[state.anchor] = state.result;
	        }
	      }
	    } else if (indentStatus === 0) {
	      // Special case: block sequences are allowed to have same indentation level as the parent.
	      // http://www.yaml.org/spec/1.2/spec.html#id2799784
	      hasContent = allowBlockCollections && readBlockSequence(state, blockIndent);
	    }
	  }

	  if (state.tag !== null && state.tag !== '!') {
	    if (state.tag === '?') {
	      // Implicit resolving is not allowed for non-scalar types, and '?'
	      // non-specific tag is only automatically assigned to plain scalars.
	      //
	      // We only need to check kind conformity in case user explicitly assigns '?'
	      // tag, for example like this: "!<?> [0]"
	      //
	      if (state.result !== null && state.kind !== 'scalar') {
	        throwError(state, 'unacceptable node kind for !<?> tag; it should be "scalar", not "' + state.kind + '"');
	      }

	      for (typeIndex = 0, typeQuantity = state.implicitTypes.length; typeIndex < typeQuantity; typeIndex += 1) {
	        type = state.implicitTypes[typeIndex];

	        if (type.resolve(state.result)) { // `state.result` updated in resolver if matched
	          state.result = type.construct(state.result);
	          state.tag = type.tag;
	          if (state.anchor !== null) {
	            state.anchorMap[state.anchor] = state.result;
	          }
	          break;
	        }
	      }
	    } else if (_hasOwnProperty.call(state.typeMap[state.kind || 'fallback'], state.tag)) {
	      type = state.typeMap[state.kind || 'fallback'][state.tag];

	      if (state.result !== null && type.kind !== state.kind) {
	        throwError(state, 'unacceptable node kind for !<' + state.tag + '> tag; it should be "' + type.kind + '", not "' + state.kind + '"');
	      }

	      if (!type.resolve(state.result)) { // `state.result` updated in resolver if matched
	        throwError(state, 'cannot resolve a node with !<' + state.tag + '> explicit tag');
	      } else {
	        state.result = type.construct(state.result);
	        if (state.anchor !== null) {
	          state.anchorMap[state.anchor] = state.result;
	        }
	      }
	    } else {
	      throwError(state, 'unknown tag !<' + state.tag + '>');
	    }
	  }

	  if (state.listener !== null) {
	    state.listener('close', state);
	  }
	  return state.tag !== null ||  state.anchor !== null || hasContent;
	}

	function readDocument(state) {
	  var documentStart = state.position,
	      _position,
	      directiveName,
	      directiveArgs,
	      hasDirectives = false,
	      ch;

	  state.version = null;
	  state.checkLineBreaks = state.legacy;
	  state.tagMap = {};
	  state.anchorMap = {};

	  while ((ch = state.input.charCodeAt(state.position)) !== 0) {
	    skipSeparationSpace(state, true, -1);

	    ch = state.input.charCodeAt(state.position);

	    if (state.lineIndent > 0 || ch !== 0x25/* % */) {
	      break;
	    }

	    hasDirectives = true;
	    ch = state.input.charCodeAt(++state.position);
	    _position = state.position;

	    while (ch !== 0 && !is_WS_OR_EOL(ch)) {
	      ch = state.input.charCodeAt(++state.position);
	    }

	    directiveName = state.input.slice(_position, state.position);
	    directiveArgs = [];

	    if (directiveName.length < 1) {
	      throwError(state, 'directive name must not be less than one character in length');
	    }

	    while (ch !== 0) {
	      while (is_WHITE_SPACE(ch)) {
	        ch = state.input.charCodeAt(++state.position);
	      }

	      if (ch === 0x23/* # */) {
	        do { ch = state.input.charCodeAt(++state.position); }
	        while (ch !== 0 && !is_EOL(ch));
	        break;
	      }

	      if (is_EOL(ch)) break;

	      _position = state.position;

	      while (ch !== 0 && !is_WS_OR_EOL(ch)) {
	        ch = state.input.charCodeAt(++state.position);
	      }

	      directiveArgs.push(state.input.slice(_position, state.position));
	    }

	    if (ch !== 0) readLineBreak(state);

	    if (_hasOwnProperty.call(directiveHandlers, directiveName)) {
	      directiveHandlers[directiveName](state, directiveName, directiveArgs);
	    } else {
	      throwWarning(state, 'unknown document directive "' + directiveName + '"');
	    }
	  }

	  skipSeparationSpace(state, true, -1);

	  if (state.lineIndent === 0 &&
	      state.input.charCodeAt(state.position)     === 0x2D/* - */ &&
	      state.input.charCodeAt(state.position + 1) === 0x2D/* - */ &&
	      state.input.charCodeAt(state.position + 2) === 0x2D/* - */) {
	    state.position += 3;
	    skipSeparationSpace(state, true, -1);

	  } else if (hasDirectives) {
	    throwError(state, 'directives end mark is expected');
	  }

	  composeNode(state, state.lineIndent - 1, CONTEXT_BLOCK_OUT, false, true);
	  skipSeparationSpace(state, true, -1);

	  if (state.checkLineBreaks &&
	      PATTERN_NON_ASCII_LINE_BREAKS.test(state.input.slice(documentStart, state.position))) {
	    throwWarning(state, 'non-ASCII line breaks are interpreted as content');
	  }

	  state.documents.push(state.result);

	  if (state.position === state.lineStart && testDocumentSeparator(state)) {

	    if (state.input.charCodeAt(state.position) === 0x2E/* . */) {
	      state.position += 3;
	      skipSeparationSpace(state, true, -1);
	    }
	    return;
	  }

	  if (state.position < (state.length - 1)) {
	    throwError(state, 'end of the stream or a document separator is expected');
	  } else {
	    return;
	  }
	}


	function loadDocuments(input, options) {
	  input = String(input);
	  options = options || {};

	  if (input.length !== 0) {

	    // Add tailing `\n` if not exists
	    if (input.charCodeAt(input.length - 1) !== 0x0A/* LF */ &&
	        input.charCodeAt(input.length - 1) !== 0x0D/* CR */) {
	      input += '\n';
	    }

	    // Strip BOM
	    if (input.charCodeAt(0) === 0xFEFF) {
	      input = input.slice(1);
	    }
	  }

	  var state = new State(input, options);

	  var nullpos = input.indexOf('\0');

	  if (nullpos !== -1) {
	    state.position = nullpos;
	    throwError(state, 'null byte is not allowed in input');
	  }

	  // Use 0 as string terminator. That significantly simplifies bounds check.
	  state.input += '\0';

	  while (state.input.charCodeAt(state.position) === 0x20/* Space */) {
	    state.lineIndent += 1;
	    state.position += 1;
	  }

	  while (state.position < (state.length - 1)) {
	    readDocument(state);
	  }

	  return state.documents;
	}


	function loadAll(input, iterator, options) {
	  if (iterator !== null && typeof iterator === 'object' && typeof options === 'undefined') {
	    options = iterator;
	    iterator = null;
	  }

	  var documents = loadDocuments(input, options);

	  if (typeof iterator !== 'function') {
	    return documents;
	  }

	  for (var index = 0, length = documents.length; index < length; index += 1) {
	    iterator(documents[index]);
	  }
	}


	function load(input, options) {
	  var documents = loadDocuments(input, options);

	  if (documents.length === 0) {
	    /*eslint-disable no-undefined*/
	    return undefined;
	  } else if (documents.length === 1) {
	    return documents[0];
	  }
	  throw new YAMLException('expected a single document in the stream, but found more');
	}


	function safeLoadAll(input, iterator, options) {
	  if (typeof iterator === 'object' && iterator !== null && typeof options === 'undefined') {
	    options = iterator;
	    iterator = null;
	  }

	  return loadAll(input, iterator, common.extend({ schema: DEFAULT_SAFE_SCHEMA }, options));
	}


	function safeLoad(input, options) {
	  return load(input, common.extend({ schema: DEFAULT_SAFE_SCHEMA }, options));
	}


	loader.loadAll     = loadAll;
	loader.load        = load;
	loader.safeLoadAll = safeLoadAll;
	loader.safeLoad    = safeLoad;
	return loader;
}

var dumper = {};

var hasRequiredDumper;

function requireDumper () {
	if (hasRequiredDumper) return dumper;
	hasRequiredDumper = 1;

	/*eslint-disable no-use-before-define*/

	var common              = requireCommon();
	var YAMLException       = requireException();
	var DEFAULT_FULL_SCHEMA = requireDefault_full();
	var DEFAULT_SAFE_SCHEMA = requireDefault_safe();

	var _toString       = Object.prototype.toString;
	var _hasOwnProperty = Object.prototype.hasOwnProperty;

	var CHAR_TAB                  = 0x09; /* Tab */
	var CHAR_LINE_FEED            = 0x0A; /* LF */
	var CHAR_CARRIAGE_RETURN      = 0x0D; /* CR */
	var CHAR_SPACE                = 0x20; /* Space */
	var CHAR_EXCLAMATION          = 0x21; /* ! */
	var CHAR_DOUBLE_QUOTE         = 0x22; /* " */
	var CHAR_SHARP                = 0x23; /* # */
	var CHAR_PERCENT              = 0x25; /* % */
	var CHAR_AMPERSAND            = 0x26; /* & */
	var CHAR_SINGLE_QUOTE         = 0x27; /* ' */
	var CHAR_ASTERISK             = 0x2A; /* * */
	var CHAR_COMMA                = 0x2C; /* , */
	var CHAR_MINUS                = 0x2D; /* - */
	var CHAR_COLON                = 0x3A; /* : */
	var CHAR_EQUALS               = 0x3D; /* = */
	var CHAR_GREATER_THAN         = 0x3E; /* > */
	var CHAR_QUESTION             = 0x3F; /* ? */
	var CHAR_COMMERCIAL_AT        = 0x40; /* @ */
	var CHAR_LEFT_SQUARE_BRACKET  = 0x5B; /* [ */
	var CHAR_RIGHT_SQUARE_BRACKET = 0x5D; /* ] */
	var CHAR_GRAVE_ACCENT         = 0x60; /* ` */
	var CHAR_LEFT_CURLY_BRACKET   = 0x7B; /* { */
	var CHAR_VERTICAL_LINE        = 0x7C; /* | */
	var CHAR_RIGHT_CURLY_BRACKET  = 0x7D; /* } */

	var ESCAPE_SEQUENCES = {};

	ESCAPE_SEQUENCES[0x00]   = '\\0';
	ESCAPE_SEQUENCES[0x07]   = '\\a';
	ESCAPE_SEQUENCES[0x08]   = '\\b';
	ESCAPE_SEQUENCES[0x09]   = '\\t';
	ESCAPE_SEQUENCES[0x0A]   = '\\n';
	ESCAPE_SEQUENCES[0x0B]   = '\\v';
	ESCAPE_SEQUENCES[0x0C]   = '\\f';
	ESCAPE_SEQUENCES[0x0D]   = '\\r';
	ESCAPE_SEQUENCES[0x1B]   = '\\e';
	ESCAPE_SEQUENCES[0x22]   = '\\"';
	ESCAPE_SEQUENCES[0x5C]   = '\\\\';
	ESCAPE_SEQUENCES[0x85]   = '\\N';
	ESCAPE_SEQUENCES[0xA0]   = '\\_';
	ESCAPE_SEQUENCES[0x2028] = '\\L';
	ESCAPE_SEQUENCES[0x2029] = '\\P';

	var DEPRECATED_BOOLEANS_SYNTAX = [
	  'y', 'Y', 'yes', 'Yes', 'YES', 'on', 'On', 'ON',
	  'n', 'N', 'no', 'No', 'NO', 'off', 'Off', 'OFF'
	];

	function compileStyleMap(schema, map) {
	  var result, keys, index, length, tag, style, type;

	  if (map === null) return {};

	  result = {};
	  keys = Object.keys(map);

	  for (index = 0, length = keys.length; index < length; index += 1) {
	    tag = keys[index];
	    style = String(map[tag]);

	    if (tag.slice(0, 2) === '!!') {
	      tag = 'tag:yaml.org,2002:' + tag.slice(2);
	    }
	    type = schema.compiledTypeMap['fallback'][tag];

	    if (type && _hasOwnProperty.call(type.styleAliases, style)) {
	      style = type.styleAliases[style];
	    }

	    result[tag] = style;
	  }

	  return result;
	}

	function encodeHex(character) {
	  var string, handle, length;

	  string = character.toString(16).toUpperCase();

	  if (character <= 0xFF) {
	    handle = 'x';
	    length = 2;
	  } else if (character <= 0xFFFF) {
	    handle = 'u';
	    length = 4;
	  } else if (character <= 0xFFFFFFFF) {
	    handle = 'U';
	    length = 8;
	  } else {
	    throw new YAMLException('code point within a string may not be greater than 0xFFFFFFFF');
	  }

	  return '\\' + handle + common.repeat('0', length - string.length) + string;
	}

	function State(options) {
	  this.schema        = options['schema'] || DEFAULT_FULL_SCHEMA;
	  this.indent        = Math.max(1, (options['indent'] || 2));
	  this.noArrayIndent = options['noArrayIndent'] || false;
	  this.skipInvalid   = options['skipInvalid'] || false;
	  this.flowLevel     = (common.isNothing(options['flowLevel']) ? -1 : options['flowLevel']);
	  this.styleMap      = compileStyleMap(this.schema, options['styles'] || null);
	  this.sortKeys      = options['sortKeys'] || false;
	  this.lineWidth     = options['lineWidth'] || 80;
	  this.noRefs        = options['noRefs'] || false;
	  this.noCompatMode  = options['noCompatMode'] || false;
	  this.condenseFlow  = options['condenseFlow'] || false;

	  this.implicitTypes = this.schema.compiledImplicit;
	  this.explicitTypes = this.schema.compiledExplicit;

	  this.tag = null;
	  this.result = '';

	  this.duplicates = [];
	  this.usedDuplicates = null;
	}

	// Indents every line in a string. Empty lines (\n only) are not indented.
	function indentString(string, spaces) {
	  var ind = common.repeat(' ', spaces),
	      position = 0,
	      next = -1,
	      result = '',
	      line,
	      length = string.length;

	  while (position < length) {
	    next = string.indexOf('\n', position);
	    if (next === -1) {
	      line = string.slice(position);
	      position = length;
	    } else {
	      line = string.slice(position, next + 1);
	      position = next + 1;
	    }

	    if (line.length && line !== '\n') result += ind;

	    result += line;
	  }

	  return result;
	}

	function generateNextLine(state, level) {
	  return '\n' + common.repeat(' ', state.indent * level);
	}

	function testImplicitResolving(state, str) {
	  var index, length, type;

	  for (index = 0, length = state.implicitTypes.length; index < length; index += 1) {
	    type = state.implicitTypes[index];

	    if (type.resolve(str)) {
	      return true;
	    }
	  }

	  return false;
	}

	// [33] s-white ::= s-space | s-tab
	function isWhitespace(c) {
	  return c === CHAR_SPACE || c === CHAR_TAB;
	}

	// Returns true if the character can be printed without escaping.
	// From YAML 1.2: "any allowed characters known to be non-printable
	// should also be escaped. [However,] This isnâ€™t mandatory"
	// Derived from nb-char - \t - #x85 - #xA0 - #x2028 - #x2029.
	function isPrintable(c) {
	  return  (0x00020 <= c && c <= 0x00007E)
	      || ((0x000A1 <= c && c <= 0x00D7FF) && c !== 0x2028 && c !== 0x2029)
	      || ((0x0E000 <= c && c <= 0x00FFFD) && c !== 0xFEFF /* BOM */)
	      ||  (0x10000 <= c && c <= 0x10FFFF);
	}

	// [34] ns-char ::= nb-char - s-white
	// [27] nb-char ::= c-printable - b-char - c-byte-order-mark
	// [26] b-char  ::= b-line-feed | b-carriage-return
	// [24] b-line-feed       ::=     #xA    /* LF */
	// [25] b-carriage-return ::=     #xD    /* CR */
	// [3]  c-byte-order-mark ::=     #xFEFF
	function isNsChar(c) {
	  return isPrintable(c) && !isWhitespace(c)
	    // byte-order-mark
	    && c !== 0xFEFF
	    // b-char
	    && c !== CHAR_CARRIAGE_RETURN
	    && c !== CHAR_LINE_FEED;
	}

	// Simplified test for values allowed after the first character in plain style.
	function isPlainSafe(c, prev) {
	  // Uses a subset of nb-char - c-flow-indicator - ":" - "#"
	  // where nb-char ::= c-printable - b-char - c-byte-order-mark.
	  return isPrintable(c) && c !== 0xFEFF
	    // - c-flow-indicator
	    && c !== CHAR_COMMA
	    && c !== CHAR_LEFT_SQUARE_BRACKET
	    && c !== CHAR_RIGHT_SQUARE_BRACKET
	    && c !== CHAR_LEFT_CURLY_BRACKET
	    && c !== CHAR_RIGHT_CURLY_BRACKET
	    // - ":" - "#"
	    // /* An ns-char preceding */ "#"
	    && c !== CHAR_COLON
	    && ((c !== CHAR_SHARP) || (prev && isNsChar(prev)));
	}

	// Simplified test for values allowed as the first character in plain style.
	function isPlainSafeFirst(c) {
	  // Uses a subset of ns-char - c-indicator
	  // where ns-char = nb-char - s-white.
	  return isPrintable(c) && c !== 0xFEFF
	    && !isWhitespace(c) // - s-white
	    // - (c-indicator ::=
	    // â€œ-â€ | â€œ?â€ | â€œ:â€ | â€œ,â€ | â€œ[â€ | â€œ]â€ | â€œ{â€ | â€œ}â€
	    && c !== CHAR_MINUS
	    && c !== CHAR_QUESTION
	    && c !== CHAR_COLON
	    && c !== CHAR_COMMA
	    && c !== CHAR_LEFT_SQUARE_BRACKET
	    && c !== CHAR_RIGHT_SQUARE_BRACKET
	    && c !== CHAR_LEFT_CURLY_BRACKET
	    && c !== CHAR_RIGHT_CURLY_BRACKET
	    // | â€œ#â€ | â€œ&â€ | â€œ*â€ | â€œ!â€ | â€œ|â€ | â€œ=â€ | â€œ>â€ | â€œ'â€ | â€œ"â€
	    && c !== CHAR_SHARP
	    && c !== CHAR_AMPERSAND
	    && c !== CHAR_ASTERISK
	    && c !== CHAR_EXCLAMATION
	    && c !== CHAR_VERTICAL_LINE
	    && c !== CHAR_EQUALS
	    && c !== CHAR_GREATER_THAN
	    && c !== CHAR_SINGLE_QUOTE
	    && c !== CHAR_DOUBLE_QUOTE
	    // | â€œ%â€ | â€œ@â€ | â€œ`â€)
	    && c !== CHAR_PERCENT
	    && c !== CHAR_COMMERCIAL_AT
	    && c !== CHAR_GRAVE_ACCENT;
	}

	// Determines whether block indentation indicator is required.
	function needIndentIndicator(string) {
	  var leadingSpaceRe = /^\n* /;
	  return leadingSpaceRe.test(string);
	}

	var STYLE_PLAIN   = 1,
	    STYLE_SINGLE  = 2,
	    STYLE_LITERAL = 3,
	    STYLE_FOLDED  = 4,
	    STYLE_DOUBLE  = 5;

	// Determines which scalar styles are possible and returns the preferred style.
	// lineWidth = -1 => no limit.
	// Pre-conditions: str.length > 0.
	// Post-conditions:
	//    STYLE_PLAIN or STYLE_SINGLE => no \n are in the string.
	//    STYLE_LITERAL => no lines are suitable for folding (or lineWidth is -1).
	//    STYLE_FOLDED => a line > lineWidth and can be folded (and lineWidth != -1).
	function chooseScalarStyle(string, singleLineOnly, indentPerLevel, lineWidth, testAmbiguousType) {
	  var i;
	  var char, prev_char;
	  var hasLineBreak = false;
	  var hasFoldableLine = false; // only checked if shouldTrackWidth
	  var shouldTrackWidth = lineWidth !== -1;
	  var previousLineBreak = -1; // count the first line correctly
	  var plain = isPlainSafeFirst(string.charCodeAt(0))
	          && !isWhitespace(string.charCodeAt(string.length - 1));

	  if (singleLineOnly) {
	    // Case: no block styles.
	    // Check for disallowed characters to rule out plain and single.
	    for (i = 0; i < string.length; i++) {
	      char = string.charCodeAt(i);
	      if (!isPrintable(char)) {
	        return STYLE_DOUBLE;
	      }
	      prev_char = i > 0 ? string.charCodeAt(i - 1) : null;
	      plain = plain && isPlainSafe(char, prev_char);
	    }
	  } else {
	    // Case: block styles permitted.
	    for (i = 0; i < string.length; i++) {
	      char = string.charCodeAt(i);
	      if (char === CHAR_LINE_FEED) {
	        hasLineBreak = true;
	        // Check if any line can be folded.
	        if (shouldTrackWidth) {
	          hasFoldableLine = hasFoldableLine ||
	            // Foldable line = too long, and not more-indented.
	            (i - previousLineBreak - 1 > lineWidth &&
	             string[previousLineBreak + 1] !== ' ');
	          previousLineBreak = i;
	        }
	      } else if (!isPrintable(char)) {
	        return STYLE_DOUBLE;
	      }
	      prev_char = i > 0 ? string.charCodeAt(i - 1) : null;
	      plain = plain && isPlainSafe(char, prev_char);
	    }
	    // in case the end is missing a \n
	    hasFoldableLine = hasFoldableLine || (shouldTrackWidth &&
	      (i - previousLineBreak - 1 > lineWidth &&
	       string[previousLineBreak + 1] !== ' '));
	  }
	  // Although every style can represent \n without escaping, prefer block styles
	  // for multiline, since they're more readable and they don't add empty lines.
	  // Also prefer folding a super-long line.
	  if (!hasLineBreak && !hasFoldableLine) {
	    // Strings interpretable as another type have to be quoted;
	    // e.g. the string 'true' vs. the boolean true.
	    return plain && !testAmbiguousType(string)
	      ? STYLE_PLAIN : STYLE_SINGLE;
	  }
	  // Edge case: block indentation indicator can only have one digit.
	  if (indentPerLevel > 9 && needIndentIndicator(string)) {
	    return STYLE_DOUBLE;
	  }
	  // At this point we know block styles are valid.
	  // Prefer literal style unless we want to fold.
	  return hasFoldableLine ? STYLE_FOLDED : STYLE_LITERAL;
	}

	// Note: line breaking/folding is implemented for only the folded style.
	// NB. We drop the last trailing newline (if any) of a returned block scalar
	//  since the dumper adds its own newline. This always works:
	//    â€¢ No ending newline => unaffected; already using strip "-" chomping.
	//    â€¢ Ending newline    => removed then restored.
	//  Importantly, this keeps the "+" chomp indicator from gaining an extra line.
	function writeScalar(state, string, level, iskey) {
	  state.dump = (function () {
	    if (string.length === 0) {
	      return "''";
	    }
	    if (!state.noCompatMode &&
	        DEPRECATED_BOOLEANS_SYNTAX.indexOf(string) !== -1) {
	      return "'" + string + "'";
	    }

	    var indent = state.indent * Math.max(1, level); // no 0-indent scalars
	    // As indentation gets deeper, let the width decrease monotonically
	    // to the lower bound min(state.lineWidth, 40).
	    // Note that this implies
	    //  state.lineWidth â‰¤ 40 + state.indent: width is fixed at the lower bound.
	    //  state.lineWidth > 40 + state.indent: width decreases until the lower bound.
	    // This behaves better than a constant minimum width which disallows narrower options,
	    // or an indent threshold which causes the width to suddenly increase.
	    var lineWidth = state.lineWidth === -1
	      ? -1 : Math.max(Math.min(state.lineWidth, 40), state.lineWidth - indent);

	    // Without knowing if keys are implicit/explicit, assume implicit for safety.
	    var singleLineOnly = iskey
	      // No block styles in flow mode.
	      || (state.flowLevel > -1 && level >= state.flowLevel);
	    function testAmbiguity(string) {
	      return testImplicitResolving(state, string);
	    }

	    switch (chooseScalarStyle(string, singleLineOnly, state.indent, lineWidth, testAmbiguity)) {
	      case STYLE_PLAIN:
	        return string;
	      case STYLE_SINGLE:
	        return "'" + string.replace(/'/g, "''") + "'";
	      case STYLE_LITERAL:
	        return '|' + blockHeader(string, state.indent)
	          + dropEndingNewline(indentString(string, indent));
	      case STYLE_FOLDED:
	        return '>' + blockHeader(string, state.indent)
	          + dropEndingNewline(indentString(foldString(string, lineWidth), indent));
	      case STYLE_DOUBLE:
	        return '"' + escapeString(string) + '"';
	      default:
	        throw new YAMLException('impossible error: invalid scalar style');
	    }
	  }());
	}

	// Pre-conditions: string is valid for a block scalar, 1 <= indentPerLevel <= 9.
	function blockHeader(string, indentPerLevel) {
	  var indentIndicator = needIndentIndicator(string) ? String(indentPerLevel) : '';

	  // note the special case: the string '\n' counts as a "trailing" empty line.
	  var clip =          string[string.length - 1] === '\n';
	  var keep = clip && (string[string.length - 2] === '\n' || string === '\n');
	  var chomp = keep ? '+' : (clip ? '' : '-');

	  return indentIndicator + chomp + '\n';
	}

	// (See the note for writeScalar.)
	function dropEndingNewline(string) {
	  return string[string.length - 1] === '\n' ? string.slice(0, -1) : string;
	}

	// Note: a long line without a suitable break point will exceed the width limit.
	// Pre-conditions: every char in str isPrintable, str.length > 0, width > 0.
	function foldString(string, width) {
	  // In folded style, $k$ consecutive newlines output as $k+1$ newlinesâ€”
	  // unless they're before or after a more-indented line, or at the very
	  // beginning or end, in which case $k$ maps to $k$.
	  // Therefore, parse each chunk as newline(s) followed by a content line.
	  var lineRe = /(\n+)([^\n]*)/g;

	  // first line (possibly an empty line)
	  var result = (function () {
	    var nextLF = string.indexOf('\n');
	    nextLF = nextLF !== -1 ? nextLF : string.length;
	    lineRe.lastIndex = nextLF;
	    return foldLine(string.slice(0, nextLF), width);
	  }());
	  // If we haven't reached the first content line yet, don't add an extra \n.
	  var prevMoreIndented = string[0] === '\n' || string[0] === ' ';
	  var moreIndented;

	  // rest of the lines
	  var match;
	  while ((match = lineRe.exec(string))) {
	    var prefix = match[1], line = match[2];
	    moreIndented = (line[0] === ' ');
	    result += prefix
	      + (!prevMoreIndented && !moreIndented && line !== ''
	        ? '\n' : '')
	      + foldLine(line, width);
	    prevMoreIndented = moreIndented;
	  }

	  return result;
	}

	// Greedy line breaking.
	// Picks the longest line under the limit each time,
	// otherwise settles for the shortest line over the limit.
	// NB. More-indented lines *cannot* be folded, as that would add an extra \n.
	function foldLine(line, width) {
	  if (line === '' || line[0] === ' ') return line;

	  // Since a more-indented line adds a \n, breaks can't be followed by a space.
	  var breakRe = / [^ ]/g; // note: the match index will always be <= length-2.
	  var match;
	  // start is an inclusive index. end, curr, and next are exclusive.
	  var start = 0, end, curr = 0, next = 0;
	  var result = '';

	  // Invariants: 0 <= start <= length-1.
	  //   0 <= curr <= next <= max(0, length-2). curr - start <= width.
	  // Inside the loop:
	  //   A match implies length >= 2, so curr and next are <= length-2.
	  while ((match = breakRe.exec(line))) {
	    next = match.index;
	    // maintain invariant: curr - start <= width
	    if (next - start > width) {
	      end = (curr > start) ? curr : next; // derive end <= length-2
	      result += '\n' + line.slice(start, end);
	      // skip the space that was output as \n
	      start = end + 1;                    // derive start <= length-1
	    }
	    curr = next;
	  }

	  // By the invariants, start <= length-1, so there is something left over.
	  // It is either the whole string or a part starting from non-whitespace.
	  result += '\n';
	  // Insert a break if the remainder is too long and there is a break available.
	  if (line.length - start > width && curr > start) {
	    result += line.slice(start, curr) + '\n' + line.slice(curr + 1);
	  } else {
	    result += line.slice(start);
	  }

	  return result.slice(1); // drop extra \n joiner
	}

	// Escapes a double-quoted string.
	function escapeString(string) {
	  var result = '';
	  var char, nextChar;
	  var escapeSeq;

	  for (var i = 0; i < string.length; i++) {
	    char = string.charCodeAt(i);
	    // Check for surrogate pairs (reference Unicode 3.0 section "3.7 Surrogates").
	    if (char >= 0xD800 && char <= 0xDBFF/* high surrogate */) {
	      nextChar = string.charCodeAt(i + 1);
	      if (nextChar >= 0xDC00 && nextChar <= 0xDFFF/* low surrogate */) {
	        // Combine the surrogate pair and store it escaped.
	        result += encodeHex((char - 0xD800) * 0x400 + nextChar - 0xDC00 + 0x10000);
	        // Advance index one extra since we already used that char here.
	        i++; continue;
	      }
	    }
	    escapeSeq = ESCAPE_SEQUENCES[char];
	    result += !escapeSeq && isPrintable(char)
	      ? string[i]
	      : escapeSeq || encodeHex(char);
	  }

	  return result;
	}

	function writeFlowSequence(state, level, object) {
	  var _result = '',
	      _tag    = state.tag,
	      index,
	      length;

	  for (index = 0, length = object.length; index < length; index += 1) {
	    // Write only valid elements.
	    if (writeNode(state, level, object[index], false, false)) {
	      if (index !== 0) _result += ',' + (!state.condenseFlow ? ' ' : '');
	      _result += state.dump;
	    }
	  }

	  state.tag = _tag;
	  state.dump = '[' + _result + ']';
	}

	function writeBlockSequence(state, level, object, compact) {
	  var _result = '',
	      _tag    = state.tag,
	      index,
	      length;

	  for (index = 0, length = object.length; index < length; index += 1) {
	    // Write only valid elements.
	    if (writeNode(state, level + 1, object[index], true, true)) {
	      if (!compact || index !== 0) {
	        _result += generateNextLine(state, level);
	      }

	      if (state.dump && CHAR_LINE_FEED === state.dump.charCodeAt(0)) {
	        _result += '-';
	      } else {
	        _result += '- ';
	      }

	      _result += state.dump;
	    }
	  }

	  state.tag = _tag;
	  state.dump = _result || '[]'; // Empty sequence if no valid values.
	}

	function writeFlowMapping(state, level, object) {
	  var _result       = '',
	      _tag          = state.tag,
	      objectKeyList = Object.keys(object),
	      index,
	      length,
	      objectKey,
	      objectValue,
	      pairBuffer;

	  for (index = 0, length = objectKeyList.length; index < length; index += 1) {

	    pairBuffer = '';
	    if (index !== 0) pairBuffer += ', ';

	    if (state.condenseFlow) pairBuffer += '"';

	    objectKey = objectKeyList[index];
	    objectValue = object[objectKey];

	    if (!writeNode(state, level, objectKey, false, false)) {
	      continue; // Skip this pair because of invalid key;
	    }

	    if (state.dump.length > 1024) pairBuffer += '? ';

	    pairBuffer += state.dump + (state.condenseFlow ? '"' : '') + ':' + (state.condenseFlow ? '' : ' ');

	    if (!writeNode(state, level, objectValue, false, false)) {
	      continue; // Skip this pair because of invalid value.
	    }

	    pairBuffer += state.dump;

	    // Both key and value are valid.
	    _result += pairBuffer;
	  }

	  state.tag = _tag;
	  state.dump = '{' + _result + '}';
	}

	function writeBlockMapping(state, level, object, compact) {
	  var _result       = '',
	      _tag          = state.tag,
	      objectKeyList = Object.keys(object),
	      index,
	      length,
	      objectKey,
	      objectValue,
	      explicitPair,
	      pairBuffer;

	  // Allow sorting keys so that the output file is deterministic
	  if (state.sortKeys === true) {
	    // Default sorting
	    objectKeyList.sort();
	  } else if (typeof state.sortKeys === 'function') {
	    // Custom sort function
	    objectKeyList.sort(state.sortKeys);
	  } else if (state.sortKeys) {
	    // Something is wrong
	    throw new YAMLException('sortKeys must be a boolean or a function');
	  }

	  for (index = 0, length = objectKeyList.length; index < length; index += 1) {
	    pairBuffer = '';

	    if (!compact || index !== 0) {
	      pairBuffer += generateNextLine(state, level);
	    }

	    objectKey = objectKeyList[index];
	    objectValue = object[objectKey];

	    if (!writeNode(state, level + 1, objectKey, true, true, true)) {
	      continue; // Skip this pair because of invalid key.
	    }

	    explicitPair = (state.tag !== null && state.tag !== '?') ||
	                   (state.dump && state.dump.length > 1024);

	    if (explicitPair) {
	      if (state.dump && CHAR_LINE_FEED === state.dump.charCodeAt(0)) {
	        pairBuffer += '?';
	      } else {
	        pairBuffer += '? ';
	      }
	    }

	    pairBuffer += state.dump;

	    if (explicitPair) {
	      pairBuffer += generateNextLine(state, level);
	    }

	    if (!writeNode(state, level + 1, objectValue, true, explicitPair)) {
	      continue; // Skip this pair because of invalid value.
	    }

	    if (state.dump && CHAR_LINE_FEED === state.dump.charCodeAt(0)) {
	      pairBuffer += ':';
	    } else {
	      pairBuffer += ': ';
	    }

	    pairBuffer += state.dump;

	    // Both key and value are valid.
	    _result += pairBuffer;
	  }

	  state.tag = _tag;
	  state.dump = _result || '{}'; // Empty mapping if no valid pairs.
	}

	function detectType(state, object, explicit) {
	  var _result, typeList, index, length, type, style;

	  typeList = explicit ? state.explicitTypes : state.implicitTypes;

	  for (index = 0, length = typeList.length; index < length; index += 1) {
	    type = typeList[index];

	    if ((type.instanceOf  || type.predicate) &&
	        (!type.instanceOf || ((typeof object === 'object') && (object instanceof type.instanceOf))) &&
	        (!type.predicate  || type.predicate(object))) {

	      state.tag = explicit ? type.tag : '?';

	      if (type.represent) {
	        style = state.styleMap[type.tag] || type.defaultStyle;

	        if (_toString.call(type.represent) === '[object Function]') {
	          _result = type.represent(object, style);
	        } else if (_hasOwnProperty.call(type.represent, style)) {
	          _result = type.represent[style](object, style);
	        } else {
	          throw new YAMLException('!<' + type.tag + '> tag resolver accepts not "' + style + '" style');
	        }

	        state.dump = _result;
	      }

	      return true;
	    }
	  }

	  return false;
	}

	// Serializes `object` and writes it to global `result`.
	// Returns true on success, or false on invalid object.
	//
	function writeNode(state, level, object, block, compact, iskey) {
	  state.tag = null;
	  state.dump = object;

	  if (!detectType(state, object, false)) {
	    detectType(state, object, true);
	  }

	  var type = _toString.call(state.dump);

	  if (block) {
	    block = (state.flowLevel < 0 || state.flowLevel > level);
	  }

	  var objectOrArray = type === '[object Object]' || type === '[object Array]',
	      duplicateIndex,
	      duplicate;

	  if (objectOrArray) {
	    duplicateIndex = state.duplicates.indexOf(object);
	    duplicate = duplicateIndex !== -1;
	  }

	  if ((state.tag !== null && state.tag !== '?') || duplicate || (state.indent !== 2 && level > 0)) {
	    compact = false;
	  }

	  if (duplicate && state.usedDuplicates[duplicateIndex]) {
	    state.dump = '*ref_' + duplicateIndex;
	  } else {
	    if (objectOrArray && duplicate && !state.usedDuplicates[duplicateIndex]) {
	      state.usedDuplicates[duplicateIndex] = true;
	    }
	    if (type === '[object Object]') {
	      if (block && (Object.keys(state.dump).length !== 0)) {
	        writeBlockMapping(state, level, state.dump, compact);
	        if (duplicate) {
	          state.dump = '&ref_' + duplicateIndex + state.dump;
	        }
	      } else {
	        writeFlowMapping(state, level, state.dump);
	        if (duplicate) {
	          state.dump = '&ref_' + duplicateIndex + ' ' + state.dump;
	        }
	      }
	    } else if (type === '[object Array]') {
	      var arrayLevel = (state.noArrayIndent && (level > 0)) ? level - 1 : level;
	      if (block && (state.dump.length !== 0)) {
	        writeBlockSequence(state, arrayLevel, state.dump, compact);
	        if (duplicate) {
	          state.dump = '&ref_' + duplicateIndex + state.dump;
	        }
	      } else {
	        writeFlowSequence(state, arrayLevel, state.dump);
	        if (duplicate) {
	          state.dump = '&ref_' + duplicateIndex + ' ' + state.dump;
	        }
	      }
	    } else if (type === '[object String]') {
	      if (state.tag !== '?') {
	        writeScalar(state, state.dump, level, iskey);
	      }
	    } else {
	      if (state.skipInvalid) return false;
	      throw new YAMLException('unacceptable kind of an object to dump ' + type);
	    }

	    if (state.tag !== null && state.tag !== '?') {
	      state.dump = '!<' + state.tag + '> ' + state.dump;
	    }
	  }

	  return true;
	}

	function getDuplicateReferences(object, state) {
	  var objects = [],
	      duplicatesIndexes = [],
	      index,
	      length;

	  inspectNode(object, objects, duplicatesIndexes);

	  for (index = 0, length = duplicatesIndexes.length; index < length; index += 1) {
	    state.duplicates.push(objects[duplicatesIndexes[index]]);
	  }
	  state.usedDuplicates = new Array(length);
	}

	function inspectNode(object, objects, duplicatesIndexes) {
	  var objectKeyList,
	      index,
	      length;

	  if (object !== null && typeof object === 'object') {
	    index = objects.indexOf(object);
	    if (index !== -1) {
	      if (duplicatesIndexes.indexOf(index) === -1) {
	        duplicatesIndexes.push(index);
	      }
	    } else {
	      objects.push(object);

	      if (Array.isArray(object)) {
	        for (index = 0, length = object.length; index < length; index += 1) {
	          inspectNode(object[index], objects, duplicatesIndexes);
	        }
	      } else {
	        objectKeyList = Object.keys(object);

	        for (index = 0, length = objectKeyList.length; index < length; index += 1) {
	          inspectNode(object[objectKeyList[index]], objects, duplicatesIndexes);
	        }
	      }
	    }
	  }
	}

	function dump(input, options) {
	  options = options || {};

	  var state = new State(options);

	  if (!state.noRefs) getDuplicateReferences(input, state);

	  if (writeNode(state, 0, input, true, true)) return state.dump + '\n';

	  return '';
	}

	function safeDump(input, options) {
	  return dump(input, common.extend({ schema: DEFAULT_SAFE_SCHEMA }, options));
	}

	dumper.dump     = dump;
	dumper.safeDump = safeDump;
	return dumper;
}

var hasRequiredJsYaml$1;

function requireJsYaml$1 () {
	if (hasRequiredJsYaml$1) return jsYaml$1;
	hasRequiredJsYaml$1 = 1;


	var loader = requireLoader();
	var dumper = requireDumper();


	function deprecated(name) {
	  return function () {
	    throw new Error('Function ' + name + ' is deprecated and cannot be used.');
	  };
	}


	jsYaml$1.Type                = requireType();
	jsYaml$1.Schema              = requireSchema();
	jsYaml$1.FAILSAFE_SCHEMA     = requireFailsafe();
	jsYaml$1.JSON_SCHEMA         = requireJson();
	jsYaml$1.CORE_SCHEMA         = requireCore();
	jsYaml$1.DEFAULT_SAFE_SCHEMA = requireDefault_safe();
	jsYaml$1.DEFAULT_FULL_SCHEMA = requireDefault_full();
	jsYaml$1.load                = loader.load;
	jsYaml$1.loadAll             = loader.loadAll;
	jsYaml$1.safeLoad            = loader.safeLoad;
	jsYaml$1.safeLoadAll         = loader.safeLoadAll;
	jsYaml$1.dump                = dumper.dump;
	jsYaml$1.safeDump            = dumper.safeDump;
	jsYaml$1.YAMLException       = requireException();

	// Deprecated schema names from JS-YAML 2.0.x
	jsYaml$1.MINIMAL_SCHEMA = requireFailsafe();
	jsYaml$1.SAFE_SCHEMA    = requireDefault_safe();
	jsYaml$1.DEFAULT_SCHEMA = requireDefault_full();

	// Deprecated functions from JS-YAML 1.x.x
	jsYaml$1.scan           = deprecated('scan');
	jsYaml$1.parse          = deprecated('parse');
	jsYaml$1.compose        = deprecated('compose');
	jsYaml$1.addConstructor = deprecated('addConstructor');
	return jsYaml$1;
}

var jsYaml;
var hasRequiredJsYaml;

function requireJsYaml () {
	if (hasRequiredJsYaml) return jsYaml;
	hasRequiredJsYaml = 1;


	var yaml = requireJsYaml$1();


	jsYaml = yaml;
	return jsYaml;
}

var hasRequiredEngines;

function requireEngines () {
	if (hasRequiredEngines) return engines.exports;
	hasRequiredEngines = 1;
	(function (module, exports) {

		const yaml = requireJsYaml();

		/**
		 * Default engines
		 */

		const engines = module.exports;

		/**
		 * YAML
		 */

		engines.yaml = {
		  parse: yaml.safeLoad.bind(yaml),
		  stringify: yaml.safeDump.bind(yaml)
		};

		/**
		 * JSON
		 */

		engines.json = {
		  parse: JSON.parse.bind(JSON),
		  stringify: function(obj, options) {
		    const opts = Object.assign({replacer: null, space: 2}, options);
		    return JSON.stringify(obj, opts.replacer, opts.space);
		  }
		};

		/**
		 * JavaScript
		 */

		engines.javascript = {
		  parse: function parse(str, options, wrap) {
		    /* eslint no-eval: 0 */
		    try {
		      if (wrap !== false) {
		        str = '(function() {\nreturn ' + str.trim() + ';\n}());';
		      }
		      return eval(str) || {};
		    } catch (err) {
		      if (wrap !== false && /(unexpected|identifier)/i.test(err.message)) {
		        return parse(str, options, false);
		      }
		      throw new SyntaxError(err);
		    }
		  },
		  stringify: function() {
		    throw new Error('stringifying JavaScript is not supported');
		  }
		}; 
	} (engines));
	return engines.exports;
}

var utils$1 = {};

/*!
 * strip-bom-string <https://github.com/jonschlinkert/strip-bom-string>
 *
 * Copyright (c) 2015, 2017, Jon Schlinkert.
 * Released under the MIT License.
 */

var stripBomString;
var hasRequiredStripBomString;

function requireStripBomString () {
	if (hasRequiredStripBomString) return stripBomString;
	hasRequiredStripBomString = 1;

	stripBomString = function(str) {
	  if (typeof str === 'string' && str.charAt(0) === '\ufeff') {
	    return str.slice(1);
	  }
	  return str;
	};
	return stripBomString;
}

var hasRequiredUtils;

function requireUtils () {
	if (hasRequiredUtils) return utils$1;
	hasRequiredUtils = 1;
	(function (exports) {

		const stripBom = requireStripBomString();
		const typeOf = requireKindOf();

		exports.define = function(obj, key, val) {
		  Reflect.defineProperty(obj, key, {
		    enumerable: false,
		    configurable: true,
		    writable: true,
		    value: val
		  });
		};

		/**
		 * Returns true if `val` is a buffer
		 */

		exports.isBuffer = function(val) {
		  return typeOf(val) === 'buffer';
		};

		/**
		 * Returns true if `val` is an object
		 */

		exports.isObject = function(val) {
		  return typeOf(val) === 'object';
		};

		/**
		 * Cast `input` to a buffer
		 */

		exports.toBuffer = function(input) {
		  return typeof input === 'string' ? Buffer.from(input) : input;
		};

		/**
		 * Cast `val` to a string.
		 */

		exports.toString = function(input) {
		  if (exports.isBuffer(input)) return stripBom(String(input));
		  if (typeof input !== 'string') {
		    throw new TypeError('expected input to be a string or buffer');
		  }
		  return stripBom(input);
		};

		/**
		 * Cast `val` to an array.
		 */

		exports.arrayify = function(val) {
		  return val ? (Array.isArray(val) ? val : [val]) : [];
		};

		/**
		 * Returns true if `str` starts with `substr`.
		 */

		exports.startsWith = function(str, substr, len) {
		  if (typeof len !== 'number') len = substr.length;
		  return str.slice(0, len) === substr;
		}; 
	} (utils$1));
	return utils$1;
}

var defaults$3;
var hasRequiredDefaults;

function requireDefaults () {
	if (hasRequiredDefaults) return defaults$3;
	hasRequiredDefaults = 1;

	const engines = requireEngines();
	const utils = requireUtils();

	defaults$3 = function(options) {
	  const opts = Object.assign({}, options);

	  // ensure that delimiters are an array
	  opts.delimiters = utils.arrayify(opts.delims || opts.delimiters || '---');
	  if (opts.delimiters.length === 1) {
	    opts.delimiters.push(opts.delimiters[0]);
	  }

	  opts.language = (opts.language || opts.lang || 'yaml').toLowerCase();
	  opts.engines = Object.assign({}, engines, opts.parsers, opts.engines);
	  return opts;
	};
	return defaults$3;
}

var engine;
var hasRequiredEngine;

function requireEngine () {
	if (hasRequiredEngine) return engine;
	hasRequiredEngine = 1;

	engine = function(name, options) {
	  let engine = options.engines[name] || options.engines[aliase(name)];
	  if (typeof engine === 'undefined') {
	    throw new Error('gray-matter engine "' + name + '" is not registered');
	  }
	  if (typeof engine === 'function') {
	    engine = { parse: engine };
	  }
	  return engine;
	};

	function aliase(name) {
	  switch (name.toLowerCase()) {
	    case 'js':
	    case 'javascript':
	      return 'javascript';
	    case 'coffee':
	    case 'coffeescript':
	    case 'cson':
	      return 'coffee';
	    case 'yaml':
	    case 'yml':
	      return 'yaml';
	    default: {
	      return name;
	    }
	  }
	}
	return engine;
}

var stringify;
var hasRequiredStringify;

function requireStringify () {
	if (hasRequiredStringify) return stringify;
	hasRequiredStringify = 1;

	const typeOf = requireKindOf();
	const getEngine = requireEngine();
	const defaults = requireDefaults();

	stringify = function(file, data, options) {
	  if (data == null && options == null) {
	    switch (typeOf(file)) {
	      case 'object':
	        data = file.data;
	        options = {};
	        break;
	      case 'string':
	        return file;
	      default: {
	        throw new TypeError('expected file to be a string or object');
	      }
	    }
	  }

	  const str = file.content;
	  const opts = defaults(options);
	  if (data == null) {
	    if (!opts.data) return file;
	    data = opts.data;
	  }

	  const language = file.language || opts.language;
	  const engine = getEngine(language, opts);
	  if (typeof engine.stringify !== 'function') {
	    throw new TypeError('expected "' + language + '.stringify" to be a function');
	  }

	  data = Object.assign({}, file.data, data);
	  const open = opts.delimiters[0];
	  const close = opts.delimiters[1];
	  const matter = engine.stringify(data, options).trim();
	  let buf = '';

	  if (matter !== '{}') {
	    buf = newline(open) + newline(matter) + newline(close);
	  }

	  if (typeof file.excerpt === 'string' && file.excerpt !== '') {
	    if (str.indexOf(file.excerpt.trim()) === -1) {
	      buf += newline(file.excerpt) + newline(close);
	    }
	  }

	  return buf + newline(str);
	};

	function newline(str) {
	  return str.slice(-1) !== '\n' ? str + '\n' : str;
	}
	return stringify;
}

var excerpt;
var hasRequiredExcerpt;

function requireExcerpt () {
	if (hasRequiredExcerpt) return excerpt;
	hasRequiredExcerpt = 1;

	const defaults = requireDefaults();

	excerpt = function(file, options) {
	  const opts = defaults(options);

	  if (file.data == null) {
	    file.data = {};
	  }

	  if (typeof opts.excerpt === 'function') {
	    return opts.excerpt(file, opts);
	  }

	  const sep = file.data.excerpt_separator || opts.excerpt_separator;
	  if (sep == null && (opts.excerpt === false || opts.excerpt == null)) {
	    return file;
	  }

	  const delimiter = typeof opts.excerpt === 'string'
	    ? opts.excerpt
	    : (sep || opts.delimiters[0]);

	  // if enabled, get the excerpt defined after front-matter
	  const idx = file.content.indexOf(delimiter);
	  if (idx !== -1) {
	    file.excerpt = file.content.slice(0, idx);
	  }

	  return file;
	};
	return excerpt;
}

var toFile;
var hasRequiredToFile;

function requireToFile () {
	if (hasRequiredToFile) return toFile;
	hasRequiredToFile = 1;

	const typeOf = requireKindOf();
	const stringify = requireStringify();
	const utils = requireUtils();

	/**
	 * Normalize the given value to ensure an object is returned
	 * with the expected properties.
	 */

	toFile = function(file) {
	  if (typeOf(file) !== 'object') {
	    file = { content: file };
	  }

	  if (typeOf(file.data) !== 'object') {
	    file.data = {};
	  }

	  // if file was passed as an object, ensure that
	  // "file.content" is set
	  if (file.contents && file.content == null) {
	    file.content = file.contents;
	  }

	  // set non-enumerable properties on the file object
	  utils.define(file, 'orig', utils.toBuffer(file.content));
	  utils.define(file, 'language', file.language || '');
	  utils.define(file, 'matter', file.matter || '');
	  utils.define(file, 'stringify', function(data, options) {
	    if (options && options.language) {
	      file.language = options.language;
	    }
	    return stringify(file, data, options);
	  });

	  // strip BOM and ensure that "file.content" is a string
	  file.content = utils.toString(file.content);
	  file.isEmpty = false;
	  file.excerpt = '';
	  return file;
	};
	return toFile;
}

var parse$7;
var hasRequiredParse;

function requireParse () {
	if (hasRequiredParse) return parse$7;
	hasRequiredParse = 1;

	const getEngine = requireEngine();
	const defaults = requireDefaults();

	parse$7 = function(language, str, options) {
	  const opts = defaults(options);
	  const engine = getEngine(language, opts);
	  if (typeof engine.parse !== 'function') {
	    throw new TypeError('expected "' + language + '.parse" to be a function');
	  }
	  return engine.parse(str, opts);
	};
	return parse$7;
}

var grayMatter;
var hasRequiredGrayMatter;

function requireGrayMatter () {
	if (hasRequiredGrayMatter) return grayMatter;
	hasRequiredGrayMatter = 1;

	const fs$1 = fs;
	const sections = requireSectionMatter();
	const defaults = requireDefaults();
	const stringify = requireStringify();
	const excerpt = requireExcerpt();
	const engines = requireEngines();
	const toFile = requireToFile();
	const parse = requireParse();
	const utils = requireUtils();

	/**
	 * Takes a string or object with `content` property, extracts
	 * and parses front-matter from the string, then returns an object
	 * with `data`, `content` and other [useful properties](#returned-object).
	 *
	 * ```js
	 * const matter = require('gray-matter');
	 * console.log(matter('---\ntitle: Home\n---\nOther stuff'));
	 * //=> { data: { title: 'Home'}, content: 'Other stuff' }
	 * ```
	 * @param {Object|String} `input` String, or object with `content` string
	 * @param {Object} `options`
	 * @return {Object}
	 * @api public
	 */

	function matter(input, options) {
	  if (input === '') {
	    return { data: {}, content: input, excerpt: '', orig: input };
	  }

	  let file = toFile(input);
	  const cached = matter.cache[file.content];

	  if (!options) {
	    if (cached) {
	      file = Object.assign({}, cached);
	      file.orig = cached.orig;
	      return file;
	    }

	    // only cache if there are no options passed. if we cache when options
	    // are passed, we would need to also cache options values, which would
	    // negate any performance benefits of caching
	    matter.cache[file.content] = file;
	  }

	  return parseMatter(file, options);
	}

	/**
	 * Parse front matter
	 */

	function parseMatter(file, options) {
	  const opts = defaults(options);
	  const open = opts.delimiters[0];
	  const close = '\n' + opts.delimiters[1];
	  let str = file.content;

	  if (opts.language) {
	    file.language = opts.language;
	  }

	  // get the length of the opening delimiter
	  const openLen = open.length;
	  if (!utils.startsWith(str, open, openLen)) {
	    excerpt(file, opts);
	    return file;
	  }

	  // if the next character after the opening delimiter is
	  // a character from the delimiter, then it's not a front-
	  // matter delimiter
	  if (str.charAt(openLen) === open.slice(-1)) {
	    return file;
	  }

	  // strip the opening delimiter
	  str = str.slice(openLen);
	  const len = str.length;

	  // use the language defined after first delimiter, if it exists
	  const language = matter.language(str, opts);
	  if (language.name) {
	    file.language = language.name;
	    str = str.slice(language.raw.length);
	  }

	  // get the index of the closing delimiter
	  let closeIndex = str.indexOf(close);
	  if (closeIndex === -1) {
	    closeIndex = len;
	  }

	  // get the raw front-matter block
	  file.matter = str.slice(0, closeIndex);

	  const block = file.matter.replace(/^\s*#[^\n]+/gm, '').trim();
	  if (block === '') {
	    file.isEmpty = true;
	    file.empty = file.content;
	    file.data = {};
	  } else {

	    // create file.data by parsing the raw file.matter block
	    file.data = parse(file.language, file.matter, opts);
	  }

	  // update file.content
	  if (closeIndex === len) {
	    file.content = '';
	  } else {
	    file.content = str.slice(closeIndex + close.length);
	    if (file.content[0] === '\r') {
	      file.content = file.content.slice(1);
	    }
	    if (file.content[0] === '\n') {
	      file.content = file.content.slice(1);
	    }
	  }

	  excerpt(file, opts);

	  if (opts.sections === true || typeof opts.section === 'function') {
	    sections(file, opts.section);
	  }
	  return file;
	}

	/**
	 * Expose engines
	 */

	matter.engines = engines;

	/**
	 * Stringify an object to YAML or the specified language, and
	 * append it to the given string. By default, only YAML and JSON
	 * can be stringified. See the [engines](#engines) section to learn
	 * how to stringify other languages.
	 *
	 * ```js
	 * console.log(matter.stringify('foo bar baz', {title: 'Home'}));
	 * // results in:
	 * // ---
	 * // title: Home
	 * // ---
	 * // foo bar baz
	 * ```
	 * @param {String|Object} `file` The content string to append to stringified front-matter, or a file object with `file.content` string.
	 * @param {Object} `data` Front matter to stringify.
	 * @param {Object} `options` [Options](#options) to pass to gray-matter and [js-yaml].
	 * @return {String} Returns a string created by wrapping stringified yaml with delimiters, and appending that to the given string.
	 * @api public
	 */

	matter.stringify = function(file, data, options) {
	  if (typeof file === 'string') file = matter(file, options);
	  return stringify(file, data, options);
	};

	/**
	 * Synchronously read a file from the file system and parse
	 * front matter. Returns the same object as the [main function](#matter).
	 *
	 * ```js
	 * const file = matter.read('./content/blog-post.md');
	 * ```
	 * @param {String} `filepath` file path of the file to read.
	 * @param {Object} `options` [Options](#options) to pass to gray-matter.
	 * @return {Object} Returns [an object](#returned-object) with `data` and `content`
	 * @api public
	 */

	matter.read = function(filepath, options) {
	  const str = fs$1.readFileSync(filepath, 'utf8');
	  const file = matter(str, options);
	  file.path = filepath;
	  return file;
	};

	/**
	 * Returns true if the given `string` has front matter.
	 * @param  {String} `string`
	 * @param  {Object} `options`
	 * @return {Boolean} True if front matter exists.
	 * @api public
	 */

	matter.test = function(str, options) {
	  return utils.startsWith(str, defaults(options).delimiters[0]);
	};

	/**
	 * Detect the language to use, if one is defined after the
	 * first front-matter delimiter.
	 * @param  {String} `string`
	 * @param  {Object} `options`
	 * @return {Object} Object with `raw` (actual language string), and `name`, the language with whitespace trimmed
	 */

	matter.language = function(str, options) {
	  const opts = defaults(options);
	  const open = opts.delimiters[0];

	  if (matter.test(str)) {
	    str = str.slice(open.length);
	  }

	  const language = str.slice(0, str.search(/\r?\n/));
	  return {
	    raw: language,
	    name: language ? language.trim() : ''
	  };
	};

	/**
	 * Expose `matter`
	 */

	matter.cache = {};
	matter.clearCache = function() {
	  matter.cache = {};
	};
	grayMatter = matter;
	return grayMatter;
}

var grayMatterExports = requireGrayMatter();
var matter = /*@__PURE__*/getDefaultExportFromCjs(grayMatterExports);

class MarkdownMessage {
    constructor(heading, message) {
        this.message = message;
        this.heading = heading;
    }
    toMarkdown() {
        return `\n\n## ${this.heading}\n\n\`\`\`txt\n${this.message}\n\`\`\``;
    }
}

const flattenObject = (obj, prefix = "") => {
    const flattened = {};
    for (const key in obj) {
        if (Object.prototype.hasOwnProperty.call(obj, key)) {
            const newKey = prefix ? `${prefix}.${key}` : key;
            const propertyValue = obj[key];
            if (Array.isArray(propertyValue)) {
                // Handle arrays by creating indexed keys
                propertyValue.forEach((item, index) => {
                    flattened[`${newKey}.${index}`] = String(item);
                });
            }
            else if (propertyValue !== null && typeof propertyValue === "object") {
                // Recursively flatten nested objects
                Object.assign(flattened, flattenObject(propertyValue, newKey));
            }
            else {
                // Convert to string for storage
                flattened[newKey] = String(propertyValue);
            }
        }
    }
    return flattened;
};
const safeMatter = (content) => {
    try {
        // Note that the gray matter API caches the results if there are no options.
        // In this system, caching is undesirable since it masks potential errors
        // and complicates reloading. Explicitly setting the language for the
        // frontmatter, other than setting our desired frontmatter also has the
        // desired side effect that caching is disabled.
        return matter(content, { language: "yaml" });
    }
    catch (error) {
        const message = error instanceof Error ? error.message : JSON.stringify(error);
        return {
            data: {},
            content: content +
                new MarkdownMessage("Frontmatter error", message).toMarkdown(),
        };
    }
};
class BaseItem {
    constructor(itemReference, filename, content) {
        this.frontmatter = {};
        this.filename = filename;
        this.id = itemReference.id;
        this.hash = itemReference.hash;
        const parsedFrontmatter = safeMatter(content);
        // Flatten the frontmatter data and store it in meta
        this.frontmatter = flattenObject(parsedFrontmatter.data);
        this.content = parsedFrontmatter.content;
    }
}

// Hash function constants
const EMPTY_STRING_HASH = "0";
const INITIAL_HASH_VALUE = 0;
const HASH_SHIFT_BITS = 5;
const HASH_RADIX = 36;
const HASH_MASK_32BIT = 0;
/**
 * Generate a cheap checksum from a string. This is used to append to duplicate
 * named things in the garden to allow de-duplication.
 *
 * @param source - string to generate a hash from
 * @returns checksum for the string
 */
const hash = (source) => {
    if (source.length === 0) {
        return EMPTY_STRING_HASH;
    }
    let hashValue = INITIAL_HASH_VALUE;
    // classic checksum
    for (let i = 0; i < source.length; i++) {
        // shift (1->32), minus current and add new character
        hashValue =
            (hashValue << HASH_SHIFT_BITS) - hashValue + source.charCodeAt(i);
        // bitwise to 32 bit integer
        hashValue |= HASH_MASK_32BIT;
    }
    // redix with radix 36, i.e. use characters in the range 0-9 or a-z
    return Math.abs(hashValue).toString(HASH_RADIX);
};

class FileDocumentReference {
    constructor(id, filename, hash) {
        this.id = id;
        this.filename = filename;
        this.hash = hash;
    }
}
/**
 * File system based repository for accessing markdown documents
 *
 * Scans a directory recursively for markdown files and provides access
 * to their content. Supports filtering options to exclude certain directories
 * and control hidden file inclusion.
 *
 * @example
 * ```typescript
 * const repository = new FileRepository('./docs', {
 *   excludes: ['node_modules', 'dist'],
 *   includeHidden: false
 * });
 *
 * for await (const ref of repository.findAll()) {
 *   const document = await repository.loadDocument(ref);
 *   console.log(document.content);
 * }
 * ```
 */
class FileRepository {
    constructor(directory, options = {}) {
        this.directory = directory;
        this.options = {
            excludes: ["node_modules", "dist"],
            includeHidden: false,
            ...Object.fromEntries(Object.entries(options).filter(([, value]) => value != undefined)),
        };
    }
    async validateDirectory() {
        try {
            await fs.promises.access(this.directory);
        }
        catch (e) {
            throw new DirectoryNotFoundError(this.directory, e);
        }
    }
    toDocumentReference(filename) {
        const normalizedDocumentId = this.normalizeFilename(filename);
        return new FileDocumentReference(normalizedDocumentId, filename, hash(filename));
    }
    normalizeFilename(filename) {
        // Use just then basename, remove .md extension and normalize path separators and lowercase
        return sysPath__default.basename(filename).replace(/\.md$/, "").toLowerCase();
    }
    async loadDocument(reference) {
        if (!(reference instanceof FileDocumentReference)) {
            throw new Error("Invalid reference type for FileRepository");
        }
        const filepath = sysPath__default.join(this.directory, reference.filename);
        try {
            const content = await fs.promises.readFile(filepath, "utf8");
            return new BaseItem(reference, reference.filename, content);
        }
        catch (error) {
            if (error &&
                typeof error === "object" &&
                "code" in error &&
                error.code === "ENOENT") {
                throw new FileNotFoundError(filepath);
            }
            throw new MarkdownParsingError(reference.filename, error);
        }
    }
    async findInDirectory(relativeDirectory, relativeFilename) {
        const absoluteDirectory = resolve$1(this.directory, relativeDirectory);
        const directories = await fs.promises.readdir(absoluteDirectory, {
            withFileTypes: true,
        });
        // Files first
        for (const child of directories) {
            if (!child.isDirectory() &&
                child.name.toLowerCase() === relativeFilename) {
                return join$2(relativeDirectory, child.name);
            }
        }
        // ... then directories
        for (const child of directories) {
            if (child.isDirectory() && this.shouldScanDirectory(child.name)) {
                const resolved = join$2(relativeDirectory, child.name);
                const candidate = await this.findInDirectory(resolved, relativeFilename);
                if (candidate) {
                    return candidate;
                }
            }
        }
        return false;
    }
    async find(id) {
        const filename = await this.findInDirectory("", `${id}.md`);
        if (!filename) {
            throw new FileNotFoundError(id);
        }
        const reference = this.toDocumentReference(filename);
        return this.loadDocument(reference);
    }
    async *findAll() {
        await this.validateDirectory(); // Lazy validation
        yield* this.findMarkdownFilesRecursively(this.directory);
    }
    shouldScanDirectory(directoryName) {
        return (!this.options.excludes.includes(directoryName) &&
            (this.options.includeHidden || !directoryName.startsWith(".")));
    }
    async *findMarkdownFilesRecursively(dir) {
        try {
            const directoryEntries = await fs.promises.readdir(dir, {
                withFileTypes: true,
            });
            for (const directoryEntry of directoryEntries) {
                const fullPath = sysPath__default.join(dir, directoryEntry.name);
                if (directoryEntry.isDirectory()) {
                    if (this.shouldScanDirectory(directoryEntry.name)) {
                        yield* this.findMarkdownFilesRecursively(fullPath);
                    }
                }
                else if (directoryEntry.isFile() &&
                    directoryEntry.name.endsWith(".md")) {
                    const relativePath = sysPath__default.relative(this.directory, fullPath);
                    yield this.toDocumentReference(relativePath);
                }
            }
        }
        catch (error) {
            // Log error but continue processing other directories
            // eslint-disable-next-line no-console
            console.warn(`Warning: Could not read directory ${dir}:`, error);
        }
    }
}

function isLength(value) {
    return Number.isSafeInteger(value) && value >= 0;
}

function isArrayLike(value) {
    return value != null && typeof value !== 'function' && isLength(value.length);
}

function getTag(value) {
    if (value == null) {
        return value === undefined ? '[object Undefined]' : '[object Null]';
    }
    return Object.prototype.toString.call(value);
}

function isTypedArray$1(x) {
    return ArrayBuffer.isView(x) && !(x instanceof DataView);
}

function isArguments(value) {
    return value !== null && typeof value === 'object' && getTag(value) === '[object Arguments]';
}

function isPrototype(value) {
    const constructor = value?.constructor;
    const prototype = typeof constructor === 'function' ? constructor.prototype : Object.prototype;
    return value === prototype;
}

function isTypedArray(x) {
    return isTypedArray$1(x);
}

function isEmpty(value) {
    if (value == null) {
        return true;
    }
    if (isArrayLike(value)) {
        if (typeof value.splice !== 'function' &&
            typeof value !== 'string' &&
            (typeof Buffer === 'undefined' || !Buffer.isBuffer(value)) &&
            !isTypedArray(value) &&
            !isArguments(value)) {
            return false;
        }
        return value.length === 0;
    }
    if (typeof value === 'object') {
        if (value instanceof Map || value instanceof Set) {
            return value.size === 0;
        }
        const keys = Object.keys(value);
        if (isPrototype(value)) {
            return keys.filter(x => x !== 'constructor').length === 0;
        }
        return keys.length === 0;
    }
    return true;
}

// Cache for link resolution to avoid repeated string operations
const linkCache = new Map();
/**
 * Generate the link name given for the text. This is a common normalisation for
 * any text so that it can be referenced in a URL.
 *
 * Uses caching to improve performance for repeated calls.
 *
 * @param name - text to normalise to a link name
 * @returns normalised link name
 */
const linkResolver = (name) => {
    const cached = linkCache.get(name);
    if (cached !== undefined)
        return cached;
    const result = name
        .replace(/[ /\\.]/g, "-")
        .toLowerCase()
        // normalize according to NFD - canonical decompisition - https://unicode.org/reports/tr15/
        // NFD effectively removes accents and reduces variations on to single form
        // more suitable for URLs
        .normalize("NFD")
        .replace(/[^a-z0-9-]/g, "");
    linkCache.set(name, result);
    return result;
};

// Constants for graph building
const ROOT_SECTION_DEPTH$1 = 1;
/**
 * Create a unique node ID for a section within a document
 */
function createNodeId(document, section) {
    if (section.depth === ROOT_SECTION_DEPTH$1) {
        // Top-level sections use the document ID
        return document.id;
    }
    // Subsections include the section title as a fragment
    return `${document.id}#${linkResolver(section.title)}`;
}
/**
 * Create metadata object for a node from document frontmatter
 */
function createNodeMeta(document) {
    if (isEmpty(document.frontmatter)) {
        return undefined;
    }
    // Cast to expected type for graph schema compatibility
    return document.frontmatter;
}
/**
 * Create a node object from a document and section
 */
function createNode(document, section) {
    const nodeId = createNodeId(document, section);
    return {
        id: nodeId,
        node: {
            label: section.title,
            meta: createNodeMeta(document),
        },
    };
}
/**
 * Create explicit links from a section
 */
function createExplicitLinks(document, section) {
    const sourceNodeId = createNodeId(document, section);
    return section.links.map((target) => ({
        source: sourceNodeId,
        target: target,
    }));
}
/**
 * Create parent-child link if section is a subsection
 */
function createParentLink(document, section) {
    if (section.depth === ROOT_SECTION_DEPTH$1) {
        // Root sections have no parent
        return null;
    }
    const childNodeId = createNodeId(document, section);
    const parentNodeId = document.id; // Parent is always the document root
    return {
        source: childNodeId,
        target: parentNodeId,
    };
}
/**
 * Get statistics about a graph
 */
function getGraphStats(graph) {
    return {
        nodeCount: Object.keys(graph.nodes).length,
        linkCount: graph.links.length,
    };
}

let methods$o = {
  one: {},
  two: {},
  three: {},
  four: {},
};

let model$6 = {
  one: {},
  two: {},
  three: {},
};
let compute$b = {};
let hooks = [];

var tmpWrld = { methods: methods$o, model: model$6, compute: compute$b, hooks };

const isArray$a = input => Object.prototype.toString.call(input) === '[object Array]';

const fns$5 = {
  /** add metadata to term objects */
  compute: function (input) {
    const { world } = this;
    const compute = world.compute;
    // do one method
    if (typeof input === 'string' && compute.hasOwnProperty(input)) {
      compute[input](this);
    }
    // allow a list of methods
    else if (isArray$a(input)) {
      input.forEach(name => {
        if (world.compute.hasOwnProperty(name)) {
          compute[name](this);
        } else {
          console.warn('no compute:', input); // eslint-disable-line
        }
      });
    }
    // allow a custom compute function
    else if (typeof input === 'function') {
      input(this);
    } else {
      console.warn('no compute:', input); // eslint-disable-line
    }
    return this
  },
};

// wrappers for loops in javascript arrays

const forEach = function (cb) {
  let ptrs = this.fullPointer;
  ptrs.forEach((ptr, i) => {
    let view = this.update([ptr]);
    cb(view, i);
  });
  return this
};

const map = function (cb, empty) {
  let ptrs = this.fullPointer;
  let res = ptrs.map((ptr, i) => {
    let view = this.update([ptr]);
    let out = cb(view, i);
    // if we returned nothing, return a view
    if (out === undefined) {
      return this.none()
    }
    return out
  });
  if (res.length === 0) {
    return empty || this.update([])
  }
  // return an array of values, or View objects?
  // user can return either from their callback
  if (res[0] !== undefined) {
    // array of strings
    if (typeof res[0] === 'string') {
      return res
    }
    // array of objects
    if (typeof res[0] === 'object' && (res[0] === null || !res[0].isView)) {
      return res
    }
  }
  // return a View object
  let all = [];
  res.forEach(ptr => {
    all = all.concat(ptr.fullPointer);
  });
  return this.toView(all)
};

const filter = function (cb) {
  let ptrs = this.fullPointer;
  ptrs = ptrs.filter((ptr, i) => {
    let view = this.update([ptr]);
    return cb(view, i)
  });
  let res = this.update(ptrs);
  return res
};

const find$6 = function (cb) {
  let ptrs = this.fullPointer;
  let found = ptrs.find((ptr, i) => {
    let view = this.update([ptr]);
    return cb(view, i)
  });
  return this.update([found])
};

const some = function (cb) {
  let ptrs = this.fullPointer;
  return ptrs.some((ptr, i) => {
    let view = this.update([ptr]);
    return cb(view, i)
  })
};

const random = function (n = 1) {
  let ptrs = this.fullPointer;
  let r = Math.floor(Math.random() * ptrs.length);
  //prevent it from going over the end
  if (r + n > this.length) {
    r = this.length - n;
    r = r < 0 ? 0 : r;
  }
  ptrs = ptrs.slice(r, r + n);
  return this.update(ptrs)
};
var loops = { forEach, map, filter, find: find$6, some, random };

const utils = {
  /** */
  termList: function () {
    return this.methods.one.termList(this.docs)
  },
  /** return individual terms*/
  terms: function (n) {
    let m = this.match('.');
    // this is a bit faster than .match('.') 
    // let ptrs = []
    // this.docs.forEach((terms) => {
    //   terms.forEach((term) => {
    //     let [y, x] = term.index || []
    //     ptrs.push([y, x, x + 1])
    //   })
    // })
    // let m = this.update(ptrs)
    return typeof n === 'number' ? m.eq(n) : m
  },

  /** */
  groups: function (group) {
    if (group || group === 0) {
      return this.update(this._groups[group] || [])
    }
    // return an object of Views
    let res = {};
    Object.keys(this._groups).forEach(k => {
      res[k] = this.update(this._groups[k]);
    });
    // this._groups = null
    return res
  },
  /** */
  eq: function (n) {
    let ptr = this.pointer;
    if (!ptr) {
      ptr = this.docs.map((_doc, i) => [i]);
    }
    if (ptr[n]) {
      return this.update([ptr[n]])
    }
    return this.none()
  },
  /** */
  first: function () {
    return this.eq(0)
  },
  /** */
  last: function () {
    let n = this.fullPointer.length - 1;
    return this.eq(n)
  },

  /** grab term[0] for every match */
  firstTerms: function () {
    return this.match('^.')
  },

  /** grab the last term for every match  */
  lastTerms: function () {
    return this.match('.$')
  },

  /** */
  slice: function (min, max) {
    let pntrs = this.pointer || this.docs.map((_o, n) => [n]);
    pntrs = pntrs.slice(min, max);
    return this.update(pntrs)
  },

  /** return a view of the entire document */
  all: function () {
    return this.update().toView()
  },
  /**  */
  fullSentences: function () {
    let ptrs = this.fullPointer.map(a => [a[0]]); //lazy!
    return this.update(ptrs).toView()
  },
  /** return a view of no parts of the document */
  none: function () {
    return this.update([])
  },

  /** are these two views looking at the same words? */
  isDoc: function (b) {
    if (!b || !b.isView) {
      return false
    }
    let aPtr = this.fullPointer;
    let bPtr = b.fullPointer;
    if (!aPtr.length === bPtr.length) {
      return false
    }
    // ensure pointers are the same
    return aPtr.every((ptr, i) => {
      if (!bPtr[i]) {
        return false
      }
      // ensure [n, start, end] are all the same
      return ptr[0] === bPtr[i][0] && ptr[1] === bPtr[i][1] && ptr[2] === bPtr[i][2]
    })
  },

  /** how many seperate terms does the document have? */
  wordCount: function () {
    return this.docs.reduce((count, terms) => {
      count += terms.filter(t => t.text !== '').length;
      return count
    }, 0)
  },

  // is the pointer the full sentence?
  isFull: function () {
    let ptrs = this.pointer;
    if (!ptrs) {
      return true
    }
    // must start at beginning
    if (ptrs.length === 0 || ptrs[0][0] !== 0) {
      return false
    }
    let wantTerms = 0;
    let haveTerms = 0;
    this.document.forEach(terms => wantTerms += terms.length);
    this.docs.forEach(terms => haveTerms += terms.length);
    return wantTerms === haveTerms
    // for (let i = 0; i < ptrs.length; i += 1) {
    //   let [n, start, end] = ptrs[i]
    //   // it's not the start
    //   if (n !== i || start !== 0) {
    //     return false
    //   }
    //   // it's too short
    //   if (document[n].length > end) {
    //     return false
    //   }
    // }
    // return true
  },

  // return the nth elem of a doc
  getNth: function (n) {
    if (typeof n === 'number') {
      return this.eq(n)
    } else if (typeof n === 'string') {
      return this.if(n)
    }
    return this
  }

};
utils.group = utils.groups;
utils.fullSentence = utils.fullSentences;
utils.sentence = utils.fullSentences;
utils.lastTerm = utils.lastTerms;
utils.firstTerm = utils.firstTerms;

const methods$n = Object.assign({}, utils, fns$5, loops);

// aliases
methods$n.get = methods$n.eq;

class View {
  constructor(document, pointer, groups = {}) {
    // invisible props
    let props = [
      ['document', document],
      ['world', tmpWrld],
      ['_groups', groups],
      ['_cache', null],
      ['viewType', 'View'],
    ];
    props.forEach(a => {
      Object.defineProperty(this, a[0], {
        value: a[1],
        writable: true,
      });
    });
    this.ptrs = pointer;
  }
  /* getters:  */
  get docs() {
    let docs = this.document;
    if (this.ptrs) {
      docs = tmpWrld.methods.one.getDoc(this.ptrs, this.document);
    }
    return docs
  }
  get pointer() {
    return this.ptrs
  }
  get methods() {
    return this.world.methods
  }
  get model() {
    return this.world.model
  }
  get hooks() {
    return this.world.hooks
  }
  get isView() {
    return true //this comes in handy sometimes
  }
  // is the view not-empty?
  get found() {
    return this.docs.length > 0
  }
  // how many matches we have
  get length() {
    return this.docs.length
  }
  // return a more-hackable pointer
  get fullPointer() {
    let { docs, ptrs, document } = this;
    // compute a proper pointer, from docs
    let pointers = ptrs || docs.map((_d, n) => [n]);
    // do we need to repair it, first?
    return pointers.map(a => {
      let [n, start, end, id, endId] = a;
      start = start || 0;
      end = end || (document[n] || []).length;
      //add frozen id, for good-measure
      if (document[n] && document[n][start]) {
        id = id || document[n][start].id;
        if (document[n][end - 1]) {
          endId = endId || document[n][end - 1].id;
        }
      }
      return [n, start, end, id, endId]
    })
  }
  // create a new View, from this one
  update(pointer) {
    let m = new View(this.document, pointer);
    // send the cache down, too?
    if (this._cache && pointer && pointer.length > 0) {
      // only keep cache if it's a full-sentence
      let cache = [];
      pointer.forEach((ptr, i) => {
        let [n, start, end] = ptr;
        if (ptr.length === 1) {
          cache[i] = this._cache[n];
        } else if (start === 0 && this.document[n].length === end) {
          cache[i] = this._cache[n];
        }
      });
      if (cache.length > 0) {
        m._cache = cache;
      }
    }
    m.world = this.world;
    return m
  }
  // create a new View, from this one
  toView(pointer) {
    return new View(this.document, pointer || this.pointer)
  }
  fromText(input) {
    const { methods } = this;
    //assume ./01-tokenize is installed
    let document = methods.one.tokenize.fromString(input, this.world);
    let doc = new View(document);
    doc.world = this.world;
    doc.compute(['normal', 'freeze', 'lexicon']);
    if (this.world.compute.preTagger) {
      doc.compute('preTagger');
    }
    doc.compute('unfreeze');
    return doc
  }
  clone() {
    // clone the whole document
    let document = this.document.slice(0); //node 17: structuredClone(document);
    document = document.map(terms => {
      return terms.map(term => {
        term = Object.assign({}, term);
        term.tags = new Set(term.tags);
        return term
      })
    });
    // clone only sub-document ?
    let m = this.update(this.pointer);
    m.document = document;
    m._cache = this._cache; //clone this too?
    return m
  }
}
Object.assign(View.prototype, methods$n);

var version = '14.14.4';

const isObject$6 = function (item) {
  return item && typeof item === 'object' && !Array.isArray(item)
};

// recursive merge of objects
function mergeDeep(model, plugin) {
  if (isObject$6(plugin)) {
    for (const key in plugin) {
      if (isObject$6(plugin[key])) {
        if (!model[key]) Object.assign(model, { [key]: {} });
        mergeDeep(model[key], plugin[key]); //recursion
      } else {
        Object.assign(model, { [key]: plugin[key] });
      }
    }
  }
  return model
}
// const merged = mergeDeep({ a: 1 }, { b: { c: { d: { e: 12345 } } } })
// console.dir(merged, { depth: 5 })

// vroom
function mergeQuick(model, plugin) {
  for (const key in plugin) {
    model[key] = model[key] || {};
    Object.assign(model[key], plugin[key]);
  }
  return model
}

const addIrregulars = function (model, conj) {
  let m = model.two.models || {};
  Object.keys(conj).forEach(k => {
    // verb forms
    if (conj[k].pastTense) {
      if (m.toPast) {
        m.toPast.ex[k] = conj[k].pastTense;
      }
      if (m.fromPast) {
        m.fromPast.ex[conj[k].pastTense] = k;
      }
    }
    if (conj[k].presentTense) {
      if (m.toPresent) {
        m.toPresent.ex[k] = conj[k].presentTense;
      }
      if (m.fromPresent) {
        m.fromPresent.ex[conj[k].presentTense] = k;
      }
    }
    if (conj[k].gerund) {
      if (m.toGerund) {
        m.toGerund.ex[k] = conj[k].gerund;
      }
      if (m.fromGerund) {
        m.fromGerund.ex[conj[k].gerund] = k;
      }
    }
    // adjective forms
    if (conj[k].comparative) {
      if (m.toComparative) {
        m.toComparative.ex[k] = conj[k].comparative;
      }
      if (m.fromComparative) {
        m.fromComparative.ex[conj[k].comparative] = k;
      }
    }
    if (conj[k].superlative) {
      if (m.toSuperlative) {
        m.toSuperlative.ex[k] = conj[k].superlative;
      }
      if (m.fromSuperlative) {
        m.fromSuperlative.ex[conj[k].superlative] = k;
      }
    }
  });
};

const extend$2 = function (plugin, world, View, nlp) {
  const { methods, model, compute, hooks } = world;
  if (plugin.methods) {
    mergeQuick(methods, plugin.methods);
  }
  if (plugin.model) {
    mergeDeep(model, plugin.model);
  }
  if (plugin.irregulars) {
    addIrregulars(model, plugin.irregulars);
  }
  // shallow-merge compute
  if (plugin.compute) {
    Object.assign(compute, plugin.compute);
  }
  // append new hooks
  if (hooks) {
    world.hooks = hooks.concat(plugin.hooks || []);
  }
  // assign new class methods
  if (plugin.api) {
    plugin.api(View);
  }
  if (plugin.lib) {
    Object.keys(plugin.lib).forEach(k => (nlp[k] = plugin.lib[k]));
  }
  if (plugin.tags) {
    nlp.addTags(plugin.tags);
  }
  if (plugin.words) {
    nlp.addWords(plugin.words);
  }
  if (plugin.frozen) {
    nlp.addWords(plugin.frozen, true);
  }
  if (plugin.mutate) {
    plugin.mutate(world, nlp);
  }
};

/** log the decision-making to console */
const verbose = function (set) {
  const env = typeof process === 'undefined' || !process.env ? self.env || {} : process.env; //use window, in browser
  env.DEBUG_TAGS = set === 'tagger' || set === true ? true : '';
  env.DEBUG_MATCH = set === 'match' || set === true ? true : '';
  env.DEBUG_CHUNKS = set === 'chunker' || set === true ? true : '';
  return this
};

const isObject$5 = val => {
  return Object.prototype.toString.call(val) === '[object Object]'
};

const isArray$9 = function (arr) {
  return Object.prototype.toString.call(arr) === '[object Array]'
};

// internal Term objects are slightly different
const fromJson = function (json) {
  return json.map(o => {
    return o.terms.map(term => {
      if (isArray$9(term.tags)) {
        term.tags = new Set(term.tags);
      }
      return term
    })
  })
};

// interpret an array-of-arrays
const preTokenized = function (arr) {
  return arr.map((a) => {
    return a.map(str => {
      return {
        text: str,
        normal: str,//cleanup
        pre: '',
        post: ' ',
        tags: new Set()
      }
    })
  })
};

const inputs = function (input, View, world) {
  const { methods } = world;
  let doc = new View([]);
  doc.world = world;
  // support a number
  if (typeof input === 'number') {
    input = String(input);
  }
  // return empty doc
  if (!input) {
    return doc
  }
  // parse a string
  if (typeof input === 'string') {
    let document = methods.one.tokenize.fromString(input, world);
    return new View(document)
  }
  // handle compromise View
  if (isObject$5(input) && input.isView) {
    return new View(input.document, input.ptrs)
  }
  // handle json input
  if (isArray$9(input)) {
    // pre-tokenized array-of-arrays 
    if (isArray$9(input[0])) {
      let document = preTokenized(input);
      return new View(document)
    }
    // handle json output
    let document = fromJson(input);
    return new View(document)
  }
  return doc
};

let world = Object.assign({}, tmpWrld);

const nlp = function (input, lex) {
  if (lex) {
    nlp.addWords(lex);
  }
  let doc = inputs(input, View, world);
  if (input) {
    doc.compute(world.hooks);
  }
  return doc
};
Object.defineProperty(nlp, '_world', {
  value: world,
  writable: true,
});

/** don't run the POS-tagger */
nlp.tokenize = function (input, lex) {
  const { compute } = this._world;
  // add user-given words to lexicon
  if (lex) {
    nlp.addWords(lex);
  }
  // run the tokenizer
  let doc = inputs(input, View, world);
  // give contractions a shot, at least
  if (compute.contractions) {
    doc.compute(['alias', 'normal', 'machine', 'contractions']); //run it if we've got it
  }
  return doc
};

/** extend compromise functionality */
nlp.plugin = function (plugin) {
  extend$2(plugin, this._world, View, this);
  return this
};
nlp.extend = nlp.plugin;


/** reach-into compromise internals */
nlp.world = function () {
  return this._world
};
nlp.model = function () {
  return this._world.model
};
nlp.methods = function () {
  return this._world.methods
};
nlp.hooks = function () {
  return this._world.hooks
};

/** log the decision-making to console */
nlp.verbose = verbose;
/** current library release version */
nlp.version = version;

const createCache = function (document) {
  let cache = document.map(terms => {
    let items = new Set();
    terms.forEach(term => {
      // add words
      if (term.normal !== '') {
        items.add(term.normal);
      }
      // cache switch-status - '%Noun|Verb%'
      if (term.switch) {
        items.add(`%${term.switch}%`);
      }
      // cache implicit words, too
      if (term.implicit) {
        items.add(term.implicit);
      }
      if (term.machine) {
        items.add(term.machine);
      }
      if (term.root) {
        items.add(term.root);
      }
      // cache slashes words, etc
      if (term.alias) {
        term.alias.forEach(str => items.add(str));
      }
      let tags = Array.from(term.tags);
      for (let t = 0; t < tags.length; t += 1) {
        items.add('#' + tags[t]);
      }
    });
    return items
  });
  return cache
};

var methods$m = {
  one: {
    cacheDoc: createCache,
  },
};

const methods$l = {
  /** */
  cache: function () {
    this._cache = this.methods.one.cacheDoc(this.document);
    return this
  },
  /** */
  uncache: function () {
    this._cache = null;
    return this
  },
};
const addAPI$3 = function (View) {
  Object.assign(View.prototype, methods$l);
};

var compute$a = {
  cache: function (view) {
    view._cache = view.methods.one.cacheDoc(view.document);
  }
};

var cache$1 = {
  api: addAPI$3,
  compute: compute$a,
  methods: methods$m,
};

var caseFns = {
  /** */
  toLowerCase: function () {
    this.termList().forEach(t => {
      t.text = t.text.toLowerCase();
    });
    return this
  },
  /** */
  toUpperCase: function () {
    this.termList().forEach(t => {
      t.text = t.text.toUpperCase();
    });
    return this
  },
  /** */
  toTitleCase: function () {
    this.termList().forEach(t => {
      t.text = t.text.replace(/^ *[a-z\u00C0-\u00FF]/, x => x.toUpperCase()); //support unicode?
    });
    return this
  },
  /** */
  toCamelCase: function () {
    this.docs.forEach(terms => {
      terms.forEach((t, i) => {
        if (i !== 0) {
          t.text = t.text.replace(/^ *[a-z\u00C0-\u00FF]/, x => x.toUpperCase()); //support unicode?
        }
        if (i !== terms.length - 1) {
          t.post = '';
        }
      });
    });
    return this
  },
};

// case logic
const isTitleCase$4 = (str) => /^\p{Lu}[\p{Ll}'â€™]/u.test(str) || /^\p{Lu}$/u.test(str);
const toTitleCase$2 = (str) => str.replace(/^\p{Ll}/u, x => x.toUpperCase());
const toLowerCase$1 = (str) => str.replace(/^\p{Lu}/u, x => x.toLowerCase());

// splice an array into an array
const spliceArr = (parent, index, child) => {
  // tag them as dirty
  child.forEach(term => term.dirty = true);
  if (parent) {
    let args = [index, 0].concat(child);
    Array.prototype.splice.apply(parent, args);
  }
  return parent
};

// add a space at end, if required
const endSpace = function (terms) {
  const hasSpace = / $/;
  const hasDash = /[-â€“â€”]/;
  let lastTerm = terms[terms.length - 1];
  if (lastTerm && !hasSpace.test(lastTerm.post) && !hasDash.test(lastTerm.post)) {
    lastTerm.post += ' ';
  }
};

// sentence-ending punctuation should move in append
const movePunct = (source, end, needle) => {
  const juicy = /[-.?!,;:)â€“â€”'"]/g;
  let wasLast = source[end - 1];
  if (!wasLast) {
    return
  }
  let post = wasLast.post;
  if (juicy.test(post)) {
    let punct = post.match(juicy).join(''); //not perfect
    let last = needle[needle.length - 1];
    last.post = punct + last.post;
    // remove it, from source
    wasLast.post = wasLast.post.replace(juicy, '');
  }
};


const moveTitleCase = function (home, start, needle) {
  let from = home[start];
  // should we bother?
  if (start !== 0 || !isTitleCase$4(from.text)) {
    return
  }
  // titlecase new first term
  needle[0].text = toTitleCase$2(needle[0].text);
  // should we un-titlecase the old word?
  let old = home[start];
  if (old.tags.has('ProperNoun') || old.tags.has('Acronym')) {
    return
  }
  if (isTitleCase$4(old.text) && old.text.length > 1) {
    old.text = toLowerCase$1(old.text);
  }
};

// put these words before the others
const cleanPrepend = function (home, ptr, needle, document) {
  let [n, start, end] = ptr;
  // introduce spaces appropriately
  if (start === 0) {
    // at start - need space in insert
    endSpace(needle);
  } else if (end === document[n].length) {
    // at end - need space in home
    endSpace(needle);
  } else {
    // in middle - need space in home and insert
    endSpace(needle);
    endSpace([home[ptr[1]]]);
  }
  moveTitleCase(home, start, needle);
  // movePunct(home, end, needle)
  spliceArr(home, start, needle);
};

const cleanAppend = function (home, ptr, needle, document) {
  let [n, , end] = ptr;
  let total = (document[n] || []).length;
  if (end < total) {
    // are we in the middle?
    // add trailing space on self
    movePunct(home, end, needle);
    endSpace(needle);
  } else if (total === end) {
    // are we at the end?
    // add a space to predecessor
    endSpace(home);
    // very end, move period
    movePunct(home, end, needle);
    // is there another sentence after?
    if (document[n + 1]) {
      needle[needle.length - 1].post += ' ';
    }
  }
  spliceArr(home, ptr[2], needle);
  // set new endId
  ptr[4] = needle[needle.length - 1].id;
};

/*
unique & ordered term ids, based on time & term index

Base 36 (numbers+ascii)
  3 digit 4,600
  2 digit 1,200
  1 digit 36

  TTT|NNN|II|R

TTT -> 46 terms since load
NNN -> 46 thousand sentences (>1 inf-jest)
II  -> 1,200 words in a sentence (nuts)
R   -> 1-36 random number 

novels: 
  avg 80,000 words
    15 words per sentence
  5,000 sentences

Infinite Jest:
  36,247 sentences
  https://en.wikipedia.org/wiki/List_of_longest_novels

collisions are more-likely after
    46 seconds have passed,
  and 
    after 46-thousand sentences

*/
let index$2 = 0;

const pad3 = (str) => {
  str = str.length < 3 ? '0' + str : str;
  return str.length < 3 ? '0' + str : str
};

const toId = function (term) {
  let [n, i] = term.index || [0, 0];
  index$2 += 1;

  //don't overflow index
  index$2 = index$2 > 46655 ? 0 : index$2;
  //don't overflow sentences
  n = n > 46655 ? 0 : n;
  // //don't overflow terms
  i = i > 1294 ? 0 : i;

  // 3 digits for time
  let id = pad3(index$2.toString(36));
  // 3 digit  for sentence index (46k)
  id += pad3(n.toString(36));

  // 1 digit for term index (36)
  let tx = i.toString(36);
  tx = tx.length < 2 ? '0' + tx : tx; //pad2
  id += tx;

  // 1 digit random number
  let r = parseInt(Math.random() * 36, 10);
  id += (r).toString(36);

  return term.normal + '|' + id.toUpperCase()
};

// setInterval(() => console.log(toId(4, 12)), 100)

// are we inserting inside a contraction?
// expand it first
const expand$3 = function (m) {
  if (m.has('@hasContraction') && typeof m.contractions === 'function') {
    //&& m.after('^.').has('@hasContraction')
    let more = m.grow('@hasContraction');
    more.contractions().expand();
  }
};

const isArray$8 = arr => Object.prototype.toString.call(arr) === '[object Array]';

// set new ids for each terms
const addIds$2 = function (terms) {
  terms = terms.map(term => {
    term.id = toId(term);
    return term
  });
  return terms
};

const getTerms = function (input, world) {
  const { methods } = world;
  // create our terms from a string
  if (typeof input === 'string') {
    return methods.one.tokenize.fromString(input, world)[0] //assume one sentence
  }
  //allow a view object
  if (typeof input === 'object' && input.isView) {
    return input.clone().docs[0] || [] //assume one sentence
  }
  //allow an array of terms, too
  if (isArray$8(input)) {
    return isArray$8(input[0]) ? input[0] : input
  }
  return []
};

const insert = function (input, view, prepend) {
  const { document, world } = view;
  view.uncache();
  // insert words at end of each doc
  let ptrs = view.fullPointer;
  let selfPtrs = view.fullPointer;
  view.forEach((m, i) => {
    let ptr = m.fullPointer[0];
    let [n] = ptr;
    // add-in the words
    let home = document[n];
    let terms = getTerms(input, world);
    // are we inserting nothing?
    if (terms.length === 0) {
      return
    }
    terms = addIds$2(terms);
    if (prepend) {
      expand$3(view.update([ptr]).firstTerm());
      cleanPrepend(home, ptr, terms, document);
    } else {
      expand$3(view.update([ptr]).lastTerm());
      cleanAppend(home, ptr, terms, document);
    }
    // harden the pointer
    if (document[n] && document[n][ptr[1]]) {
      ptr[3] = document[n][ptr[1]].id;
    }
    // change self backwards by len
    selfPtrs[i] = ptr;
    // extend the pointer
    ptr[2] += terms.length;
    ptrs[i] = ptr;
  });
  let doc = view.toView(ptrs);
  // shift our self pointer, if necessary
  view.ptrs = selfPtrs;
  // try to tag them, too
  doc.compute(['id', 'index', 'freeze', 'lexicon']);
  if (doc.world.compute.preTagger) {
    doc.compute('preTagger');
  }
  doc.compute('unfreeze');
  return doc
};

const fns$4 = {
  insertAfter: function (input) {
    return insert(input, this, false)
  },
  insertBefore: function (input) {
    return insert(input, this, true)
  },
};
fns$4.append = fns$4.insertAfter;
fns$4.prepend = fns$4.insertBefore;
fns$4.insert = fns$4.insertAfter;

const dollarStub = /\$[0-9a-z]+/g;
const fns$3 = {};

// case logic
const isTitleCase$3 = (str) => /^\p{Lu}[\p{Ll}'â€™]/u.test(str) || /^\p{Lu}$/u.test(str);
const toTitleCase$1 = (str) => str.replace(/^\p{Ll}/u, x => x.toUpperCase());
const toLowerCase = (str) => str.replace(/^\p{Lu}/u, x => x.toLowerCase());

// doc.replace('foo', (m)=>{})
const replaceByFn = function (main, fn, keep) {
  main.forEach(m => {
    let out = fn(m);
    m.replaceWith(out, keep);
  });
  return main
};

// support 'foo $0' replacements
const subDollarSign = function (input, main) {
  if (typeof input !== 'string') {
    return input
  }
  let groups = main.groups();
  input = input.replace(dollarStub, a => {
    let num = a.replace(/\$/, '');
    if (groups.hasOwnProperty(num)) {
      return groups[num].text()
    }
    return a
  });
  return input
};

fns$3.replaceWith = function (input, keep = {}) {
  let ptrs = this.fullPointer;
  let main = this;
  this.uncache();
  if (typeof input === 'function') {
    return replaceByFn(main, input, keep)
  }
  let terms = main.docs[0];
  if (!terms) return main
  let isOriginalPossessive = keep.possessives && terms[terms.length - 1].tags.has('Possessive');
  let isOriginalTitleCase = keep.case && isTitleCase$3(terms[0].text);
  // support 'foo $0' replacements
  input = subDollarSign(input, main);

  let original = this.update(ptrs);
  // soften-up pointer
  ptrs = ptrs.map(ptr => ptr.slice(0, 3));
  // original.freeze()
  let oldTags = (original.docs[0] || []).map(term => Array.from(term.tags));
  let originalPre = original.docs[0][0].pre;
  let originalPost = original.docs[0][original.docs[0].length - 1].post;
  // slide this in
  if (typeof input === 'string') {
    input = this.fromText(input).compute('id');
  }
  main.insertAfter(input);
  // are we replacing part of a contraction?
  if (original.has('@hasContraction') && main.contractions) {
    let more = main.grow('@hasContraction+');
    more.contractions().expand();
  }
  // delete the original terms
  main.delete(original); //science.

  // keep "John's"
  if (isOriginalPossessive) {
    let tmp = main.docs[0];
    let term = tmp[tmp.length - 1];
    if (!term.tags.has('Possessive')) {
      term.text += "'s";
      term.normal += "'s";
      term.tags.add('Possessive');
    }
  }

  // try to keep some pre-punctuation
  if (originalPre && main.docs[0]) {
    main.docs[0][0].pre = originalPre;
  }
  // try to keep any post-punctuation
  if (originalPost && main.docs[0]) {
    let lastOne = main.docs[0][main.docs[0].length - 1];
    if (!lastOne.post.trim()) {
      lastOne.post = originalPost;
    }
  }

  // what should we return?
  let m = main.toView(ptrs).compute(['index', 'freeze', 'lexicon']);
  if (m.world.compute.preTagger) {
    m.compute('preTagger');
  }
  m.compute('unfreeze');
  // replace any old tags
  if (keep.tags) {
    m.terms().forEach((term, i) => {
      term.tagSafe(oldTags[i]);
    });
  }

  if (!m.docs[0] || !m.docs[0][0]) return m

  // try to co-erce case, too
  if (keep.case) {
    let transformCase = isOriginalTitleCase ? toTitleCase$1 : toLowerCase;
    m.docs[0][0].text = transformCase(m.docs[0][0].text);
  }

  // console.log(input.docs[0])
  // let regs = input.docs[0].map(t => {
  //   return { id: t.id, optional: true }
  // })
  // m.after('(a|hoy)').debug()
  // m.growRight('(a|hoy)').debug()
  // console.log(m)
  return m
};

fns$3.replace = function (match, input, keep) {
  if (match && !input) {
    return this.replaceWith(match, keep)
  }
  let m = this.match(match);
  if (!m.found) {
    return this
  }
  this.soften();
  return m.replaceWith(input, keep)
};

// transfer sentence-ending punctuation
const repairPunct = function (terms, len) {
  let last = terms.length - 1;
  let from = terms[last];
  let to = terms[last - len];
  if (to && from) {
    to.post += from.post; //this isn't perfect.
    to.post = to.post.replace(/ +([.?!,;:])/, '$1');
    // don't allow any silly punctuation outcomes like ',!'
    to.post = to.post.replace(/[,;:]+([.?!])/, '$1');
  }
};

// remove terms from document json
const pluckOut = function (document, nots) {
  nots.forEach(ptr => {
    let [n, start, end] = ptr;
    let len = end - start;
    if (!document[n]) {
      return // weird!
    }
    if (end === document[n].length && end > 1) {
      repairPunct(document[n], len);
    }
    document[n].splice(start, len); // replaces len terms at index start
  });
  // remove any now-empty sentences
  // (foreach + splice = 'mutable filter')
  for (let i = document.length - 1; i >= 0; i -= 1) {
    if (document[i].length === 0) {
      document.splice(i, 1);
      // remove any trailing whitespace before our removed sentence
      if (i === document.length && document[i - 1]) {
        let terms = document[i - 1];
        let lastTerm = terms[terms.length - 1];
        if (lastTerm) {
          lastTerm.post = lastTerm.post.trimEnd();
        }
      }
      // repair any downstream indexes
      // for (let k = i; k < document.length; k += 1) {
      //   document[k].forEach(term => term.index[0] -= 1)
      // }
    }
  }
  return document
};

const fixPointers$1 = function (ptrs, gonePtrs) {
  ptrs = ptrs.map(ptr => {
    let [n] = ptr;
    if (!gonePtrs[n]) {
      return ptr
    }
    gonePtrs[n].forEach(no => {
      let len = no[2] - no[1];
      // does it effect our pointer?
      if (ptr[1] <= no[1] && ptr[2] >= no[2]) {
        ptr[2] -= len;
      }
    });
    return ptr
  });

  // decrement any pointers after a now-empty pointer
  ptrs.forEach((ptr, i) => {
    // is the pointer now empty?
    if (ptr[1] === 0 && ptr[2] == 0) {
      // go down subsequent pointers
      for (let n = i + 1; n < ptrs.length; n += 1) {
        ptrs[n][0] -= 1;
        if (ptrs[n][0] < 0) {
          ptrs[n][0] = 0;
        }
      }
    }
  });
  // remove any now-empty pointers
  ptrs = ptrs.filter(ptr => ptr[2] - ptr[1] > 0);

  // remove old hard-pointers
  ptrs = ptrs.map((ptr) => {
    ptr[3] = null;
    ptr[4] = null;
    return ptr
  });
  return ptrs
};

const methods$k = {
  /** */
  remove: function (reg) {
    const { indexN } = this.methods.one.pointer;
    this.uncache();
    // two modes:
    //  - a. remove self, from full parent
    let self = this.all();
    let not = this;
    //  - b. remove a match, from self
    if (reg) {
      self = this;
      not = this.match(reg);
    }
    let isFull = !self.ptrs;
    // is it part of a contraction?
    if (not.has('@hasContraction') && not.contractions) {
      let more = not.grow('@hasContraction');
      more.contractions().expand();
    }

    let ptrs = self.fullPointer;
    let nots = not.fullPointer.reverse();
    // remove them from the actual document)
    let document = pluckOut(this.document, nots);
    // repair our pointers
    let gonePtrs = indexN(nots);
    ptrs = fixPointers$1(ptrs, gonePtrs);
    // clean up our original inputs
    self.ptrs = ptrs;
    self.document = document;
    self.compute('index');
    // if we started zoomed-out, try to end zoomed-out
    if (isFull) {
      self.ptrs = undefined;
    }
    if (!reg) {
      this.ptrs = [];
      return self.none()
    }
    let res = self.toView(ptrs); //return new document
    return res
  },
};

// aliases
methods$k.delete = methods$k.remove;

const methods$j = {
  /** add this punctuation or whitespace before each match: */
  pre: function (str, concat) {
    if (str === undefined && this.found) {
      return this.docs[0][0].pre
    }
    this.docs.forEach(terms => {
      let term = terms[0];
      if (concat === true) {
        term.pre += str;
      } else {
        term.pre = str;
      }
    });
    return this
  },

  /** add this punctuation or whitespace after each match: */
  post: function (str, concat) {
    if (str === undefined) {
      let last = this.docs[this.docs.length - 1];
      return last[last.length - 1].post
    }
    this.docs.forEach(terms => {
      let term = terms[terms.length - 1];
      if (concat === true) {
        term.post += str;
      } else {
        term.post = str;
      }
    });
    return this
  },

  /** remove whitespace from start/end */
  trim: function () {
    if (!this.found) {
      return this
    }
    let docs = this.docs;
    let start = docs[0][0];
    start.pre = start.pre.trimStart();
    let last = docs[docs.length - 1];
    let end = last[last.length - 1];
    end.post = end.post.trimEnd();
    return this
  },

  /** connect words with hyphen, and remove whitespace */
  hyphenate: function () {
    this.docs.forEach(terms => {
      //remove whitespace
      terms.forEach((t, i) => {
        if (i !== 0) {
          t.pre = '';
        }
        if (terms[i + 1]) {
          t.post = '-';
        }
      });
    });
    return this
  },

  /** remove hyphens between words, and set whitespace */
  dehyphenate: function () {
    const hasHyphen = /[-â€“â€”]/;
    this.docs.forEach(terms => {
      //remove whitespace
      terms.forEach(t => {
        if (hasHyphen.test(t.post)) {
          t.post = ' ';
        }
      });
    });
    return this
  },

  /** add quotations around these matches */
  toQuotations: function (start, end) {
    start = start || `"`;
    end = end || `"`;
    this.docs.forEach(terms => {
      terms[0].pre = start + terms[0].pre;
      let last = terms[terms.length - 1];
      last.post = end + last.post;
    });
    return this
  },

  /** add brackets around these matches */
  toParentheses: function (start, end) {
    start = start || `(`;
    end = end || `)`;
    this.docs.forEach(terms => {
      terms[0].pre = start + terms[0].pre;
      let last = terms[terms.length - 1];
      last.post = end + last.post;
    });
    return this
  },
};

// aliases
methods$j.deHyphenate = methods$j.dehyphenate;
methods$j.toQuotation = methods$j.toQuotations;

/** alphabetical order */
const alpha = (a, b) => {
  if (a.normal < b.normal) {
    return -1
  }
  if (a.normal > b.normal) {
    return 1
  }
  return 0
};

/** count the # of characters of each match */
const length = (a, b) => {
  let left = a.normal.trim().length;
  let right = b.normal.trim().length;
  if (left < right) {
    return 1
  }
  if (left > right) {
    return -1
  }
  return 0
};

/** count the # of terms in each match */
const wordCount$1 = (a, b) => {
  if (a.words < b.words) {
    return 1
  }
  if (a.words > b.words) {
    return -1
  }
  return 0
};

/** count the # of terms in each match */
const sequential = (a, b) => {
  if (a[0] < b[0]) {
    return 1
  }
  if (a[0] > b[0]) {
    return -1
  }
  return a[1] > b[1] ? 1 : -1
};

/** sort by # of duplicates in the document*/
const byFreq = function (arr) {
  let counts = {};
  arr.forEach(o => {
    counts[o.normal] = counts[o.normal] || 0;
    counts[o.normal] += 1;
  });
  // sort by freq
  arr.sort((a, b) => {
    let left = counts[a.normal];
    let right = counts[b.normal];
    if (left < right) {
      return 1
    }
    if (left > right) {
      return -1
    }
    return 0
  });
  return arr
};

var methods$i = { alpha, length, wordCount: wordCount$1, sequential, byFreq };

// aliases
const seqNames = new Set(['index', 'sequence', 'seq', 'sequential', 'chron', 'chronological']);
const freqNames = new Set(['freq', 'frequency', 'topk', 'repeats']);
const alphaNames = new Set(['alpha', 'alphabetical']);

// support function as parameter
const customSort = function (view, fn) {
  let ptrs = view.fullPointer;
  ptrs = ptrs.sort((a, b) => {
    a = view.update([a]);
    b = view.update([b]);
    return fn(a, b)
  });
  view.ptrs = ptrs; //mutate original
  return view
};

/** re-arrange the order of the matches (in place) */
const sort = function (input) {
  let { docs, pointer } = this;
  this.uncache();
  if (typeof input === 'function') {
    return customSort(this, input)
  }
  input = input || 'alpha';
  let ptrs = pointer || docs.map((_d, n) => [n]);
  let arr = docs.map((terms, n) => {
    return {
      index: n,
      words: terms.length,
      normal: terms.map(t => t.machine || t.normal || '').join(' '),
      pointer: ptrs[n],
    }
  });
  // 'chronological' sorting
  if (seqNames.has(input)) {
    input = 'sequential';
  }
  // alphabetical sorting
  if (alphaNames.has(input)) {
    input = 'alpha';
  }
  // sort by frequency
  if (freqNames.has(input)) {
    arr = methods$i.byFreq(arr);
    return this.update(arr.map(o => o.pointer))
  }
  // apply sort method on each phrase
  if (typeof methods$i[input] === 'function') {
    arr = arr.sort(methods$i[input]);
    return this.update(arr.map(o => o.pointer))
  }
  return this
};

/** reverse the order of the matches, but not the words or index */
const reverse$1 = function () {
  let ptrs = this.pointer || this.docs.map((_d, n) => [n]);
  ptrs = [].concat(ptrs);
  ptrs = ptrs.reverse();
  if (this._cache) {
    this._cache = this._cache.reverse();
  }
  return this.update(ptrs)
};

/** remove any duplicate matches */
const unique$1 = function () {
  let already = new Set();
  let res = this.filter(m => {
    let txt = m.text('machine');
    if (already.has(txt)) {
      return false
    }
    already.add(txt);
    return true
  });
  // this.ptrs = res.ptrs //mutate original?
  return res//.compute('index')
};

var sort$1 = { unique: unique$1, reverse: reverse$1, sort };

const isArray$7 = (arr) => Object.prototype.toString.call(arr) === '[object Array]';

// append a new document, somehow
const combineDocs = function (homeDocs, inputDocs) {
  if (homeDocs.length > 0) {
    // add a space
    let end = homeDocs[homeDocs.length - 1];
    let last = end[end.length - 1];
    if (/ /.test(last.post) === false) {
      last.post += ' ';
    }
  }
  homeDocs = homeDocs.concat(inputDocs);
  return homeDocs
};

const combineViews = function (home, input) {
  // is it a view from the same document?
  if (home.document === input.document) {
    let ptrs = home.fullPointer.concat(input.fullPointer);
    return home.toView(ptrs).compute('index')
  }
  // update n of new pointer, to end of our pointer
  let ptrs = input.fullPointer;
  ptrs.forEach(a => {
    a[0] += home.document.length;
  });
  home.document = combineDocs(home.document, input.docs);
  return home.all()
};

var concat = {
  // add string as new match/sentence
  concat: function (input) {
    // parse and splice-in new terms
    if (typeof input === 'string') {
      let more = this.fromText(input);
      // easy concat
      if (!this.found || !this.ptrs) {
        this.document = this.document.concat(more.document);
      } else {
        // if we are in the middle, this is actually a splice operation
        let ptrs = this.fullPointer;
        let at = ptrs[ptrs.length - 1][0];
        this.document.splice(at, 0, ...more.document);
      }
      // put the docs
      return this.all().compute('index')
    }
    // plop some view objects together
    if (typeof input === 'object' && input.isView) {
      return combineViews(this, input)
    }
    // assume it's an array of terms
    if (isArray$7(input)) {
      let docs = combineDocs(this.document, input);
      this.document = docs;
      return this.all()
    }
    return this
  },
};

// add indexes to pointers
const harden = function () {
  this.ptrs = this.fullPointer;
  return this
};
// remove indexes from pointers
const soften = function () {
  let ptr = this.ptrs;
  if (!ptr || ptr.length < 1) {
    return this
  }
  ptr = ptr.map(a => a.slice(0, 3));
  this.ptrs = ptr;
  return this
};
var harden$1 = { harden, soften };

const methods$h = Object.assign({}, caseFns, fns$4, fns$3, methods$k, methods$j, sort$1, concat, harden$1);

const addAPI$2 = function (View) {
  Object.assign(View.prototype, methods$h);
};

const compute$9 = {
  id: function (view) {
    let docs = view.docs;
    for (let n = 0; n < docs.length; n += 1) {
      for (let i = 0; i < docs[n].length; i += 1) {
        let term = docs[n][i];
        term.id = term.id || toId(term);
      }
    }
  }
};

var change = {
  api: addAPI$2,
  compute: compute$9,
};

var contractions$1 = [
  // simple mappings
  { word: '@', out: ['at'] },
  { word: 'arent', out: ['are', 'not'] },
  { word: 'alot', out: ['a', 'lot'] },
  { word: 'brb', out: ['be', 'right', 'back'] },
  { word: 'cannot', out: ['can', 'not'] },
  { word: 'dun', out: ['do', 'not'] },
  { word: "can't", out: ['can', 'not'] },
  { word: "shan't", out: ['should', 'not'] },
  { word: "won't", out: ['will', 'not'] },
  { word: "that's", out: ['that', 'is'] },
  { word: "what's", out: ['what', 'is'] },
  { word: "let's", out: ['let', 'us'] },
  // { word: "there's", out: ['there', 'is'] },
  { word: 'dunno', out: ['do', 'not', 'know'] },
  { word: 'gonna', out: ['going', 'to'] },
  { word: 'gotta', out: ['have', 'got', 'to'] }, //hmm
  { word: 'gimme', out: ['give', 'me'] },
  { word: 'outta', out: ['out', 'of'] },
  { word: 'tryna', out: ['trying', 'to'] },
  { word: 'gtg', out: ['got', 'to', 'go'] },
  { word: 'im', out: ['i', 'am'] },
  { word: 'imma', out: ['I', 'will'] },
  { word: 'imo', out: ['in', 'my', 'opinion'] },
  { word: 'irl', out: ['in', 'real', 'life'] },
  { word: 'ive', out: ['i', 'have'] },
  { word: 'rn', out: ['right', 'now'] },
  { word: 'tbh', out: ['to', 'be', 'honest'] },
  { word: 'wanna', out: ['want', 'to'] },
  { word: `c'mere`, out: ['come', 'here'] },
  { word: `c'mon`, out: ['come', 'on'] },
  // shoulda, coulda
  { word: 'shoulda', out: ['should', 'have'] },
  { word: 'coulda', out: ['coulda', 'have'] },
  { word: 'woulda', out: ['woulda', 'have'] },
  { word: 'musta', out: ['must', 'have'] },

  { word: "tis", out: ['it', 'is'] },
  { word: "twas", out: ['it', 'was'] },
  { word: `y'know`, out: ['you', 'know'] },
  { word: "ne'er", out: ['never'] },
  { word: "o'er", out: ['over'] },
  // contraction-part mappings
  { after: 'll', out: ['will'] },
  { after: 've', out: ['have'] },
  { after: 're', out: ['are'] },
  { after: 'm', out: ['am'] },
  // french contractions
  { before: 'c', out: ['ce'] },
  { before: 'm', out: ['me'] },
  { before: 'n', out: ['ne'] },
  { before: 'qu', out: ['que'] },
  { before: 's', out: ['se'] },
  { before: 't', out: ['tu'] }, // t'aime

  // missing apostrophes
  { word: 'shouldnt', out: ['should', 'not'] },
  { word: 'couldnt', out: ['could', 'not'] },
  { word: 'wouldnt', out: ['would', 'not'] },
  { word: 'hasnt', out: ['has', 'not'] },
  { word: 'wasnt', out: ['was', 'not'] },
  { word: 'isnt', out: ['is', 'not'] },
  { word: 'cant', out: ['can', 'not'] },
  { word: 'dont', out: ['do', 'not'] },
  { word: 'wont', out: ['will', 'not'] },
  // apostrophe d
  { word: 'howd', out: ['how', 'did'] },
  { word: 'whatd', out: ['what', 'did'] },
  { word: 'whend', out: ['when', 'did'] },
  { word: 'whered', out: ['where', 'did'] },
];

// number suffixes that are not units
const t$2 = true;
var numberSuffixes = {
  'st': t$2,
  'nd': t$2,
  'rd': t$2,
  'th': t$2,
  'am': t$2,
  'pm': t$2,
  'max': t$2,
  'Â°': t$2,
  's': t$2, // 1990s
  'e': t$2, // 18e - french/spanish ordinal
  'er': t$2, //french 1er
  'Ã¨re': t$2, //''
  'Ã¨me': t$2, //french 2Ã¨me
};

var model$5 = {
  one: {
    contractions: contractions$1,
    numberSuffixes
  }
};

// put n new words where 1 word was
const insertContraction$1 = function (document, point, words) {
  let [n, w] = point;
  if (!words || words.length === 0) {
    return
  }
  words = words.map((word, i) => {
    word.implicit = word.text;
    word.machine = word.text;
    word.pre = '';
    word.post = '';
    word.text = '';
    word.normal = '';
    word.index = [n, w + i];
    return word
  });
  if (words[0]) {
    // move whitespace over
    words[0].pre = document[n][w].pre;
    words[words.length - 1].post = document[n][w].post;
    // add the text/normal to the first term
    words[0].text = document[n][w].text;
    words[0].normal = document[n][w].normal; // move tags too?
  }
  // do the splice
  document[n].splice(w, 1, ...words);
};

const hasContraction$3 = /'/;
//look for a past-tense verb
// const hasPastTense = (terms, i) => {
//   let after = terms.slice(i + 1, i + 3)
//   return after.some(t => t.tags.has('PastTense'))
// }
// he'd walked -> had
// how'd -> did
// he'd go -> would

const alwaysDid = new Set([
  'what',
  'how',
  'when',
  'where',
  'why',
]);

// after-words
const useWould = new Set([
  'be',
  'go',
  'start',
  'think',
  'need',
]);

const useHad = new Set([
  'been',
  'gone'
]);
// they'd gone
// they'd go


// he'd been
//    he had been
//    he would been

const _apostropheD$1 = function (terms, i) {
  let before = terms[i].normal.split(hasContraction$3)[0];

  // what'd, how'd
  if (alwaysDid.has(before)) {
    return [before, 'did']
  }
  if (terms[i + 1]) {
    // they'd gone
    if (useHad.has(terms[i + 1].normal)) {
      return [before, 'had']
    }
    // they'd go
    if (useWould.has(terms[i + 1].normal)) {
      return [before, 'would']
    }
  }
  return null
  //   if (hasPastTense(terms, i) === true) {
  //     return [before, 'had']
  //   }
  //   // had/would/did
  //   return [before, 'would']
};

//ain't -> are/is not
const apostropheT$1 = function (terms, i) {
  if (terms[i].normal === "ain't" || terms[i].normal === 'aint') {
    return null //do this in ./two/
  }
  let before = terms[i].normal.replace(/n't/, '');
  return [before, 'not']
};

const hasContraction$2 = /'/;
const isFeminine = /(e|Ã©|aison|sion|tion)$/;
const isMasculine = /(age|isme|acle|ege|oire)$/;
// l'amour
const preL = (terms, i) => {
  // le/la
  let after = terms[i].normal.split(hasContraction$2)[1];
  // quick french gender disambig (rough)
  if (after && after.endsWith('e')) {
    return ['la', after]
  }
  return ['le', after]
};

// d'amerique
const preD = (terms, i) => {
  let after = terms[i].normal.split(hasContraction$2)[1];
  // quick guess for noun-agreement (rough)
  if (after && isFeminine.test(after) && !isMasculine.test(after)) {
    return ['du', after]
  } else if (after && after.endsWith('s')) {
    return ['des', after]
  }
  return ['de', after]
};

// j'aime
const preJ = (terms, i) => {
  let after = terms[i].normal.split(hasContraction$2)[1];
  return ['je', after]
};

var french = {
  preJ,
  preL,
  preD,
};

const isRange = /^([0-9.]{1,4}[a-z]{0,2}) ?[-â€“â€”] ?([0-9]{1,4}[a-z]{0,2})$/i;
const timeRange = /^([0-9]{1,2}(:[0-9][0-9])?(am|pm)?) ?[-â€“â€”] ?([0-9]{1,2}(:[0-9][0-9])?(am|pm)?)$/i;
const phoneNum = /^[0-9]{3}-[0-9]{4}$/;

const numberRange = function (terms, i) {
  let term = terms[i];
  let parts = term.text.match(isRange);
  if (parts !== null) {
    // 123-1234 is a phone number, not a number-range
    if (term.tags.has('PhoneNumber') === true || phoneNum.test(term.text)) {
      return null
    }
    return [parts[1], 'to', parts[2]]
  } else {
    parts = term.text.match(timeRange);
    if (parts !== null) {
      return [parts[1], 'to', parts[4]]
    }
  }
  return null
};

const numUnit = /^([+-]?[0-9][.,0-9]*)([a-zÂ°Â²Â³Âµ/]+)$/; //(must be lowercase)

const numberUnit = function (terms, i, world) {
  const notUnit = world.model.one.numberSuffixes || {};
  let term = terms[i];
  let parts = term.text.match(numUnit);
  if (parts !== null) {
    // is it a recognized unit, like 'km'?
    let unit = parts[2].toLowerCase().trim();
    // don't split '3rd'
    if (notUnit.hasOwnProperty(unit)) {
      return null
    }
    return [parts[1], unit] //split it
  }
  return null
};

const byApostrophe$1 = /'/;
const numDash = /^[0-9][^-â€“â€”]*[-â€“â€”].*?[0-9]/;

// run tagger on our new implicit terms
const reTag$1 = function (terms, view, start, len) {
  let tmp = view.update();
  tmp.document = [terms];
  // offer to re-tag neighbours, too
  let end = start + len;
  if (start > 0) {
    start -= 1;
  }
  if (terms[end]) {
    end += 1;
  }
  tmp.ptrs = [[0, start, end]];
};

const byEnd$1 = {
  // ain't
  t: (terms, i) => apostropheT$1(terms, i),
  // how'd
  d: (terms, i) => _apostropheD$1(terms, i),
};

const byStart = {
  // j'aime
  j: (terms, i) => french.preJ(terms, i),
  // l'amour
  l: (terms, i) => french.preL(terms, i),
  // d'amerique
  d: (terms, i) => french.preD(terms, i),
};

// pull-apart known contractions from model
const knownOnes = function (list, term, before, after) {
  for (let i = 0; i < list.length; i += 1) {
    let o = list[i];
    // look for word-word match (cannot-> [can, not])
    if (o.word === term.normal) {
      return o.out
    }
    // look for after-match ('re -> [_, are])
    else if (after !== null && after === o.after) {
      return [before].concat(o.out)
    }
    // look for before-match (l' -> [le, _])
    else if (before !== null && before === o.before && after && after.length > 2) {
      return o.out.concat(after)
      // return [o.out, after] //typeof o.out === 'string' ? [o.out, after] : o.out(terms, i)
    }
  }
  return null
};

const toDocs$1 = function (words, view) {
  let doc = view.fromText(words.join(' '));
  doc.compute(['id', 'alias']);
  return doc.docs[0]
};

// there's is usually [there, is]
// but can be 'there has' for 'there has (..) been'
const thereHas = function (terms, i) {
  for (let k = i + 1; k < 5; k += 1) {
    if (!terms[k]) {
      break
    }
    if (terms[k].normal === 'been') {
      return ['there', 'has']
    }
  }
  return ['there', 'is']
};

//really easy ones
const contractions = view => {
  let { world, document } = view;
  const { model, methods } = world;
  let list = model.one.contractions || [];
  // let units = new Set(model.one.units || [])
  // each sentence
  document.forEach((terms, n) => {
    // loop through terms backwards
    for (let i = terms.length - 1; i >= 0; i -= 1) {
      let before = null;
      let after = null;
      if (byApostrophe$1.test(terms[i].normal) === true) {
        let res = terms[i].normal.split(byApostrophe$1);
        before = res[0];
        after = res[1];
      }
      // any known-ones, like 'dunno'?
      let words = knownOnes(list, terms[i], before, after);
      // ['foo', 's']
      if (!words && byEnd$1.hasOwnProperty(after)) {
        words = byEnd$1[after](terms, i, world);
      }
      // ['j', 'aime']
      if (!words && byStart.hasOwnProperty(before)) {
        words = byStart[before](terms, i);
      }
      // 'there is' vs 'there has'
      if (before === 'there' && after === 's') {
        words = thereHas(terms, i);
      }
      // actually insert the new terms
      if (words) {
        words = toDocs$1(words, view);
        insertContraction$1(document, [n, i], words);
        reTag$1(document[n], view, i, words.length);
        continue
      }
      // '44-2' has special care
      if (numDash.test(terms[i].normal)) {
        words = numberRange(terms, i);
        if (words) {
          words = toDocs$1(words, view);
          insertContraction$1(document, [n, i], words);
          methods.one.setTag(words, 'NumberRange', world); //add custom tag
          // is it a time-range, like '5-9pm'
          if (words[2] && words[2].tags.has('Time')) {
            methods.one.setTag([words[0]], 'Time', world, null, 'time-range');
          }
          reTag$1(document[n], view, i, words.length);
        }
        continue
      }
      // split-apart '4km'
      words = numberUnit(terms, i, world);
      if (words) {
        words = toDocs$1(words, view);
        insertContraction$1(document, [n, i], words);
        methods.one.setTag([words[1]], 'Unit', world, null, 'contraction-unit');
      }
    }
  });
};

var compute$8 = { contractions };

const plugin$3 = {
  model: model$5,
  compute: compute$8,
  hooks: ['contractions'],
};

const freeze$1 = function (view) {
  const world = view.world;
  const { model, methods } = view.world;
  const setTag = methods.one.setTag;
  const { frozenLex } = model.one;
  const multi = model.one._multiCache || {};

  view.docs.forEach(terms => {
    for (let i = 0; i < terms.length; i += 1) {
      // basic lexicon lookup
      let t = terms[i];
      let word = t.machine || t.normal;

      // test a multi-word
      if (multi[word] !== undefined && terms[i + 1]) {
        let end = i + multi[word] - 1;
        for (let k = end; k > i; k -= 1) {
          let words = terms.slice(i, k + 1);
          let str = words.map(term => term.machine || term.normal).join(' ');
          // lookup frozen lexicon
          if (frozenLex.hasOwnProperty(str) === true) {
            setTag(words, frozenLex[str], world, false, '1-frozen-multi-lexicon');
            words.forEach(term => (term.frozen = true));
            continue
          }
        }
      }
      // test single word
      if (frozenLex[word] !== undefined && frozenLex.hasOwnProperty(word)) {
        setTag([t], frozenLex[word], world, false, '1-freeze-lexicon');
        t.frozen = true;
        continue
      }
    }
  });
};

const unfreeze = function (view) {
  view.docs.forEach(ts => {
    ts.forEach(term => {
      delete term.frozen;
    });
  });
  return view
};
var compute$7 = { frozen: freeze$1, freeze: freeze$1, unfreeze };

/* eslint-disable no-console */
const blue = str => '\x1b[34m' + str + '\x1b[0m';
const dim = str => '\x1b[3m\x1b[2m' + str + '\x1b[0m';

const debug$2 = function (view) {
  view.docs.forEach(terms => {
    console.log(blue('\n  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€'));
    terms.forEach(t => {
      let str = `  ${dim('â”‚')}  `;
      let txt = t.implicit || t.text || '-';
      if (t.frozen === true) {
        str += `${blue(txt)} â„ï¸`;
      } else {
        str += dim(txt);
      }
      console.log(str);
    });
  });
};

var freeze = {
  // add .compute('freeze')
  compute: compute$7,

  mutate: world => {
    const methods = world.methods.one;
    // add @isFrozen method
    methods.termMethods.isFrozen = term => term.frozen === true;
    // adds `.debug('frozen')`
    methods.debug.freeze = debug$2;
    methods.debug.frozen = debug$2;
  },

  api: function (View) {
    // set all terms to reject any desctructive tags
    View.prototype.freeze = function () {
      this.docs.forEach(ts => {
        ts.forEach(term => {
          term.frozen = true;
        });
      });
      return this
    };
    // reset all terms to allow  any desctructive tags
    View.prototype.unfreeze = function () {
      this.compute('unfreeze');
    };
    // return all frozen terms
    View.prototype.isFrozen = function () {
      return this.match('@isFrozen+')
    };
  },
  // run it in init
  hooks: ['freeze'],
};

// scan-ahead to match multiple-word terms - 'jack rabbit'
const multiWord = function (terms, start_i, world) {
  const { model, methods } = world;
  const setTag = methods.one.setTag;
  const multi = model.one._multiCache || {};
  const { lexicon } = model.one || {};
  let t = terms[start_i];
  let word = t.machine || t.normal;

  // found a word to scan-ahead on
  if (multi[word] !== undefined && terms[start_i + 1]) {
    let end = start_i + multi[word] - 1;
    for (let i = end; i > start_i; i -= 1) {
      let words = terms.slice(start_i, i + 1);
      if (words.length <= 1) {
        return false
      }
      let str = words.map(term => term.machine || term.normal).join(' ');
      // lookup regular lexicon
      if (lexicon.hasOwnProperty(str) === true) {
        let tag = lexicon[str];
        setTag(words, tag, world, false, '1-multi-lexicon');
        // special case for phrasal-verbs - 2nd word is a #Particle
        if (tag && tag.length === 2 && (tag[0] === 'PhrasalVerb' || tag[1] === 'PhrasalVerb')) {
          setTag([words[1]], 'Particle', world, false, '1-phrasal-particle');
        }
        return true
      }
    }
    return false
  }
  return null
};

const prefix$3 = /^(under|over|mis|re|un|dis|semi|pre|post)-?/;
// anti|non|extra|inter|intra|over
const allowPrefix = new Set(['Verb', 'Infinitive', 'PastTense', 'Gerund', 'PresentTense', 'Adjective', 'Participle']);

// tag any words in our lexicon
const checkLexicon = function (terms, i, world) {
  const { model, methods } = world;
  // const fastTag = methods.one.fastTag
  const setTag = methods.one.setTag;
  const { lexicon } = model.one;

  // basic lexicon lookup
  let t = terms[i];
  let word = t.machine || t.normal;
  // normal lexicon lookup
  if (lexicon[word] !== undefined && lexicon.hasOwnProperty(word)) {
    setTag([t], lexicon[word], world, false, '1-lexicon');
    return true
  }
  // lookup aliases in the lexicon
  if (t.alias) {
    let found = t.alias.find(str => lexicon.hasOwnProperty(str));
    if (found) {
      setTag([t], lexicon[found], world, false, '1-lexicon-alias');
      return true
    }
  }
  // prefixing for verbs/adjectives
  if (prefix$3.test(word) === true) {
    let stem = word.replace(prefix$3, '');
    if (lexicon.hasOwnProperty(stem) && stem.length > 3) {
      // only allow prefixes for verbs/adjectives
      if (allowPrefix.has(lexicon[stem])) {
        // console.log('->', word, stem, lexicon[stem])
        setTag([t], lexicon[stem], world, false, '1-lexicon-prefix');
        return true
      }
    }
  }
  return null
};

// tag any words in our lexicon - even if it hasn't been filled-up yet
// rest of pre-tagger is in ./two/preTagger
const lexicon$3 = function (view) {
  const world = view.world;
  // loop through our terms
  view.docs.forEach(terms => {
    for (let i = 0; i < terms.length; i += 1) {
      if (terms[i].tags.size === 0) {
        let found = null;
        found = found || multiWord(terms, i, world);
        // lookup known words
        found = found || checkLexicon(terms, i, world);
      }
    }
  });
};

var compute$6 = {
  lexicon: lexicon$3,
};

// derive clever things from our lexicon key-value pairs
const expand$2 = function (words) {
  // const { methods, model } = world
  let lex = {};
  // console.log('start:', Object.keys(lex).length)
  let _multi = {};
  // go through each word in this key-value obj:
  Object.keys(words).forEach(word => {
    let tag = words[word];
    // normalize lexicon a little bit
    word = word.toLowerCase().trim();
    word = word.replace(/'s\b/, '');
    // cache multi-word terms
    let split = word.split(/ /);
    if (split.length > 1) {
      // prefer longer ones
      if (_multi[split[0]] === undefined || split.length > _multi[split[0]]) {
        _multi[split[0]] = split.length;
      }
    }
    lex[word] = lex[word] || tag;
  });
  // cleanup
  delete lex[''];
  delete lex[null];
  delete lex[' '];
  return { lex, _multi }
};

var methods$g = {
  one: {
    expandLexicon: expand$2,
  }
};

/** insert new words/phrases into the lexicon */
const addWords = function (words, isFrozen = false) {
  const world = this.world();
  const { methods, model } = world;
  if (!words) {
    return
  }
  // normalize tag vals
  Object.keys(words).forEach(k => {
    if (typeof words[k] === 'string' && words[k].startsWith('#')) {
      words[k] = words[k].replace(/^#/, '');
    }
  });
  // these words go into a seperate lexicon
  if (isFrozen === true) {
    let { lex, _multi } = methods.one.expandLexicon(words, world);
    Object.assign(model.one._multiCache, _multi);
    Object.assign(model.one.frozenLex, lex);
    return
  }
  // add some words to our lexicon
  if (methods.two.expandLexicon) {
    // do fancy ./two version
    let { lex, _multi } = methods.two.expandLexicon(words, world);
    Object.assign(model.one.lexicon, lex);
    Object.assign(model.one._multiCache, _multi);
  }
  // do basic ./one version
  let { lex, _multi } = methods.one.expandLexicon(words, world);
  Object.assign(model.one.lexicon, lex);
  Object.assign(model.one._multiCache, _multi);
};

var lib$5 = { addWords };

const model$4 = {
  one: {
    lexicon: {}, //setup blank lexicon
    _multiCache: {},
    frozenLex: {}, //2nd lexicon
  },
};

var lexicon$2 = {
  model: model$4,
  methods: methods$g,
  compute: compute$6,
  lib: lib$5,
  hooks: ['lexicon'],
};

// edited by Spencer Kelly
// credit to https://github.com/BrunoRB/ahocorasick by Bruno Roberto BÃºrigo.

const tokenize$1 = function (phrase, world) {
  const { methods, model } = world;
  let terms = methods.one.tokenize.splitTerms(phrase, model).map(t => methods.one.tokenize.splitWhitespace(t, model));
  return terms.map(term => term.text.toLowerCase())
};

// turn an array or object into a compressed aho-corasick structure
const buildTrie = function (phrases, world) {

  // const tokenize=methods.one.
  let goNext = [{}];
  let endAs = [null];
  let failTo = [0];

  let xs = [];
  let n = 0;
  phrases.forEach(function (phrase) {
    let curr = 0;
    // let wordsB = phrase.split(/ /g).filter(w => w)
    let words = tokenize$1(phrase, world);
    for (let i = 0; i < words.length; i++) {
      let word = words[i];
      if (goNext[curr] && goNext[curr].hasOwnProperty(word)) {
        curr = goNext[curr][word];
      } else {
        n++;
        goNext[curr][word] = n;
        goNext[n] = {};
        curr = n;
        endAs[n] = null;
      }
    }
    endAs[curr] = [words.length];
  });
  // f(s) = 0 for all states of depth 1 (the ones from which the 0 state can transition to)
  for (let word in goNext[0]) {
    n = goNext[0][word];
    failTo[n] = 0;
    xs.push(n);
  }

  while (xs.length) {
    let r = xs.shift();
    // for each symbol a such that g(r, a) = s
    let keys = Object.keys(goNext[r]);
    for (let i = 0; i < keys.length; i += 1) {
      let word = keys[i];
      let s = goNext[r][word];
      xs.push(s);
      // set state = f(r)
      n = failTo[r];
      while (n > 0 && !goNext[n].hasOwnProperty(word)) {
        n = failTo[n];
      }
      if (goNext.hasOwnProperty(n)) {
        let fs = goNext[n][word];
        failTo[s] = fs;
        if (endAs[fs]) {
          endAs[s] = endAs[s] || [];
          endAs[s] = endAs[s].concat(endAs[fs]);
        }
      } else {
        failTo[s] = 0;
      }
    }
  }
  return { goNext, endAs, failTo }
};

// console.log(buildTrie(['smart and cool', 'smart and nice']))

// follow our trie structure
const scanWords = function (terms, trie, opts) {
  let n = 0;
  let results = [];
  for (let i = 0; i < terms.length; i++) {
    let word = terms[i][opts.form] || terms[i].normal;
    // main match-logic loop:
    while (n > 0 && (trie.goNext[n] === undefined || !trie.goNext[n].hasOwnProperty(word))) {
      n = trie.failTo[n] || 0; // (usually back to 0)
    }
    // did we fail?
    if (!trie.goNext[n].hasOwnProperty(word)) {
      continue
    }
    n = trie.goNext[n][word];
    if (trie.endAs[n]) {
      let arr = trie.endAs[n];
      for (let o = 0; o < arr.length; o++) {
        let len = arr[o];
        let term = terms[i - len + 1];
        let [no, start] = term.index;
        results.push([no, start, start + len, term.id]);
      }
    }
  }
  return results
};

const cacheMiss = function (words, cache) {
  for (let i = 0; i < words.length; i += 1) {
    if (cache.has(words[i]) === true) {
      return false
    }
  }
  return true
};

const scan = function (view, trie, opts) {
  let results = [];
  opts.form = opts.form || 'normal';
  let docs = view.docs;
  if (!trie.goNext || !trie.goNext[0]) {
    console.error('Compromise invalid lookup trie');//eslint-disable-line
    return view.none()
  }
  let firstWords = Object.keys(trie.goNext[0]);
  // do each phrase
  for (let i = 0; i < docs.length; i++) {
    // can we skip the phrase, all together?
    if (view._cache && view._cache[i] && cacheMiss(firstWords, view._cache[i]) === true) {
      continue
    }
    let terms = docs[i];
    let found = scanWords(terms, trie, opts);
    if (found.length > 0) {
      results = results.concat(found);
    }
  }
  return view.update(results)
};

const isObject$4 = val => {
  return Object.prototype.toString.call(val) === '[object Object]'
};

function api$m (View) {

  /** find all matches in this document */
  View.prototype.lookup = function (input, opts = {}) {
    if (!input) {
      return this.none()
    }
    if (typeof input === 'string') {
      input = [input];
    }
    let trie = isObject$4(input) ? input : buildTrie(input, this.world);
    let res = scan(this, trie, opts);
    res = res.settle();
    return res
  };
}

// chop-off tail of redundant vals at end of array
const truncate = (list, val) => {
  for (let i = list.length - 1; i >= 0; i -= 1) {
    if (list[i] !== val) {
      list = list.slice(0, i + 1);
      return list
    }
  }
  return list
};

// prune trie a bit
const compress = function (trie) {
  trie.goNext = trie.goNext.map(o => {
    if (Object.keys(o).length === 0) {
      return undefined
    }
    return o
  });
  // chop-off tail of undefined vals in goNext array
  trie.goNext = truncate(trie.goNext, undefined);
  // chop-off tail of zeros in failTo array
  trie.failTo = truncate(trie.failTo, 0);
  // chop-off tail of nulls in endAs array
  trie.endAs = truncate(trie.endAs, null);
  return trie
};

/** pre-compile a list of matches to lookup */
const lib$4 = {
  /** turn an array or object into a compressed trie*/
  buildTrie: function (input) {
    const trie = buildTrie(input, this.world());
    return compress(trie)
  }
};
// add alias
lib$4.compile = lib$4.buildTrie;

var lookup = {
  api: api$m,
  lib: lib$4
};

const relPointer = function (ptrs, parent) {
  if (!parent) {
    return ptrs
  }
  ptrs.forEach(ptr => {
    let n = ptr[0];
    if (parent[n]) {
      ptr[0] = parent[n][0]; //n
      ptr[1] += parent[n][1]; //start
      ptr[2] += parent[n][1]; //end
    }
  });
  return ptrs
};

// make match-result relative to whole document
const fixPointers = function (res, parent) {
  let { ptrs, byGroup } = res;
  ptrs = relPointer(ptrs, parent);
  Object.keys(byGroup).forEach(k => {
    byGroup[k] = relPointer(byGroup[k], parent);
  });
  return { ptrs, byGroup }
};

// turn any matchable input intp a list of matches
const parseRegs = function (regs, opts, world) {
  const one = world.methods.one;
  if (typeof regs === 'number') {
    regs = String(regs);
  }
  // support param as string
  if (typeof regs === 'string') {
    regs = one.killUnicode(regs, world);
    regs = one.parseMatch(regs, opts, world);
  }
  return regs
};

const isObject$3 = val => {
  return Object.prototype.toString.call(val) === '[object Object]'
};

// did they pass-in a compromise object?
const isView = val => val && isObject$3(val) && val.isView === true;

const isNet = val => val && isObject$3(val) && val.isNet === true;

const match$1 = function (regs, group, opts) {
  const one = this.methods.one;
  // support param as view object
  if (isView(regs)) {
    return this.intersection(regs)
  }
  // support a compiled set of matches
  if (isNet(regs)) {
    return this.sweep(regs, { tagger: false }).view.settle()
  }
  regs = parseRegs(regs, opts, this.world);
  let todo = { regs, group };
  let res = one.match(this.docs, todo, this._cache);
  let { ptrs, byGroup } = fixPointers(res, this.fullPointer);
  let view = this.toView(ptrs);
  view._groups = byGroup;
  return view
};

const matchOne = function (regs, group, opts) {
  const one = this.methods.one;
  // support at view as a param
  if (isView(regs)) {
    return this.intersection(regs).eq(0)
  }
  // support a compiled set of matches
  if (isNet(regs)) {
    return this.sweep(regs, { tagger: false, matchOne: true }).view
  }
  regs = parseRegs(regs, opts, this.world);
  let todo = { regs, group, justOne: true };
  let res = one.match(this.docs, todo, this._cache);
  let { ptrs, byGroup } = fixPointers(res, this.fullPointer);
  let view = this.toView(ptrs);
  view._groups = byGroup;
  return view
};

const has = function (regs, group, opts) {
  const one = this.methods.one;
  // support view as input
  if (isView(regs)) {
    let ptrs = this.intersection(regs).fullPointer;
    return ptrs.length > 0
  }
  // support a compiled set of matches
  if (isNet(regs)) {
    return this.sweep(regs, { tagger: false }).view.found
  }
  regs = parseRegs(regs, opts, this.world);
  let todo = { regs, group, justOne: true };
  let ptrs = one.match(this.docs, todo, this._cache).ptrs;
  return ptrs.length > 0
};

// 'if'
const ifFn = function (regs, group, opts) {
  const one = this.methods.one;
  // support view as input
  if (isView(regs)) {
    return this.filter(m => m.intersection(regs).found)
  }
  // support a compiled set of matches
  if (isNet(regs)) {
    let m = this.sweep(regs, { tagger: false }).view.settle();
    return this.if(m) //recurse with result
  }
  regs = parseRegs(regs, opts, this.world);
  let todo = { regs, group, justOne: true };
  let ptrs = this.fullPointer;
  let cache = this._cache || [];
  ptrs = ptrs.filter((ptr, i) => {
    let m = this.update([ptr]);
    let res = one.match(m.docs, todo, cache[i]).ptrs;
    return res.length > 0
  });
  let view = this.update(ptrs);
  // try and reconstruct the cache
  if (this._cache) {
    view._cache = ptrs.map(ptr => cache[ptr[0]]);
  }
  return view
};

const ifNo = function (regs, group, opts) {
  const { methods } = this;
  const one = methods.one;
  // support a view object as input
  if (isView(regs)) {
    return this.filter(m => !m.intersection(regs).found)
  }
  // support a compiled set of matches
  if (isNet(regs)) {
    let m = this.sweep(regs, { tagger: false }).view.settle();
    return this.ifNo(m)
  }
  // otherwise parse the match string
  regs = parseRegs(regs, opts, this.world);
  let cache = this._cache || [];
  let view = this.filter((m, i) => {
    let todo = { regs, group, justOne: true };
    let ptrs = one.match(m.docs, todo, cache[i]).ptrs;
    return ptrs.length === 0
  });
  // try to reconstruct the cache
  if (this._cache) {
    view._cache = view.ptrs.map(ptr => cache[ptr[0]]);
  }
  return view
};

var match$2 = { matchOne, match: match$1, has, if: ifFn, ifNo };

const before = function (regs, group, opts) {
  const { indexN } = this.methods.one.pointer;
  let pre = [];
  let byN = indexN(this.fullPointer);
  Object.keys(byN).forEach(k => {
    // check only the earliest match in the sentence
    let first = byN[k].sort((a, b) => (a[1] > b[1] ? 1 : -1))[0];
    if (first[1] > 0) {
      pre.push([first[0], 0, first[1]]);
    }
  });
  let preWords = this.toView(pre);
  if (!regs) {
    return preWords
  }
  return preWords.match(regs, group, opts)
};

const after = function (regs, group, opts) {
  const { indexN } = this.methods.one.pointer;
  let post = [];
  let byN = indexN(this.fullPointer);
  let document = this.document;
  Object.keys(byN).forEach(k => {
    // check only the latest match in the sentence
    let last = byN[k].sort((a, b) => (a[1] > b[1] ? -1 : 1))[0];
    let [n, , end] = last;
    if (end < document[n].length) {
      post.push([n, end, document[n].length]);
    }
  });
  let postWords = this.toView(post);
  if (!regs) {
    return postWords
  }
  return postWords.match(regs, group, opts)
};

const growLeft = function (regs, group, opts) {
  if (typeof regs === 'string') {
    regs = this.world.methods.one.parseMatch(regs, opts, this.world);
  }
  regs[regs.length - 1].end = true; // ensure matches are beside us â†
  let ptrs = this.fullPointer;
  this.forEach((m, n) => {
    let more = m.before(regs, group);
    if (more.found) {
      let terms = more.terms();
      ptrs[n][1] -= terms.length;
      ptrs[n][3] = terms.docs[0][0].id;
    }
  });
  return this.update(ptrs)
};

const growRight = function (regs, group, opts) {
  if (typeof regs === 'string') {
    regs = this.world.methods.one.parseMatch(regs, opts, this.world);
  }
  regs[0].start = true; // ensure matches are beside us â†’
  let ptrs = this.fullPointer;
  this.forEach((m, n) => {
    let more = m.after(regs, group);
    if (more.found) {
      let terms = more.terms();
      ptrs[n][2] += terms.length;
      ptrs[n][4] = null; //remove end-id
    }
  });
  return this.update(ptrs)
};

const grow = function (regs, group, opts) {
  return this.growRight(regs, group, opts).growLeft(regs, group, opts)
};

var lookaround = { before, after, growLeft, growRight, grow };

const combine = function (left, right) {
  return [left[0], left[1], right[2]]
};

const isArray$6 = function (arr) {
  return Object.prototype.toString.call(arr) === '[object Array]'
};

const getDoc$2 = (reg, view, group) => {
  if (typeof reg === 'string' || isArray$6(reg)) {
    return view.match(reg, group)
  }
  if (!reg) {
    return view.none()
  }
  return reg
};

const addIds$1 = function (ptr, view) {
  let [n, start, end] = ptr;
  if (view.document[n] && view.document[n][start]) {
    ptr[3] = ptr[3] || view.document[n][start].id;
    if (view.document[n][end - 1]) {
      ptr[4] = ptr[4] || view.document[n][end - 1].id;
    }
  }
  return ptr
};

const methods$f = {};
// [before], [match], [after]
methods$f.splitOn = function (m, group) {
  const { splitAll } = this.methods.one.pointer;
  let splits = getDoc$2(m, this, group).fullPointer;
  let all = splitAll(this.fullPointer, splits);
  let res = [];
  all.forEach(o => {
    res.push(o.passthrough);
    res.push(o.before);
    res.push(o.match);
    res.push(o.after);
  });
  res = res.filter(p => p);
  res = res.map(p => addIds$1(p, this));
  return this.update(res)
};

// [before], [match after]
methods$f.splitBefore = function (m, group) {
  const { splitAll } = this.methods.one.pointer;
  let splits = getDoc$2(m, this, group).fullPointer;
  let all = splitAll(this.fullPointer, splits);
  // repair matches to favor [match, after]
  // - instead of [before, match]
  for (let i = 0; i < all.length; i += 1) {
    // move a before to a preceding after
    if (!all[i].after && all[i + 1] && all[i + 1].before) {
      // ensure it's from the same original sentence
      if (all[i].match && all[i].match[0] === all[i + 1].before[0]) {
        all[i].after = all[i + 1].before;
        delete all[i + 1].before;
      }
    }
  }

  let res = [];
  all.forEach(o => {
    res.push(o.passthrough);
    res.push(o.before);
    // a, [x, b]
    if (o.match && o.after) {
      res.push(combine(o.match, o.after));
    } else {
      // a, [x], b
      res.push(o.match);
    }
  });
  res = res.filter(p => p);
  res = res.map(p => addIds$1(p, this));
  return this.update(res)
};

// [before match], [after]
methods$f.splitAfter = function (m, group) {
  const { splitAll } = this.methods.one.pointer;
  let splits = getDoc$2(m, this, group).fullPointer;
  let all = splitAll(this.fullPointer, splits);
  let res = [];
  all.forEach(o => {
    res.push(o.passthrough);
    if (o.before && o.match) {
      res.push(combine(o.before, o.match));
    } else {
      res.push(o.before);
      res.push(o.match);
    }
    res.push(o.after);
  });
  res = res.filter(p => p);
  res = res.map(p => addIds$1(p, this));
  return this.update(res)
};
methods$f.split = methods$f.splitAfter;

// check if two pointers are perfectly consecutive
const isNeighbour = function (ptrL, ptrR) {
  // validate
  if (!ptrL || !ptrR) {
    return false
  }
  // same sentence
  if (ptrL[0] !== ptrR[0]) {
    return false
  }
  // ensure R starts where L ends
  return ptrL[2] === ptrR[1]
};

// join two neighbouring words, if they both match
const mergeIf = function (doc, lMatch, rMatch) {
  const world = doc.world;
  const parseMatch = world.methods.one.parseMatch;
  lMatch = lMatch || '.$'; //defaults
  rMatch = rMatch || '^.';
  let leftMatch = parseMatch(lMatch, {}, world);
  let rightMatch = parseMatch(rMatch, {}, world);
  // ensure end-requirement to left-match, start-requiremnts to right match
  leftMatch[leftMatch.length - 1].end = true;
  rightMatch[0].start = true;
  // let's get going.
  let ptrs = doc.fullPointer;
  let res = [ptrs[0]];
  for (let i = 1; i < ptrs.length; i += 1) {
    let ptrL = res[res.length - 1];
    let ptrR = ptrs[i];
    let left = doc.update([ptrL]);
    let right = doc.update([ptrR]);
    // should we marge left+right?
    if (isNeighbour(ptrL, ptrR) && left.has(leftMatch) && right.has(rightMatch)) {
      // merge right ptr into existing result
      res[res.length - 1] = [ptrL[0], ptrL[1], ptrR[2], ptrL[3], ptrR[4]];
    } else {
      res.push(ptrR);
    }
  }
  // return new pointers
  return doc.update(res)
};

const methods$e = {
  //  merge only if conditions are met
  joinIf: function (lMatch, rMatch) {
    return mergeIf(this, lMatch, rMatch)
  },
  // merge all neighbouring matches
  join: function () {
    return mergeIf(this)
  },
};

const methods$d = Object.assign({}, match$2, lookaround, methods$f, methods$e);
// aliases
methods$d.lookBehind = methods$d.before;
methods$d.lookBefore = methods$d.before;

methods$d.lookAhead = methods$d.after;
methods$d.lookAfter = methods$d.after;

methods$d.notIf = methods$d.ifNo;
const matchAPI = function (View) {
  Object.assign(View.prototype, methods$d);
};

// match  'foo /yes/' and not 'foo/no/bar'
const bySlashes = /(?:^|\s)([![^]*(?:<[^<]*>)?\/.*?[^\\/]\/[?\]+*$~]*)(?:\s|$)/;
// match '(yes) but not foo(no)bar'
const byParentheses = /([!~[^]*(?:<[^<]*>)?\([^)]+[^\\)]\)[?\]+*$~]*)(?:\s|$)/;
// okay
const byWord$1 = / /g;

const isBlock = str => {
  return /^[![^]*(<[^<]*>)?\(/.test(str) && /\)[?\]+*$~]*$/.test(str)
};
const isReg = str => {
  return /^[![^]*(<[^<]*>)?\//.test(str) && /\/[?\]+*$~]*$/.test(str)
};

const cleanUp$1 = function (arr) {
  arr = arr.map(str => str.trim());
  arr = arr.filter(str => str);
  return arr
};

const parseBlocks = function (txt) {
  // parse by /regex/ first
  let arr = txt.split(bySlashes);
  let res = [];
  // parse by (blocks), next
  arr.forEach(str => {
    if (isReg(str)) {
      res.push(str);
      return
    }
    res = res.concat(str.split(byParentheses));
  });
  res = cleanUp$1(res);
  // split by spaces, now
  let final = [];
  res.forEach(str => {
    if (isBlock(str)) {
      final.push(str);
    } else if (isReg(str)) {
      final.push(str);
    } else {
      final = final.concat(str.split(byWord$1));
    }
  });
  final = cleanUp$1(final);
  return final
};

const hasMinMax = /\{([0-9]+)?(, *[0-9]*)?\}/;
const andSign = /&&/;
// const hasDash = /\p{Letter}[-â€“â€”]\p{Letter}/u
const captureName = new RegExp(/^<\s*(\S+)\s*>/);
/* break-down a match expression into this:
{
  word:'',
  tag:'',
  regex:'',

  start:false,
  end:false,
  negative:false,
  anything:false,
  greedy:false,
  optional:false,

  named:'',
  choices:[],
}
*/
const titleCase$2 = str => str.charAt(0).toUpperCase() + str.substring(1);
const end = (str) => str.charAt(str.length - 1);
const start = (str) => str.charAt(0);
const stripStart = (str) => str.substring(1);
const stripEnd = (str) => str.substring(0, str.length - 1);

const stripBoth = function (str) {
  str = stripStart(str);
  str = stripEnd(str);
  return str
};
//
const parseToken = function (w, opts) {
  let obj = {};
  //collect any flags (do it twice)
  for (let i = 0; i < 2; i += 1) {
    //end-flag
    if (end(w) === '$') {
      obj.end = true;
      w = stripEnd(w);
    }
    //front-flag
    if (start(w) === '^') {
      obj.start = true;
      w = stripStart(w);
    }
    if (end(w) === '?') {
      obj.optional = true;
      w = stripEnd(w);
    }
    //capture group (this one can span multiple-terms)
    if (start(w) === '[' || end(w) === ']') {
      obj.group = null;
      if (start(w) === '[') {
        obj.groupStart = true;
      }
      if (end(w) === ']') {
        obj.groupEnd = true;
      }
      w = w.replace(/^\[/, '');
      w = w.replace(/\]$/, '');
      // Use capture group name
      if (start(w) === '<') {
        const res = captureName.exec(w);
        if (res.length >= 2) {
          obj.group = res[1];
          w = w.replace(res[0], '');
        }
      }
    }
    //back-flags
    if (end(w) === '+') {
      obj.greedy = true;
      w = stripEnd(w);
    }
    if (w !== '*' && end(w) === '*' && w !== '\\*') {
      obj.greedy = true;
      w = stripEnd(w);
    }
    if (start(w) === '!') {
      obj.negative = true;
      // obj.optional = true
      w = stripStart(w);
    }
    //soft-match
    if (start(w) === '~' && end(w) === '~' && w.length > 2) {
      w = stripBoth(w);
      obj.fuzzy = true;
      obj.min = opts.fuzzy || 0.85;
      if (/\(/.test(w) === false) {
        obj.word = w;
        return obj
      }
    }

    //regex
    if (start(w) === '/' && end(w) === '/') {
      w = stripBoth(w);
      if (opts.caseSensitive) {
        obj.use = 'text';
      }
      obj.regex = new RegExp(w); //potential vuln - security/detect-non-literal-regexp
      return obj
    }

    // support foo{1,9}
    if (hasMinMax.test(w) === true) {
      w = w.replace(hasMinMax, (_a, b, c) => {
        if (c === undefined) {
          // '{3}'	Exactly three times
          obj.min = Number(b);
          obj.max = Number(b);
        } else {
          c = c.replace(/, */, '');
          if (b === undefined) {
            // '{,9}' implied zero min
            obj.min = 0;
            obj.max = Number(c);
          } else {
            // '{2,4}' Two to four times
            obj.min = Number(b);
            // '{3,}' Three or more times
            obj.max = Number(c || 999);
          }
        }
        // use same method as '+'
        obj.greedy = true;
        // 0 as min means the same as '?'
        if (!obj.min) {
          obj.optional = true;
        }
        return ''
      });
    }

    //wrapped-flags
    if (start(w) === '(' && end(w) === ')') {
      // support (one && two)
      if (andSign.test(w)) {
        obj.choices = w.split(andSign);
        obj.operator = 'and';
      } else {
        obj.choices = w.split('|');
        obj.operator = 'or';
      }
      //remove '(' and ')'
      obj.choices[0] = stripStart(obj.choices[0]);
      let last = obj.choices.length - 1;
      obj.choices[last] = stripEnd(obj.choices[last]);
      // clean up the results
      obj.choices = obj.choices.map(s => s.trim());
      obj.choices = obj.choices.filter(s => s);
      //recursion alert!
      obj.choices = obj.choices.map(str => {
        return str.split(/ /g).map(s => parseToken(s, opts))
      });
      w = '';
    }

    //root/sense overloaded
    if (start(w) === '{' && end(w) === '}') {
      w = stripBoth(w);
      // obj.sense = w
      obj.root = w;
      if (/\//.test(w)) {
        let split = obj.root.split(/\//);
        obj.root = split[0];
        obj.pos = split[1];
        if (obj.pos === 'adj') {
          obj.pos = 'Adjective';
        }
        // titlecase
        obj.pos = obj.pos.charAt(0).toUpperCase() + obj.pos.substr(1).toLowerCase();
        // add sense-number too
        if (split[2] !== undefined) {
          obj.sense = split[2];
        }
      }
      return obj
    }
    //chunks
    if (start(w) === '<' && end(w) === '>') {
      w = stripBoth(w);
      obj.chunk = titleCase$2(w);
      obj.greedy = true;
      return obj
    }
    if (start(w) === '%' && end(w) === '%') {
      w = stripBoth(w);
      obj.switch = w;
      return obj
    }
  }
  //do the actual token content
  if (start(w) === '#') {
    obj.tag = stripStart(w);
    obj.tag = titleCase$2(obj.tag);
    return obj
  }
  //dynamic function on a term object
  if (start(w) === '@') {
    obj.method = stripStart(w);
    return obj
  }
  if (w === '.') {
    obj.anything = true;
    return obj
  }
  //support alone-astrix
  if (w === '*') {
    obj.anything = true;
    obj.greedy = true;
    obj.optional = true;
    return obj
  }
  if (w) {
    //somehow handle encoded-chars?
    w = w.replace('\\*', '*');
    w = w.replace('\\.', '.');
    if (opts.caseSensitive) {
      obj.use = 'text';
    } else {
      w = w.toLowerCase();
    }
    obj.word = w;
  }
  return obj
};

const hasDash$2 = /[a-z0-9][-â€“â€”][a-z]/i;

// match 're-do' -> ['re','do']
const splitHyphens$1 = function (regs, world) {
  let prefixes = world.model.one.prefixes;
  for (let i = regs.length - 1; i >= 0; i -= 1) {
    let reg = regs[i];
    if (reg.word && hasDash$2.test(reg.word)) {
      let words = reg.word.split(/[-â€“â€”]/g);
      // don't split 're-cycle', etc
      if (prefixes.hasOwnProperty(words[0])) {
        continue
      }
      words = words.filter(w => w).reverse();
      regs.splice(i, 1);
      words.forEach(w => {
        let obj = Object.assign({}, reg);
        obj.word = w;
        regs.splice(i, 0, obj);
      });
    }
  }
  return regs
};

// add all conjugations of this verb
const addVerbs = function (token, world) {
  let { all } = world.methods.two.transform.verb || {};
  let str = token.root;
  if (!all) {
    return []
  }
  return all(str, world.model)
};

// add all inflections of this noun
const addNoun = function (token, world) {
  let { all } = world.methods.two.transform.noun || {};
  if (!all) {
    return [token.root]
  }
  return all(token.root, world.model)
};

// add all inflections of this adjective
const addAdjective = function (token, world) {
  let { all } = world.methods.two.transform.adjective || {};
  if (!all) {
    return [token.root]
  }
  return all(token.root, world.model)
};

// turn '{walk}' into 'walking', 'walked', etc
const inflectRoot = function (regs, world) {
  // do we have compromise/two?
  regs = regs.map(token => {
    // a reg to convert '{foo}'
    if (token.root) {
      // check if compromise/two is loaded
      if (world.methods.two && world.methods.two.transform) {
        let choices = [];
        // have explicitly set from POS - '{sweet/adjective}'
        if (token.pos) {
          if (token.pos === 'Verb') {
            choices = choices.concat(addVerbs(token, world));
          } else if (token.pos === 'Noun') {
            choices = choices.concat(addNoun(token, world));
          } else if (token.pos === 'Adjective') {
            choices = choices.concat(addAdjective(token, world));
          }
        } else {
          // do verb/noun/adj by default
          choices = choices.concat(addVerbs(token, world));
          choices = choices.concat(addNoun(token, world));
          choices = choices.concat(addAdjective(token, world));
        }
        choices = choices.filter(str => str);
        if (choices.length > 0) {
          token.operator = 'or';
          token.fastOr = new Set(choices);
        }
      } else {
        // if no compromise/two, drop down into 'machine' lookup
        token.machine = token.root;
        delete token.id;
        delete token.root;
      }
    }
    return token
  });

  return regs
};

// name any [unnamed] capture-groups with a number
const nameGroups = function (regs) {
  let index = 0;
  let inGroup = null;
  //'fill in' capture groups between start-end
  for (let i = 0; i < regs.length; i++) {
    const token = regs[i];
    if (token.groupStart === true) {
      inGroup = token.group;
      if (inGroup === null) {
        inGroup = String(index);
        index += 1;
      }
    }
    if (inGroup !== null) {
      token.group = inGroup;
    }
    if (token.groupEnd === true) {
      inGroup = null;
    }
  }
  return regs
};

// optimize an 'or' lookup, when the (a|b|c) list is simple or multi-word
const doFastOrMode = function (tokens) {
  return tokens.map(token => {
    if (token.choices !== undefined) {
      // make sure it's an OR
      if (token.operator !== 'or') {
        return token
      }
      if (token.fuzzy === true) {
        return token
      }
      // are they all straight-up words? then optimize them.
      let shouldPack = token.choices.every(block => {
        if (block.length !== 1) {
          return false
        }
        let reg = block[0];
        // ~fuzzy~ words need more care
        if (reg.fuzzy === true) {
          return false
        }
        // ^ and $ get lost in fastOr
        if (reg.start || reg.end) {
          return false
        }
        if (reg.word !== undefined && reg.negative !== true && reg.optional !== true && reg.method !== true) {
          return true //reg is simple-enough
        }
        return false
      });
      if (shouldPack === true) {
        token.fastOr = new Set();
        token.choices.forEach(block => {
          token.fastOr.add(block[0].word);
        });
        delete token.choices;
      }
    }
    return token
  })
};

// support ~(a|b|c)~
const fuzzyOr = function (regs) {
  return regs.map(reg => {
    if (reg.fuzzy && reg.choices) {
      // pass fuzzy-data to each OR choice
      reg.choices.forEach(r => {
        if (r.length === 1 && r[0].word) {
          r[0].fuzzy = true;
          r[0].min = reg.min;
        }
      });
    }
    return reg
  })
};

const postProcess = function (regs) {
  // ensure all capture groups names are filled between start and end
  regs = nameGroups(regs);
  // convert 'choices' format to 'fastOr' format
  regs = doFastOrMode(regs);
  // support ~(foo|bar)~
  regs = fuzzyOr(regs);
  return regs
};

/** parse a match-syntax string into json */
const syntax = function (input, opts, world) {
  // fail-fast
  if (input === null || input === undefined || input === '') {
    return []
  }
  opts = opts || {};
  if (typeof input === 'number') {
    input = String(input); //go for it?
  }
  let tokens = parseBlocks(input);
  //turn them into objects
  tokens = tokens.map(str => parseToken(str, opts));
  // '~re-do~'
  tokens = splitHyphens$1(tokens, world);
  // '{walk}'
  tokens = inflectRoot(tokens, world);
  //clean up anything weird
  tokens = postProcess(tokens);
  // console.log(tokens)
  return tokens
};

const anyIntersection = function (setA, setB) {
  for (let elem of setB) {
    if (setA.has(elem)) {
      return true
    }
  }
  return false
};
// check words/tags against our cache
const failFast = function (regs, cache) {
  for (let i = 0; i < regs.length; i += 1) {
    let reg = regs[i];
    if (reg.optional === true || reg.negative === true || reg.fuzzy === true) {
      continue
    }
    // is the word missing from the cache?
    if (reg.word !== undefined && cache.has(reg.word) === false) {
      return true
    }
    // is the tag missing?
    if (reg.tag !== undefined && cache.has('#' + reg.tag) === false) {
      return true
    }
    // perform a speedup for fast-or
    if (reg.fastOr && anyIntersection(reg.fastOr, cache) === false) {
      return false
    }
  }
  return false
};

// fuzzy-match (damerau-levenshtein)
// Based on  tad-lispy /node-damerau-levenshtein
// https://github.com/tad-lispy/node-damerau-levenshtein/blob/master/index.js
// count steps (insertions, deletions, substitutions, or transpositions)
const editDistance = function (strA, strB) {
  let aLength = strA.length,
    bLength = strB.length;
  // fail-fast
  if (aLength === 0) {
    return bLength
  }
  if (bLength === 0) {
    return aLength
  }
  // If the limit is not defined it will be calculate from this and that args.
  let limit = (bLength > aLength ? bLength : aLength) + 1;
  if (Math.abs(aLength - bLength) > (limit || 100)) {
    return limit || 100
  }
  // init the array
  let matrix = [];
  for (let i = 0; i < limit; i++) {
    matrix[i] = [i];
    matrix[i].length = limit;
  }
  for (let i = 0; i < limit; i++) {
    matrix[0][i] = i;
  }
  // Calculate matrix.
  let j, a_index, b_index, cost, min, t;
  for (let i = 1; i <= aLength; ++i) {
    a_index = strA[i - 1];
    for (j = 1; j <= bLength; ++j) {
      // Check the jagged distance total so far
      if (i === j && matrix[i][j] > 4) {
        return aLength
      }
      b_index = strB[j - 1];
      cost = a_index === b_index ? 0 : 1; // Step 5
      // Calculate the minimum (much faster than Math.min(...)).
      min = matrix[i - 1][j] + 1; // Deletion.
      if ((t = matrix[i][j - 1] + 1) < min) min = t; // Insertion.
      if ((t = matrix[i - 1][j - 1] + cost) < min) min = t; // Substitution.
      // Update matrix.
      let shouldUpdate =
        i > 1 && j > 1 && a_index === strB[j - 2] && strA[i - 2] === b_index && (t = matrix[i - 2][j - 2] + cost) < min;
      if (shouldUpdate) {
        matrix[i][j] = t;
      } else {
        matrix[i][j] = min;
      }
    }
  }
  // return number of steps
  return matrix[aLength][bLength]
};
// score similarity by from 0-1 (steps/length)
const fuzzyMatch = function (strA, strB, minLength = 3) {
  if (strA === strB) {
    return 1
  }
  //don't even bother on tiny strings
  if (strA.length < minLength || strB.length < minLength) {
    return 0
  }
  const steps = editDistance(strA, strB);
  let length = Math.max(strA.length, strB.length);
  let relative = length === 0 ? 0 : steps / length;
  let similarity = 1 - relative;
  return similarity
};

// these methods are called with '@hasComma' in the match syntax
// various unicode quotation-mark formats
const startQuote =
  /([\u0022\uFF02\u0027\u201C\u2018\u201F\u201B\u201E\u2E42\u201A\u00AB\u2039\u2035\u2036\u2037\u301D\u0060\u301F])/;

const endQuote = /([\u0022\uFF02\u0027\u201D\u2019\u00BB\u203A\u2032\u2033\u2034\u301E\u00B4])/;

const hasHyphen$1 = /^[-â€“â€”]$/;
const hasDash$1 = / [-â€“â€”]{1,3} /;

/** search the term's 'post' punctuation  */
const hasPost = (term, punct) => term.post.indexOf(punct) !== -1;
/** search the term's 'pre' punctuation  */
// const hasPre = (term, punct) => term.pre.indexOf(punct) !== -1

const methods$c = {
  /** does it have a quotation symbol?  */
  hasQuote: term => startQuote.test(term.pre) || endQuote.test(term.post),
  /** does it have a comma?  */
  hasComma: term => hasPost(term, ','),
  /** does it end in a period? */
  hasPeriod: term => hasPost(term, '.') === true && hasPost(term, '...') === false,
  /** does it end in an exclamation */
  hasExclamation: term => hasPost(term, '!'),
  /** does it end with a question mark? */
  hasQuestionMark: term => hasPost(term, '?') || hasPost(term, 'Â¿'),
  /** is there a ... at the end? */
  hasEllipses: term => hasPost(term, '..') || hasPost(term, 'â€¦'),
  /** is there a semicolon after term word? */
  hasSemicolon: term => hasPost(term, ';'),
  /** is there a colon after term word? */
  hasColon: term => hasPost(term, ':'),
  /** is there a slash '/' in term word? */
  hasSlash: term => /\//.test(term.text),
  /** a hyphen connects two words like-term */
  hasHyphen: term => hasHyphen$1.test(term.post) || hasHyphen$1.test(term.pre),
  /** a dash separates words - like that */
  hasDash: term => hasDash$1.test(term.post) || hasDash$1.test(term.pre),
  /** is it multiple words combinded */
  hasContraction: term => Boolean(term.implicit),
  /** is it an acronym */
  isAcronym: term => term.tags.has('Acronym'),
  /** does it have any tags */
  isKnown: term => term.tags.size > 0,
  /** uppercase first letter, then a lowercase */
  isTitleCase: term => /^\p{Lu}[a-z'\u00C0-\u00FF]/u.test(term.text),
  /** uppercase all letters */
  isUpperCase: term => /^\p{Lu}+$/u.test(term.text),
};
// aliases
methods$c.hasQuotation = methods$c.hasQuote;

//declare it up here
let wrapMatch = function () { };
/** ignore optional/greedy logic, straight-up term match*/
const doesMatch$1 = function (term, reg, index, length) {
  // support '.'
  if (reg.anything === true) {
    return true
  }
  // support '^' (in parentheses)
  if (reg.start === true && index !== 0) {
    return false
  }
  // support '$' (in parentheses)
  if (reg.end === true && index !== length - 1) {
    return false
  }
  // match an id
  if (reg.id !== undefined && reg.id === term.id) {
    return true
  }
  //support a text match
  if (reg.word !== undefined) {
    // check case-sensitivity, etc
    if (reg.use) {
      return reg.word === term[reg.use]
    }
    //match contractions, machine-form
    if (term.machine !== null && term.machine === reg.word) {
      return true
    }
    // term aliases for slashes and things
    if (term.alias !== undefined && term.alias.hasOwnProperty(reg.word)) {
      return true
    }
    // support ~ fuzzy match
    if (reg.fuzzy === true) {
      if (reg.word === term.root) {
        return true
      }
      let score = fuzzyMatch(reg.word, term.normal);
      if (score >= reg.min) {
        return true
      }
    }
    // match slashes and things
    if (term.alias && term.alias.some(str => str === reg.word)) {
      return true
    }
    //match either .normal or .text
    return reg.word === term.text || reg.word === term.normal
  }
  //support #Tag
  if (reg.tag !== undefined) {
    return term.tags.has(reg.tag) === true
  }
  //support @method
  if (reg.method !== undefined) {
    if (typeof methods$c[reg.method] === 'function' && methods$c[reg.method](term) === true) {
      return true
    }
    return false
  }
  //support whitespace/punctuation
  if (reg.pre !== undefined) {
    return term.pre && term.pre.includes(reg.pre)
  }
  if (reg.post !== undefined) {
    return term.post && term.post.includes(reg.post)
  }
  //support /reg/
  if (reg.regex !== undefined) {
    let str = term.normal;
    if (reg.use) {
      str = term[reg.use];
    }
    return reg.regex.test(str)
  }
  //support <chunk>
  if (reg.chunk !== undefined) {
    return term.chunk === reg.chunk
  }
  //support %Noun|Verb%
  if (reg.switch !== undefined) {
    return term.switch === reg.switch
  }
  //support {machine}
  if (reg.machine !== undefined) {
    return term.normal === reg.machine || term.machine === reg.machine || term.root === reg.machine
  }
  //support {word/sense}
  if (reg.sense !== undefined) {
    return term.sense === reg.sense
  }
  // support optimized (one|two)
  if (reg.fastOr !== undefined) {
    // {work/verb} must be a verb
    if (reg.pos && !term.tags.has(reg.pos)) {
      return null
    }
    let str = term.root || term.implicit || term.machine || term.normal;
    return reg.fastOr.has(str) || reg.fastOr.has(term.text)
  }
  //support slower (one|two)
  if (reg.choices !== undefined) {
    // try to support && operator
    if (reg.operator === 'and') {
      // must match them all
      return reg.choices.every(r => wrapMatch(term, r, index, length))
    }
    // or must match one
    return reg.choices.some(r => wrapMatch(term, r, index, length))
  }
  return false
};
// wrap result for !negative match logic
wrapMatch = function (t, reg, index, length) {
  let result = doesMatch$1(t, reg, index, length);
  if (reg.negative === true) {
    return !result
  }
  return result
};

// for greedy checking, we no longer care about the reg.start
// value, and leaving it can cause failures for anchored greedy
// matches.  ditto for end-greedy matches: we need an earlier non-
// ending match to succceed until we get to the actual end.
const getGreedy = function (state, endReg) {
  let reg = Object.assign({}, state.regs[state.r], { start: false, end: false });
  let start = state.t;
  for (; state.t < state.terms.length; state.t += 1) {
    //stop for next-reg match
    if (endReg && wrapMatch(state.terms[state.t], endReg, state.start_i + state.t, state.phrase_length)) {
      return state.t
    }
    let count = state.t - start + 1;
    // is it max-length now?
    if (reg.max !== undefined && count === reg.max) {
      return state.t
    }
    //stop here
    if (wrapMatch(state.terms[state.t], reg, state.start_i + state.t, state.phrase_length) === false) {
      // is it too short?
      if (reg.min !== undefined && count < reg.min) {
        return null
      }
      return state.t
    }
  }
  return state.t
};

const greedyTo = function (state, nextReg) {
  let t = state.t;
  //if there's no next one, just go off the end!
  if (!nextReg) {
    return state.terms.length
  }
  //otherwise, we're looking for the next one
  for (; t < state.terms.length; t += 1) {
    if (wrapMatch(state.terms[t], nextReg, state.start_i + t, state.phrase_length) === true) {
      // console.log(`greedyTo ${state.terms[t].normal}`)
      return t
    }
  }
  //guess it doesn't exist, then.
  return null
};

const isEndGreedy = function (reg, state) {
  if (reg.end === true && reg.greedy === true) {
    if (state.start_i + state.t < state.phrase_length - 1) {
      let tmpReg = Object.assign({}, reg, { end: false });
      if (wrapMatch(state.terms[state.t], tmpReg, state.start_i + state.t, state.phrase_length) === true) {
        // console.log(`endGreedy ${state.terms[state.t].normal}`)
        return true
      }
    }
  }
  return false
};

const getGroup$1 = function (state, term_index) {
  if (state.groups[state.inGroup]) {
    return state.groups[state.inGroup]
  }
  state.groups[state.inGroup] = {
    start: term_index,
    length: 0,
  };
  return state.groups[state.inGroup]
};

//support 'unspecific greedy' .* properly
// its logic is 'greedy until', where it's looking for the next token
// '.+ foo' means we check for 'foo', indefinetly
const doAstrix = function (state) {
  let { regs } = state;
  let reg = regs[state.r];

  let skipto = greedyTo(state, regs[state.r + 1]);
  //maybe we couldn't find it
  if (skipto === null || skipto === 0) {
    return null
  }
  // ensure it's long enough
  if (reg.min !== undefined && skipto - state.t < reg.min) {
    return null
  }
  // reduce it back, if it's too long
  if (reg.max !== undefined && skipto - state.t > reg.max) {
    state.t = state.t + reg.max;
    return true
  }
  // set the group result
  if (state.hasGroup === true) {
    const g = getGroup$1(state, state.t);
    g.length = skipto - state.t;
  }
  state.t = skipto;
  // log(`âœ“ |greedy|`)
  return true
};

const isArray$5 = function (arr) {
  return Object.prototype.toString.call(arr) === '[object Array]'
};

const doOrBlock = function (state, skipN = 0) {
  let block = state.regs[state.r];
  let wasFound = false;
  // do each multiword sequence
  for (let c = 0; c < block.choices.length; c += 1) {
    // try to match this list of tokens
    let regs = block.choices[c];
    if (!isArray$5(regs)) {
      return false
    }
    wasFound = regs.every((cr, w_index) => {
      let extra = 0;
      let t = state.t + w_index + skipN + extra;
      if (state.terms[t] === undefined) {
        return false
      }
      let foundBlock = wrapMatch(state.terms[t], cr, t + state.start_i, state.phrase_length);
      // this can be greedy - '(foo+ bar)'
      if (foundBlock === true && cr.greedy === true) {
        for (let i = 1; i < state.terms.length; i += 1) {
          let term = state.terms[t + i];
          if (term) {
            let keepGoing = wrapMatch(term, cr, state.start_i + i, state.phrase_length);
            if (keepGoing === true) {
              extra += 1;
            } else {
              break
            }
          }
        }
      }
      skipN += extra;
      return foundBlock
    });
    if (wasFound) {
      skipN += regs.length;
      break
    }
  }
  // we found a match -  is it greedy though?
  if (wasFound && block.greedy === true) {
    return doOrBlock(state, skipN) // try it again!
  }
  return skipN
};

const doAndBlock = function (state) {
  let longest = 0;
  // all blocks must match, and we return the greediest match
  let reg = state.regs[state.r];
  let allDidMatch = reg.choices.every(block => {
    //  for multi-word blocks, all must match
    let allWords = block.every((cr, w_index) => {
      let tryTerm = state.t + w_index;
      if (state.terms[tryTerm] === undefined) {
        return false
      }
      return wrapMatch(state.terms[tryTerm], cr, tryTerm, state.phrase_length)
    });
    if (allWords === true && block.length > longest) {
      longest = block.length;
    }
    return allWords
  });
  if (allDidMatch === true) {
    // console.log(`doAndBlock ${state.terms[state.t].normal}`)
    return longest
  }
  return false
};

const orBlock = function (state) {
  const { regs } = state;
  let reg = regs[state.r];
  let skipNum = doOrBlock(state);
  // did we find a match?
  if (skipNum) {
    // handle 'not' logic
    if (reg.negative === true) {
      return null // die
    }
    // tuck in as named-group
    if (state.hasGroup === true) {
      const g = getGroup$1(state, state.t);
      g.length += skipNum;
    }
    // ensure we're at the end
    if (reg.end === true) {
      let end = state.phrase_length;
      if (state.t + state.start_i + skipNum !== end) {
        return null
      }
    }
    state.t += skipNum;
    // log(`âœ“ |found-or|`)
    return true
  } else if (!reg.optional) {
    return null //die
  }
  return true
};

// '(foo && #Noun)' - require all matches on the term
const andBlock = function (state) {
  const { regs } = state;
  let reg = regs[state.r];

  let skipNum = doAndBlock(state);
  if (skipNum) {
    // handle 'not' logic
    if (reg.negative === true) {
      return null // die
    }
    if (state.hasGroup === true) {
      const g = getGroup$1(state, state.t);
      g.length += skipNum;
    }
    // ensure we're at the end
    if (reg.end === true) {
      let end = state.phrase_length - 1;
      if (state.t + state.start_i !== end) {
        return null
      }
    }
    state.t += skipNum;
    // log(`âœ“ |found-and|`)
    return true
  } else if (!reg.optional) {
    return null //die
  }
  return true
};

const negGreedy = function (state, reg, nextReg) {
  let skip = 0;
  for (let t = state.t; t < state.terms.length; t += 1) {
    let found = wrapMatch(state.terms[t], reg, state.start_i + state.t, state.phrase_length);
    // we don't want a match, here
    if (found) {
      break//stop going
    }
    // are we doing 'greedy-to'?
    // - "!foo+ after"  should stop at 'after'
    if (nextReg) {
      found = wrapMatch(state.terms[t], nextReg, state.start_i + state.t, state.phrase_length);
      if (found) {
        break
      }
    }
    skip += 1;
    // is it max-length now?
    if (reg.max !== undefined && skip === reg.max) {
      break
    }
  }
  if (skip === 0) {
    return false //dead
  }
  // did we satisfy min for !foo{min,max}
  if (reg.min && reg.min > skip) {
    return false//dead
  }
  state.t += skip;
  // state.r += 1
  return true
};

// '!foo' should match anything that isn't 'foo'
// if it matches, return false
const doNegative = function (state) {
  const { regs } = state;
  let reg = regs[state.r];

  // match *anything* but this term
  let tmpReg = Object.assign({}, reg);
  tmpReg.negative = false; // try removing it

  // found it? if so, we die here
  let found = wrapMatch(state.terms[state.t], tmpReg, state.start_i + state.t, state.phrase_length);
  if (found) {
    return false//bye
  }
  // should we skip the term too?
  if (reg.optional) {
    // "before after" - "before !foo? after"
    // does the next reg match the this term?
    let nextReg = regs[state.r + 1];
    if (nextReg) {
      let fNext = wrapMatch(state.terms[state.t], nextReg, state.start_i + state.t, state.phrase_length);
      if (fNext) {
        state.r += 1;
      } else if (nextReg.optional && regs[state.r + 2]) {
        // ugh. ok,
        // support "!foo? extra? need"
        // but don't scan ahead more than that.
        let fNext2 = wrapMatch(state.terms[state.t], regs[state.r + 2], state.start_i + state.t, state.phrase_length);
        if (fNext2) {
          state.r += 2;
        }
      }
    }
  }
  // negative greedy - !foo+  - super hard!
  if (reg.greedy) {
    return negGreedy(state, tmpReg, regs[state.r + 1])
  }
  state.t += 1;
  return true
};

// 'foo? foo' matches are tricky.
const foundOptional = function (state) {
  const { regs } = state;
  let reg = regs[state.r];
  let term = state.terms[state.t];
  // does the next reg match it too?
  let nextRegMatched = wrapMatch(term, regs[state.r + 1], state.start_i + state.t, state.phrase_length);
  if (reg.negative || nextRegMatched) {
    // but does the next reg match the next term??
    // only skip if it doesn't
    let nextTerm = state.terms[state.t + 1];
    if (!nextTerm || !wrapMatch(nextTerm, regs[state.r + 1], state.start_i + state.t, state.phrase_length)) {
      state.r += 1;
    }
  }
};

// keep 'foo+' or 'foo*' going..
const greedyMatch = function (state) {
  const { regs, phrase_length } = state;
  let reg = regs[state.r];
  state.t = getGreedy(state, regs[state.r + 1]);
  if (state.t === null) {
    return null //greedy was too short
  }
  // foo{2,4} - has a greed-minimum
  if (reg.min && reg.min > state.t) {
    return null //greedy was too short
  }
  // 'foo+$' - if also an end-anchor, ensure we really reached the end
  if (reg.end === true && state.start_i + state.t !== phrase_length) {
    return null //greedy didn't reach the end
  }
  return true
};

// for: ['we', 'have']
// a match for "we have" should work as normal
// but matching "we've" should skip over implict terms
const contractionSkip = function (state) {
  let term = state.terms[state.t];
  let reg = state.regs[state.r];
  // did we match the first part of a contraction?
  if (term.implicit && state.terms[state.t + 1]) {
    let nextTerm = state.terms[state.t + 1];
    // ensure next word is implicit
    if (!nextTerm.implicit) {
      return
    }
    // we matched "we've" - skip-over [we, have]
    if (reg.word === term.normal) {
      state.t += 1;
    }
    // also skip for @hasContraction
    if (reg.method === 'hasContraction') {
      state.t += 1;
    }
  }
};

// '[foo]' should also be logged as a group
const setGroup = function (state, startAt) {
  let reg = state.regs[state.r];
  // Get or create capture group
  const g = getGroup$1(state, startAt);
  // Update group - add greedy or increment length
  if (state.t > 1 && reg.greedy) {
    g.length += state.t - startAt;
  } else {
    g.length++;
  }
};

// when a reg matches a term
const simpleMatch = function (state) {
  const { regs } = state;
  let reg = regs[state.r];
  let term = state.terms[state.t];
  let startAt = state.t;
  // if it's a negative optional match... :0
  if (reg.optional && regs[state.r + 1] && reg.negative) {
    return true
  }
  // okay, it was a match, but if it's optional too,
  // we should check the next reg too, to skip it?
  if (reg.optional && regs[state.r + 1]) {
    foundOptional(state);
  }
  // Contraction skip:
  // did we match the first part of a contraction?
  if (term.implicit && state.terms[state.t + 1]) {
    contractionSkip(state);
  }
  //advance to the next term!
  state.t += 1;
  //check any ending '$' flags
  //if this isn't the last term, refuse the match
  if (reg.end === true && state.t !== state.terms.length && reg.greedy !== true) {
    return null //die
  }
  // keep 'foo+' going...
  if (reg.greedy === true) {
    let alive = greedyMatch(state);
    if (!alive) {
      return null
    }
  }
  // log '[foo]' as a group
  if (state.hasGroup === true) {
    setGroup(state, startAt);
  }
  return true
};

// i formally apologize for how complicated this is.

/** 
 * try a sequence of match tokens ('regs') 
 * on a sequence of terms, 
 * starting at this certain term.
 */
const tryHere = function (terms, regs, start_i, phrase_length) {
  // console.log(`\n\n:start: '${terms[0].text}':`)
  if (terms.length === 0 || regs.length === 0) {
    return null
  }
  // all the variables that matter
  let state = {
    t: 0,
    terms: terms,
    r: 0,
    regs: regs,
    groups: {},
    start_i: start_i,
    phrase_length: phrase_length,
    inGroup: null,
  };

  // we must satisfy every token in 'regs'
  // if we get to the end, we have a match.
  for (; state.r < regs.length; state.r += 1) {
    let reg = regs[state.r];
    // Check if this reg has a named capture group
    state.hasGroup = Boolean(reg.group);
    // Reuse previous capture group if same
    if (state.hasGroup === true) {
      state.inGroup = reg.group;
    } else {
      state.inGroup = null;
    }
    //have we run-out of terms?
    if (!state.terms[state.t]) {
      //are all remaining regs optional or negative?
      const alive = regs.slice(state.r).some(remain => !remain.optional);
      if (alive === false) {
        break //done!
      }
      return null // die
    }
    // support 'unspecific greedy' .* properly
    if (reg.anything === true && reg.greedy === true) {
      let alive = doAstrix(state);
      if (!alive) {
        return null
      }
      continue
    }
    // slow-OR - multi-word OR (a|b|foo bar)
    if (reg.choices !== undefined && reg.operator === 'or') {
      let alive = orBlock(state);
      if (!alive) {
        return null
      }
      continue
    }
    // slow-AND - multi-word AND (#Noun && foo) blocks
    if (reg.choices !== undefined && reg.operator === 'and') {
      let alive = andBlock(state);
      if (!alive) {
        return null
      }
      continue
    }
    // support '.' as any-single
    if (reg.anything === true) {
      // '!.' negative anything should insta-fail
      if (reg.negative && reg.anything) {
        return null
      }
      let alive = simpleMatch(state);
      if (!alive) {
        return null
      }
      continue
    }
    // support 'foo*$' until the end
    if (isEndGreedy(reg, state) === true) {
      let alive = simpleMatch(state);
      if (!alive) {
        return null
      }
      continue
    }
    // ok, it doesn't match - but maybe it wasn't *supposed* to?
    if (reg.negative) {
      // we want *anything* but this term
      let alive = doNegative(state);
      if (!alive) {
        return null
      }
      continue
    }
    // ok, finally test the term-reg
    let hasMatch = wrapMatch(state.terms[state.t], reg, state.start_i + state.t, state.phrase_length);
    if (hasMatch === true) {
      let alive = simpleMatch(state);
      if (!alive) {
        return null
      }
      continue
    }
    //ok who cares, keep going
    if (reg.optional === true) {
      continue
    }

    // finally, we die
    return null
  }
  //return our results, as pointers
  let pntr = [null, start_i, state.t + start_i];
  if (pntr[1] === pntr[2]) {
    return null //found 0 terms
  }
  let groups = {};
  Object.keys(state.groups).forEach(k => {
    let o = state.groups[k];
    let start = start_i + o.start;
    groups[k] = [null, start, start + o.length];
  });
  return { pointer: pntr, groups: groups }
};

// support returning a subset of a match
// like 'foo [bar] baz' -> bar
const getGroup = function (res, group) {
  let ptrs = [];
  let byGroup = {};
  if (res.length === 0) {
    return { ptrs, byGroup }
  }
  if (typeof group === 'number') {
    group = String(group);
  }
  if (group) {
    res.forEach(r => {
      if (r.groups[group]) {
        ptrs.push(r.groups[group]);
      }
    });
  } else {
    res.forEach(r => {
      ptrs.push(r.pointer);
      Object.keys(r.groups).forEach(k => {
        byGroup[k] = byGroup[k] || [];
        byGroup[k].push(r.groups[k]);
      });
    });
  }
  return { ptrs, byGroup }
};

const notIf$1 = function (results, not, docs) {
  results = results.filter(res => {
    let [n, start, end] = res.pointer;
    let terms = docs[n].slice(start, end);
    for (let i = 0; i < terms.length; i += 1) {
      let slice = terms.slice(i);
      let found = tryHere(slice, not, i, terms.length);
      if (found !== null) {
        return false
      }
    }
    return true
  });
  return results
};

// make proper pointers
const addSentence = function (res, n) {
  res.pointer[0] = n;
  Object.keys(res.groups).forEach(k => {
    res.groups[k][0] = n;
  });
  return res
};

const handleStart = function (terms, regs, n) {
  let res = tryHere(terms, regs, 0, terms.length);
  if (res) {
    res = addSentence(res, n);
    return res //getGroup([res], group)
  }
  return null
};

// ok, here we go.
const runMatch$1 = function (docs, todo, cache) {
  cache = cache || [];
  let { regs, group, justOne } = todo;
  let results = [];
  if (!regs || regs.length === 0) {
    return { ptrs: [], byGroup: {} }
  }

  const minLength = regs.filter(r => r.optional !== true && r.negative !== true).length;
  docs: for (let n = 0; n < docs.length; n += 1) {
    let terms = docs[n];
    // let index = terms[0].index || []
    // can we skip this sentence?
    if (cache[n] && failFast(regs, cache[n])) {
      continue
    }
    // ^start regs only run once, per phrase
    if (regs[0].start === true) {
      let foundStart = handleStart(terms, regs, n);
      if (foundStart) {
        results.push(foundStart);
      }
      continue
    }
    //ok, try starting the match now from every term
    for (let i = 0; i < terms.length; i += 1) {
      let slice = terms.slice(i);
      // ensure it's long-enough
      if (slice.length < minLength) {
        break
      }
      let res = tryHere(slice, regs, i, terms.length);
      // did we find a result?
      if (res) {
        // res = addSentence(res, index[0])
        res = addSentence(res, n);
        results.push(res);
        // should we stop here?
        if (justOne === true) {
          break docs
        }
        // skip ahead, over these results
        let end = res.pointer[2];
        if (Math.abs(end - 1) > i) {
          i = Math.abs(end - 1);
        }
      }
    }
  }
  // ensure any end-results ($) match until the last term
  if (regs[regs.length - 1].end === true) {
    results = results.filter(res => {
      let n = res.pointer[0];
      return docs[n].length === res.pointer[2]
    });
  }
  if (todo.notIf) {
    results = notIf$1(results, todo.notIf, docs);
  }
  // grab the requested group
  results = getGroup(results, group);
  // add ids to pointers
  results.ptrs.forEach(ptr => {
    let [n, start, end] = ptr;
    ptr[3] = docs[n][start].id;//start-id
    ptr[4] = docs[n][end - 1].id;//end-id
  });
  return results
};

const methods$b = {
  one: {
    termMethods: methods$c,
    parseMatch: syntax,
    match: runMatch$1,
  },
};

var lib$3 = {
  /** pre-parse any match statements */
  parseMatch: function (str, opts) {
    const world = this.world();
    let killUnicode = world.methods.one.killUnicode;
    if (killUnicode) {
      str = killUnicode(str, world);
    }
    return world.methods.one.parseMatch(str, opts, world)
  }
};

var match = {
  api: matchAPI,
  methods: methods$b,
  lib: lib$3,
};

const isClass = /^\../;
const isId = /^#./;

const escapeXml = str => {
  str = str.replace(/&/g, '&amp;');
  str = str.replace(/</g, '&lt;');
  str = str.replace(/>/g, '&gt;');
  str = str.replace(/"/g, '&quot;');
  str = str.replace(/'/g, '&apos;');
  return str
};

// interpret .class, #id, tagName
const toTag = function (k) {
  let start = '';
  let end = '</span>';
  k = escapeXml(k);
  if (isClass.test(k)) {
    start = `<span class="${k.replace(/^\./, '')}"`;
  } else if (isId.test(k)) {
    start = `<span id="${k.replace(/^#/, '')}"`;
  } else {
    start = `<${k}`;
    end = `</${k}>`;
  }
  start += '>';
  return { start, end }
};

const getIndex = function (doc, obj) {
  let starts = {};
  let ends = {};
  Object.keys(obj).forEach(k => {
    let res = obj[k];
    let tag = toTag(k);
    if (typeof res === 'string') {
      res = doc.match(res);
    }
    res.docs.forEach(terms => {
      // don't highlight implicit terms
      if (terms.every(t => t.implicit)) {
        return
      }
      let a = terms[0].id;
      starts[a] = starts[a] || [];
      starts[a].push(tag.start);
      let b = terms[terms.length - 1].id;
      ends[b] = ends[b] || [];
      ends[b].push(tag.end);
    });
  });
  return { starts, ends }
};

const html = function (obj) {
  // index ids to highlight
  let { starts, ends } = getIndex(this, obj);
  // create the text output
  let out = '';
  this.docs.forEach(terms => {
    for (let i = 0; i < terms.length; i += 1) {
      let t = terms[i];
      // do a span tag
      if (starts.hasOwnProperty(t.id)) {
        out += starts[t.id].join('');
      }
      out += t.pre || '';
      out += t.text || '';
      if (ends.hasOwnProperty(t.id)) {
        out += ends[t.id].join('');
      }
      out += t.post || '';
    }
  });
  return out
};
var html$1 = { html };

const trimEnd = /[,:;)\]*.?~!\u0022\uFF02\u201D\u2019\u00BB\u203A\u2032\u2033\u2034\u301E\u00B4â€”-]+$/;
const trimStart =
  /^[(['"*~\uFF02\u201C\u2018\u201F\u201B\u201E\u2E42\u201A\u00AB\u2039\u2035\u2036\u2037\u301D\u0060\u301F]+/;

const punctToKill = /[,:;)('"\u201D\]]/;
const isHyphen = /^[-â€“â€”]$/;
const hasSpace = / /;

const textFromTerms = function (terms, opts, keepSpace = true) {
  let txt = '';
  terms.forEach(t => {
    let pre = t.pre || '';
    let post = t.post || '';
    if (opts.punctuation === 'some') {
      pre = pre.replace(trimStart, '');
      // replace a hyphen with a space
      if (isHyphen.test(post)) {
        post = ' ';
      }
      post = post.replace(punctToKill, '');
      // cleanup exclamations
      post = post.replace(/\?!+/, '?');
      post = post.replace(/!+/, '!');
      post = post.replace(/\?+/, '?');
      // kill elipses
      post = post.replace(/\.{2,}/, '');
      // kill abbreviation periods
      if (t.tags.has('Abbreviation')) {
        post = post.replace(/\./, '');
      }
    }
    if (opts.whitespace === 'some') {
      pre = pre.replace(/\s/, ''); //remove pre-whitespace
      post = post.replace(/\s+/, ' '); //replace post-whitespace with a space
    }
    if (!opts.keepPunct) {
      pre = pre.replace(trimStart, '');
      if (post === '-') {
        post = ' ';
      } else {
        post = post.replace(trimEnd, '');
      }
    }
    // grab the correct word format
    let word = t[opts.form || 'text'] || t.normal || '';
    if (opts.form === 'implicit') {
      word = t.implicit || t.text;
    }
    if (opts.form === 'root' && t.implicit) {
      word = t.root || t.implicit || t.normal;
    }
    // add an implicit space, for contractions
    if ((opts.form === 'machine' || opts.form === 'implicit' || opts.form === 'root') && t.implicit) {
      if (!post || !hasSpace.test(post)) {
        post += ' ';
      }
    }
    txt += pre + word + post;
  });
  if (keepSpace === false) {
    txt = txt.trim();
  }
  if (opts.lowerCase === true) {
    txt = txt.toLowerCase();
  }
  return txt
};

const textFromDoc = function (docs, opts) {
  let text = '';
  if (!docs || !docs[0] || !docs[0][0]) {
    return text
  }
  for (let i = 0; i < docs.length; i += 1) {
    // middle
    text += textFromTerms(docs[i], opts, true);
  }
  if (!opts.keepSpace) {
    text = text.trim();
  }
  if (opts.keepEndPunct === false) {
    // don't remove ':)' etc
    if (!docs[0][0].tags.has('Emoticon')) {
      text = text.replace(trimStart, '');
    }
    // remove ending periods
    let last = docs[docs.length - 1];
    if (!last[last.length - 1].tags.has('Emoticon')) {
      text = text.replace(trimEnd, '');
    }
    // kill end quotations
    if (text.endsWith(`'`) && !text.endsWith(`s'`)) {
      text = text.replace(/'/, '');
    }
  }
  if (opts.cleanWhitespace === true) {
    text = text.trim();
  }
  return text
};

const fmts = {
  text: {
    form: 'text',
  },
  normal: {
    whitespace: 'some',
    punctuation: 'some',
    case: 'some',
    unicode: 'some',
    form: 'normal',
  },
  machine: {
    keepSpace: false,
    whitespace: 'some',
    punctuation: 'some',
    case: 'none',
    unicode: 'some',
    form: 'machine',
  },
  root: {
    keepSpace: false,
    whitespace: 'some',
    punctuation: 'some',
    case: 'some',
    unicode: 'some',
    form: 'root',
  },
  implicit: {
    form: 'implicit',
  }
};
fmts.clean = fmts.normal;
fmts.reduced = fmts.root;

/* eslint-disable no-bitwise */
/* eslint-disable no-mixed-operators */
/* eslint-disable no-multi-assign */

// https://github.com/jbt/tiny-hashes/
let k$1 = [],
  i$2 = 0;
for (; i$2 < 64; ) {
  k$1[i$2] = 0 | (Math.sin(++i$2 % Math.PI) * 4294967296);
}

const md5 = function (s) {
  let b,
    c,
    d,
    h = [(b = 0x67452301), (c = 0xefcdab89), ~b, ~c],
    words = [],
    j = decodeURI(encodeURI(s)) + '\x80',
    a = j.length;

  s = (--a / 4 + 2) | 15;

  words[--s] = a * 8;

  for (; ~a; ) {
    words[a >> 2] |= j.charCodeAt(a) << (8 * a--);
  }

  for (i$2 = j = 0; i$2 < s; i$2 += 16) {
    a = h;

    for (
      ;
      j < 64;
      a = [
        (d = a[3]),
        b +
          (((d =
            a[0] +
            [(b & c) | (~b & d), (d & b) | (~d & c), b ^ c ^ d, c ^ (b | ~d)][(a = j >> 4)] +
            k$1[j] +
            ~~words[i$2 | ([j, 5 * j + 1, 3 * j + 5, 7 * j][a] & 15)]) <<
            (a = [7, 12, 17, 22, 5, 9, 14, 20, 4, 11, 16, 23, 6, 10, 15, 21][4 * a + (j++ % 4)])) |
            (d >>> -a)),
        b,
        c,
      ]
    ) {
      b = a[1] | 0;
      c = a[2];
    }
    for (j = 4; j; ) h[--j] += a[j];
  }

  for (s = ''; j < 32; ) {
    s += ((h[j >> 3] >> ((1 ^ j++) * 4)) & 15).toString(16);
  }

  return s
};
// console.log(md5('food-safety'))

const defaults$2 = {
  text: true,
  terms: true,
};

let opts = { case: 'none', unicode: 'some', form: 'machine', punctuation: 'some' };

const merge = function (a, b) {
  return Object.assign({}, a, b)
};

const fns$2 = {
  text: terms => textFromTerms(terms, { keepPunct: true }, false),
  normal: terms => textFromTerms(terms, merge(fmts.normal, { keepPunct: true }), false),
  implicit: terms => textFromTerms(terms, merge(fmts.implicit, { keepPunct: true }), false),

  machine: terms => textFromTerms(terms, opts, false),
  root: terms => textFromTerms(terms, merge(opts, { form: 'root' }), false),

  hash: terms => md5(textFromTerms(terms, { keepPunct: true }, false)),

  offset: terms => {
    let len = fns$2.text(terms).length;
    return {
      index: terms[0].offset.index,
      start: terms[0].offset.start,
      length: len,
    }
  },
  terms: terms => {
    return terms.map(t => {
      let term = Object.assign({}, t);
      term.tags = Array.from(t.tags);
      return term
    })
  },
  confidence: (_terms, view, i) => view.eq(i).confidence(),
  syllables: (_terms, view, i) => view.eq(i).syllables(),
  sentence: (_terms, view, i) => view.eq(i).fullSentence().text(),
  dirty: terms => terms.some(t => t.dirty === true),
};
fns$2.sentences = fns$2.sentence;
fns$2.clean = fns$2.normal;
fns$2.reduced = fns$2.root;

const toJSON$2 = function (view, option) {
  option = option || {};
  if (typeof option === 'string') {
    option = {};
  }
  option = Object.assign({}, defaults$2, option);
  // run any necessary upfront steps
  if (option.offset) {
    view.compute('offset');
  }
  return view.docs.map((terms, i) => {
    let res = {};
    Object.keys(option).forEach(k => {
      if (option[k] && fns$2[k]) {
        res[k] = fns$2[k](terms, view, i);
      }
    });
    return res
  })
};

const methods$a = {
  /** return data */
  json: function (n) {
    let res = toJSON$2(this, n);
    if (typeof n === 'number') {
      return res[n]
    }
    return res
  },
};
methods$a.data = methods$a.json;

const isClientSide = () => typeof window !== 'undefined' && window.document;

//output some helpful stuff to the console
const debug$1 = function (fmt) {
  let debugMethods = this.methods.one.debug || {};
  // see if method name exists
  if (fmt && debugMethods.hasOwnProperty(fmt)) {
    debugMethods[fmt](this);
    return this
  }
  // log default client-side view
  if (isClientSide()) {
    debugMethods.clientSide(this);
    return this
  }
  // else, show regular server-side tags view
  debugMethods.tags(this);
  return this
};

const toText$3 = function (term) {
  let pre = term.pre || '';
  let post = term.post || '';
  return pre + term.text + post
};

const findStarts = function (doc, obj) {
  let starts = {};
  Object.keys(obj).forEach(reg => {
    let m = doc.match(reg);
    m.fullPointer.forEach(a => {
      starts[a[3]] = { fn: obj[reg], end: a[2] };
    });
  });
  return starts
};

const wrap$1 = function (doc, obj) {
  // index ids to highlight
  let starts = findStarts(doc, obj);
  let text = '';
  doc.docs.forEach((terms, n) => {
    for (let i = 0; i < terms.length; i += 1) {
      let t = terms[i];
      // do a span tag
      if (starts.hasOwnProperty(t.id)) {
        let { fn, end } = starts[t.id];
        let m = doc.update([[n, i, end]]);
        text += terms[i].pre || '';
        text += fn(m);
        i = end - 1;
        text += terms[i].post || '';
      } else {
        text += toText$3(t);
      }
    }
  });
  return text
};

const isObject$2 = val => {
  return Object.prototype.toString.call(val) === '[object Object]'
};

// sort by frequency
const topk = function (arr) {
  let obj = {};
  arr.forEach(a => {
    obj[a] = obj[a] || 0;
    obj[a] += 1;
  });
  let res = Object.keys(obj).map(k => {
    return { normal: k, count: obj[k] }
  });
  return res.sort((a, b) => (a.count > b.count ? -1 : 0))
};

/** some named output formats */
const out = function (method) {
  // support custom outputs
  if (isObject$2(method)) {
    return wrap$1(this, method)
  }
  // text out formats
  if (method === 'text') {
    return this.text()
  }
  if (method === 'normal') {
    return this.text('normal')
  }
  if (method === 'root') {
    return this.text('root')
  }
  if (method === 'machine' || method === 'reduced') {
    return this.text('machine')
  }
  if (method === 'hash' || method === 'md5') {
    return md5(this.text())
  }

  // json data formats
  if (method === 'json') {
    return this.json()
  }
  if (method === 'offset' || method === 'offsets') {
    this.compute('offset');
    return this.json({ offset: true })
  }
  if (method === 'array') {
    let arr = this.docs.map(terms => {
      return terms
        .reduce((str, t) => {
          return str + t.pre + t.text + t.post
        }, '')
        .trim()
    });
    return arr.filter(str => str)
  }
  // return terms sorted by frequency
  if (method === 'freq' || method === 'frequency' || method === 'topk') {
    return topk(this.json({ normal: true }).map(o => o.normal))
  }

  // some handy ad-hoc outputs
  if (method === 'terms') {
    let list = [];
    this.docs.forEach(terms => {
      let words = terms.map(t => t.text);
      words = words.filter(t => t);
      list = list.concat(words);
    });
    return list
  }
  if (method === 'tags') {
    return this.docs.map(terms => {
      return terms.reduce((h, t) => {
        h[t.implicit || t.normal] = Array.from(t.tags);
        return h
      }, {})
    })
  }
  if (method === 'debug') {
    return this.debug() //allow
  }
  return this.text()
};

const methods$9 = {
  /** */
  debug: debug$1,
  /** */
  out,
  /** */
  wrap: function (obj) {
    return wrap$1(this, obj)
  },
};

const isObject$1 = val => {
  return Object.prototype.toString.call(val) === '[object Object]'
};

var text$2 = {
  /** */
  text: function (fmt) {
    let opts = {};
    if (fmt && typeof fmt === 'string' && fmts.hasOwnProperty(fmt)) {
      opts = Object.assign({}, fmts[fmt]);
    } else if (fmt && isObject$1(fmt)) {
      opts = Object.assign({}, fmt); //todo: fixme
    }
    // is it a full document?
    if (opts.keepSpace === undefined && !this.isFull()) {
      //
      opts.keepSpace = false;
    }
    if (opts.keepEndPunct === undefined && this.pointer) {
      let ptr = this.pointer[0];
      if (ptr && ptr[1]) {
        opts.keepEndPunct = false;
      } else {
        opts.keepEndPunct = true;
      }
    }
    // set defaults
    if (opts.keepPunct === undefined) {
      opts.keepPunct = true;
    }
    if (opts.keepSpace === undefined) {
      opts.keepSpace = true;
    }
    return textFromDoc(this.docs, opts)
  },
};

const methods$8 = Object.assign({}, methods$9, text$2, methods$a, html$1);

const addAPI$1 = function (View) {
  Object.assign(View.prototype, methods$8);
};

/* eslint-disable no-console */
const logClientSide = function (view) {
  console.log('%c -=-=- ', 'background-color:#6699cc;');
  view.forEach(m => {
    console.groupCollapsed(m.text());
    let terms = m.docs[0];
    let out = terms.map(t => {
      let text = t.text || '-';
      if (t.implicit) {
        text = '[' + t.implicit + ']';
      }
      let tags = '[' + Array.from(t.tags).join(', ') + ']';
      return { text, tags }
    });
    console.table(out, ['text', 'tags']);
    console.groupEnd();
  });
};

// https://stackoverflow.com/questions/9781218/how-to-change-node-jss-console-font-color
const reset = '\x1b[0m';

//cheaper than requiring chalk
const cli = {
  green: str => '\x1b[32m' + str + reset,
  red: str => '\x1b[31m' + str + reset,
  blue: str => '\x1b[34m' + str + reset,
  magenta: str => '\x1b[35m' + str + reset,
  cyan: str => '\x1b[36m' + str + reset,
  yellow: str => '\x1b[33m' + str + reset,
  black: str => '\x1b[30m' + str + reset,
  dim: str => '\x1b[2m' + str + reset,
  i: str => '\x1b[3m' + str + reset,
};

/* eslint-disable no-console */

const tagString = function (tags, model) {
  if (model.one.tagSet) {
    tags = tags.map(tag => {
      if (!model.one.tagSet.hasOwnProperty(tag)) {
        return tag
      }
      const c = model.one.tagSet[tag].color || 'blue';
      return cli[c](tag)
    });
  }
  return tags.join(', ')
};

const showTags = function (view) {
  let { docs, model } = view;
  if (docs.length === 0) {
    console.log(cli.blue('\n     â”€â”€â”€â”€â”€â”€'));
  }
  docs.forEach(terms => {
    console.log(cli.blue('\n  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€'));
    terms.forEach(t => {
      let tags = [...(t.tags || [])];
      let text = t.text || '-';
      if (t.sense) {
        text = `{${t.normal}/${t.sense}}`;
      }
      if (t.implicit) {
        text = '[' + t.implicit + ']';
      }
      text = cli.yellow(text);
      let word = "'" + text + "'";
      if (t.reference) {
        let str = view.update([t.reference]).text('normal');
        word += ` - ${cli.dim(cli.i('[' + str + ']'))}`;
      }
      word = word.padEnd(18);
      let str = cli.blue('  â”‚ ') + cli.i(word) + '  - ' + tagString(tags, model);
      console.log(str);
    });
  });
  console.log('\n');
};

/* eslint-disable no-console */

const showChunks = function (view) {
  let { docs } = view;
  console.log('');
  docs.forEach(terms => {
    let out = [];
    terms.forEach(term => {
      if (term.chunk === 'Noun') {
        out.push(cli.blue(term.implicit || term.normal));
      } else if (term.chunk === 'Verb') {
        out.push(cli.green(term.implicit || term.normal));
      } else if (term.chunk === 'Adjective') {
        out.push(cli.yellow(term.implicit || term.normal));
      } else if (term.chunk === 'Pivot') {
        out.push(cli.red(term.implicit || term.normal));
      } else {
        out.push(term.implicit || term.normal);
      }
    });
    console.log(out.join(' '), '\n');
  });
  console.log('\n');
};

/* eslint-disable no-console */

const split$1 = (txt, offset, index) => {
  let buff = index * 9; //there are 9 new chars addded to each highlight
  let start = offset.start + buff;
  let end = start + offset.length;
  let pre = txt.substring(0, start);
  let mid = txt.substring(start, end);
  let post = txt.substring(end, txt.length);
  return [pre, mid, post]
};

const spliceIn = function (txt, offset, index) {
  let parts = split$1(txt, offset, index);
  return `${parts[0]}${cli.blue(parts[1])}${parts[2]}`
};

const showHighlight = function (doc) {
  if (!doc.found) {
    return
  }
  let bySentence = {};
  doc.fullPointer.forEach(ptr => {
    bySentence[ptr[0]] = bySentence[ptr[0]] || [];
    bySentence[ptr[0]].push(ptr);
  });
  Object.keys(bySentence).forEach(k => {
    let full = doc.update([[Number(k)]]);
    let txt = full.text();
    let matches = doc.update(bySentence[k]);
    let json = matches.json({ offset: true });
    json.forEach((obj, i) => {
      txt = spliceIn(txt, obj.offset, i);
    });
    console.log(txt);
  });
  console.log('\n');
};

const debug = {
  tags: showTags,
  clientSide: logClientSide,
  chunks: showChunks,
  highlight: showHighlight,
};

var output = {
  api: addAPI$1,
  methods: {
    one: {
      hash: md5,
      debug,
    },
  },
};

// do the pointers intersect?
const doesOverlap = function (a, b) {
  if (a[0] !== b[0]) {
    return false
  }
  let [, startA, endA] = a;
  let [, startB, endB] = b;
  // [a,a,a,-,-,-,]
  // [-,-,b,b,b,-,]
  if (startA <= startB && endA > startB) {
    return true
  }
  // [-,-,-,a,a,-,]
  // [-,-,b,b,b,-,]
  if (startB <= startA && endB > startA) {
    return true
  }
  return false
};

// get widest min/max
const getExtent = function (ptrs) {
  let min = ptrs[0][1];
  let max = ptrs[0][2];
  ptrs.forEach(ptr => {
    if (ptr[1] < min) {
      min = ptr[1];
    }
    if (ptr[2] > max) {
      max = ptr[2];
    }
  });
  return [ptrs[0][0], min, max]
};

// collect pointers by sentence number
const indexN = function (ptrs) {
  let byN = {};
  ptrs.forEach(ref => {
    byN[ref[0]] = byN[ref[0]] || [];
    byN[ref[0]].push(ref);
  });
  return byN
};

// remove exact duplicates
const uniquePtrs = function (arr) {
  let obj = {};
  for (let i = 0; i < arr.length; i += 1) {
    obj[arr[i].join(',')] = arr[i];
  }
  return Object.values(obj)
};

// a before b
// console.log(doesOverlap([0, 0, 4], [0, 2, 5]))
// // b before a
// console.log(doesOverlap([0, 3, 4], [0, 1, 5]))
// // disjoint
// console.log(doesOverlap([0, 0, 3], [0, 4, 5]))
// neighbours
// console.log(doesOverlap([0, 1, 3], [0, 3, 5]))
// console.log(doesOverlap([0, 3, 5], [0, 1, 3]))

// console.log(
//   getExtent([
//     [0, 3, 4],
//     [0, 4, 5],
//     [0, 1, 2],
//   ])
// )

// split a pointer, by match pointer
const pivotBy = function (full, m) {
  let [n, start] = full;
  let mStart = m[1];
  let mEnd = m[2];
  let res = {};
  // is there space before the match?
  if (start < mStart) {
    let end = mStart < full[2] ? mStart : full[2]; // find closest end-point
    res.before = [n, start, end]; //before segment
  }
  res.match = m;
  // is there space after the match?
  if (full[2] > mEnd) {
    res.after = [n, mEnd, full[2]]; //after segment
  }
  return res
};

const doesMatch = function (full, m) {
  return full[1] <= m[1] && m[2] <= full[2]
};

const splitAll = function (full, m) {
  let byN = indexN(m);
  let res = [];
  full.forEach(ptr => {
    let [n] = ptr;
    let matches = byN[n] || [];
    matches = matches.filter(p => doesMatch(ptr, p));
    if (matches.length === 0) {
      res.push({ passthrough: ptr });
      return
    }
    // ensure matches are in-order
    matches = matches.sort((a, b) => a[1] - b[1]);
    // start splitting our left-to-right
    let carry = ptr;
    matches.forEach((p, i) => {
      let found = pivotBy(carry, p);
      // last one
      if (!matches[i + 1]) {
        res.push(found);
      } else {
        res.push({ before: found.before, match: found.match });
        if (found.after) {
          carry = found.after;
        }
      }
    });
  });
  return res
};

const max$1 = 20;

// sweep-around looking for our start term uuid
const blindSweep = function (id, doc, n) {
  for (let i = 0; i < max$1; i += 1) {
    // look up a sentence
    if (doc[n - i]) {
      let index = doc[n - i].findIndex(term => term.id === id);
      if (index !== -1) {
        return [n - i, index]
      }
    }
    // look down a sentence
    if (doc[n + i]) {
      let index = doc[n + i].findIndex(term => term.id === id);
      if (index !== -1) {
        return [n + i, index]
      }
    }
  }
  return null
};

const repairEnding = function (ptr, document) {
  let [n, start, , , endId] = ptr;
  let terms = document[n];
  // look for end-id
  let newEnd = terms.findIndex(t => t.id === endId);
  if (newEnd === -1) {
    // if end-term wasn't found, so go all the way to the end
    ptr[2] = document[n].length;
    ptr[4] = terms.length ? terms[terms.length - 1].id : null;
  } else {
    ptr[2] = newEnd; // repair ending pointer
  }
  return document[n].slice(start, ptr[2] + 1)
};

/** return a subset of the document, from a pointer */
const getDoc$1 = function (ptrs, document) {
  let doc = [];
  ptrs.forEach((ptr, i) => {
    if (!ptr) {
      return
    }
    let [n, start, end, id, endId] = ptr; //parsePointer(ptr)
    let terms = document[n] || [];
    if (start === undefined) {
      start = 0;
    }
    if (end === undefined) {
      end = terms.length;
    }
    if (id && (!terms[start] || terms[start].id !== id)) {
      // console.log('  repairing pointer...')
      let wild = blindSweep(id, document, n);
      if (wild !== null) {
        let len = end - start;
        terms = document[wild[0]].slice(wild[1], wild[1] + len);
        // actually change the pointer
        let startId = terms[0] ? terms[0].id : null;
        ptrs[i] = [wild[0], wild[1], wild[1] + len, startId];
      }
    } else {
      terms = terms.slice(start, end);
    }
    if (terms.length === 0) {
      return
    }
    if (start === end) {
      return
    }
    // test end-id, if it exists
    if (endId && terms[terms.length - 1].id !== endId) {
      terms = repairEnding(ptr, document);
    }
    // otherwise, looks good!
    doc.push(terms);
  });
  doc = doc.filter(a => a.length > 0);
  return doc
};

// flat list of terms from nested document
const termList = function (docs) {
  let arr = [];
  for (let i = 0; i < docs.length; i += 1) {
    for (let t = 0; t < docs[i].length; t += 1) {
      arr.push(docs[i][t]);
    }
  }
  return arr
};

var methods$7 = {
  one: {
    termList,
    getDoc: getDoc$1,
    pointer: {
      indexN,
      splitAll,
    }
  },
};

// a union is a + b, minus duplicates
const getUnion = function (a, b) {
  let both = a.concat(b);
  let byN = indexN(both);
  let res = [];
  both.forEach(ptr => {
    let [n] = ptr;
    if (byN[n].length === 1) {
      // we're alone on this sentence, so we're good
      res.push(ptr);
      return
    }
    // there may be overlaps
    let hmm = byN[n].filter(m => doesOverlap(ptr, m));
    hmm.push(ptr);
    let range = getExtent(hmm);
    res.push(range);
  });
  res = uniquePtrs(res);
  return res
};

// two disjoint
// console.log(getUnion([[1, 3, 4]], [[0, 1, 2]]))
// two disjoint
// console.log(getUnion([[0, 3, 4]], [[0, 1, 2]]))
// overlap-plus
// console.log(getUnion([[0, 1, 4]], [[0, 2, 6]]))
// overlap
// console.log(getUnion([[0, 1, 4]], [[0, 2, 3]]))
// neighbours
// console.log(getUnion([[0, 1, 3]], [[0, 3, 5]]))

const subtract = function (refs, not) {
  let res = [];
  let found = splitAll(refs, not);
  found.forEach(o => {
    if (o.passthrough) {
      res.push(o.passthrough);
    }
    if (o.before) {
      res.push(o.before);
    }
    if (o.after) {
      res.push(o.after);
    }
  });
  return res
};

// console.log(subtract([[0, 0, 2]], [[0, 0, 1]]))
// console.log(subtract([[0, 0, 2]], [[0, 1, 2]]))

// [a,a,a,a,-,-,]
// [-,-,b,b,b,-,]
// [-,-,x,x,-,-,]
const intersection = function (a, b) {
  // find the latest-start
  let start = a[1] < b[1] ? b[1] : a[1];
  // find the earliest-end
  let end = a[2] > b[2] ? b[2] : a[2];
  // does it form a valid pointer?
  if (start < end) {
    return [a[0], start, end]
  }
  return null
};

const getIntersection = function (a, b) {
  let byN = indexN(b);
  let res = [];
  a.forEach(ptr => {
    let hmm = byN[ptr[0]] || [];
    hmm = hmm.filter(p => doesOverlap(ptr, p));
    // no sentence-pairs, so no intersection
    if (hmm.length === 0) {
      return
    }
    hmm.forEach(h => {
      let overlap = intersection(ptr, h);
      if (overlap) {
        res.push(overlap);
      }
    });
  });
  return res
};

// console.log(getIntersection([[0, 1, 3]], [[0, 2, 4]]))

const isArray$4 = function (arr) {
  return Object.prototype.toString.call(arr) === '[object Array]'
};

const getDoc = (m, view) => {
  if (typeof m === 'string' || isArray$4(m)) {
    return view.match(m)
  }
  if (!m) {
    return view.none()
  }
  // support pre-parsed reg object
  return m
};

// 'harden' our json pointers, again
const addIds = function (ptrs, docs) {
  return ptrs.map(ptr => {
    let [n, start] = ptr;
    if (docs[n] && docs[n][start]) {
      ptr[3] = docs[n][start].id;
    }
    return ptr
  })
};

const methods$6 = {};

// all parts, minus duplicates
methods$6.union = function (m) {
  m = getDoc(m, this);
  let ptrs = getUnion(this.fullPointer, m.fullPointer);
  ptrs = addIds(ptrs, this.document);
  return this.toView(ptrs)
};
methods$6.and = methods$6.union;

// only parts they both have
methods$6.intersection = function (m) {
  m = getDoc(m, this);
  let ptrs = getIntersection(this.fullPointer, m.fullPointer);
  ptrs = addIds(ptrs, this.document);
  return this.toView(ptrs)
};

// only parts of a that b does not have
methods$6.not = function (m) {
  m = getDoc(m, this);
  let ptrs = subtract(this.fullPointer, m.fullPointer);
  ptrs = addIds(ptrs, this.document);
  return this.toView(ptrs)
};
methods$6.difference = methods$6.not;

// get opposite of a match
methods$6.complement = function () {
  let doc = this.all();
  let ptrs = subtract(doc.fullPointer, this.fullPointer);
  ptrs = addIds(ptrs, this.document);
  return this.toView(ptrs)
};

// remove overlaps
methods$6.settle = function () {
  let ptrs = this.fullPointer;
  ptrs.forEach(ptr => {
    ptrs = getUnion(ptrs, [ptr]);
  });
  ptrs = addIds(ptrs, this.document);
  return this.update(ptrs)
};

const addAPI = function (View) {
  // add set/intersection/union
  Object.assign(View.prototype, methods$6);
};

var pointers = {
  methods: methods$7,
  api: addAPI,
};

var lib$2 = {
  // compile a list of matches into a match-net
  buildNet: function (matches) {
    const methods = this.methods();
    let net = methods.one.buildNet(matches, this.world());
    net.isNet = true;
    return net
  }
};

const api$l = function (View) {

  /** speedy match a sequence of matches */
  View.prototype.sweep = function (net, opts = {}) {
    const { world, docs } = this;
    const { methods } = world;
    let found = methods.one.bulkMatch(docs, net, this.methods, opts);

    // apply any changes
    if (opts.tagger !== false) {
      methods.one.bulkTagger(found, docs, this.world);
    }
    // fix the pointers
    // collect all found results into a View
    found = found.map(o => {
      let ptr = o.pointer;
      let term = docs[ptr[0]][ptr[1]];
      let len = ptr[2] - ptr[1];
      if (term.index) {
        o.pointer = [
          term.index[0],
          term.index[1],
          ptr[1] + len
        ];
      }
      return o
    });
    let ptrs = found.map(o => o.pointer);
    // cleanup results a bit
    found = found.map(obj => {
      obj.view = this.update([obj.pointer]);
      delete obj.regs;
      delete obj.needs;
      delete obj.pointer;
      delete obj._expanded;
      return obj
    });
    return {
      view: this.update(ptrs),
      found
    }
  };

};

// extract the clear needs for an individual match token
const getTokenNeeds = function (reg) {
  // negatives can't be cached
  if (reg.optional === true || reg.negative === true) {
    return null
  }
  if (reg.tag) {
    return '#' + reg.tag
  }
  if (reg.word) {
    return reg.word
  }
  if (reg.switch) {
    return `%${reg.switch}%`
  }
  return null
};

const getNeeds = function (regs) {
  let needs = [];
  regs.forEach(reg => {
    needs.push(getTokenNeeds(reg));
    // support AND (foo && tag)
    if (reg.operator === 'and' && reg.choices) {
      reg.choices.forEach(oneSide => {
        oneSide.forEach(r => {
          needs.push(getTokenNeeds(r));
        });
      });
    }
  });
  return needs.filter(str => str)
};

const getWants = function (regs) {
  let wants = [];
  let count = 0;
  regs.forEach(reg => {
    if (reg.operator === 'or' && !reg.optional && !reg.negative) {
      // add fast-or terms
      if (reg.fastOr) {
        Array.from(reg.fastOr).forEach(w => {
          wants.push(w);
        });
      }
      // add slow-or
      if (reg.choices) {
        reg.choices.forEach(rs => {
          rs.forEach(r => {
            let n = getTokenNeeds(r);
            if (n) {
              wants.push(n);
            }
          });
        });
      }
      count += 1;
    }
  });
  return { wants, count }
};

const parse$6 = function (matches, world) {
  const parseMatch = world.methods.one.parseMatch;
  matches.forEach(obj => {
    obj.regs = parseMatch(obj.match, {}, world);
    // wrap these ifNo properties into an array
    if (typeof obj.ifNo === 'string') {
      obj.ifNo = [obj.ifNo];
    }
    if (obj.notIf) {
      obj.notIf = parseMatch(obj.notIf, {}, world);
    }
    // cache any requirements up-front 
    obj.needs = getNeeds(obj.regs);
    let { wants, count } = getWants(obj.regs);
    obj.wants = wants;
    obj.minWant = count;
    // get rid of tiny sentences
    obj.minWords = obj.regs.filter(o => !o.optional).length;
  });
  return matches
};

// do some indexing on the list of matches
const buildNet = function (matches, world) {
  // turn match-syntax into json
  matches = parse$6(matches, world);

  // collect by wants and needs
  let hooks = {};
  matches.forEach(obj => {
    // add needs
    obj.needs.forEach(str => {
      hooks[str] = Array.isArray(hooks[str]) ? hooks[str] : [];
      hooks[str].push(obj);
    });
    // add wants
    obj.wants.forEach(str => {
      hooks[str] = Array.isArray(hooks[str]) ? hooks[str] : [];
      hooks[str].push(obj);
    });
  });
  // remove duplicates
  Object.keys(hooks).forEach(k => {
    let already = {};
    hooks[k] = hooks[k].filter(obj => {
      if (typeof already[obj.match] === 'boolean') {
        return false
      }
      already[obj.match] = true;
      return true
    });
  });

  // keep all un-cacheable matches (those with no needs) 
  let always = matches.filter(o => o.needs.length === 0 && o.wants.length === 0);
  return {
    hooks,
    always
  }
};

// for each cached-sentence, find a list of possible matches
const getHooks = function (docCaches, hooks) {
  return docCaches.map((set, i) => {
    let maybe = [];
    Object.keys(hooks).forEach(k => {
      if (docCaches[i].has(k)) {
        maybe = maybe.concat(hooks[k]);
      }
    });
    // remove duplicates
    let already = {};
    maybe = maybe.filter(m => {
      if (typeof already[m.match] === 'boolean') {
        return false
      }
      already[m.match] = true;
      return true
    });
    return maybe
  })
};

// filter-down list of maybe-matches
const localTrim = function (maybeList, docCache) {
  return maybeList.map((list, n) => {
    let haves = docCache[n];
    // ensure all stated-needs of the match are met
    list = list.filter(obj => {
      return obj.needs.every(need => haves.has(need))
    });
    // ensure nothing matches in our 'ifNo' property
    list = list.filter(obj => {
      if (obj.ifNo !== undefined && obj.ifNo.some(no => haves.has(no)) === true) {
        return false
      }
      return true
    });
    // ensure atleast one(?) of the wants is found
    list = list.filter(obj => {
      if (obj.wants.length === 0) {
        return true
      }
      // ensure there's one cache-hit
      let found = obj.wants.filter(str => haves.has(str)).length;
      return found >= obj.minWant
    });
    return list
  })
};

// finally,
// actually run these match-statements on the terms
const runMatch = function (maybeList, document, docCache, methods, opts) {
  let results = [];
  for (let n = 0; n < maybeList.length; n += 1) {
    for (let i = 0; i < maybeList[n].length; i += 1) {
      let m = maybeList[n][i];
      // ok, actually do the work.
      let res = methods.one.match([document[n]], m);
      // found something.
      if (res.ptrs.length > 0) {
        res.ptrs.forEach(ptr => {
          ptr[0] = n; // fix the sentence pointer
          // check ifNo
          // if (m.ifNo !== undefined) {
          //   let terms = document[n].slice(ptr[1], ptr[2])
          //   for (let k = 0; k < m.ifNo.length; k += 1) {
          //     const no = m.ifNo[k]
          //     // quick-check cache
          //     if (docCache[n].has(no)) {
          //       if (no.startsWith('#')) {
          //         let tag = no.replace(/^#/, '')
          //         if (terms.find(t => t.tags.has(tag))) {
          //           console.log('+' + tag)
          //           return
          //         }
          //       } else if (terms.find(t => t.normal === no || t.tags.has(no))) {
          //         console.log('+' + no)
          //         return
          //       }
          //     }
          //   }
          // }
          let todo = Object.assign({}, m, { pointer: ptr });
          if (m.unTag !== undefined) {
            todo.unTag = m.unTag;
          }
          results.push(todo);
        });
        //ok cool, can we stop early?
        if (opts.matchOne === true) {
          return [results[0]]
        }
      }
    }
  }
  return results
};

const tooSmall = function (maybeList, document) {
  return maybeList.map((arr, i) => {
    let termCount = document[i].length;
    arr = arr.filter(o => {
      return termCount >= o.minWords
    });
    return arr
  })
};

const sweep$1 = function (document, net, methods, opts = {}) {
  // find suitable matches to attempt, on each sentence
  let docCache = methods.one.cacheDoc(document);
  // collect possible matches for this document
  let maybeList = getHooks(docCache, net.hooks);
  // ensure all defined needs are met for each match
  maybeList = localTrim(maybeList, docCache);
  // add unchacheable matches to each sentence's todo-list
  if (net.always.length > 0) {
    maybeList = maybeList.map(arr => arr.concat(net.always));
  }
  // if we don't have enough words
  maybeList = tooSmall(maybeList, document);

  // now actually run the matches
  let results = runMatch(maybeList, document, docCache, methods, opts);
  // console.dir(results, { depth: 5 })
  return results
};

// is this tag consistent with the tags they already have?
const canBe$1 = function (terms, tag, model) {
  let tagSet = model.one.tagSet;
  if (!tagSet.hasOwnProperty(tag)) {
    return true
  }
  let not = tagSet[tag].not || [];
  for (let i = 0; i < terms.length; i += 1) {
    let term = terms[i];
    for (let k = 0; k < not.length; k += 1) {
      if (term.tags.has(not[k]) === true) {
        return false //found a tag conflict - bail!
      }
    }
  }
  return true
};

const tagger$1 = function (list, document, world) {
  const { model, methods } = world;
  const { getDoc, setTag, unTag } = methods.one;
  const looksPlural = methods.two.looksPlural;
  if (list.length === 0) {
    return list
  }
  // some logging for debugging
  const env = typeof process === 'undefined' || !process.env ? self.env || {} : process.env;
  if (env.DEBUG_TAGS) {
    console.log(`\n\n  \x1b[32mâ†’ ${list.length} post-tagger:\x1b[0m`); //eslint-disable-line
  }
  return list.map(todo => {
    if (!todo.tag && !todo.chunk && !todo.unTag) {
      return
    }
    let reason = todo.reason || todo.match;
    let terms = getDoc([todo.pointer], document)[0];
    // handle 'safe' tag
    if (todo.safe === true) {
      // check for conflicting tags
      if (canBe$1(terms, todo.tag, model) === false) {
        return
      }
      // dont tag half of a hyphenated word
      if (terms[terms.length - 1].post === '-') {
        return
      }
    }
    if (todo.tag !== undefined) {
      setTag(terms, todo.tag, world, todo.safe, `[post] '${reason}'`);
      // quick and dirty plural tagger ðŸ˜•
      if (todo.tag === 'Noun' && looksPlural) {
        let term = terms[terms.length - 1];
        if (looksPlural(term.text)) {
          setTag([term], 'Plural', world, todo.safe, 'quick-plural');
        } else {
          setTag([term], 'Singular', world, todo.safe, 'quick-singular');
        }
      }
      // allow freezing this match, too
      if (todo.freeze === true) {
        terms.forEach(term => (term.frozen = true));
      }
    }
    if (todo.unTag !== undefined) {
      unTag(terms, todo.unTag, world, todo.safe, reason);
    }
    // allow setting chunks, too
    if (todo.chunk) {
      terms.forEach(t => (t.chunk = todo.chunk));
    }
  })
};

var methods$5 = {
  buildNet,
  bulkMatch: sweep$1,
  bulkTagger: tagger$1
};

var sweep = {
  lib: lib$2,
  api: api$l,
  methods: {
    one: methods$5,
  }
};

const isMulti = / /;

const addChunk = function (term, tag) {
  if (tag === 'Noun') {
    term.chunk = tag;
  }
  if (tag === 'Verb') {
    term.chunk = tag;
  }
};

const tagTerm = function (term, tag, tagSet, isSafe) {
  // does it already have this tag?
  if (term.tags.has(tag) === true) {
    return null
  }
  // allow this shorthand in multiple-tag strings
  if (tag === '.') {
    return null
  }
  // don't overwrite any tags, if term is frozen
  if (term.frozen === true) {
    isSafe = true;
  }
  // for known tags, do logical dependencies first
  let known = tagSet[tag];
  if (known) {
    // first, we remove any conflicting tags
    if (known.not && known.not.length > 0) {
      for (let o = 0; o < known.not.length; o += 1) {
        // if we're in tagSafe, skip this term.
        if (isSafe === true && term.tags.has(known.not[o])) {
          return null
        }
        term.tags.delete(known.not[o]);
      }
    }
    // add parent tags
    if (known.parents && known.parents.length > 0) {
      for (let o = 0; o < known.parents.length; o += 1) {
        term.tags.add(known.parents[o]);
        addChunk(term, known.parents[o]);
      }
    }
  }
  // finally, add our tag
  term.tags.add(tag);
  // now it's dirty?
  term.dirty = true;
  // add a chunk too, if it's easy
  addChunk(term, tag);
  return true
};

// support '#Noun . #Adjective' syntax
const multiTag = function (terms, tagString, tagSet, isSafe) {
  let tags = tagString.split(isMulti);
  terms.forEach((term, i) => {
    let tag = tags[i];
    if (tag) {
      tag = tag.replace(/^#/, '');
      tagTerm(term, tag, tagSet, isSafe);
    }
  });
};

const isArray$3 = function (arr) {
  return Object.prototype.toString.call(arr) === '[object Array]'
};

// verbose-mode tagger debuging
const log$1 = (terms, tag, reason = '') => {
  const yellow = str => '\x1b[33m\x1b[3m' + str + '\x1b[0m';
  const i = str => '\x1b[3m' + str + '\x1b[0m';
  let word = terms
    .map(t => {
      return t.text || '[' + t.implicit + ']'
    })
    .join(' ');
  if (typeof tag !== 'string' && tag.length > 2) {
    tag = tag.slice(0, 2).join(', #') + ' +'; //truncate the list of tags
  }
  tag = typeof tag !== 'string' ? tag.join(', #') : tag;
  console.log(` ${yellow(word).padEnd(24)} \x1b[32mâ†’\x1b[0m #${tag.padEnd(22)}  ${i(reason)}`); // eslint-disable-line
};

// add a tag to all these terms
const setTag = function (terms, tag, world = {}, isSafe, reason) {
  const tagSet = world.model.one.tagSet || {};
  if (!tag) {
    return
  }
  // some logging for debugging
  const env = typeof process === 'undefined' || !process.env ? self.env || {} : process.env;
  if (env && env.DEBUG_TAGS) {
    log$1(terms, tag, reason);
  }
  if (isArray$3(tag) === true) {
    tag.forEach(tg => setTag(terms, tg, world, isSafe));
    return
  }
  if (typeof tag !== 'string') {
    console.warn(`compromise: Invalid tag '${tag}'`); // eslint-disable-line
    return
  }
  tag = tag.trim();
  // support '#Noun . #Adjective' syntax
  if (isMulti.test(tag)) {
    multiTag(terms, tag, tagSet, isSafe);
    return
  }
  tag = tag.replace(/^#/, '');
  // let set = false
  for (let i = 0; i < terms.length; i += 1) {
    tagTerm(terms[i], tag, tagSet, isSafe);
  }
};

// remove this tag, and its children, from these terms
const unTag = function (terms, tag, tagSet) {
  tag = tag.trim().replace(/^#/, '');
  for (let i = 0; i < terms.length; i += 1) {
    let term = terms[i];
    // don't untag anything if term is frozen
    if (term.frozen === true) {
      continue
    }
    // support clearing all tags, with '*'
    if (tag === '*') {
      term.tags.clear();
      continue
    }
    // for known tags, do logical dependencies first
    let known = tagSet[tag];
    // removing #Verb should also remove #PastTense
    if (known && known.children.length > 0) {
      for (let o = 0; o < known.children.length; o += 1) {
        term.tags.delete(known.children[o]);
      }
    }
    term.tags.delete(tag);
  }
};

// quick check if this tag will require any untagging
const canBe = function (term, tag, tagSet) {
  if (!tagSet.hasOwnProperty(tag)) {
    return true // everything can be an unknown tag
  }
  let not = tagSet[tag].not || [];
  for (let i = 0; i < not.length; i += 1) {
    if (term.tags.has(not[i])) {
      return false
    }
  }
  return true
};

const e$1=function(e){return e.children=e.children||[],e._cache=e._cache||{},e.props=e.props||{},e._cache.parents=e._cache.parents||[],e._cache.children=e._cache.children||[],e},t$1=/^ *(#|\/\/)/,n$2=function(t){let n=t.trim().split(/->/),r=[];n.forEach((t=>{r=r.concat(function(t){if(!(t=t.trim()))return null;if(/^\[/.test(t)&&/\]$/.test(t)){let n=(t=(t=t.replace(/^\[/,"")).replace(/\]$/,"")).split(/,/);return n=n.map((e=>e.trim())).filter((e=>e)),n=n.map((t=>e$1({id:t}))),n}return [e$1({id:t})]}(t));})),r=r.filter((e=>e));let i=r[0];for(let e=1;e<r.length;e+=1)i.children.push(r[e]),i=r[e];return r[0]},r$1=(e,t)=>{let n=[],r=[e];for(;r.length>0;){let e=r.pop();n.push(e),e.children&&e.children.forEach((n=>{t&&t(e,n),r.push(n);}));}return n},i$1=e=>"[object Array]"===Object.prototype.toString.call(e),c$1=e=>(e=e||"").trim(),s$2=function(c=[]){return "string"==typeof c?function(r){let i=r.split(/\r?\n/),c=[];i.forEach((e=>{if(!e.trim()||t$1.test(e))return;let r=(e=>{const t=/^( {2}|\t)/;let n=0;for(;t.test(e);)e=e.replace(t,""),n+=1;return n})(e);c.push({indent:r,node:n$2(e)});}));let s=function(e){let t={children:[]};return e.forEach(((n,r)=>{0===n.indent?t.children=t.children.concat(n.node):e[r-1]&&function(e,t){let n=e[t].indent;for(;t>=0;t-=1)if(e[t].indent<n)return e[t];return e[0]}(e,r).node.children.push(n.node);})),t}(c);return s=e$1(s),s}(c):i$1(c)?function(t){let n={};t.forEach((e=>{n[e.id]=e;}));let r=e$1({});return t.forEach((t=>{if((t=e$1(t)).parent)if(n.hasOwnProperty(t.parent)){let e=n[t.parent];delete t.parent,e.children.push(t);}else console.warn(`[Grad] - missing node '${t.parent}'`);else r.children.push(t);})),r}(c):(r$1(s=c).forEach(e$1),s);var s;},h$1=e=>"[31m"+e+"[0m",o$1=e=>"[2m"+e+"[0m",l$1=function(e,t){let n="-> ";t&&(n=o$1("â†’ "));let i="";return r$1(e).forEach(((e,r)=>{let c=e.id||"";if(t&&(c=h$1(c)),0===r&&!e.id)return;let s=e._cache.parents.length;i+="    ".repeat(s)+n+c+"\n";})),i},a$1=function(e){let t=r$1(e);t.forEach((e=>{delete(e=Object.assign({},e)).children;}));let n=t[0];return n&&!n.id&&0===Object.keys(n.props).length&&t.shift(),t},p$4={text:l$1,txt:l$1,array:a$1,flat:a$1},d=function(e,t){return "nested"===t||"json"===t?e:"debug"===t?(console.log(l$1(e,true)),null):p$4.hasOwnProperty(t)?p$4[t](e):e},u$1=e=>{r$1(e,((e,t)=>{e.id&&(e._cache.parents=e._cache.parents||[],t._cache.parents=e._cache.parents.concat([e.id]));}));},f$2=(e,t)=>(Object.keys(t).forEach((n=>{if(t[n]instanceof Set){let r=e[n]||new Set;e[n]=new Set([...r,...t[n]]);}else {if((e=>e&&"object"==typeof e&&!Array.isArray(e))(t[n])){let r=e[n]||{};e[n]=Object.assign({},t[n],r);}else i$1(t[n])?e[n]=t[n].concat(e[n]||[]):void 0===e[n]&&(e[n]=t[n]);}})),e),j=/\//;let g$2 = class g{constructor(e={}){Object.defineProperty(this,"json",{enumerable:false,value:e,writable:true});}get children(){return this.json.children}get id(){return this.json.id}get found(){return this.json.id||this.json.children.length>0}props(e={}){let t=this.json.props||{};return "string"==typeof e&&(t[e]=true),this.json.props=Object.assign(t,e),this}get(t){if(t=c$1(t),!j.test(t)){let e=this.json.children.find((e=>e.id===t));return new g(e)}let n=((e,t)=>{let n=(e=>"string"!=typeof e?e:(e=e.replace(/^\//,"")).split(/\//))(t=t||"");for(let t=0;t<n.length;t+=1){let r=e.children.find((e=>e.id===n[t]));if(!r)return null;e=r;}return e})(this.json,t)||e$1({});return new g(n)}add(t,n={}){if(i$1(t))return t.forEach((e=>this.add(c$1(e),n))),this;t=c$1(t);let r=e$1({id:t,props:n});return this.json.children.push(r),new g(r)}remove(e){return e=c$1(e),this.json.children=this.json.children.filter((t=>t.id!==e)),this}nodes(){return r$1(this.json).map((e=>(delete(e=Object.assign({},e)).children,e)))}cache(){return (e=>{let t=r$1(e,((e,t)=>{e.id&&(e._cache.parents=e._cache.parents||[],e._cache.children=e._cache.children||[],t._cache.parents=e._cache.parents.concat([e.id]));})),n={};t.forEach((e=>{e.id&&(n[e.id]=e);})),t.forEach((e=>{e._cache.parents.forEach((t=>{n.hasOwnProperty(t)&&n[t]._cache.children.push(e.id);}));})),e._cache.children=Object.keys(n);})(this.json),this}list(){return r$1(this.json)}fillDown(){var e;return e=this.json,r$1(e,((e,t)=>{t.props=f$2(t.props,e.props);})),this}depth(){u$1(this.json);let e=r$1(this.json),t=e.length>1?1:0;return e.forEach((e=>{if(0===e._cache.parents.length)return;let n=e._cache.parents.length+1;n>t&&(t=n);})),t}out(e){return u$1(this.json),d(this.json,e)}debug(){return u$1(this.json),d(this.json,"debug"),this}};const _=function(e){let t=s$2(e);return new g$2(t)};_.prototype.plugin=function(e){e(this);};

// i just made these up
const colors = {
  Noun: 'blue',
  Verb: 'green',
  Negative: 'green',
  Date: 'red',
  Value: 'red',
  Adjective: 'magenta',
  Preposition: 'cyan',
  Conjunction: 'cyan',
  Determiner: 'cyan',
  Hyphenated: 'cyan',
  Adverb: 'cyan',
};

const getColor = function (node) {
  if (colors.hasOwnProperty(node.id)) {
    return colors[node.id]
  }
  if (colors.hasOwnProperty(node.is)) {
    return colors[node.is]
  }
  let found = node._cache.parents.find(c => colors[c]);
  return colors[found]
};

// convert tags to our final format
const fmt = function (nodes) {
  const res = {};
  nodes.forEach(node => {
    let { not, also, is, novel } = node.props;
    let parents = node._cache.parents;
    if (also) {
      parents = parents.concat(also);
    }
    res[node.id] = {
      is,
      not,
      novel,
      also,
      parents,
      children: node._cache.children,
      color: getColor(node)
    };
  });
  // lastly, add all children of all nots
  Object.keys(res).forEach(k => {
    let nots = new Set(res[k].not);
    res[k].not.forEach(not => {
      if (res[not]) {
        res[not].children.forEach(tag => nots.add(tag));
      }
    });
    res[k].not = Array.from(nots);
  });
  return res
};

const toArr = function (input) {
  if (!input) {
    return []
  }
  if (typeof input === 'string') {
    return [input]
  }
  return input
};

const addImplied = function (tags, already) {
  Object.keys(tags).forEach(k => {
    // support deprecated fmts
    if (tags[k].isA) {
      tags[k].is = tags[k].isA;
    }
    if (tags[k].notA) {
      tags[k].not = tags[k].notA;
    }
    // add any implicit 'is' tags
    if (tags[k].is && typeof tags[k].is === 'string') {
      if (!already.hasOwnProperty(tags[k].is) && !tags.hasOwnProperty(tags[k].is)) {
        tags[tags[k].is] = {};
      }
    }
    // add any implicit 'not' tags
    if (tags[k].not && typeof tags[k].not === 'string' && !tags.hasOwnProperty(tags[k].not)) {
      if (!already.hasOwnProperty(tags[k].not) && !tags.hasOwnProperty(tags[k].not)) {
        tags[tags[k].not] = {};
      }
    }
  });
  return tags
};


const validate = function (tags, already) {

  tags = addImplied(tags, already);

  // property validation
  Object.keys(tags).forEach(k => {
    tags[k].children = toArr(tags[k].children);
    tags[k].not = toArr(tags[k].not);
  });
  // not links are bi-directional
  // add any incoming not tags
  Object.keys(tags).forEach(k => {
    let nots = tags[k].not || [];
    nots.forEach(no => {
      if (tags[no] && tags[no].not) {
        tags[no].not.push(k);
      }
    });
  });
  return tags
};

// 'fill-down' parent logic inference
const compute$5 = function (allTags) {
  // setup graph-lib format
  const flatList = Object.keys(allTags).map(k => {
    let o = allTags[k];
    const props = { not: new Set(o.not), also: o.also, is: o.is, novel: o.novel };
    return { id: k, parent: o.is, props, children: [] }
  });
  const graph = _(flatList).cache().fillDown();
  return graph.out('array')
};

const fromUser = function (tags) {
  Object.keys(tags).forEach(k => {
    tags[k] = Object.assign({}, tags[k]);
    tags[k].novel = true;
  });
  return tags
};

const addTags$1 = function (tags, already) {
  // are these tags internal ones, or user-generated?
  if (Object.keys(already).length > 0) {
    tags = fromUser(tags);
  }
  tags = validate(tags, already);

  let allTags = Object.assign({}, already, tags);
  // do some basic setting-up
  // 'fill-down' parent logic
  const nodes = compute$5(allTags);
  // convert it to our final format
  const res = fmt(nodes);
  return res
};

var methods$4 = {
  one: {
    setTag,
    unTag,
    addTags: addTags$1,
    canBe,
  },
};

/* eslint no-console: 0 */
const isArray$2 = function (arr) {
  return Object.prototype.toString.call(arr) === '[object Array]'
};
const fns$1 = {
  /** add a given tag, to all these terms */
  tag: function (input, reason = '', isSafe) {
    if (!this.found || !input) {
      return this
    }
    let terms = this.termList();
    if (terms.length === 0) {
      return this
    }
    const { methods, verbose, world } = this;
    // logger
    if (verbose === true) {
      console.log(' +  ', input, reason || '');
    }
    if (isArray$2(input)) {
      input.forEach(tag => methods.one.setTag(terms, tag, world, isSafe, reason));
    } else {
      methods.one.setTag(terms, input, world, isSafe, reason);
    }
    // uncache
    this.uncache();
    return this
  },

  /** add a given tag, only if it is consistent */
  tagSafe: function (input, reason = '') {
    return this.tag(input, reason, true)
  },

  /** remove a given tag from all these terms */
  unTag: function (input, reason) {
    if (!this.found || !input) {
      return this
    }
    let terms = this.termList();
    if (terms.length === 0) {
      return this
    }
    const { methods, verbose, model } = this;
    // logger
    if (verbose === true) {
      console.log(' -  ', input, reason || '');
    }
    let tagSet = model.one.tagSet;
    if (isArray$2(input)) {
      input.forEach(tag => methods.one.unTag(terms, tag, tagSet));
    } else {
      methods.one.unTag(terms, input, tagSet);
    }
    // uncache
    this.uncache();
    return this
  },

  /** return only the terms that can be this tag  */
  canBe: function (tag) {
    tag = tag.replace(/^#/, '');
    let tagSet = this.model.one.tagSet;
    let canBe = this.methods.one.canBe;
    let nope = [];
    this.document.forEach((terms, n) => {
      terms.forEach((term, i) => {
        if (!canBe(term, tag, tagSet)) {
          nope.push([n, i, i + 1]);
        }
      });
    });
    let noDoc = this.update(nope);
    return this.difference(noDoc)
  },
};

const tagAPI = function (View) {
  Object.assign(View.prototype, fns$1);
};

// wire-up more pos-tags to our model
const addTags = function (tags) {
  const { model, methods } = this.world();
  const tagSet = model.one.tagSet;
  const fn = methods.one.addTags;
  let res = fn(tags, tagSet);
  model.one.tagSet = res;
  return this
};

var lib$1 = { addTags };

const boringTags = new Set(['Auxiliary', 'Possessive']);

const sortByKids = function (tags, tagSet) {
  tags = tags.sort((a, b) => {
    // (unknown tags are interesting)
    if (boringTags.has(a) || !tagSet.hasOwnProperty(b)) {
      return 1
    }
    if (boringTags.has(b) || !tagSet.hasOwnProperty(a)) {
      return -1
    }
    let kids = tagSet[a].children || [];
    let aKids = kids.length;
    kids = tagSet[b].children || [];
    let bKids = kids.length;
    return aKids - bKids
  });
  return tags
};

const tagRank = function (view) {
  const { document, world } = view;
  const tagSet = world.model.one.tagSet;
  document.forEach(terms => {
    terms.forEach(term => {
      let tags = Array.from(term.tags);
      term.tagRank = sortByKids(tags, tagSet);
    });
  });
};

var tag = {
  model: {
    one: { tagSet: {} }
  },
  compute: {
    tagRank
  },
  methods: methods$4,
  api: tagAPI,
  lib: lib$1
};

// split by periods, question marks, unicode â‡, etc
const initSplit = /([.!?\u203D\u2E18\u203C\u2047-\u2049\u3002]+\s)/g;
// merge these back into prev sentence
const splitsOnly = /^[.!?\u203D\u2E18\u203C\u2047-\u2049\u3002]+\s$/;
const newLine = /((?:\r?\n|\r)+)/; // Match different new-line formats

// Start with a regex:
const basicSplit = function (text) {
  let all = [];
  //first, split by newline
  let lines = text.split(newLine);
  for (let i = 0; i < lines.length; i++) {
    //split by period, question-mark, and exclamation-mark
    let arr = lines[i].split(initSplit);
    for (let o = 0; o < arr.length; o++) {
      // merge 'foo' + '.'
      if (arr[o + 1] && splitsOnly.test(arr[o + 1]) === true) {
        arr[o] += arr[o + 1];
        arr[o + 1] = '';
      }
      if (arr[o] !== '') {
        all.push(arr[o]);
      }
    }
  }
  return all
};

const hasLetter$1 = /[a-z0-9\u00C0-\u00FF\u00a9\u00ae\u2000-\u3300\ud000-\udfff]/i;
const hasSomething$1 = /\S/;

const notEmpty = function (splits) {
  let chunks = [];
  for (let i = 0; i < splits.length; i++) {
    let s = splits[i];
    if (s === undefined || s === '') {
      continue
    }
    //this is meaningful whitespace
    if (hasSomething$1.test(s) === false || hasLetter$1.test(s) === false) {
      //add it to the last one
      if (chunks[chunks.length - 1]) {
        chunks[chunks.length - 1] += s;
        continue
      } else if (splits[i + 1]) {
        //add it to the next one
        splits[i + 1] = s + splits[i + 1];
        continue
      }
    }
    //else, only whitespace, no terms, no sentence
    chunks.push(s);
  }
  return chunks
};

//loop through these chunks, and join the non-sentence chunks back together..
const smartMerge = function (chunks, world) {
  const isSentence = world.methods.one.tokenize.isSentence;
  const abbrevs = world.model.one.abbreviations || new Set();

  let sentences = [];
  for (let i = 0; i < chunks.length; i++) {
    let c = chunks[i];
    //should this chunk be combined with the next one?
    if (chunks[i + 1] && isSentence(c, abbrevs) === false) {
      chunks[i + 1] = c + (chunks[i + 1] || '');
    } else if (c && c.length > 0) {
      //this chunk is a proper sentence..
      sentences.push(c);
      chunks[i] = '';
    }
  }
  return sentences
};

/* eslint-disable regexp/no-dupe-characters-character-class */

// merge embedded quotes into 1 sentence
// like - 'he said "no!" and left.'
const MAX_QUOTE = 280;// Â¯\_(ãƒ„)_/Â¯

// don't support single-quotes for multi-sentences
const pairs$1 = {
  '\u0022': '\u0022', // 'StraightDoubleQuotes'
  '\uFF02': '\uFF02', // 'StraightDoubleQuotesWide'
  // '\u0027': '\u0027', // 'StraightSingleQuotes'
  '\u201C': '\u201D', // 'CommaDoubleQuotes'
  // '\u2018': '\u2019', // 'CommaSingleQuotes'
  '\u201F': '\u201D', // 'CurlyDoubleQuotesReversed'
  // '\u201B': '\u2019', // 'CurlySingleQuotesReversed'
  '\u201E': '\u201D', // 'LowCurlyDoubleQuotes'
  '\u2E42': '\u201D', // 'LowCurlyDoubleQuotesReversed'
  '\u201A': '\u2019', // 'LowCurlySingleQuotes'
  '\u00AB': '\u00BB', // 'AngleDoubleQuotes'
  '\u2039': '\u203A', // 'AngleSingleQuotes'
  '\u2035': '\u2032', // 'PrimeSingleQuotes'
  '\u2036': '\u2033', // 'PrimeDoubleQuotes'
  '\u2037': '\u2034', // 'PrimeTripleQuotes'
  '\u301D': '\u301E', // 'PrimeDoubleQuotes'
  // '\u0060': '\u00B4', // 'PrimeSingleQuotes'
  '\u301F': '\u301E', // 'LowPrimeDoubleQuotesReversed'
};
const openQuote = RegExp('[' + Object.keys(pairs$1).join('') + ']', 'g');
const closeQuote = RegExp('[' + Object.values(pairs$1).join('') + ']', 'g');

const closesQuote = function (str) {
  if (!str) {
    return false
  }
  let m = str.match(closeQuote);
  if (m !== null && m.length === 1) {
    return true
  }
  return false
};

// allow micro-sentences when inside a quotation, like:
// the doc said "no sir. i will not beg" and walked away.
const quoteMerge = function (splits) {
  let arr = [];
  for (let i = 0; i < splits.length; i += 1) {
    let split = splits[i];
    // do we have an open-quote and not a closed one?
    let m = split.match(openQuote);
    if (m !== null && m.length === 1) {

      // look at the next sentence for a closing quote,
      if (closesQuote(splits[i + 1]) && splits[i + 1].length < MAX_QUOTE) {
        splits[i] += splits[i + 1];// merge them
        arr.push(splits[i]);
        splits[i + 1] = '';
        i += 1;
        continue
      }
      // look at n+2 for a closing quote,
      if (closesQuote(splits[i + 2])) {
        let toAdd = splits[i + 1] + splits[i + 2];// merge them all
        //make sure it's not too-long
        if (toAdd.length < MAX_QUOTE) {
          splits[i] += toAdd;
          arr.push(splits[i]);
          splits[i + 1] = '';
          splits[i + 2] = '';
          i += 2;
          continue
        }
      }
    }
    arr.push(splits[i]);
  }
  return arr
};

const MAX_LEN = 250;// Â¯\_(ãƒ„)_/Â¯

// support unicode variants?
// https://stackoverflow.com/questions/13535172/list-of-all-unicodes-open-close-brackets
const hasOpen$2 = /\(/g;
const hasClosed$2 = /\)/g;
const mergeParens = function (splits) {
  let arr = [];
  for (let i = 0; i < splits.length; i += 1) {
    let split = splits[i];
    let m = split.match(hasOpen$2);
    if (m !== null && m.length === 1) {
      // look at next sentence, for closing parenthesis
      if (splits[i + 1] && splits[i + 1].length < MAX_LEN) {
        let m2 = splits[i + 1].match(hasClosed$2);
        if (m2 !== null && m.length === 1 && !hasOpen$2.test(splits[i + 1])) {
          // merge in 2nd sentence
          splits[i] += splits[i + 1];
          arr.push(splits[i]);
          splits[i + 1] = '';
          i += 1;
          continue
        }
      }
    }
    arr.push(splits[i]);
  }
  return arr
};

//(Rule-based sentence boundary segmentation) - chop given text into its proper sentences.
// Ignore periods/questions/exclamations used in acronyms/abbreviations/numbers, etc.
//regs-
const hasSomething = /\S/;
const startWhitespace = /^\s+/;

const splitSentences = function (text, world) {
  text = text || '';
  text = String(text);
  // Ensure it 'smells like' a sentence
  if (!text || typeof text !== 'string' || hasSomething.test(text) === false) {
    return []
  }
  // cleanup unicode-spaces
  text = text.replace('\xa0', ' ');
  // First do a greedy-split..
  let splits = basicSplit(text);
  // Filter-out the crap ones
  let sentences = notEmpty(splits);
  //detection of non-sentence chunks:
  sentences = smartMerge(sentences, world);
  // allow 'he said "no sir." and left.'
  sentences = quoteMerge(sentences);
  // allow 'i thought (no way!) and left.'
  sentences = mergeParens(sentences);
  //if we never got a sentence, return the given text
  if (sentences.length === 0) {
    return [text]
  }
  //move whitespace to the ends of sentences, when possible
  //['hello',' world'] -> ['hello ','world']
  for (let i = 1; i < sentences.length; i += 1) {
    let ws = sentences[i].match(startWhitespace);
    if (ws !== null) {
      sentences[i - 1] += ws[0];
      sentences[i] = sentences[i].replace(startWhitespace, '');
    }
  }
  return sentences
};

const hasHyphen = function (str, model) {
  let parts = str.split(/[-â€“â€”]/);
  if (parts.length <= 1) {
    return false
  }
  const { prefixes, suffixes } = model.one;

  // l-theanine, x-ray
  if (parts[0].length === 1 && /[a-z]/i.test(parts[0])) {
    return false
  }
  //dont split 're-do'
  if (prefixes.hasOwnProperty(parts[0])) {
    return false
  }
  //dont split 'flower-like'
  parts[1] = parts[1].trim().replace(/[.?!]$/, '');
  if (suffixes.hasOwnProperty(parts[1])) {
    return false
  }
  //letter-number 'aug-20'
  let reg = /^([a-z\u00C0-\u00FF`"'/]+)[-â€“â€”]([a-z0-9\u00C0-\u00FF].*)/i;
  if (reg.test(str) === true) {
    return true
  }
  //number-letter '20-aug'
  let reg2 = /^[('"]?([0-9]{1,4})[-â€“â€”]([a-z\u00C0-\u00FF`"'/-]+[)'"]?$)/i;
  if (reg2.test(str) === true) {
    return true
  }
  return false
};

const splitHyphens = function (word) {
  let arr = [];
  //support multiple-hyphenated-terms
  const hyphens = word.split(/[-â€“â€”]/);
  let whichDash = '-';
  let found = word.match(/[-â€“â€”]/);
  if (found && found[0]) {
    whichDash = found;
  }
  for (let o = 0; o < hyphens.length; o++) {
    if (o === hyphens.length - 1) {
      arr.push(hyphens[o]);
    } else {
      arr.push(hyphens[o] + whichDash);
    }
  }
  return arr
};

// combine '2 - 5' like '2-5' is
// 2-4: 2, 4
const combineRanges = function (arr) {
  const startRange = /^[0-9]{1,4}(:[0-9][0-9])?([a-z]{1,2})? ?[-â€“â€”] ?$/;
  const endRange = /^[0-9]{1,4}([a-z]{1,2})? ?$/;
  for (let i = 0; i < arr.length - 1; i += 1) {
    if (arr[i + 1] && startRange.test(arr[i]) && endRange.test(arr[i + 1])) {
      arr[i] = arr[i] + arr[i + 1];
      arr[i + 1] = null;
    }
  }
  return arr
};

const isSlash = /\p{L} ?\/ ?\p{L}+$/u;

// 'he / she' should be one word
const combineSlashes = function (arr) {
  for (let i = 1; i < arr.length - 1; i++) {
    if (isSlash.test(arr[i])) {
      arr[i - 1] += arr[i] + arr[i + 1];
      arr[i] = null;
      arr[i + 1] = null;
    }
  }
  return arr
};

const wordlike = /\S/;
const isBoundary = /^[!?.]+$/;
const naiiveSplit = /(\S+)/;

let notWord = [
  '.',
  '?',
  '!',
  ':',
  ';',
  '-',
  'â€“',
  'â€”',
  '--',
  '...',
  '(',
  ')',
  '[',
  ']',
  '"',
  "'",
  '`',
  'Â«',
  'Â»',
  '*',
  'â€¢',
];
notWord = notWord.reduce((h, c) => {
  h[c] = true;
  return h
}, {});

const isArray$1 = function (arr) {
  return Object.prototype.toString.call(arr) === '[object Array]'
};

//turn a string into an array of strings (naiive for now, lumped later)
const splitWords = function (str, model) {
  let result = [];
  let arr = [];
  //start with a naiive split
  str = str || '';
  if (typeof str === 'number') {
    str = String(str);
  }
  if (isArray$1(str)) {
    return str
  }
  const words = str.split(naiiveSplit);
  for (let i = 0; i < words.length; i++) {
    //split 'one-two'
    if (hasHyphen(words[i], model) === true) {
      arr = arr.concat(splitHyphens(words[i]));
      continue
    }
    arr.push(words[i]);
  }
  //greedy merge whitespace+arr to the right
  let carry = '';
  for (let i = 0; i < arr.length; i++) {
    let word = arr[i];
    //if it's more than a whitespace
    if (wordlike.test(word) === true && notWord.hasOwnProperty(word) === false && isBoundary.test(word) === false) {
      //put whitespace on end of previous term, if possible
      if (result.length > 0) {
        result[result.length - 1] += carry;
        result.push(word);
      } else {
        //otherwise, but whitespace before
        result.push(carry + word);
      }
      carry = '';
    } else {
      carry += word;
    }
  }
  //handle last one
  if (carry) {
    if (result.length === 0) {
      result[0] = '';
    }
    result[result.length - 1] += carry; //put it on the end
  }
  // combine 'one / two'
  result = combineSlashes(result);
  result = combineRanges(result);
  // remove empty results
  result = result.filter(s => s);
  return result
};

//all punctuation marks, from https://en.wikipedia.org/wiki/Punctuation

//we have slightly different rules for start/end - like #hashtags.
const isLetter = /\p{Letter}/u;
const isNumber = /[\p{Number}\p{Currency_Symbol}]/u;
const hasAcronym = /^[a-z]\.([a-z]\.)+/i;
const chillin = /[sn]['â€™]$/;

const normalizePunctuation = function (str, model) {
  // quick lookup for allowed pre/post punctuation
  let { prePunctuation, postPunctuation, emoticons } = model.one;
  let original = str;
  let pre = '';
  let post = '';
  let chars = Array.from(str);

  // punctuation-only words, like '<3'
  if (emoticons.hasOwnProperty(str.trim())) {
    return { str: str.trim(), pre, post: ' ' } //not great
  }

  // pop any punctuation off of the start
  let len = chars.length;
  for (let i = 0; i < len; i += 1) {
    let c = chars[0];
    // keep any declared chars
    if (prePunctuation[c] === true) {
      continue//keep it
    }
    // keep '+' or '-' only before a number
    if ((c === '+' || c === '-') && isNumber.test(chars[1])) {
      break//done
    }
    // '97 - year short-form
    if (c === "'" && c.length === 3 && isNumber.test(chars[1])) {
      break//done
    }
    // start of word
    if (isLetter.test(c) || isNumber.test(c)) {
      break //done
    }
    // punctuation
    pre += chars.shift();//keep going
  }

  // pop any punctuation off of the end
  len = chars.length;
  for (let i = 0; i < len; i += 1) {
    let c = chars[chars.length - 1];
    // keep any declared chars
    if (postPunctuation[c] === true) {
      continue//keep it
    }
    // start of word
    if (isLetter.test(c) || isNumber.test(c)) {
      break //done
    }
    // F.B.I.
    if (c === '.' && hasAcronym.test(original) === true) {
      continue//keep it
    }
    //  keep s-apostrophe - "flanders'" or "chillin'"
    if (c === "'" && chillin.test(original) === true) {
      continue//keep it
    }
    // punctuation
    post = chars.pop() + post;//keep going
  }
  str = chars.join('');
  //we went too far..
  if (str === '') {
    // do a very mild parse, and hope for the best.
    original = original.replace(/ *$/, after => {
      post = after || '';
      return ''
    });
    str = original;
    pre = '';
  }
  return { str, pre, post }
};

const parseTerm = (txt, model) => {
  // cleanup any punctuation as whitespace
  let { str, pre, post } = normalizePunctuation(txt, model);
  const parsed = {
    text: str,
    pre: pre,
    post: post,
    tags: new Set(),
  };
  return parsed
};

// 'BjÃ¶rk' to 'Bjork'.
const killUnicode = function (str, world) {
  const unicode = world.model.one.unicode || {};
  str = str || '';
  let chars = str.split('');
  chars.forEach((s, i) => {
    if (unicode[s]) {
      chars[i] = unicode[s];
    }
  });
  return chars.join('')
};

/** some basic operations on a string to reduce noise */
const clean = function (str) {
  str = str || '';
  str = str.toLowerCase();
  str = str.trim();
  let original = str;
  //punctuation
  str = str.replace(/[,;.!?]+$/, '');
  //coerce Unicode ellipses
  str = str.replace(/\u2026/g, '...');
  //en-dash
  str = str.replace(/\u2013/g, '-');
  //strip leading & trailing grammatical punctuation
  if (/^[:;]/.test(str) === false) {
    str = str.replace(/\.{3,}$/g, '');
    str = str.replace(/[",.!:;?)]+$/g, '');
    str = str.replace(/^['"(]+/g, '');
  }
  // remove zero-width characters
  str = str.replace(/[\u200B-\u200D\uFEFF]/g, '');
  //do this again..
  str = str.trim();
  //oh shucks,
  if (str === '') {
    str = original;
  }
  //no-commas in numbers
  str = str.replace(/([0-9]),([0-9])/g, '$1$2');
  return str
};

// do acronyms need to be ASCII?  ... kind of?
const periodAcronym$1 = /([A-Z]\.)+[A-Z]?,?$/;
const oneLetterAcronym$1 = /^[A-Z]\.,?$/;
const noPeriodAcronym$1 = /[A-Z]{2,}('s|,)?$/;
const lowerCaseAcronym$1 = /([a-z]\.)+[a-z]\.?$/;

const isAcronym$2 = function (str) {
  //like N.D.A
  if (periodAcronym$1.test(str) === true) {
    return true
  }
  //like c.e.o
  if (lowerCaseAcronym$1.test(str) === true) {
    return true
  }
  //like 'F.'
  if (oneLetterAcronym$1.test(str) === true) {
    return true
  }
  //like NDA
  if (noPeriodAcronym$1.test(str) === true) {
    return true
  }
  return false
};

const doAcronym = function (str) {
  if (isAcronym$2(str)) {
    str = str.replace(/\./g, '');
  }
  return str
};

const normalize$2 = function (term, world) {
  const killUnicode = world.methods.one.killUnicode;
  // console.log(world.methods.one)
  let str = term.text || '';
  str = clean(str);
  //(very) rough ASCII transliteration -  bjÅrk -> bjork
  str = killUnicode(str, world);
  str = doAcronym(str);
  term.normal = str;
};

// turn a string input into a 'document' json format
const parse$5 = function (input, world) {
  const { methods, model } = world;
  const { splitSentences, splitTerms, splitWhitespace } = methods.one.tokenize;
  input = input || '';
  // split into sentences
  let sentences = splitSentences(input, world);
  // split into word objects
  input = sentences.map((txt) => {
    let terms = splitTerms(txt, model);
    // split into [pre-text-post]
    terms = terms.map(t => splitWhitespace(t, model));
    // add normalized term format, always
    terms.forEach((t) => {
      normalize$2(t, world);
    });
    return terms
  });
  return input
};

const isAcronym$1 = /[ .][A-Z]\.? *$/i; //asci - 'n.s.a.'
const hasEllipse = /(?:\u2026|\.{2,}) *$/; // '...'
const hasLetter = /\p{L}/u;
const hasPeriod$1 = /\. *$/;
const leadInit = /^[A-Z]\. $/; // "W. Kensington"

/** does this look like a sentence? */
const isSentence = function (str, abbrevs) {
  // must have a letter
  if (hasLetter.test(str) === false) {
    return false
  }
  // check for 'F.B.I.'
  if (isAcronym$1.test(str) === true) {
    return false
  }
  // check for leading initial - "W. Kensington"
  if (str.length === 3 && leadInit.test(str)) {
    return false
  }
  //check for '...'
  if (hasEllipse.test(str) === true) {
    return false
  }
  let txt = str.replace(/[.!?\u203D\u2E18\u203C\u2047-\u2049] *$/, '');
  let words = txt.split(' ');
  let lastWord = words[words.length - 1].toLowerCase();
  // check for 'Mr.' (and not mr?)
  if (abbrevs.hasOwnProperty(lastWord) === true && hasPeriod$1.test(str) === true) {
    return false
  }
  // //check for jeopardy!
  // if (blacklist.hasOwnProperty(lastWord)) {
  //   return false
  // }
  return true
};

var methods$3 = {
  one: {
    killUnicode,
    tokenize: {
      splitSentences,
      isSentence,
      splitTerms: splitWords,
      splitWhitespace: parseTerm,
      fromString: parse$5,
    },
  },
};

const aliases$1 = {
  '&': 'and',
  '@': 'at',
  '%': 'percent',
  'plz': 'please',
  'bein': 'being',
};

var misc$6 = [
  'approx',
  'apt',
  'bc',
  'cyn',
  'eg',
  'esp',
  'est',
  'etc',
  'ex',
  'exp',
  'prob', //probably
  'pron', // Pronunciation
  'gal', //gallon
  'min',
  'pseud',
  'fig', //figure
  'jd',
  'lat', //latitude
  'lng', //longitude
  'vol', //volume
  'fm', //not am
  'def', //definition
  'misc',
  'plz', //please
  'ea', //each
  'ps',
  'sec', //second
  'pt',
  'pref', //preface
  'pl', //plural
  'pp', //pages
  'qt', //quarter
  'fr', //french
  'sq',
  'nee', //given name at birth
  'ss', //ship, or sections
  'tel',
  'temp',
  'vet',
  'ver', //version
  'fem', //feminine
  'masc', //masculine
  'eng', //engineering/english
  'adj', //adjective
  'vb', //verb
  'rb', //adverb
  'inf', //infinitive
  'situ', // in situ
  'vivo',
  'vitro',
  'wr', //world record
];

var honorifics$1 = [
  'adj',
  'adm',
  'adv',
  'asst',
  'atty',
  'bldg',
  'brig',
  'capt',
  'cmdr',
  'comdr',
  'cpl',
  'det',
  'dr',
  'esq',
  'gen',
  'gov',
  'hon',
  'jr',
  'llb',
  'lt',
  'maj',
  'messrs',
  'mlle',
  'mme',
  'mr',
  'mrs',
  'ms',
  'mstr',
  'phd',
  'prof',
  'pvt',
  'rep',
  'reps',
  'res',
  'rev',
  'sen',
  'sens',
  'sfc',
  'sgt',
  'sir',
  'sr',
  'supt',
  'surg'
  //miss
  //misses
];

var months = ['jan', 'feb', 'mar', 'apr', 'jun', 'jul', 'aug', 'sep', 'sept', 'oct', 'nov', 'dec'];

var nouns$3 = [
  'ad',
  'al',
  'arc',
  'ba',
  'bl',
  'ca',
  'cca',
  'col',
  'corp',
  'ft',
  'fy',
  'ie',
  'lit',
  'ma',
  'md',
  'pd',
  'tce',
];

var organizations = ['dept', 'univ', 'assn', 'bros', 'inc', 'ltd', 'co'];

var places$2 = [
  'rd',
  'st',
  'dist',
  'mt',
  'ave',
  'blvd',
  'cl',
  // 'ct',
  'cres',
  'hwy',
  //states
  'ariz',
  'cal',
  'calif',
  'colo',
  'conn',
  'fla',
  'fl',
  'ga',
  'ida',
  'ia',
  'kan',
  'kans',

  'minn',
  'neb',
  'nebr',
  'okla',
  'penna',
  'penn',
  'pa',
  'dak',
  'tenn',
  'tex',
  'ut',
  'vt',
  'va',
  'wis',
  'wisc',
  'wy',
  'wyo',
  'usafa',
  'alta',
  'ont',
  'que',
  'sask',
];

// units that are abbreviations too
var units = [
  'dl',
  'ml',
  'gal',
  // 'ft', //ambiguous
  'qt',
  'pt',
  'tbl',
  'tsp',
  'tbsp',
  'km',
  'dm', //decimeter
  'cm',
  'mm',
  'mi',
  'td',
  'hr', //hour
  'hrs', //hour
  'kg',
  'hg',
  'dg', //decigram
  'cg', //centigram
  'mg', //milligram
  'Âµg', //microgram
  'lb', //pound
  'oz', //ounce
  'sq ft',
  'hz', //hertz
  'mps', //meters per second
  'mph',
  'kmph', //kilometers per hour
  'kb', //kilobyte
  'mb', //megabyte
  // 'gb', //ambig
  'tb', //terabyte
  'lx', //lux
  'lm', //lumen
  // 'pa', //ambig
  'fl oz', //
  'yb',
];

// add our abbreviation list to our lexicon
let list$3 = [
  [misc$6],
  [units, 'Unit'],
  [nouns$3, 'Noun'],
  [honorifics$1, 'Honorific'],
  [months, 'Month'],
  [organizations, 'Organization'],
  [places$2, 'Place'],
];
// create key-val for sentence-tokenizer
let abbreviations = {};
// add them to a future lexicon
let lexicon$1 = {};

list$3.forEach(a => {
  a[0].forEach(w => {
    // sentence abbrevs
    abbreviations[w] = true;
    // future-lexicon
    lexicon$1[w] = 'Abbreviation';
    if (a[1] !== undefined) {
      lexicon$1[w] = [lexicon$1[w], a[1]];
    }
  });
});

// dashed prefixes that are not independent words
//  'mid-century', 'pre-history'
var prefixes$1 = [
  'anti',
  'bi',
  'co',
  'contra',
  'de',
  'extra',
  'infra',
  'inter',
  'intra',
  'macro',
  'micro',
  'mis',
  'mono',
  'multi',
  'peri',
  'pre',
  'pro',
  'proto',
  'pseudo',
  're',
  'sub',
  'supra',
  'trans',
  'tri',
  'un',
  'out', //out-lived
  'ex',//ex-wife

  // 'counter',
  // 'mid',
  // 'out',
  // 'non',
  // 'over',
  // 'post',
  // 'semi',
  // 'super', //'super-cool'
  // 'ultra', //'ulta-cool'
  // 'under',
  // 'whole',
].reduce((h, str) => {
  h[str] = true;
  return h
}, {});

// dashed suffixes that are not independent words
//  'flower-like', 'president-elect'
var suffixes$4 = {
  'like': true,
  'ish': true,
  'less': true,
  'able': true,
  'elect': true,
  'type': true,
  'designate': true,
  // 'fold':true,
};

//a hugely-ignorant, and widely subjective transliteration of latin, cryllic, greek unicode characters to english ascii.
//approximate visual (not semantic or phonetic) relationship between unicode and ascii characters
//http://en.wikipedia.org/wiki/List_of_Unicode_characters
//https://docs.google.com/spreadsheet/ccc?key=0Ah46z755j7cVdFRDM1A2YVpwa1ZYWlpJM2pQZ003M0E
let compact = {
  '!': 'Â¡',
  '?': 'Â¿É',
  '"': 'â€œâ€"ââž',
  "'": 'â€˜â€›â›âœâ€™',
  '-': 'â€”â€“',
  a: 'ÂªÃ€ÃÃ‚ÃƒÃ„Ã…Ã Ã¡Ã¢Ã£Ã¤Ã¥Ä€ÄÄ‚ÄƒÄ„Ä…ÇÇŽÇžÇŸÇ Ç¡ÇºÇ»È€ÈÈ‚ÈƒÈ¦È§ÈºÎ†Î‘Î”Î›Î¬Î±Î»ÐÐ°Ñ¦Ñ§ÓÓ‘Ó’Ó“Æ›Ã¦',
  b: 'ÃŸÃ¾Æ€ÆÆ‚ÆƒÆ„Æ…ÉƒÎ’Î²ÏÏ¦Ð‘Ð’ÐªÐ¬Ð²ÑŠÑŒÑ¢Ñ£ÒŒÒ',
  c: 'Â¢Â©Ã‡Ã§Ä†Ä‡ÄˆÄ‰ÄŠÄ‹ÄŒÄÆ†Æ‡ÆˆÈ»È¼Í»Í¼Ï²Ï¹Ï½Ï¾Ð¡ÑÑ”Ò€ÒÒªÒ«',
  d: 'ÃÄŽÄÄÄ‘Æ‰ÆŠÈ¡Æ‹ÆŒ',
  e: 'ÃˆÃ‰ÃŠÃ‹Ã¨Ã©ÃªÃ«Ä’Ä“Ä”Ä•Ä–Ä—Ä˜Ä™ÄšÄ›ÆÈ„È…È†È‡È¨È©É†É‡ÎˆÎ•ÎžÎ£Î­ÎµÎ¾ÏµÐ€ÐÐ•ÐµÑÑ‘Ò¼Ò½Ò¾Ò¿Ó–Ó—á»…',
  f: 'Æ‘Æ’ÏœÏÓºÓ»Ò’Ò“Å¿',
  g: 'ÄœÄÄžÄŸÄ Ä¡Ä¢Ä£Æ“Ç¤Ç¥Ç¦Ç§Ç´Çµ',
  h: 'Ä¤Ä¥Ä¦Ä§Æ•Ç¶ÈžÈŸÎ‰Î—Ð‚ÐŠÐ‹ÐÐ½Ñ’Ñ›Ò¢Ò£Ò¤Ò¥ÒºÒ»Ó‰ÓŠ',
  I: 'ÃŒÃÃŽÃ',
  i: 'Ã¬Ã­Ã®Ã¯Ä¨Ä©ÄªÄ«Ä¬Ä­Ä®Ä¯Ä°Ä±Æ–Æ—ÈˆÈ‰ÈŠÈ‹ÎŠÎÎªÎ¯Î¹ÏŠÐ†Ð‡Ñ–Ñ—iÌ‡',
  j: 'Ä´ÄµÇ°È·ÉˆÉ‰Ï³ÐˆÑ˜',
  k: 'Ä¶Ä·Ä¸Æ˜Æ™Ç¨Ç©ÎšÎºÐŒÐ–ÐšÐ¶ÐºÑœÒšÒ›ÒœÒÒžÒŸÒ Ò¡',
  l: 'Ä¹ÄºÄ»Ä¼Ä½Ä¾Ä¿Å€ÅÅ‚ÆšÆªÇ€ÇÇÈ´È½Î™Ó€Ó',
  m: 'ÎœÏºÏ»ÐœÐ¼ÓÓŽ',
  n: 'Ã‘Ã±ÅƒÅ„Å…Å†Å‡ÅˆÅ‰ÅŠÅ‹ÆÆžÇ¸Ç¹È ÈµÎÎ Î®Î·ÏžÐÐ˜Ð™Ð›ÐŸÐ¸Ð¹Ð»Ð¿ÑÒŠÒ‹Ó…Ó†Ó¢Ó£Ó¤Ó¥Ï€',
  o: 'Ã’Ã“Ã”Ã•Ã–Ã˜Ã°Ã²Ã³Ã´ÃµÃ¶Ã¸ÅŒÅÅŽÅÅÅ‘ÆŸÆ Æ¡Ç‘Ç’ÇªÇ«Ç¬Ç­Ç¾Ç¿ÈŒÈÈŽÈÈªÈ«È¬È­È®È¯È°È±ÎŒÎ˜ÎŸÎ¸Î¿ÏƒÏŒÏ•Ï˜Ï™Ï¬Ï´ÐžÐ¤Ð¾Ñ²Ñ³Ó¦Ó§Ó¨Ó©ÓªÓ«',
  p: 'Æ¤Î¡ÏÏ·Ï¸Ï¼Ð Ñ€ÒŽÒÃž',
  q: 'ÉŠÉ‹',
  r: 'Å”Å•Å–Å—Å˜Å™Æ¦ÈÈ‘È’È“ÉŒÉÐƒÐ“Ð¯Ð³ÑÑ“ÒÒ‘',
  s: 'ÅšÅ›ÅœÅÅžÅŸÅ Å¡Æ§Æ¨È˜È™È¿Ð…Ñ•',
  t: 'Å¢Å£Å¤Å¥Å¦Å§Æ«Æ¬Æ­Æ®ÈšÈ›È¶È¾Î“Î¤Ï„Ï®Ð¢Ñ‚',
  u: 'Ã™ÃšÃ›ÃœÃ¹ÃºÃ»Ã¼Å¨Å©ÅªÅ«Å¬Å­Å®Å¯Å°Å±Å²Å³Æ¯Æ°Æ±Æ²Ç“Ç”Ç•Ç–Ç—Ç˜Ç™ÇšÇ›ÇœÈ”È•È–È—É„Î°Ï…Ï‹Ï',
  v: 'Î½Ñ´ÑµÑ¶Ñ·',
  w: 'Å´ÅµÆœÏ‰ÏŽÏ–Ï¢Ï£Ð¨Ð©ÑˆÑ‰Ñ¡Ñ¿',
  x: 'Ã—Î§Ï‡Ï—Ï°Ð¥Ñ…Ò²Ò³Ó¼Ó½Ó¾Ó¿',
  y: 'ÃÃ½Ã¿Å¶Å·Å¸Æ³Æ´È²È³ÉŽÉÎŽÎ¥Î«Î³ÏˆÏ’Ï“Ï”ÐŽÐ£ÑƒÑ‡ÑžÑ°Ñ±Ò®Ò¯Ò°Ò±Ó®Ó¯Ó°Ó±Ó²Ó³',
  z: 'Å¹ÅºÅ»Å¼Å½Å¾ÆµÆ¶È¤È¥É€Î–',
};
//decompress data into two hashes
let unicode = {};
Object.keys(compact).forEach(function (k) {
  compact[k].split('').forEach(function (s) {
    unicode[s] = k;
  });
});

// https://util.unicode.org/UnicodeJsps/list-unicodeset.jsp?a=%5Cp%7Bpunctuation%7D

// punctuation to keep at start of word
const prePunctuation = {
  '#': true, //#hastag
  '@': true, //@atmention
  '_': true,//underscore
  'Â°': true,
  // '+': true,//+4
  // '\\-',//-4  (escape)
  // '.',//.4
  // zero-width chars
  '\u200B': true,
  '\u200C': true,
  '\u200D': true,
  '\uFEFF': true
};

// punctuation to keep at end of word
const postPunctuation = {
  '%': true,//88%
  '_': true,//underscore
  'Â°': true,//degrees, italian ordinal
  // '\'',// sometimes
  // zero-width chars
  '\u200B': true,
  '\u200C': true,
  '\u200D': true,
  '\uFEFF': true
};

const emoticons$1 = {
  '<3': true,
  '</3': true,
  '<\\3': true,
  ':^P': true,
  ':^p': true,
  ':^O': true,
  ':^3': true,
};

var model$3 = {
  one: {
    aliases: aliases$1,
    abbreviations,
    prefixes: prefixes$1,
    suffixes: suffixes$4,
    prePunctuation,
    postPunctuation,
    lexicon: lexicon$1, //give this one forward
    unicode,
    emoticons: emoticons$1
  },
};

const hasSlash$1 = /\//;
const hasDomain = /[a-z]\.[a-z]/i;
const isMath = /[0-9]/;
// const hasSlash = /[a-z\u00C0-\u00FF] ?\/ ?[a-z\u00C0-\u00FF]/
// const hasApostrophe = /['â€™]s$/

const addAliases = function (term, world) {
  let str = term.normal || term.text || term.machine;
  const aliases = world.model.one.aliases;
  // lookup known aliases like '&'
  if (aliases.hasOwnProperty(str)) {
    term.alias = term.alias || [];
    term.alias.push(aliases[str]);
  }
  // support slashes as aliases
  if (hasSlash$1.test(str) && !hasDomain.test(str) && !isMath.test(str)) {
    let arr = str.split(hasSlash$1);
    // don't split urls and things
    if (arr.length <= 3) {
      arr.forEach(word => {
        word = word.trim();
        if (word !== '') {
          term.alias = term.alias || [];
          term.alias.push(word);
        }
      });
    }
  }
  // aliases for apostrophe-s
  // if (hasApostrophe.test(str)) {
  //   let main = str.replace(hasApostrophe, '').trim()
  //   term.alias = term.alias || []
  //   term.alias.push(main)
  // }
  return term
};

const hasDash = /^\p{Letter}+-\p{Letter}+$/u;
// 'machine' is a normalized form that looses human-readability
const doMachine = function (term) {
  let str = term.implicit || term.normal || term.text;
  // remove apostrophes
  str = str.replace(/['â€™]s$/, '');
  str = str.replace(/s['â€™]$/, 's');
  //lookin'->looking (make it easier for conjugation)
  str = str.replace(/([aeiou][ktrp])in'$/, '$1ing');
  //turn re-enactment to reenactment
  if (hasDash.test(str)) {
    str = str.replace(/-/g, '');
  }
  //#tags, @mentions
  str = str.replace(/^[#@]/, '');
  if (str !== term.normal) {
    term.machine = str;
  }
};

// sort words by frequency
const freq = function (view) {
  let docs = view.docs;
  let counts = {};
  for (let i = 0; i < docs.length; i += 1) {
    for (let t = 0; t < docs[i].length; t += 1) {
      let term = docs[i][t];
      let word = term.machine || term.normal;
      counts[word] = counts[word] || 0;
      counts[word] += 1;
    }
  }
  // add counts on each term
  for (let i = 0; i < docs.length; i += 1) {
    for (let t = 0; t < docs[i].length; t += 1) {
      let term = docs[i][t];
      let word = term.machine || term.normal;
      term.freq = counts[word];
    }
  }
};

// get all character startings in doc
const offset = function (view) {
  let elapsed = 0;
  let index = 0;
  let docs = view.document; //start from the actual-top
  for (let i = 0; i < docs.length; i += 1) {
    for (let t = 0; t < docs[i].length; t += 1) {
      let term = docs[i][t];
      term.offset = {
        index: index,
        start: elapsed + term.pre.length,
        length: term.text.length,
      };
      elapsed += term.pre.length + term.text.length + term.post.length;
      index += 1;
    }
  }
};

// cheat- add the document's pointer to the terms
const index$1 = function (view) {
  // console.log('reindex')
  let document = view.document;
  for (let n = 0; n < document.length; n += 1) {
    for (let i = 0; i < document[n].length; i += 1) {
      document[n][i].index = [n, i];
    }
  }
  // let ptrs = b.fullPointer
  // console.log(ptrs)
  // for (let i = 0; i < docs.length; i += 1) {
  //   const [n, start] = ptrs[i]
  //   for (let t = 0; t < docs[i].length; t += 1) {
  //     let term = docs[i][t]
  //     term.index = [n, start + t]
  //   }
  // }
};

const wordCount = function (view) {
  let n = 0;
  let docs = view.docs;
  for (let i = 0; i < docs.length; i += 1) {
    for (let t = 0; t < docs[i].length; t += 1) {
      if (docs[i][t].normal === '') {
        continue //skip implicit words
      }
      n += 1;
      docs[i][t].wordCount = n;
    }
  }
};

// cheat-method for a quick loop
const termLoop$1 = function (view, fn) {
  let docs = view.docs;
  for (let i = 0; i < docs.length; i += 1) {
    for (let t = 0; t < docs[i].length; t += 1) {
      fn(docs[i][t], view.world);
    }
  }
};

const methods$2 = {
  alias: (view) => termLoop$1(view, addAliases),
  machine: (view) => termLoop$1(view, doMachine),
  normal: (view) => termLoop$1(view, normalize$2),
  freq,
  offset,
  index: index$1,
  wordCount,
};

var tokenize = {
  compute: methods$2,
  methods: methods$3,
  model: model$3,
  hooks: ['alias', 'machine', 'index', 'id'],
};

// const plugin = function (world) {
//   let { methods, model, parsers } = world
//   Object.assign({}, methods, _methods)
//   Object.assign(model, _model)
//   methods.one.tokenize.fromString = tokenize
//   parsers.push('normal')
//   parsers.push('alias')
//   parsers.push('machine')
//   // extend View class
//   // addMethods(View)
// }
// export default plugin

// lookup last word in the type-ahead prefixes
const typeahead$1 = function (view) {
  const prefixes = view.model.one.typeahead;
  const docs = view.docs;
  if (docs.length === 0 || Object.keys(prefixes).length === 0) {
    return
  }
  let lastPhrase = docs[docs.length - 1] || [];
  let lastTerm = lastPhrase[lastPhrase.length - 1];
  // if we've already put whitespace, end.
  if (lastTerm.post) {
    return
  }
  // if we found something
  if (prefixes.hasOwnProperty(lastTerm.normal)) {
    let found = prefixes[lastTerm.normal];
    // add full-word as an implicit result
    lastTerm.implicit = found;
    lastTerm.machine = found;
    lastTerm.typeahead = true;
    // tag it, as our assumed term
    if (view.compute.preTagger) {
      view.last().unTag('*').compute(['lexicon', 'preTagger']);
    }
  }
};

var compute$4 = { typeahead: typeahead$1 };

// assume any discovered prefixes
const autoFill = function () {
  const docs = this.docs;
  if (docs.length === 0) {
    return this
  }
  let lastPhrase = docs[docs.length - 1] || [];
  let term = lastPhrase[lastPhrase.length - 1];
  if (term.typeahead === true && term.machine) {
    term.text = term.machine;
    term.normal = term.machine;
  }
  return this
};

const api$k = function (View) {
  View.prototype.autoFill = autoFill;
};

// generate all the possible prefixes up-front
const getPrefixes = function (arr, opts, world) {
  let index = {};
  let collisions = [];
  let existing = world.prefixes || {};
  arr.forEach((str) => {
    str = str.toLowerCase().trim();
    let max = str.length;
    if (opts.max && max > opts.max) {
      max = opts.max;
    }
    for (let size = opts.min; size < max; size += 1) {
      let prefix = str.substring(0, size);
      // ensure prefix is not a word
      if (opts.safe && world.model.one.lexicon.hasOwnProperty(prefix)) {
        continue
      }
      // does it already exist?
      if (existing.hasOwnProperty(prefix) === true) {
        collisions.push(prefix);
        continue
      }
      if (index.hasOwnProperty(prefix) === true) {
        collisions.push(prefix);
        continue
      }
      index[prefix] = str;
    }
  });
  // merge with existing prefixes
  index = Object.assign({}, existing, index);
  // remove ambiguous-prefixes
  collisions.forEach((str) => {
    delete index[str];
  });
  return index
};

const isObject = val => {
  return Object.prototype.toString.call(val) === '[object Object]'
};

const defaults$1 = {
  safe: true,
  min: 3,
};

const prepare = function (words = [], opts = {}) {
  let model = this.model();
  opts = Object.assign({}, defaults$1, opts);
  if (isObject(words)) {
    Object.assign(model.one.lexicon, words);
    words = Object.keys(words);
  }
  let prefixes = getPrefixes(words, opts, this.world());
  // manually combine these with any existing prefixes
  Object.keys(prefixes).forEach(str => {
    // explode any overlaps
    if (model.one.typeahead.hasOwnProperty(str)) {
      delete model.one.typeahead[str];
      return
    }
    model.one.typeahead[str] = prefixes[str];
  });
  return this
};

var lib = {
  typeahead: prepare
};

const model$2 = {
  one: {
    typeahead: {} //set a blank key-val
  }
};
var typeahead = {
  model: model$2,
  api: api$k,
  lib,
  compute: compute$4,
  hooks: ['typeahead']
};

// order here matters
nlp.extend(change); //0kb
nlp.extend(output); //0kb
nlp.extend(match); //10kb
nlp.extend(pointers); //2kb
nlp.extend(tag); //2kb
nlp.plugin(plugin$3); //~6kb
nlp.extend(tokenize); //7kb
nlp.extend(freeze); //
nlp.plugin(cache$1); //~1kb
nlp.extend(lookup); //7kb
nlp.extend(typeahead); //1kb
nlp.extend(lexicon$2); //1kb
nlp.extend(sweep); //1kb

//nouns with irregular plural/singular forms
//used in nouns.toPlural(), and also in the lexicon.

var irregularPlurals = {
  // -a
  addendum: 'addenda',
  corpus: 'corpora',
  criterion: 'criteria',
  curriculum: 'curricula',
  genus: 'genera',
  memorandum: 'memoranda',
  opus: 'opera',
  ovum: 'ova',
  phenomenon: 'phenomena',
  referendum: 'referenda',

  // -ae
  alga: 'algae',
  alumna: 'alumnae',
  antenna: 'antennae',
  formula: 'formulae',
  larva: 'larvae',
  nebula: 'nebulae',
  vertebra: 'vertebrae',

  // -is
  analysis: 'analyses',
  axis: 'axes',
  diagnosis: 'diagnoses',
  parenthesis: 'parentheses',
  prognosis: 'prognoses',
  synopsis: 'synopses',
  thesis: 'theses',
  neurosis: 'neuroses',
  // -x
  appendix: 'appendices',
  index: 'indices',
  matrix: 'matrices',
  ox: 'oxen',
  sex: 'sexes',

  // -i
  alumnus: 'alumni',
  bacillus: 'bacilli',
  cactus: 'cacti',
  fungus: 'fungi',
  hippopotamus: 'hippopotami',
  libretto: 'libretti',
  modulus: 'moduli',
  nucleus: 'nuclei',
  octopus: 'octopi',
  radius: 'radii',
  stimulus: 'stimuli',
  syllabus: 'syllabi',

  // -ie
  cookie: 'cookies',
  calorie: 'calories',
  auntie: 'aunties',
  movie: 'movies',
  pie: 'pies',
  rookie: 'rookies',
  tie: 'ties',
  zombie: 'zombies',

  // -f
  leaf: 'leaves',
  loaf: 'loaves',
  thief: 'thieves',

  // ee-
  foot: 'feet',
  goose: 'geese',
  tooth: 'teeth',

  // -eaux
  beau: 'beaux',
  chateau: 'chateaux',
  tableau: 'tableaux',

  // -ses
  bus: 'buses',
  gas: 'gases',
  circus: 'circuses',
  crisis: 'crises',
  virus: 'viruses',
  database: 'databases',
  excuse: 'excuses',
  abuse: 'abuses',

  avocado: 'avocados',
  barracks: 'barracks',
  child: 'children',
  clothes: 'clothes',
  echo: 'echoes',
  embargo: 'embargoes',
  epoch: 'epochs',
  deer: 'deer',
  halo: 'halos',
  man: 'men',
  woman: 'women',
  mosquito: 'mosquitoes',
  mouse: 'mice',
  person: 'people',
  quiz: 'quizzes',
  rodeo: 'rodeos',
  shoe: 'shoes',
  sombrero: 'sombreros',
  stomach: 'stomachs',
  tornado: 'tornados',
  tuxedo: 'tuxedos',
  volcano: 'volcanoes',

};

// generated in ./lib/lexicon
var lexData = {
  "Comparative": "trueÂ¦bett1f0;arth0ew0in0;er",
  "Superlative": "trueÂ¦earlier",
  "PresentTense": "trueÂ¦bests,sounds",
  "Condition": "trueÂ¦lest,unless",
  "PastTense": "trueÂ¦began,came,d4had,kneel3l2m0sa4we1;ea0sg2;nt;eap0i0;ed;id",
  "Participle": "trueÂ¦0:09;a06b01cZdXeat0fSgQhPoJprov0rHs7t6u4w1;ak0ithdra02o2r1;i02uY;k0v0;nd1pr04;ergoJoJ;ak0hHo3;e9h7lain,o6p5t4un3w1;o1um;rn;g,k;ol0reS;iQok0;ught,wn;ak0o1runk;ne,wn;en,wn;ewriNi1uJ;dd0s0;ut3ver1;do4se0t1;ak0h2;do2g1;roG;ne;ast0i7;iv0o1;ne,tt0;all0loBor1;bi3g2s1;ak0e0;iv0o9;dd0;ove,r1;a5eamt,iv0;hos0lu1;ng;e4i3lo2ui1;lt;wn;tt0;at0en,gun;r2w1;ak0ok0;is0;en",
  "Gerund": "trueÂ¦accord0be0doin,go0result0stain0;ing",
  "Expression": "trueÂ¦a0Yb0Uc0Sd0Oe0Mfarew0Lg0FhZjeez,lWmVnToOpLsJtIuFvEw7y0;a5e3i1u0;ck,p;k04p0;ee,pee;a0p,s;!h;!a,h,y;a5h2o1t0;af,f;rd up,w;atsoever,e1o0;a,ops;e,w;hoo,t;ery w06oi0L;gh,h0;! 0h,m;huh,oh;here nPsk,ut tut;h0ic;eesh,hh,it,oo;ff,h1l0ow,sst;ease,s,z;ew,ooey;h1i,mg,o0uch,w,y;h,o,ps;! 0h;hTmy go0wT;d,sh;a7evertheless,o0;!pe;eh,mm;ah,eh,m1ol0;!s;ao,fao;aCeBi9o2u0;h,mph,rra0zzC;h,y;l1o0;r6y9;la,y0;! 0;c1moCsmok0;es;ow;!p hip hoor0;ay;ck,e,llo,y;ha1i,lleluj0;ah;!ha;ah,ee4o1r0;eat scott,r;l1od0sh; grief,bye;ly;! whiz;ell;e0h,t cetera,ureka,ww,xcuse me;k,p;'oh,a0rat,uh;m0ng;mit,n0;!it;mon,o0;ngratulations,wabunga;a2oo1r0tw,ye;avo,r;!ya;h,m; 1h0ka,las,men,rgh,ye;!a,em,h,oy;la",
  "Negative": "trueÂ¦n0;ever,o0;n,t",
  "QuestionWord": "trueÂ¦how3wh0;at,e1ich,o0y;!m,se;n,re; come,'s",
  "Reflexive": "trueÂ¦h4it5my5o1the0your2;ir1m1;ne3ur0;sel0;f,ves;er0im0;self",
  "Plural": "trueÂ¦dick0gre0ones,records;ens",
  "Unit|Noun": "trueÂ¦cEfDgChBinchAk9lb,m6newt5oz,p4qt,t1y0;ardEd;able1b0ea1sp;!l,sp;spo1;a,t,x;on9;!b,g,i1l,m,p0;h,s;!les;!b,elvin,g,m;!es;g,z;al,b;eet,oot,t;m,up0;!s",
  "Value": "trueÂ¦a few",
  "Imperative": "trueÂ¦bewa0come he0;re",
  "Plural|Verb": "trueÂ¦leaves",
  "Demonym": "trueÂ¦0:15;1:12;a0Vb0Oc0Dd0Ce08f07g04h02iYjVkTlPmLnIomHpEqatari,rCs7t5u4v3welAz2;am0Gimbabwe0;enezuel0ietnam0I;gAkrai1;aiwTex0hai,rinida0Ju2;ni0Prkmen;a5cotti4e3ingapoOlovak,oma0Spaniard,udRw2y0W;ede,iss;negal0Cr09;sh;mo0uT;o5us0Jw2;and0;a2eru0Fhilippi0Nortugu07uerto r0S;kist3lesti1na2raguay0;ma1;ani;ami00i2orweP;caragu0geri2;an,en;a3ex0Lo2;ngo0Drocc0;cedo1la2;gasy,y07;a4eb9i2;b2thua1;e0Cy0;o,t01;azakh,eny0o2uwaiI;re0;a2orda1;ma0Ap2;anO;celandic,nd4r2sraeli,ta01vo05;a2iB;ni0qi;i0oneU;aiAin2ondur0unO;di;amEe2hanai0reek,uatemal0;or2rm0;gi0;ilipino,ren8;cuadoVgyp4mira3ngli2sto1thiopi0urope0;shm0;ti;ti0;aPominUut3;a9h6o4roat3ub0ze2;ch;!i0;lom2ngol5;bi0;a6i2;le0n2;ese;lifor1m2na3;bo2eroo1;di0;angladeshi,el6o4r3ul2;gaE;azi9it;li2s1;vi0;aru2gi0;si0;fAl7merBngol0r5si0us2;sie,tr2;a2i0;li0;genti2me1;ne;ba1ge2;ri0;ni0;gh0r2;ic0;an",
  "Organization": "trueÂ¦0:4Q;a3Tb3Bc2Od2He2Df27g1Zh1Ti1Pj1Nk1Ll1Gm12n0Po0Mp0Cqu0Br02sTtHuCv9w3xiaomi,y1;amaha,m1Bou1w1B;gov,tu3C;a4e2iki1orld trade organizati33;leaRped0O;lls fargo,st1;fie2Hinghou2R;l1rner br3U;gree3Jl street journ2Im1E;an halOeriz2Xisa,o1;dafo2Yl1;kswagMvo;b4kip,n2ps,s1;a tod3Aps;es3Mi1;lev3Fted natio3C;er,s; mobi32aco beRd bOe9gi frida3Lh3im horto3Amz,o1witt3D;shi49y1;ota,s r 05;e 1in lizzy;b3carpen3Jdaily ma3Dguess w2holli0s1w2;mashing pumpki35uprem0;ho;ea1lack eyed pe3Xyr0Q;ch bo3Dtl0;l2n3Qs1xas instrumen1U;co,la m1F;efoni0Kus;a8cientology,e5ieme2Ymirnoff,np,o3pice gir6quare0Ata1ubaru;rbuc1to34;ks;ny,undgard1;en;a2x pisto1;ls;g1Wrs;few2Minsbur31lesfor03msu2E;adiohead,b8e4o1yana3C;man empi1Xyal 1;b1dutch she4;ank;a3d 1max,vl20;bu1c2Ahot chili peppe2Ylobst2N;ll;ders dige1Ll madrid;c,s;ant3Aizn2Q;a8bs,e5fiz2Ihilip4i3r1;emier 1udenti1D;leagTo2K;nk floyd,zza hut; morrBs;psi2tro1uge0E;br33chi0Tn33;!co;lant2Un1yp16; 2ason27da2P;ld navy,pec,range juli2xf1;am;us;aAb9e6fl,h5i4o1sa,vid3wa;k2tre dame,vart1;is;ia;ke,ntendo,ss0QvZ;l,s;c,st1Otflix,w1; 1sweek;kids on the block,york0D;a,c;nd22s2t1;ional aca2Po,we0U;a,c02d0S;aDcdonalCe9i6lb,o3tv,y1;spa1;ce;b1Tnsanto,ody blu0t1;ley cr1or0T;ue;c2t1;as,subisO;helin,rosoft;dica2rcedes benz,talli1;ca;id,re;ds;cs milk,tt19z24;a3e1g,ittle caesa1P; ore09novo,x1;is,mark,us; 1bour party;pres0Dz boy;atv,fc,kk,lm,m1od1O;art;iffy lu0Roy divisi0Jpmorgan1sa;! cha09;bm,hop,k3n1tv;g,te1;l,rpol;ea;a5ewlett pack1Vi3o1sbc,yundai;me dep1n1P;ot;tac1zbollah;hi;lliburt08sbro;eneral 6hq,ithub,l5mb,o2reen d0Ou1;cci,ns n ros0;ldman sachs,o1;dye1g0H;ar;axo smith kli04encoW;electr0Nm1;oto0Z;a5bi,c barcelo4da,edex,i2leetwood m03o1rito l0G;rd,xcY;at,fa,nancial1restoZ; tim0;na;cebook,nnie mae;b0Asa,u3xxon1; m1m1;ob0J;!rosceptics;aiml0De5isney,o4u1;nkin donu2po0Zran dur1;an;ts;j,w jon0;a,f lepp12ll,peche mode,r spieg02stiny's chi1;ld;aJbc,hFiDloudflaCnn,o3r1;aigsli5eedence clearwater reviv1ossra09;al;c7inba6l4m1o0Est09;ca2p1;aq;st;dplSg1;ate;se;a c1o chanQ;ola;re;a,sco1tigroup;! systems;ev2i1;ck fil a,na daily;r1y;on;d2pital o1rls jr;ne;bury,ill1;ac;aEbc,eBf9l5mw,ni,o1p,rexiteeU;ei3mbardiIston 1;glo1pizza;be;ng;o2ue c1;roV;ckbuster video,omingda1;le; g1g1;oodriL;cht2e ge0rkshire hathaw1;ay;el;cardi,idu,nana republ3s1xt5y5;f,kin robbi1;ns;ic;bYcTdidSerosmith,iRlKmEnheuser busDol,ppleAr6s4u3v2y1;er;is,on;di,todesk;hland o1sociated E;il;b3g2m1;co;os;ys; compu1be0;te1;rs;ch;c,d,erican3t1;!r1;ak; ex1;pre1;ss; 5catel2ta1;ir;! lu1;ce1;nt;jazeera,qae1;da;g,rbnb;as;/dc,a3er,tivision1;! blizz1;ard;demy of scienc0;es;ba",
  "Possessive": "trueÂ¦its,my,our0thy;!s",
  "Noun|Verb": "trueÂ¦0:9W;1:AA;2:96;3:A3;4:9R;5:A2;6:9K;7:8N;8:7L;9:A8;A:93;B:8D;C:8X;a9Ob8Qc7Id6Re6Gf5Sg5Hh55i4Xj4Uk4Rl4Em40n3Vo3Sp2Squ2Rr21s0Jt02u00vVwGyFzD;ip,oD;ne,om;awn,e6Fie68;aOeMhJiHoErD;ap,e9Oink2;nd0rDuC;kDry,sh5Hth;!shop;ck,nDpe,re,sh;!d,g;e86iD;p,sD;k,p0t2;aDed,lco8W;r,th0;it,lk,rEsDt4ve,x;h,te;!ehou1ra9;aGen5FiFoD;iDmAte,w;ce,d;be,ew,sA;cuum,l4B;pDr7;da5gra6Elo6A;aReQhrPiOoMrGuEwiDy5Z;n,st;nDrn;e,n7O;aGeFiEoDu6;t,ub2;bu5ck4Jgg0m,p;at,k,nd;ck,de,in,nsDp,v7J;f0i8R;ll,ne,p,r4Yss,t94uD;ch,r;ck,de,e,le,me,p,re;e5Wow,u6;ar,e,ll,mp0st,xt;g,lDng2rg7Ps5x;k,ly;a0Sc0Ne0Kh0Fi0Dk0Cl0Am08n06o05pXquaBtKuFwD;ea88iD;ng,pe,t4;bGit,m,ppErD;fa3ge,pri1v2U;lDo6S;e6Py;!je8;aMeLiKoHrEuDy2;dy,ff,mb2;a85eEiDo5Pugg2;ke,ng;am,ss,t4;ckEop,p,rD;e,m;ing,pi2;ck,nk,t4;er,m,p;ck,ff,ge,in,ke,lEmp,nd,p2rDte,y;!e,t;k,l;aJeIiHlGoFrDur,y;ay,e56inDu3;g,k2;ns8Bt;a5Qit;ll,n,r87te;ed,ll;m,n,rk;b,uC;aDee1Tow;ke,p;a5Je4FiDo53;le,rk;eep,iDou4;ce,p,t;ateboa7Ii;de,gnDl2Vnk,p,ze;!al;aGeFiEoDuff2;ck,p,re,w;ft,p,v0;d,i3Ylt0;ck,de,pe,re,ve;aEed,nDrv1It;se,t2N;l,r4t;aGhedu2oBrD;aEeDibb2o3Z;en,w;pe,t4;le,n,r2M;cDfegua72il,mp2;k,rifi3;aZeHhy6LiGoEuD;b,in,le,n,s5X;a6ck,ll,oDpe,u5;f,t;de,ng,ot,p,s1W;aTcSdo,el,fQgPje8lOmMnLo17pJque6sFturn,vDwa6V;eDi27;al,r1;er74oFpe8tEuD;lt,me;!a55;l71rt;air,eaDly,o53;l,t;dezvo2Zt;aDedy;ke,rk;ea1i4G;a6Iist0r5N;act6Yer1Vo71uD;nd,se;a38o6F;ch,s6G;c1Dge,iEke,lly,nDp1Wt1W;ge,k,t;n,se;es6Biv0;a04e00hYiXlToNrEsy4uD;mp,n4rcha1sh;aKeIiHoDu4O;be,ceFdu3fi2grDje8mi1p,te6;amDe6W;!me;ed,ss;ce,de,nt;sDy;er6Cs;cti3i1;iHlFoEp,re,sDuCw0;e,i5Yt;l,p;iDl;ce,sh;nt,s5V;aEce,e32uD;g,mp,n7;ce,nDy;!t;ck,le,n17pe,tNvot;a1oD;ne,tograph;ak,eFnErDt;fu55mA;!c32;!l,r;ckJiInHrFsEtDu1y;ch,e9;s,te;k,tD;!y;!ic;nt,r,se;!a7;bje8ff0il,oErDutli3Qver4B;bAd0ie9;ze;a4ReFoDur1;d,tD;e,i3;ed,gle8tD;!work;aMeKiIoEuD;rd0;ck,d3Rld,nEp,uDve;nt,th;it5EkD;ey;lk,n4Brr5CsDx;s,ta2B;asuBn4UrDss;ge,it;il,nFp,rk3WsEtD;ch,t0;h,k,t0;da5n0oeuvB;aLeJiHoEuD;mp,st;aEbby,ck,g,oDve;k,t;d,n;cDe,ft,mAnIst;en1k;aDc0Pe4vK;ch,d,k,p,se;bFcEnd,p,t4uD;gh,n4;e,k;el,o2U;eEiDno4E;ck,d,ll,ss;el,y;aEo1OuD;i3mp;m,zz;mpJnEr46ssD;ue;c1Rdex,fluGha2k,se2HteDvoi3;nt,rD;e6fa3viD;ew;en3;a8le2A;aJeHiGoEuD;g,nt;l3Ano2Dok,pDr1u1;!e;ghli1Fke,nt,re,t;aDd7lp;d,t;ck,mGndFrEsh,tDu9;ch,e;bo3Xm,ne4Eve6;!le;!m0;aMear,ift,lKossJrFuD;arDe4Alp,n;antee,d;aFiEoDumb2;uCwth;ll,nd,p;de,sp;ip;aBoDue;ss,w;g,in,me,ng,s,te,ze;aZeWiRlNoJrFuD;ck,el,nDss,zz;c38d;aEoDy;st,wn;cDgme,me,nchi1;tuB;cFg,il,ld,rD;ce,e29mDwa31;!at;us;aFe0Vip,oDy;at,ck,od,wD;!er;g,ke,me,re,sh,vo1E;eGgFlEnDre,sh,t,x;an3i0Q;e,m,t0;ht,uB;ld;aEeDn3;d,l;r,tuB;ce,il,ll,rm,vo2W;cho,d7ffe8nMsKxFyeD;!baD;ll;cGerci1hFpDtra8;eriDo0W;en3me9;au6ibA;el,han7u1;caDtima5;pe;count0d,vy;a01eSiMoJrEuDye;b,el,mp,pli2X;aGeFiEoD;ne,p;ft,ll,nk,p,ve;am,ss;ft,g,in;cEd7ubt,wnloD;ad;k,u0E;ge6p,sFt4vD;e,iDor3;de;char7gui1h,liEpD;at4lay,u5;ke;al,bKcJfeIlGmaCposAsEtaD;il;e07iD;gn,re;ay,ega5iD;ght;at,ct;li04rea1;a5ut;b,ma7n3rDte;e,t;a0Eent0Dh06irc2l03oKrFuD;be,e,rDt;b,e,l,ve;aGeFoEuDy;sh;p,ss,wd;dAep;ck,ft,sh;at,de,in,lTmMnFordina5py,re,st,uDv0;gh,nDp2rt;s01t;ceHdu8fli8glomeIsFtDveN;a8rD;a6ol;e9tru8;ct;ntDrn;ra5;bHfoGmFpD;leDouCromi1;me9;aCe9it,u5;rt;at,iD;ne;lap1oD;r,ur;aEiDoud,ub;ck,p;im,w;aEeDip;at,ck,er;iGllen7nErD;ge,m,t;ge,nD;el;n,r;er,re;ke,ll,mp,noe,pGrXsFtEuDve;se,ti0I;alog,ch;h,t;!tuB;re;a03eZiXlToPrHuEyD;pa11;bb2ck2dgEff0mp,rDst,zz;den,n;et;anJeHiFoadEuD;i1sh;ca6;be,d7;ge;aDed;ch,k;ch,d;aFg,mb,nEoDrd0tt2x,ycott;k,st,t;d,e;rd,st;aFeCiDoYur;nk,tz;nd;me;as,d,ke,nd,opsy,tD;!ch,e;aFef,lt,nDt;d,efA;it;r,t;ck,il,lan3nIrFsEtt2;le;e,h;!gDk;aDe;in;!d,g,k;bu1c05dZge,iYlVnTppQrLsIttGucEwaD;rd;tiD;on;aDempt;ck;k,sD;i6ocia5;st;chFmD;!oD;ur;!iD;ve;eEroa4;ch;al;chDg0sw0;or;aEt0;er;rm;d,m,r;dreHvD;an3oD;ca5;te;ce;ss;cDe,he,t;eFoD;rd,u9;nt;nt,ss;se",
  "Actor": "trueÂ¦0:7B;1:7G;2:6A;3:7F;4:7O;5:7K;a6Nb62c4Ud4Be41f3Sg3Bh30i2Uj2Qkin2Pl2Km26n1Zo1Sp0Vqu0Tr0JsQtJuHvEw8yo6;gi,ut6;h,ub0;aAe9i8o7r6;estl0it0;m2rk0;fe,nn0t2Bza2H;atherm2ld0;ge earn0it0nder0rri1;eter7i6oyF;ll5Qp,s3Z;an,ina2U;n6s0;c6Uder03;aoisea23e9herapi5iktok0o8r6ut1yco6S;a6endseLo43;d0mp,nscri0Bvel0;ddl0u1G;a0Qchn7en6na4st0;ag0;i3Oo0D;aiXcUeRhPiMki0mu26oJpGquaFtBu7wee6;p0theart;lt2per7r6;f0ge6Iviv1;h6inten0Ist5Ivis1;ero,um2;a8ep7r6;ang0eam0;bro2Nc2Ofa2Nmo2Nsi20;ff0tesm2;tt0;ec7ir2Do6;kesp59u0M;ia5Jt3;l7me6An,rcere6ul;r,ss;di0oi5;n7s6;sy,t0;g0n0;am2ephe1Iow6;girl,m2r2Q;cretInior cit3Fr6;gea4v6;a4it1;hol4Xi7reen6ulpt1;wr2C;e01on;l1nt;aEe9o8u6;l0nn6;er up,ingE;g40le mod3Zof0;a4Zc8fug2Ppo32searQv6;ere4Uolution6;ary;e6luYru22;ptio3T;bbi,dic5Vpp0;arter6e2Z;back;aYeWhSiRlOoKr8sycho7u6;nk,p31;logi5;aGeDiBo6;d9fess1g7ph47s6;pe2Ktitu51;en6ramm0;it1y;igy,uc0;est4Nme mini0Unce6s3E;!ss;a7si6;de4;ch0;ctiti39nk0P;dca0Oet,li6pula50rnst42;c2Itic6;al scie6i2;nti5;a6umb0;nn0y6;er,ma4Lwright;lgrim,one0;a8iloso7otogra7ra6ysi1V;se;ph0;ntom,rmaci5;r6ssi1T;form0s4O;i3El,nel3Yr8st1tr6wn;i6on;arWot;ent4Wi42tn0;ccupa4ffBp8r7ut6;ca5l0B;ac4Iganiz0ig2Fph2;er3t6;i1Jomet6;ri5;ic0spring;aBe9ie4Xo7u6;n,rser3J;b6mad,vi4V;le2Vo4D;i6mesis,phew;ce,ghb1;nny,rr3t1X;aEeDiAo7u6yst1Y;m8si16;der3gul,m7n6th0;arDk;!my;ni7s6;f02s0Jt0;on,st0;chan1Qnt1rcha4;gi9k0n8rtyr,t6y1;e,riar6;ch;ag0iac;ci2stra3I;a7e2Aieutena4o6;rd,s0v0;bor0d7ndlo6ss,urea3Fwy0ym2;rd;!y;!s28;e8o7u6;ggl0;gg0urna2U;st0;c3Hdol,llu3Ummigra4n6; l9c1Qfa4habi42nov3s7ve6;nt1stig3;pe0Nt6;a1Fig3ru0M;aw;airFeBistoAo8u6ygie1K;man6sba2H;!ita8;bo,st6usekN;age,e3P;ri2;ir,r6;m7o6;!ine;it;dress0sty2C;aLeIhostGirl26ladi3oCrand7u6;e5ru;c9daug0Jfa8m7pa6s2Y;!re4;a,o6;th0;hi1B;al7d6lf0;!de3A;ie,k6te26;eep0;!wr6;it0;isha,n6;i6tl04;us;mbl0rden0;aDella,iAo7r6;eela2Nie1P;e,re6ster pare4;be1Hm2r6st0;unn0;an2ZgZlmm17nanci0r6tt0;e6st la2H; marsh2OfigXm2;rm0th0;conoEdDlectriCm8n7x6;amin0cellency,i2A;emy,trepreneur,vironmenta1J;c8p6;er1loye6;e,r;ee;ci2;it1;mi5;aKeBi8ork,ri7u6we02;de,tche2H;ft0v0;ct3eti7plom2Hre6va;ct1;ci2ti2;aDcor3fencCi0InAput9s7tectLvel6;op0;ce1Ge6ign0;rt0;ee,y;iz6;en;em2;c1Ml0;d8nc0redev7ug6;ht0;il;!dy;a06e04fo,hXitizenWlToBr9u6;r3stomer6;! representat6;ive;e3it6;ic;lJmGnAord9rpor1Nu7w6;boy,ork0;n6ri0;ciTte1Q;in3;fidantAgressSs9t6;e0Kr6;ibut1o6;ll0;tab13ul1O;!e;edi2m6pos0rade;a0EeQissi6;on0;leag8on7um6;ni5;el;ue;e6own;an0r6;ic,k;!s;a9e7i6um;ld;erle6f;ad0;ir7nce6plFract0;ll1;m2wI;lebri6o;ty;dBptAr6shi0;e7pe6;nt0;r,t6;ak0;ain;et;aMeLiJlogg0oErBu6;dd0Fild0rgl9siness6;m2p7w6;om2;ers05;ar;i7o6;!k0th0;cklay0de,gadi0;hemi2oge8y6;!frie6;nd;ym2;an;cyc6sR;li5;atbox0ings;by,nk0r6;b0on7te6;nd0;!e07;c04dWge4nQpLrHsFtAu7yatull6;ah;nt7t6;h1oG;!ie;h8t6;e6orney;nda4;ie5le6;te;sis00tron6;aut,om0;chbis8isto7tis6;an,t;crU;hop;ost9p6;ari6rentiS;ti6;on;le;a9cest1im3nou8y6;bo6;dy;nc0;ly5rc6;hi5;mi8v6;entur0is1;er;ni7r6;al;str3;at1;or;counBquaintanArob9t6;ivi5or,re6;ss;st;at;ce;ta4;nt",
  "Adj|Noun": "trueÂ¦0:16;a1Db17c0Ud0Re0Mf0Dg0Ah08i06ju05l02mWnUoSpNrIsBt7u4v1watershed;a1ision0Z;gabo4nilla,ria1;b0Vnt;ndergr1pstairs;adua14ou1;nd;a3e1oken,ri0;en,r1;min0rori13;boo,n;age,e5ilv0Flack,o3quat,ta2u1well;bordina0Xper5;b0Lndard;ciali0Yl1vereign;e,ve16;cret,n1ri0;ior;a4e2ou1ubbiL;nd,tiY;ar,bBl0Wnt0p1side11;resent0Vublican;ci0Qsh;a4eriodic0last0Zotenti0r1;emi2incip0o1;!fession0;er,um;rall4st,tie0U;ff1pposi0Hv0;ens0Oi0C;agg01ov1uts;el;a5e3iniatJo1;bi01der07r1;al,t0;di1tr0N;an,um;le,riG;attOi2u1;sh;ber0ght,qC;stice,veniT;de0mpressioYn1;cumbe0Edividu0no0Dsta0Eterim;alf,o1umdrum;bby,melF;en2old,ra1;ph0Bve;er0ious;a7e5i4l3u1;git03t1;ure;uid;ne;llow,m1;aFiL;ir,t,vo1;riOuriO;l3p00x1;c1ecutUpeV;ess;d1iK;er;ar2e1;mographUrivO;k,l2;hiGlassSo2rude,unn1;ing;m5n1operK;creCstitueOte2vertab1;le;mpor1nt;ary;ic,m2p1;anion,lex;er2u1;ni8;ci0;al;e5lank,o4r1;i2u1;te;ef;ttom,urgeois;st;cadem9d6l2ntarct9r1;ab,ct8;e3tern1;at1;ive;rt;oles1ult;ce1;nt;ic",
  "Adj|Past": "trueÂ¦0:4Q;1:4C;2:4H;3:4E;a44b3Tc36d2Je29f20g1Wh1Si1Jj1Gkno1Fl1Am15n12o0Xp0Mqu0Kr08sLtEuAv9w4yellow0;a7ea6o4rinkl0;r4u3Y;n,ri0;k31th3;rp0sh0tZ;ari0e1O;n5p4s0;d1li1Rset;cov3derstood,i4;fi0t0;a8e3Rhr7i6ouTr4urn0wi4C;a4imm0ou2G;ck0in0pp0;ed,r0;eat2Qi37;m0nn0r4;get0ni2T;aOcKeIhGimFm0Hoak0pDt7u4;bsid3Ogge44s4;pe4ta2Y;ct0nd0;a8e7i2Eok0r5u4;ff0mp0nn0;ength2Hip4;ed,p0;am0reotyp0;in0t0;eci4ik0oH;al3Efi0;pRul1;a4ock0ut;d0r0;a4c1Jle2t31;l0s3Ut0;a6or5r4;at4e25;ch0;r0tt3;t4ut0;is2Mur1;aEe5o4;tt0;cAdJf2Bg9je2l8m0Knew0p7qu6s4;eTpe2t4;or0ri2;e3Dir0;e1lac0;at0e2Q;i0Rul1;eiv0o4ycl0;mme2Lrd0v3;in0lli0ti2A;a4ot0;li28;aCer30iBlAo9r5u4;mp0zzl0;e6i2Oo4;ce2Fd4lo1Anou30pos0te2v0;uc0;fe1CocCp0Iss0;i2Kli1L;ann0e2CuS;ck0erc0ss0;ck0i2Hr4st0;allLk0;bse7c6pp13rgan2Dver4;lo4whelm0;ok0;cupi0;rv0;aJe5o4;t0uri1A;ed0gle2;a6e5ix0o4ut0ys1N;di1Nt15u26;as0Clt0;n4rk0;ag0ufact0A;e6i5o4;ad0ck0st,v0;cens0m04st0;ft,v4;el0;tt0wn;a5o15u4;dg0s1B;gg0;llumSmpAn4sol1;br0cre1Ldebt0f8jZspir0t5v4;it0olv0;e4ox0Y;gr1n4re23;d0si15;e2l1o1Wuri1;li0o01r4;ov0;a6e1o4um03;ok0r4;ri0Z;mm3rm0;i6r5u4;a1Bid0;a0Ui0Rown;ft0;aAe9i8l6oc0Ir4;a4i0oz0Y;ctHg19m0;avo0Ju4;st3;ni08tt0x0;ar0;d0il0sc4;in1;dCl1mBn9quipp0s8x4;agger1c6p4te0T;a0Se4os0;ct0rie1D;it0;cap0tabliZ;cha0XgFha1As4;ur0;a0Zbarra0N;i0Buc1;aMeDi5r4;a01i0;gni08miniSre2s4;a9c6grun0Ft4;o4re0Hu17;rt0;iplWou4;nt0r4;ag0;bl0;cBdRf9l8p7ra6t5v4;elop0ot0;ail0ermQ;ng0;re07;ay0ight0;e4in0o0M;rr0;ay0enTor1;m5t0z4;ed,zl0;ag0p4;en0;aPeLhIlHo9r6u4;lt4r0stom03;iv1;a5owd0u4;sh0;ck0mp0;d0loAm7n4ok0v3;centr1f5s4troC;id3olid1;us0;b5pl4;ic1;in0;r0ur0;assi9os0utt3;ar5i4;ll0;g0m0;lebr1n6r4;ti4;fi0;tralJ;g0lcul1;aDewild3iCl9o7r5urn4;ed,t;ok4uis0;en;il0r0t4und;tl0;e5i4;nd0;ss0;as0;ffl0k0laMs0tt3;bPcNdKfIg0lFmaz0nDppBrm0ss9u5wa4;rd0;g5thor4;iz0;me4;nt0;o6u4;m0r0;li0re4;ci1;im1ticip1;at0;a5leg0t3;er0;rm0;fe2;ct0;ju5o7va4;nc0;st0;ce4knowledg0;pt0;and5so4;rb0;on0;ed",
  "Singular": "trueÂ¦0:5J;1:5H;2:4W;3:4S;4:52;5:57;6:5L;7:56;8:5B;a52b4Lc3Nd35e2Xf2Og2Jh28in24j23k22l1Um1Ln1Ho1Bp0Rqu0Qr0FsZtMuHvCw9x r58yo yo;a9ha3Po3Q;f3i4Rt0Gy9;! arou39;arCeAideo ga2Qo9;cabu4Jl5C;gOr9t;di4Zt1Y;iety,ni4P;nBp30rAs 9;do43s5E;bani1in0;coordinat3Ader9;estima1to24we41; rex,aKeJhHiFoErBuAv9;! show;m2On2rntLto1D;agedy,ib9o4E;e,u9;n0ta46;ni1p2rq3L;c,er,m9;etF;ing9ree26;!y;am,mp3F;ct2le6x return;aNcMeKhor4QiJkHoGpin off,tDuBy9;ll9ner7st4T;ab2X;b9i1n28per bowl,rro1X;st3Ltot0;atAipe2Go1Lrate7udent9;! lo0I;i39u1;ft ser4Lmeo1I;elet5i9;ll,r3V;b38gn2Tte;ab2Jc9min3B;t,urity gua2N;e6ho2Y;bbatic0la3Jndwi0Qpi5;av5eDhetor2iAo9;de6om,w;tAv9;erb2C;e,u0;bDcBf9publ2r10spi1;er9orm3;e6r0;i9ord label;p2Ht0;a1u46;estion mark,ot2F;aPeMhoLiIlGoErAu9yram1F;ddi3HpErpo1Js3J;eBo9;bl3Zs9;pe3Jta1;dic1Rmi1Fp1Qroga8ss relea1F;p9rt0;py;a9ebisci1;q2Dte;cn2eAg9;!gy;!r;ne call,tocoK;anut,dAr9t0yo1;cen3Jsp3K;al,est0;nop4rAt9;e,hog5;adi11i2V;atme0bj3FcBpia1rde0thers,utspok5ve9wn3;n,r9;ti0Pview;cuAe9;an;pi3;arBitAot9umb3;a2Fhi2R;e,ra1;cot2ra8;aFeCiAo9ur0;nopo4p18rni2Nsq1Rti36uld;c,li11n0As9tt5;chief,si34;dAnu,t9;al,i3;al,ic;gna1mm0nd15rsupi0te9yf4;ri0;aDegCiBu9;ddi1n9;ch;me,p09; Be0M;bor14y9; 9er;up;eyno1itt5;el4ourn0;cBdices,itia8ni25sAtel0Lvert9;eb1J;e28titu1;en8i2T;aIeEighDoAu9;man right,s22;me9rmoFsp1Ftb0K;! r9;un; scho0YriY;a9i1N;d9v5; start,pho9;ne;ndful,sh brown,v5ze;aBelat0Ilaci3r9ul4yp1S;an9enadi3id;a1Cd slam,ny;df4r9;l2ni1I;aGeti1HiFlu1oCrAun9;er0;ee market,i9onti3;ga1;l4ur9;so9;me;ePref4;br2mi4;conoFffi7gg,lecto0Rmbas1EnCpidem2s1Zth2venBxAyel9;id;ampZempl0Nte6;i19t;er7terp9;ri9;se;my;eLiEoBr9ump tru0U;agonf4i9;er,ve thru;cAg7i4or,ssi3wn9;side;to0EumenE;aEgniDnn3sAvide9;nd;conte6incen8p9tri11;osi9;ti0C;ta0H;le0X;athBcAf9ni0terre6;ault 05err0;al,im0;!b9;ed;aWeThMiLlJoDr9;edit caBuc9;ib9;le;rd;efficDke,lCmmuniqLnsApi3rr0t0Xus9yo1;in;erv9uI;ato02;ic,lQ;ie6;er7i9oth;e6n2;ty,vil wM;aDeqCick5ocoBr9;istmas car9ysanthemum;ol;la1;ue;ndeli3racteri9;st2;iAllEr9;e0tifica1;liZ;hi3nFpErCt9ucus;erpi9hedr0;ll9;ar;!bohyd9ri3;ra1;it0;aAe,nib0t9;on;l,ry;aMeLiop2leJoHrDu9;nny,r9tterf4;g9i0;la9;ry;eakAi9;ck;fa9throB;st;dy,ro9wl;ugh;mi9;sh;an,l4;nkiArri3;er;ng;cSdMlInFppeti1rDsBtt2utop9;sy;ic;ce6pe9;ct;r9sen0;ay;ecAoma4tiA;ly;do1;i5l9;er7y;gy;en; hominDjAvan9;tage;ec8;ti9;ve;em;cCeAqui9;tt0;ta1;te;iAru0;al;de6;nt",
  "Person|Noun": "trueÂ¦a0Eb07c03dWeUfQgOhLjHkiGlFmCnBolive,p7r4s3trini06v1wa0;ng,rd,tts;an,enus,iol0;a,et;ky,onPumm09;ay,e1o0uby;bin,d,se;ed,x;a2e1o0;l,tt04;aLnJ;dYge,tR;at,orm;a0eloW;t0x,ya;!s;a9eo,iH;ng,tP;a2e1o0;lGy;an,w3;de,smi4y;a0erb,iOolBuntR;ll,z0;el;ail,e0iLuy;ne;a1ern,i0lo;elds,nn;ith,n0;ny;a0dEmir,ula,ve;rl;a4e3i1j,ol0;ly;ck,x0;ie;an,ja;i0wn;sy;am,h0liff,rystal;a0in,ristian;mbers,ri0;ty;a4e3i2o,r0ud;an0ook;dy;ll;nedict,rg;k0nks;er;l0rt;fredo,ma",
  "Actor|Verb": "trueÂ¦aCb8c5doctor,engineAfool,g3host,judge,m2nerd,p1recruit,scout,ushAvolunteAwi0;mp,tneA;arent,ilot;an,ime;eek,oof,r0uide;adu8oom;ha1o0;ach,nscript,ok;mpion,uffeur;o2u0;lly,tch0;er;ss;ddi1ffili0rchite1;ate;ct",
  "MaleName": "trueÂ¦0:H6;1:FZ;2:DS;3:GQ;4:CZ;5:FV;6:GM;7:FP;8:GW;9:ET;A:C2;B:GD;aF8bE1cCQdBMeASfA1g8Yh88i7Uj6Sk6Bl5Mm48n3So3Ip33qu31r26s1Et0Ru0Ov0CwTxSyHzC;aCor0;cChC1karia,nAT;!hDkC;!aF6;!ar7CeF5;aJevgenBSoEuC;en,rFVsCu3FvEF;if,uf;nDs6OusC;ouf,s6N;aCg;s,tC;an,h0;hli,nCrosE1ss09;is,nC;!iBU;avi2ho5;aPeNiDoCyaEL;jcieBJlfgang,odrFutR;lFnC;f8TsC;lCt1;ow;bGey,frEhe4QlC;aE5iCy;am,e,s;ed8iC;d,ed;eAur;i,ndeD2rn2sC;!l9t1;lDyC;l1ne;lDtC;!er;aCHy;aKernDAiFladDoC;jteB0lodymyr;!iC;mFQsDB;cFha0ktBZnceDrgCOvC;a0ek;!nC;t,zo;!e4StBV;lCnC7sily;!entC;in9J;ghE2lCm70nax,ri,sm0;riCyss87;ch,k;aWeRhNiLoGrEuDyC;!l2roEDs1;n6r6E;avD0eCist0oy,um0;ntCRvBKy;bFdAWmCny;!asDmCoharu;aFFie,y;!z;iA6y;mCt4;!my,othy;adEeoDia0SomC;!as;!dor91;!de4;dFrC;enBKrC;anBJeCy;ll,nBI;!dy;dgh,ha,iCnn2req,tsu5V;cDAka;aYcotWeThPiMlobod0oKpenc2tEurDvenAEyCzym1;ed,lvest2;aj,e9V;anFeDuC;!aA;fan17phEQvCwaA;e77ie;!islaCl9;v,w;lom1rBuC;leymaDHta;dDgmu9UlCm1yabonga;as,v8B;!dhart8Yn9;aEeClo75;lCrm0;d1t1;h9Jne,qu1Jun,wn,yne;aDbastiEDk2Yl5Mpp,rgCth,ymoCU;e1Dio;m4n;!tC;!ie,y;eDPlFmEnCq67tosCMul;dCj2UtiA5;e01ro;!iATkeB6mC4u5;!ik,vato9K;aZeUheC8iRoGuDyC;an,ou;b99dDf4peAssC;!elEG;ol00y;an,bLc7MdJel,geIh0lHmGnEry,sDyC;!ce;ar7Ocoe,s;!aCnBU;ld,n;an,eo;a7Ef;l7Jr;e3Eg2n9olfo,riC;go;bBNeDH;cCl9;ar87c86h54kCo;!ey,ie,y;cFeA3gDid,ubByCza;an8Ln06;g85iC;naC6s;ep;ch8Kfa5hHin2je8HlGmFndEoHpha5sDul,wi36yC;an,mo8O;h9Im4;alDSol3O;iD0on;f,ph;ul;e9CinC;cy,t1;aOeLhilJiFrCyoG;aDeC;m,st1;ka85v2O;eDoC;tr;r8GtC;er,ro;!ipCl6H;!p6U;dCLrcy,tC;ar,e9JrC;!o7;b9Udra8So9UscAHtri62ulCv8I;!ie,o7;ctav6Ji2lImHndrBRrGsDtCum6wB;is,to;aDc6k6m0vCwaBE;al79;ma;i,vR;ar,er;aDeksandr,ivC;er,i2;f,v;aNeLguyBiFoCu3O;aDel,j4l0ma0rC;beAm0;h,m;cFels,g5i9EkDlC;es,s;!au,h96l78olaC;!i,y;hCkCol76;ol75;al,d,il,ls1vC;ilAF;hom,tC;e,hC;anCy;!a5i5;aYeViLoGuDyC;l4Nr1;hamDr84staC;fa,p6E;ed,mG;di10e,hamEis4JntDritz,sCussa;es,he;e,y;ad,ed,mC;ad,ed;cGgu5hai,kFlEnDtchC;!e8O;a9Pik;house,o7t1;ae73eC3ha8Iolaj;ah,hDkC;!ey,y;aDeC;al,l;el,l;hDlv3rC;le,ri8Ev4T;di,met;ay0c00gn4hWjd,ks2NlTmadZnSrKsXtDuric7VxC;imilBKwe8B;eHhEi69tCus,y69;!eo,hCia7;ew,i67;eDiC;as,eu,s;us,w;j,o;cHiGkFlEqu8Qsha83tCv3;iCy;!m,n;in,on;el,o7us;a6Yo7us;!elCin,o7us;!l8o;frAEi5Zny,u5;achDcoCik;lm;ai,y;amDdi,e5VmC;oud;adCm6W;ou;aulCi9P;ay;aWeOiMloyd,oJuDyC;le,nd1;cFdEiDkCth2uk;a7e;gi,s,z;ov7Cv6Hw6H;!as,iC;a6Een;g0nn52renDuCvA4we7D;!iS;!zo;am,n4oC;n5r;a9Yevi,la5KnHoFst2thaEvC;eCi;nte;bo;nCpo8V;!a82el,id;!nC;aAy;mEnd1rDsz73urenCwr6K;ce,t;ry,s;ar,beAont;aOeIhalHiFla4onr63rDu5SylC;e,s;istCzysztof;i0oph2;er0ngsl9p,rC;ilA9k,ollos;ed,id;en0iGnDrmCv4Z;it;!dDnCt1;e2Ny;ri4Z;r,th;cp2j4mEna8BrDsp6them,uC;ri;im,l;al,il;a03eXiVoFuC;an,lCst3;en,iC;an,en,o,us;aQeOhKkub4AnIrGsDzC;ef;eDhCi9Wue;!ua;!f,ph;dCge;i,on;!aCny;h,s,th6J;anDnC;!ath6Hie,n72;!nC;!es;!l,sCy;ph;o,qu3;an,mC;!i,m6V;d,ffFns,rCs4;a7JemDmai7QoCry;me,ni1H;i9Dy;!e73rC;ey,y;cKdBkImHrEsDvi2yC;dBs1;on,p2;ed,oDrCv67;e6Qod;d,s61;al,es5Wis1;a,e,oCub;b,v;ob,qu13;aTbNchiMgLke53lija,nuKonut,rIsEtCv0;ai,suC;ki;aDha0i8XmaCsac;el,il;ac,iaC;h,s;a,vinCw3;!g;k,nngu6X;nac1Xor;ka;ai,rahC;im;aReLoIuCyd6;beAgGmFsC;eyDsC;a3e3;in,n;ber5W;h,o;m2raDsse3wC;a5Pie;c49t1K;a0Qct3XiGnDrC;beAman08;dr7VrC;iCy2N;!k,q1R;n0Tt3S;bKlJmza,nIo,rEsDyC;a5KdB;an,s0;lEo67r2IuCv9;hi5Hki,tC;a,o;an,ey;k,s;!im;ib;a08e00iUlenToQrMuCyorgy;iHnFsC;!taC;f,vC;!e,o;n6tC;er,h2;do,lC;herDlC;auCerQ;me;aEegCov2;!g,orC;!io,y;dy,h7C;dfr9nza3XrDttfC;ri6C;an,d47;!n;acoGlEno,oCuseppe;rgiCvan6O;!o,s;be6Ies,lC;es;mo;oFrC;aDha4HrC;it,y;ld,rd8;ffErgC;!e7iCy;!os;!r9;bElBrCv3;eCla1Nr4Hth,y;th;e,rC;e3YielC;!i4;aXeSiQlOorrest,rCyod2E;aHedFiC;edDtC;s,z;ri18;!d42eri11riC;ck,k;nCs2;cEkC;ie,lC;in,yn;esLisC;!co,z3M;etch2oC;ri0yd;d5lConn;ip;deriFliEng,rC;dinaCg4nan0B;nd8;pe,x;co;bCdi,hd;iEriC;ce,zC;io;an,en,o;benez2dZfrYit0lTmMnJo3rFsteb0th0ugenEvCymBzra;an,eCge4D;ns,re3K;!e;gi,iDnCrol,v3w3;est8ie,st;cCk;!h,k;o0DriCzo;co,qC;ue;aHerGiDmC;aGe3A;lCrh0;!iC;a10o,s;s1y;nu5;beAd1iEliDm2t1viCwood;n,s;ot28s;!as,j5Hot,sC;ha;a3en;!dGg6mFoDua2QwC;a2Pin;arC;do;oZuZ;ie;a04eTiOmitrNoFrag0uEwDylC;an,l0;ay3Hig4D;a3Gdl9nc0st3;minFnDri0ugCvydGy2S;!lF;!a36nCov0;e1Eie,y;go,iDykC;as;cCk;!k;i,y;armuFetDll1mitri7neCon,rk;sh;er,m6riC;ch;id;andLepak,j0lbeAmetri4nIon,rGsEvDwCxt2;ay30ey;en,in;hawn,moC;nd;ek,riC;ck;is,nC;is,y;rt;re;an,le,mKnIrEvC;e,iC;!d;en,iEne0PrCyl;eCin,yl;l45n;n,o,us;!iCny;el,lo;iCon;an,en,on;a0Fe0Ch03iar0lRoJrFuDyrC;il,us;rtC;!is;aEistC;iaCob12;no;ig;dy,lInErC;ey,neliCy;s,us;nEor,rDstaC;nt3;ad;or;by,e,in,l3t1;aHeEiCyde;fCnt,ve;fo0Xt1;menDt4;us;s,t;rFuDyC;!t1;dCs;e,io;enC;ce;aHeGrisC;!toC;phCs;!eC;!r;st2t;d,rCs;b5leC;s,y;cDdrCs6;ic;il;lHmFrC;ey,lDroCy;ll;!o7t1;er1iC;lo;!eb,v3;a09eZiVjorn,laUoSrEuCyr1;ddy,rtKst2;er;aKeFiEuDyC;an,ce,on;ce,no;an,ce;nDtC;!t;dDtC;!on;an,on;dFnC;dDisC;lav;en,on;!foOl9y;bby,gd0rCyd;is;i0Lke;bElDshC;al;al,lL;ek;nIrCshoi;at,nEtC;!raC;m,nd;aDhaCie;rd;rd8;!iDjam3nCs1;ie,y;to;kaMlazs,nHrC;n9rDtC;!holomew;eCy;tt;ey;dCeD;ar,iC;le;ar1Nb1Dd16fon15gust3hm12i0Zja0Yl0Bm07nTputsiSrGsaFugustEveDyCziz;a0kh0;ry;o,us;hi;aMchiKiJjun,mHnEon,tCy0;em,hCie,ur8;ur;aDoC;!ld;ud,v;aCin;an,nd8;!el,ki;baCe;ld;ta;aq;aMdHgel8tCw6;hoFoC;iDnC;!i8y;ne;ny;er7rCy;eDzC;ej;!as,i,j,s,w;!s;s,tolC;iCy;!y;ar,iEmaCos;nu5r;el;ne,r,t;aVbSdBeJfHiGl01onFphonsEt1vC;aPin;on;e,o;so,zo;!sR;!onZrC;ed;c,jaHksFssaHxC;!andC;er,rC;e,os,u;andCei;ar,er,r;ndC;ro;en;eDrecC;ht;rt8;dd3in,n,sC;taC;ir;ni;dDm6;ar;an,en;ad,eC;d,t;in;so;aGi,olErDvC;ik;ian8;f8ph;!o;mCn;!a;dGeFraDuC;!bakr,lfazl;hCm;am;!l;allFel,oulaye,ulC;!lDrahm0;an;ah,o;ah;av,on",
  "Uncountable": "trueÂ¦0:2E;1:2L;2:33;a2Ub2Lc29d22e1Rf1Ng1Eh16i11j0Yk0Wl0Rm0Hn0Do0Cp03rZsLt9uran2Jv7w3you gu0E;a5his17i4oo3;d,l;ldlife,ne;rm8t1;apor,ernacul29i3;neg28ol1Otae;eDhBiAo8r4un3yranny;a,gst1B;aff2Oea1Ko4ue nor3;th;o08u3;bleshoot2Ose1Tt;night,othpas1Vwn3;foEsfoE;me off,n;er3und1;e,mod2S;a,nnis;aDcCeBhAi9ki8o7p6t4u3weepstak0;g1Unshi2Hshi;ati08e3;am,el;ace2Keci0;ap,cc1meth2C;n,ttl0;lk;eep,ingl0or1C;lf,na1Gri0;ene1Kisso1C;d0Wfe2l4nd,t3;i0Iurn;m1Ut;abi0e4ic3;e,ke15;c3i01laxa11search;ogni10rea10;a9e8hys7luto,o5re3ut2;amble,mis0s3ten20;en1Zs0L;l3rk;i28l0EyH; 16i28;a24tr0F;nt3ti0M;i0s;bstetri24vercrowd1Qxyg09;a5e4owada3utella;ys;ptu1Ows;il poliZtional securi2;aAe8o5u3;m3s1H;ps;n3o1K;ey,o3;gamy;a3cha0Elancholy,rchandi1Htallurgy;sl0t;chine3g1Aj1Hrs,thema1Q; learn1Cry;aught1e6i5ogi4u3;ck,g12;c,s1M;ce,ghtn18nguis1LteratWv1;ath1isVss;ara0EindergartPn3;icke0Aowled0Y;e3upit1;a3llyfiGwel0G;ns;ce,gnor6mp5n3;forma00ter3;net,sta07;atiSort3rov;an18;a7e6isto09o3ung1;ckey,mework,ne4o3rseradi8spitali2use arrest;ky;s2y;adquarteXre;ir,libut,ppiHs3;hi3te;sh;ene8l6o5r3um,ymnas11;a3eZ;niUss;lf,re;ut3yce0F;en; 3ti0W;edit0Hpo3;ol;aNicFlour,o4urnit3;ure;od,rgive3uri1wl;ness;arCcono0LducaBlectr9n7quip8thi0Pvery6x3;ist4per3;ti0B;en0J;body,o08th07;joy3tertain3;ment;ici2o3;ni0H;tiS;nings,th;emi02i6o4raugh3ynas2;ts;pe,wnstai3;rs;abet0ce,s3;honZrepu3;te;aDelciChAivi07l8o3urrency;al,ld w6mmenta5n3ral,ttIuscoB;fusiHt 3;ed;ry;ar;assi01oth0;es;aos,e3;eMwK;us;d,rO;a8i6lood,owlHread5u3;ntGtt1;er;!th;lliarJs3;on;g3ss;ga3;ge;cKdviJeroGirFmBn6ppeal court,r4spi3thleL;rin;ithmet3sen3;ic;i6y3;o4th3;ing;ne;se;en5n3;es2;ty;ds;craft;bi8d3nau7;yna3;mi6;ce;id,ous3;ti3;cs",
  "Infinitive": "trueÂ¦0:9G;1:9T;2:AD;3:90;4:9Z;5:84;6:AH;7:A9;8:92;9:A0;A:AG;B:AI;C:9V;D:8R;E:8O;F:97;G:6H;H:7D;a94b8Hc7Jd68e4Zf4Mg4Gh4Ai3Qj3Nk3Kl3Bm34nou48o2Vp2Equ2Dr1Es0CtZuTvRwI;aOeNiLors5rI;eJiI;ng,te;ak,st3;d5e8TthI;draw,er;a2d,ep;i2ke,nIrn;d1t;aIie;liADniAry;nJpI;ho8Llift;cov1dJear8Hfound8DlIplug,rav82tie,ve94;eaAo3X;erIo;cut,go,staAFvalA3w2G;aSeQhNoMrIu73;aIe72;ffi3Smp3nsI;aBfo7CpI;i8oD;pp3ugh5;aJiJrIwaD;eat5i2;nk;aImA0;ch,se;ck3ilor,keImp1r8L;! paD;a0Ic0He0Fh0Bi0Al08mugg3n07o05p02qu01tUuLwI;aJeeIim;p,t5;ll7Wy;bNccMffLggeCmmKppJrI;mouFpa6Zvi2;o0re6Y;ari0on;er,i4;e7Numb;li9KmJsiIveD;de,st;er9it;aMe8MiKrI;ang3eIi2;ng27w;fIng;f5le;b,gg1rI;t3ve;a4AiA;a4UeJit,l7DoI;il,of;ak,nd;lIot7Kw;icEve;atGeak,i0O;aIi6;m,y;ft,ng,t;aKi6CoJriIun;nk,v6Q;ot,rt5;ke,rp5tt1;eIll,nd,que8Gv1w;!k,m;aven9ul8W;dd5tis1Iy;a0FeKiJoI;am,t,ut;d,p5;a0Ab08c06d05f01group,hea00iZjoi4lXmWnVpTq3MsOtMup,vI;amp,eJiIo3B;sEve;l,rI;e,t;i8rI;ie2ofE;eLiKpo8PtIurfa4;o24rI;aHiBuctu8;de,gn,st;mb3nt;el,hra0lIreseF;a4e71;d1ew,o07;aHe3Fo2;a7eFiIo6Jy;e2nq41ve;mbur0nf38;r0t;inKleBocus,rJuI;el,rbiA;aBeA;an4e;aBu4;ei2k8Bla43oIyc3;gni39nci3up,v1;oot,uI;ff;ct,d,liIp;se,ze;tt3viA;aAenGit,o7;aWerUinpoiFlumm1LoTrLuI;b47ke,niArIt;poDsuI;aFe;eMoI;cKd,fe4XhibEmo7noJpo0sp1tru6vI;e,i6o5L;un4;la3Nu8;aGclu6dJf1occupy,sup0JvI;a6BeF;etermi4TiB;aGllu7rtr5Ksse4Q;cei2fo4NiAmea7plex,sIva6;eve8iCua6;mp1rItrol,ve;a6It6E;bOccuNmEpMutLverIwe;l07sJtu6Yu0wI;helm;ee,h1F;gr5Cnu2Cpa4;era7i4Ipo0;py,r;ey,seItaH;r2ss;aMe0ViJoIultiply;leCu6Pw;micJnIspla4;ce,g3us;!k;iIke,na9;m,ntaH;aPeLiIo0u3N;ke,ng1quIv5;eIi6S;fy;aKnIss5;d,gI;th5;rn,ve;ng2Gu1N;eep,idnJnI;e4Cow;ap;oHuI;gg3xtaI;po0;gno8mVnIrk;cTdRfQgeChPitia7ju8q1CsNtKun6EvI;a6eIo11;nt,rt,st;erJimi6BoxiPrI;odu4u6;aBn,pr03ru6C;iCpi8tIu8;all,il,ruB;abEibE;eCo3Eu0;iIul9;ca7;i7lu6;b5Xmer0pI;aLer4Uin9ly,oJrI;e3Ais6Bo2;rt,se,veI;riA;le,rt;aLeKiIoiCuD;de,jaInd1;ck;ar,iT;mp1ng,pp5raIve;ng5Mss;ath1et,iMle27oLrI;aJeIow;et;b,pp3ze;!ve5A;gg3ve;aTer45i5RlSorMrJuI;lf4Cndrai0r48;eJiIolic;ght5;e0Qsh5;b3XeLfeEgJsI;a3Dee;eIi2;!t;clo0go,shIwa4Z;ad3F;att1ee,i36;lt1st5;a0OdEl0Mm0FnXquip,rWsVtGvTxI;aRcPeDhOiNpJtIu6;ing0Yol;eKi8lIo0un9;aHoI;it,re;ct,di7l;st,t;a3oDu3B;e30lI;a10u6;lt,mi28;alua7oI;ke,l2;chew,pou0tab19;a0u4U;aYcVdTfSgQhan4joy,lPqOrNsuMtKvI;e0YisI;a9i50;er,i4rI;aHenGuC;e,re;iGol0F;ui8;ar9iC;a9eIra2ulf;nd1;or4;ang1oIu8;r0w;irc3lo0ou0ErJuI;mb1;oaGy4D;b3ct;bKer9pI;hasiIow1;ze;aKody,rI;a4oiI;d1l;lm,rk;ap0eBuI;ci40de;rIt;ma0Rn;a0Re04iKo,rIwind3;aw,ed9oI;wn;agno0e,ff1g,mi2Kne,sLvI;eIul9;rIst;ge,t;aWbVcQlod9mant3pNru3TsMtI;iIoDu37;lJngI;uiA;!l;ol2ua6;eJlIo0ro2;a4ea0;n0r0;a2Xe36lKoIu0S;uIv1;ra9;aIo0;im;a3Kur0;b3rm;af5b01cVduBep5fUliTmQnOpMrLsiCtaGvI;eIol2;lop;ch;a20i2;aDiBloIoD;re,y;oIy;te,un4;eJoI;liA;an;mEv1;a4i0Ao06raud,y;ei2iMla8oKrI;ee,yI;!pt;de,mIup3;missi34po0;de,ma7ph1;aJrief,uI;g,nk;rk;mp5rk5uF;a0Dea0h0Ai09l08oKrIurta1G;a2ea7ipp3uI;mb3;ales4e04habEinci6ll03m00nIrro6;cXdUfQju8no7qu1sLtKvI;eIin4;ne,r9y;aHin2Bribu7;er2iLoli2Epi8tJuI;lt,me;itu7raH;in;d1st;eKiJoIroFu0;rm;de,gu8rm;ss;eJoI;ne;mn,n0;eIlu6ur;al,i2;buCe,men4pI;eIi3ly;l,te;eBi6u6;r4xiC;ean0iT;rcumveFte;eJirp,oI;o0p;riAw;ncIre5t1ulk;el;a02eSi6lQoPrKuI;iXrIy;st,y;aLeaKiJoad5;en;ng;stfeLtX;ke;il,l11mba0WrrMth1;eIow;ed;!coQfrie1LgPhMliLqueaKstJtrIwild1;ay;ow;th;e2tt3;a2eJoI;ld;ad;!in,ui3;me;bysEckfi8ff3tI;he;b15c0Rd0Iff0Ggree,l0Cm09n03ppZrXsQttOuMvJwaE;it;eDoI;id;rt;gIto0X;meF;aIeCraB;ch,in;pi8sJtoI;niA;aKeIi04u8;mb3rt,ss;le;il;re;g0Hi0ou0rI;an9i2;eaKly,oiFrI;ai0o2;nt;r,se;aMi0GnJtI;icipa7;eJoIul;un4y;al;ly0;aJu0;se;lga08ze;iKlI;e9oIu6;t,w;gn;ix,oI;rd;a03jNmiKoJsoI;rb;pt,rn;niIt;st1;er;ouJuC;st;rn;cLhie2knowled9quiItiva7;es4re;ce;ge;eQliOoKrJusI;e,tom;ue;mIst;moJpI;any,liA;da7;ma7;te;pt;andPduBet,i6oKsI;coKol2;ve;liArt,uI;nd;sh;de;ct;on",
  "Person": "trueÂ¦0:1Q;a29b1Zc1Md1Ee18f15g13h0Ri0Qj0Nk0Jl0Gm09n06o05p00rPsItCusain bolt,v9w4xzibit,y1;anni,oko on2uji,v1;an,es;en,o;a3ednesday adams,i2o1;lfram,o0Q;ll ferrell,z khalifa;lt disn1Qr1;hol,r0G;a2i1oltai06;n dies0Zrginia wo17;lentino rossi,n goG;a4h3i2ripp,u1yra banks;lZpac shakur;ger woods,mba07;eresa may,or;kashi,t1ylor;um,ya1B;a5carlett johanss0h4i3lobodan milosevic,no2ocr1Lpider1uperm0Fwami; m0Em0E;op dogg,w whi1H;egfried,nbad;akespeaTerlock holm1Sia labeouf;ddam hussa16nt1;a cla11ig9;aAe6i5o3u1za;mi,n dmc,paul,sh limbau1;gh;bin hood,d stew16nald1thko;in0Mo;han0Yngo starr,valdo;ese witherspo0i1mbrandt;ll2nh1;old;ey,y;chmaninoff,ffi,iJshid,y roma1H;a4e3i2la16o1uff daddy;cahont0Ie;lar,p19;le,rZ;lm17ris hilt0;leg,prah winfr0Sra;a2e1iles cra1Bostradam0J; yo,l5tt06wmQ;pole0s;a5e4i2o1ubar03;by,lie5net,rriss0N;randa ju1tt romn0M;ly;rl0GssiaB;cklemo1rkov,s0ta hari,ya angelou;re;ady gaga,e1ibera0Pu;bron jam0Xch wale1e;sa;anye west,e3i1obe bryant;d cudi,efer suther1;la0P;ats,sha;a2effers0fk,k rowling,rr tolki1;en;ck the ripp0Mwaharlal nehru,y z;liTnez,ron m7;a7e5i3u1;lk hog5mphrey1sa01;! bog05;l1tl0H;de; m1dwig,nry 4;an;ile selassFlle ber4m3rrison1;! 1;ford;id,mo09;ry;ast0iannis,o1;odwPtye;ergus0lorence nightinga08r1;an1ederic chopN;s,z;ff5m2nya,ustaXzeki1;el;eril lagasse,i1;le zatop1nem;ek;ie;a6e4i2octor w1rake;ho;ck w1ego maradoC;olf;g1mi lovaOnzel washingt0;as;l1nHrth vadR;ai lNt0;a8h5lint0o1thulhu;n1olio;an,fuci1;us;on;aucKop2ristian baMy1;na;in;millo,ptain beefhe4r1;dinal wols2son1;! palmF;ey;art;a8e5hatt,i3oHro1;ck,n1;te;ll g1ng crosby;atB;ck,nazir bhut2rtil,yon1;ce;to;nksy,rack ob1;ama;l 6r3shton kutch2vril lavig8yn ra1;nd;er;chimed2istot1;le;es;capo2paci1;no;ne",
  "Adjective": "trueÂ¦0:AI;1:BS;2:BI;3:BA;4:A8;5:84;6:AV;7:AN;8:AF;9:7H;A:BQ;B:AY;C:BC;D:BH;E:9Y;aA2b9Ec8Fd7We79f6Ng6Eh61i4Xj4Wk4Tl4Im41n3Po36p2Oquart7Pr2Ds1Dt14uSvOwFye29;aMeKhIiHoF;man5oFrth7G;dADzy;despreB1n w97s86;acked1UoleF;!sa6;ather1PeFll o70ste1D;!k5;nt1Ist6Ate4;aHeGiFola5T;bBUce versa,gi3Lle;ng67rsa5R;ca1gBSluAV;lt0PnLpHrGsFttermoBL;ef9Ku3;b96ge1; Hb32pGsFtiAH;ca6ide d4R;er,i85;f52to da2;a0Fbeco0Hc0Bd04e02f01gu1XheaBGiXkn4OmUnTopp06pRrNsJtHus0wF;aFiel3K;nt0rra0P;app0eXoF;ld,uS;eHi37o5ApGuF;perv06spec39;e1ok9O;en,ttl0;eFu5;cogn06gul2RlGqu84sF;erv0olv0;at0en33;aFrecede0E;id,rallel0;am0otic0;aFet;rri0tF;ch0;nFq26vers3;sur0terFv7U;eFrupt0;st0;air,inish0orese98;mploy0n7Ov97xpF;ect0lain0;eHisFocume01ue;clFput0;os0;cid0rF;!a8Scov9ha8Jlyi8nea8Gprivileg0sMwF;aFei9I;t9y;hGircumcFonvin2U;is0;aFeck0;lleng0rt0;b20ppea85ssuGttend0uthorF;iz0;mi8;i4Ara;aLeIhoHip 25oGrF;anspare1encha1i2;geth9leADp notch,rpB;rny,ugh6H;ena8DmpGrFs6U;r49tia4;eCo8P;leFst4M;nt0;a0Dc09e07h06i04ki03l01mug,nobbi4XoVpRqueami4XtKuFymb94;bHccinAi generis,pFr5;erFre7N;! dup9b,vi70;du0li7Lp6IsFurb7J;eq9Atanda9X;aKeJi16o2QrGubboFy4Q;rn;aightFin5GungS; fFfF;or7V;adfa9Pri6;lwa6Ftu82;arHeGir6NlendBot Fry;on;c3Qe1S;k5se; call0lImb9phistic16rHuFviV;ndFth1B;proof;dBry;dFub6; o2A;e60ipF;pe4shod;ll0n d7R;g2HnF;ceEg6ist9;am3Se9;co1Zem5lfFn6Are7; suf4Xi43;aGholFient3A;ar5;rlFt4A;et;cr0me,tisfac7F;aOeIheumatoBiGoF;bu8Ztt7Gy3;ghtFv3; 1Sf6X;cJdu8PlInown0pro69sGtF;ard0;is47oF;lu2na1;e1Suc45;alcit8Xe1ondi2;bBci3mpa1;aSePicayu7laOoNrGuF;bl7Tnjabi;eKiIoF;b7VfGmi49pFxi2M;er,ort81;a7uD;maFor,sti7va2;!ry;ciDexis0Ima2CpaB;in55puli8G;cBid;ac2Ynt 3IrFti2;ma40tFv7W;!i3Z;i2YrFss7R;anoBtF; 5XiF;al,s5V;bSffQkPld OnMrLth9utKverF;!aIbMdHhGni75seas,t,wF;ei74rou74;a63e7A;ue;ll;do1Ger,si6A;d3Qg2Aotu5Z; bFbFe on o7g3Uli7;oa80;fashion0school;!ay; gua7XbFha5Uli7;eat;eHligGsF;ce7er0So1C;at0;diFse;a1e1;aOeNiMoGuF;anc0de; moEnHrthFt6V;!eFwe7L;a7Krn;chaGdescri7Iprof30sF;top;la1;ght5;arby,cessa4ighbor5wlyw0xt;k0usiaFv3;ti8;aQeNiLoHuF;dIltiF;facet0p6;deHlGnFot,rbBst;ochro4Xth5;dy;rn,st;ddle ag0nF;dbloZi,or;ag9diocEga,naGrFtropolit4Q;e,ry;ci8;cIgenta,inHj0Fkeshift,mmGnFri4Oscu61ver18;da5Dy;ali4Lo4U;!stream;abEho;aOeLiIoFumberi8;ngFuti1R;stan3RtF;erm,i4H;ghtGteraF;l,ry,te;heart0wei5O;ft JgFss9th3;al,eFi0M;nda4;nguBps0te5;apGind5noF;wi8;ut;ad0itte4uniW;ce co0Hgno6Mll0Cm04nHpso 2UrF;a2releF;va1; ZaYcoWdReQfOgrNhibi4Ri05nMoLsHtFvalu5M;aAeF;nDrdepe2K;a7iGolFuboI;ub6ve1;de,gF;nifica1;rdi5N;a2er;own;eriIiLluenVrF;ar0eq5H;pt,rt;eHiGoFul1O;or;e,reA;fiFpe26termi5E;ni2;mpFnsideCrreA;le2;ccuCdeq5Ene,ppr4J;fFsitu,vitro;ro1;mJpF;arHeGl15oFrop9;li2r11;n2LrfeA;ti3;aGeFi18;d4BnD;tuE;egGiF;c0YteC;al,iF;tiF;ma2;ld;aOelNiLoFuma7;a4meInHrrGsFur5;ti6;if4E;e58o3U; ma3GsF;ick;ghfalut2HspF;an49;li00pf33;i4llow0ndGrdFtM; 05coEworki8;sy,y;aLener44iga3Blob3oKrGuF;il1Nng ho;aFea1Fizzl0;cGtF;ef2Vis;ef2U;ld3Aod;iFuc2D;nf2R;aVeSiQlOoJrF;aGeFil5ug3;q43tf2O;gFnt3S;i6ra1;lk13oHrF; keeps,eFge0Vm9tu41;g0Ei2Ds3R;liF;sh;ag4Mowe4uF;e1or45;e4nF;al,i2;d Gmini7rF;ti6ve1;up;bl0lDmIr Fst pac0ux;oGreacF;hi8;ff;ed,ili0R;aXfVlTmQnOqu3rMthere3veryday,xF;aApIquisi2traHuF;be48lF;ta1;!va2L;edRlF;icF;it;eAstF;whi6; Famor0ough,tiE;rou2sui2;erGiF;ne1;ge1;dFe2Aoq34;er5;ficF;ie1;g9sF;t,ygF;oi8;er;aWeMiHoGrFue;ea4owY;ci6mina1ne,r31ti8ubQ;dact2Jfficult,m,sGverF;ge1se;creGePjoi1paCtF;a1inA;et,te; Nadp0WceMfiLgeneCliJmuEpeIreliAsGvoF;id,ut;pFtitu2ul1L;eCoF;nde1;ca2ghF;tf13;a1ni2;as0;facto;i5ngero0I;ar0Ce09h07i06l05oOrIuF;rmudgeon5stoma4teF;sy;ly;aIeHu1EystalF; cleFli7;ar;epy;fFv17z0;ty;erUgTloSmPnGrpoCunterclVveFy;rt;cLdJgr21jIsHtrF;aFi2;dic0Yry;eq1Yta1;oi1ug3;escenFuN;di8;a1QeFiD;it0;atoDmensuCpF;ass1SulF;so4;ni3ss3;e1niza1;ci1J;ockwiD;rcumspeAvil;eFintzy;e4wy;leGrtaF;in;ba2;diac,ef00;a00ePiLliJoGrFuck nak0;and new,isk,on22;gGldface,naF; fi05fi05;us;nd,tF;he;gGpartisFzarE;an;tiF;me;autifOhiNlLnHsFyoN;iWtselF;li8;eGiFt;gn;aFfi03;th;at0oF;v0w;nd;ul;ckwards,rF;e,rT; priori,b13c0Zd0Tf0Ng0Ihe0Hl09mp6nt06pZrTsQttracti0MuLvIwF;aGkF;wa1B;ke,re;ant garGeraF;ge;de;diIsteEtF;heFoimmu7;nt07;re;to4;hGlFtu2;eep;en;bitIchiv3roHtF;ifiFsy;ci3;ga1;ra4;ry;pFt;aHetizi8rF;oprF;ia2;llFre1;ed,i8;ng;iquFsy;at0e;ed;cohKiJkaHl,oGriFterX;ght;ne,of;li7;ne;ke,ve;olF;ic;ad;ain07gressiIi6rF;eeF;ab6;le;ve;fGraB;id;ectGlF;ue1;ioF;na2; JaIeGvF;erD;pt,qF;ua2;ma1;hoc,infinitum;cuCquiGtu3u2;al;esce1;ra2;erSjeAlPoNrKsGuF;nda1;e1olu2trF;aAuD;se;te;eaGuF;pt;st;aFve;rd;aFe;ze;ct;ra1;nt",
  "Pronoun": "trueÂ¦elle,h3i2me,she,th0us,we,you;e0ou;e,m,y;!l,t;e,im",
  "Preposition": "trueÂ¦aPbMcLdKexcept,fIinGmid,notwithstandiWoDpXqua,sCt7u4v2w0;/o,hereSith0;! whHin,oW;ersus,i0;a,s a vis;n1p0;!on;like,til;h1ill,oward0;!s;an,ereby,r0;ough0u;!oM;ans,ince,o that,uch G;f1n0ut;!to;!f;! 0to;effect,part;or,r0;om;espite,own,u3;hez,irca;ar1e0oBy;sides,tween;ri7;bo8cross,ft7lo6m4propos,round,s1t0;!op;! 0;a whole,long 0;as;id0ong0;!st;ng;er;ut",
  "SportsTeam": "trueÂ¦0:18;1:1E;2:1D;3:14;a1Db15c0Sd0Kfc dallas,g0Ihouston 0Hindiana0Gjacksonville jagua0k0El0Am01new UoRpKqueens parkJreal salt lake,sBt6utah jazz,vancouver whitecaps,w4yW;ashington 4h10;natio1Mredski2wizar0W;ampa bay 7e6o4;ronto 4ttenham hotspur;blue ja0Mrapto0;nnessee tita2xasD;buccanee0ra0K;a8eattle 6porting kansas0Wt4; louis 4oke0V;c1Drams;marine0s4;eah13ounH;cramento Rn 4;antonio spu0diego 4francisco gJjose earthquak1;char08paB; ran07;a9h6ittsburgh 5ortland t4;imbe0rail blaze0;pirat1steele0;il4oenix su2;adelphia 4li1;eagl1philNunE;dr1;akland 4klahoma city thunder,rlando magic;athle0Lrai4;de0;england 8orleans 7york 4;g5je3knYme3red bul0Xy4;anke1;ian3;pelica2sain3;patrio3revolut4;ion;anchEeAi4ontreal impact;ami 8lwaukee b7nnesota 4;t5vi4;kings;imberwolv1wi2;rewe0uc0J;dolphi2heat,marli2;mphis grizz4ts;li1;a6eic5os angeles 4;clippe0dodFlaB;esterV; galaxy,ke0;ansas city 4nF;chiefs,roya0D; pace0polis col3;astr05dynamo,rocke3texa2;olden state warrio0reen bay pac4;ke0;allas 8e4i04od6;nver 6troit 4;lio2pisto2ti4;ge0;broncYnugge3;cowbo5maver4;icZ;ys;arEelLhAincinnati 8leveland 6ol4;orado r4umbus crew sc;api7ocki1;brow2cavalie0guar4in4;dia2;bengaVre4;ds;arlotte horAicago 4;b5cubs,fire,wh4;iteB;ea0ulQ;diff4olina panthe0; city;altimore Alackburn rove0oston 6rooklyn 4uffalo bilN;ne3;ts;cel5red4; sox;tics;rs;oriol1rave2;rizona Ast8tlanta 4;brav1falco2h4;awA;ns;es;on villa,r4;os;c6di4;amondbac4;ks;ardi4;na4;ls",
  "Unit": "trueÂ¦a07b04cXdWexVfTgRhePinYjoule0BkMlJmDnan08oCp9quart0Bsq ft,t7volts,w6y2ze3Â°1Âµ0;g,s;c,f,n;dVear1o0;ttR; 0s 0;old;att,b;erNon0;!ne02;ascals,e1i0;cXnt00;rcent,tJ;hms,unceY;/s,e4i0mÂ²,Â²,Â³;/h,cro2l0;e0liK;!Â²;grLsR;gCtJ;it1u0;menQx;erPreP;b5elvins,ilo1m0notO;/h,ph,Â²;!byGgrEmCs;ct0rtzL;aJogrC;allonJb0ig3rB;ps;a0emtEl oz,t4;hrenheit,radG;aby9;eci3m1;aratDe1m0oulombD;Â²,Â³;lsius,nti0;gr2lit1m0;et0;er8;am7;b1y0;te5;l,ps;c2tt0;os0;econd1;re0;!s",
  "Noun|Gerund": "trueÂ¦0:3O;1:3M;2:3N;3:3D;4:32;5:2V;6:3E;7:3K;8:36;9:3J;A:3B;a3Pb37c2Jd27e23f1Vg1Sh1Mi1Ij1Gk1Dl18m13n11o0Wp0Pques0Sr0EsTtNunderMvKwFyDzB;eroi0oB;ni0o3P;aw2eB;ar2l3;aEed4hispe5i5oCrB;ap8est3i1;n0ErB;ki0r31;i1r2s9tc9;isualizi0oB;lunt1Vti0;stan4ta6;aFeDhin6iCraBy8;c6di0i2vel1M;mi0p8;aBs1;c9si0;l6n2s1;aUcReQhOiMkatKl2Wmo6nowJpeItFuCwB;ea5im37;b35f0FrB;fi0vB;e2Mi2J;aAoryt1KrCuB;d2KfS;etc9ugg3;l3n4;bCi0;ebBi0;oar4;gnBnAt1;a3i0;ip8oB;p8rte2u1;a1r27t1;hCo5reBulp1;a2Qe2;edu3oo3;i3yi0;aKeEi4oCuB;li0n2;oBwi0;fi0;aFcEhear7laxi0nDpor1sB;pon4tructB;r2Iu5;de5;or4yc3;di0so2;p8ti0;aFeacek20laEoCrBublis9;a1Teten4in1oces7;iso2siB;tio2;n2yi0;ckaAin1rB;ki0t1O;fEpeDrganiCvB;erco24ula1;si0zi0;ni0ra1;fe5;avi0QeBur7;gotia1twor6;aDeCi2oB;de3nito5;a2dita1e1ssaA;int0XnBrke1;ifUufactu5;aEeaDiBodAyi0;cen7f1mi1stB;e2i0;r2si0;n4ug9;iCnB;ea4it1;c6l3;ogAuB;dAgg3stif12;ci0llust0VmDnBro2;nova1sp0NterBven1;ac1vie02;agi2plo4;aDea1iCoBun1;l4w3;ki0ri0;nd3rB;roWvB;es1;aCene0Lli4rBui4;ee1ie0N;rde2the5;aHeGiDlCorBros1un4;e0Pmat1;ir1oo4;gh1lCnBs9;anZdi0;i0li0;e3nX;r0Zscina1;a1du01nCxB;erci7plo5;chan1di0ginB;ee5;aLeHiGoub1rCum8wB;el3;aDeCiB;bb3n6vi0;a0Qs7;wi0;rTscoDvi0;ba1coZlBvelo8;eCiB;ve5;ga1;nGti0;aVelebUhSlPoDrBur3yc3;aBos7yi0;f1w3;aLdi0lJmFnBo6pi0ve5;dDsCvinB;ci0;trBul1;uc1;muniDpB;lBo7;ai2;ca1;lBo5;ec1;c9ti0;ap8eaCimToBubT;ni0t9;ni0ri0;aBee5;n1t1;ra1;m8rCs1te5;ri0;vi0;aPeNitMlLoGrDuB;dge1il4llBr8;yi0;an4eat9oadB;cas1;di0;a1mEokB;i0kB;ee8;pi0;bi0;es7oa1;c9i0;gin2lonAt1;gi0;bysit1c6ki0tt3;li0;ki0;bando2cGdverti7gi0pproac9rgDssuCtB;trac1;mi0;ui0;hi0;si0;coun1ti0;ti0;ni0;ng",
  "PhrasalVerb": "trueÂ¦0:92;1:96;2:8H;3:8V;4:8A;5:83;6:85;7:98;8:90;9:8G;A:8X;B:8R;C:8U;D:8S;E:70;F:97;G:8Y;H:81;I:7H;J:79;a9Fb7Uc6Rd6Le6Jf5Ig50h4Biron0j47k40l3Em31n2Yo2Wp2Cquiet Hr1Xs0KtZuXvacuu6QwNyammerBzK;ero Dip LonK;e0k0;by,ov9up;aQeMhLiKor0Mrit19;mp0n3Fpe0r5s5;ackAeel Di0S;aLiKn33;gh 3Wrd0;n Dr K;do1in,oJ;it 79k5lk Lrm 69sh Kt83v60;aw3do1o7up;aw3in,oC;rgeBsK;e 2herE;a00eYhViRoQrMuKypP;ckErn K;do1in,oJup;aLiKot0y 30;ckl7Zp F;ck HdK;e 5Y;n7Wp 3Es5K;ck MdLe Kghten 6me0p o0Rre0;aw3ba4do1in,up;e Iy 2;by,oG;ink Lrow K;aw3ba4in,up;ba4ov9up;aKe 77ll62;m 2r 5M;ckBke Llk K;ov9shit,u47;aKba4do1in,leave,o4Dup;ba4ft9pa69w3;a0Vc0Te0Mh0Ii0Fl09m08n07o06p01quar5GtQuOwK;earMiK;ngLtch K;aw3ba4o8K; by;cKi6Bm 2ss0;k 64;aReQiPoNrKud35;aigh2Det75iK;ke 7Sng K;al6Yup;p Krm2F;by,in,oG;c3Ln3Lr 2tc4O;p F;c3Jmp0nd LrKveAy 2O;e Ht 2L;ba4do1up;ar3GeNiMlLrKurB;ead0ingBuc5;a49it 6H;c5ll o3Cn 2;ak Fe1Xll0;a3Bber 2rt0und like;ap 5Vow Duggl5;ash 6Noke0;eep NiKow 6;cLp K;o6Dup;e 68;in,oK;ff,v9;de19gn 4NnKt 6Gz5;gKkE; al6Ale0;aMoKu5W;ot Kut0w 7M;aw3ba4f48oC;c2WdeEk6EveA;e Pll1Nnd Orv5tK; Ktl5J;do1foLin,o7upK;!on;ot,r5Z;aw3ba4do1in,o33up;oCto;al66out0rK;ap65ew 6J;ilAv5;aXeUiSoOuK;b 5Yle0n Kstl5;aLba4do1inKo2Ith4Nu5P;!to;c2Xr8w3;ll Mot LpeAuK;g3Ind17;a2Wf3Po7;ar8in,o7up;ng 68p oKs5;ff,p18;aKelAinEnt0;c6Hd K;o4Dup;c27t0;aZeYiWlToQrOsyc35uK;ll Mn5Kt K;aKba4do1in,oJto47up;pa4Dw3;a3Jdo1in,o21to45up;attleBess KiNop 2;ah2Fon;iLp Kr4Zu1Gwer 6N;do1in,o6Nup;nt0;aLuK;gEmp 6;ce u20y 6D;ck Kg0le 4An 6p5B;oJup;el 5NncilE;c53ir 39n0ss MtLy K;ba4oG; Hc2R;aw3ba4in,oJ;pKw4Y;e4Xt D;aLerd0oK;dAt53;il Hrrow H;aTeQiPoLuK;ddl5ll I;c1FnkeyMp 6uthAve K;aKdo1in,o4Lup;l4Nw3; wi4K;ss0x 2;asur5e3SlLss K;a21up;t 6;ke Ln 6rKs2Ax0;k 6ryA;do,fun,oCsure,up;a02eViQoLuK;ck0st I;aNc4Fg MoKse0;k Kse4D;aft9ba4do1forw37in56o0Zu46;in,oJ;d 6;e NghtMnLsKve 00;ten F;e 2k 2; 2e46;ar8do1in;aMt LvelK; oC;do1go,in,o7up;nEve K;in,oK;pKut;en;c5p 2sh LtchBughAy K;do1o59;in4Po7;eMick Lnock K;do1oCup;oCup;eLy K;in,up;l Ip K;aw3ba4do1f04in,oJto,up;aMoLuK;ic5mpE;ke3St H;c43zz 2;a01eWiToPuK;nLrrKsh 6;y 2;keLt K;ar8do1;r H;lKneErse3K;d Ke 2;ba4dKfast,o0Cup;ear,o1;de Lt K;ba4on,up;aw3o7;aKlp0;d Ml Ir Kt 2;fKof;rom;f11in,o03uW;cPm 2nLsh0ve Kz2P;at,it,to;d Lg KkerP;do1in,o2Tup;do1in,oK;ut,v9;k 2;aZeTive Rloss IoMrLunK; f0S;ab hold,in43ow 2U; Kof 2I;aMb1Mit,oLr8th1IuK;nd9;ff,n,v9;bo7ft9hQw3;aw3bKdo1in,oJrise,up,w3;a4ir2H;ar 6ek0t K;aLb1Fdo1in,oKr8up;ff,n,ut,v9;cLhKl2Fr8t,w3;ead;ross;d aKng 2;bo7;a0Ee07iYlUoQrMuK;ck Ke2N;ar8up;eLighten KownBy 2;aw3oG;eKshe27; 2z5;g 2lMol Krk I;aKwi20;bo7r8;d 6low 2;aLeKip0;sh0;g 6ke0mKrKtten H;e F;gRlPnNrLsKzzle0;h F;e Km 2;aw3ba4up;d0isK;h 2;e Kl 1T;aw3fPin,o7;ht ba4ure0;ePnLsK;s 2;cMd K;fKoG;or;e D;d04l 2;cNll Krm0t1G;aLbKdo1in,o09sho0Eth08victim;a4ehi2O;pa0C;e K;do1oGup;at Kdge0nd 12y5;in,o7up;aOi1HoNrK;aLess 6op KuN;aw3b03in,oC;gBwB; Ile0ubl1B;m 2;a0Ah05l02oOrLut K;aw3ba4do1oCup;ackBeep LoKy0;ss Dwd0;by,do1in,o0Uup;me NoLuntK; o2A;k 6l K;do1oG;aRbQforOin,oNtKu0O;hLoKrue;geth9;rough;ff,ut,v9;th,wK;ard;a4y;paKr8w3;rt;eaLose K;in,oCup;n 6r F;aNeLiK;ll0pE;ck Der Kw F;on,up;t 2;lRncel0rOsMtch LveE; in;o1Nup;h Dt K;doubt,oG;ry LvK;e 08;aw3oJ;l Km H;aLba4do1oJup;ff,n,ut;r8w3;a0Ve0MiteAl0Fo04rQuK;bblNckl05il0Dlk 6ndl05rLsKtMy FzzA;t 00;n 0HsK;t D;e I;ov9;anWeaUiLush K;oGup;ghQng K;aNba4do1forMin,oLuK;nd9p;n,ut;th;bo7lKr8w3;ong;teK;n 2;k K;do1in,o7up;ch0;arTg 6iRn5oPrNssMttlLunce Kx D;aw3ba4;e 6; ar8;e H;do1;k Dt 2;e 2;l 6;do1up;d 2;aPeed0oKurt0;cMw K;aw3ba4do1o7up;ck;k K;in,oC;ck0nk0stA; oQaNef 2lt0nd K;do1ov9up;er;up;r Lt K;do1in,oCup;do1o7;ff,nK;to;ck Pil0nMrgLsK;h D;ainBe D;g DkB; on;in,o7;aw3do1in,oCup;ff,ut;ay;ct FdQir0sk MuctionA; oG;ff;ar8o7;ouK;nd; o7;d K;do1oKup;ff,n;wn;o7up;ut",
  "ProperNoun": "trueÂ¦aIbDc8dalhousHe7f5gosford,h4iron maiden,kirby,landsdowne,m2nis,r1s0wembF;herwood,paldiB;iel,othwe1;cgi0ercedes,issy;ll;intBudsB;airview,lorence,ra0;mpt9nco;lmo,uro;a1h0;arlt6es5risti;rl0talina;et4i0;ng;arb3e0;et1nt0rke0;ley;on;ie;bid,jax",
  "Person|Place": "trueÂ¦a8d6h4jordan,k3orlando,s1vi0;ctor9rgin9;a0ydney;lvador,mara,ntia4;ent,obe;amil0ous0;ton;arw2ie0;go;lexandr1ust0;in;ia",
  "LastName": "trueÂ¦0:BR;1:BF;2:B5;3:BH;4:AX;5:9Y;6:B6;7:BK;8:B0;9:AV;A:AL;B:8Q;C:8G;D:7K;E:BM;F:AH;aBDb9Zc8Wd88e81f7Kg6Wh64i60j5Lk4Vl4Dm39n2Wo2Op25quispe,r1Ls0Pt0Ev03wTxSyKzG;aIhGimmerm6A;aGou,u;ng,o;khar5ytsE;aKeun9BiHoGun;koya32shiBU;!lG;diGmaz;rim,z;maGng;da,g52mo83sGzaC;aChiBV;iao,u;aLeJiHoGright,u;jcA5lff,ng;lGmm0nkl0sniewsC;kiB1liams33s3;bGiss,lt0;b,er,st0;a6Vgn0lHtG;anabe,s3;k0sh,tG;e2Non;aLeKiHoGukD;gt,lk5roby5;dHllalGnogr3Kr1Css0val3S;ba,ob1W;al,ov4;lasHsel8W;lJn dIrgBEsHzG;qu7;ilyEqu7siljE;en b6Aijk,yk;enzueAIverde;aPeix1VhKi2j8ka43oJrIsui,uG;om5UrG;c2n0un1;an,emblA7ynisC;dorAMlst3Km4rrAth;atch0i8UoG;mHrG;are84laci79;ps3sG;en,on;hirDkah9Mnaka,te,varA;a06ch01eYhUiRmOoMtIuHvGzabo;en9Jobod3N;ar7bot4lliv2zuC;aIeHoG;i7Bj4AyanAB;ele,in2FpheBvens25;l8rm0;kol5lovy5re7Tsa,to,uG;ng,sa;iGy72;rn5tG;!h;l71mHnGrbu;at9cla9Egh;moBo7M;aIeGimizu;hu,vchG;en8Luk;la,r1G;gu9infe5YmGoh,pulveA7rra5P;jGyG;on5;evi6iltz,miHneid0roed0uGwarz;be3Elz;dHtG;!t,z;!t;ar4Th8ito,ka4OlJnGr4saCto,unde19v4;ch7dHtGz;a5Le,os;b53e16;as,ihDm4Po0Y;aVeSiPoJuHyG;a6oo,u;bio,iz,sG;so,u;bKc8Fdrigue67ge10j9YmJosevelt,sItHux,wG;e,li6;a9Ch;enb4Usi;a54e4L;erts15i93;bei4JcHes,vGzzo;as,e9;ci,hards12;ag2es,iHut0yG;es,nol5N;s,t0;dImHnGsmu97v6C;tan1;ir7os;ic,u;aUeOhMiJoHrGut8;asad,if6Zochazk27;lishc2GpGrti72u10we76;e3Aov51;cHe45nG;as,to;as70hl0;aGillips;k,m,n6I;a3Hde3Wete0Bna,rJtG;ersHrovGters54;!a,ic;!en,on;eGic,kiBss3;i9ra,tz,z;h86k,padopoulIrk0tHvG;ic,l4N;el,te39;os;bMconn2Ag2TlJnei6PrHsbor6XweBzG;dem7Rturk;ella4DtGwe6N;ega,iz;iGof7Hs8I;vGyn1R;ei9;aSri1;aPeNiJoGune50ym2;rHvGwak;ak4Qik5otn66;odahl,r4S;cholsZeHkolGls4Jx3;ic,ov84;ls1miG;!n1;ils3mG;co4Xec;gy,kaGray2sh,var38;jiGmu9shiG;ma;a07c04eZiWoMuHyeG;rs;lJnIrGssoli6S;atGp03r7C;i,ov4;oz,te58;d0l0;h2lOnNo0RrHsGza1A;er,s;aKeJiIoz5risHtG;e56on;!on;!n7K;au,i9no,t5J;!lA;r1Btgome59;i3El0;cracFhhail5kkeHlG;l0os64;ls1;hmeJiIj30lHn3Krci0ssiGyer2N;!er;n0Po;er,j0;dDti;cartHlG;aughl8e2;hy;dQe7Egnu68i0jer3TkPmNnMrItHyG;er,r;ei,ic,su21thews;iHkDquAroqu8tinG;ez,s;a5Xc,nG;!o;ci5Vn;a5UmG;ad5;ar5e6Kin1;rig77s1;aVeOiLoJuHyG;!nch;k4nGo;d,gu;mbarGpe3Fvr4we;di;!nGu,yana2B;coln,dG;b21holm,strom;bedEfeKhIitn0kaHn8rGw35;oy;!j;m11tG;in1on1;bvGvG;re;iGmmy,ng,rs2Qu,voie,ws3;ne,t1F;aZeYh2iWlUnez50oNrJuHvar2woG;k,n;cerGmar68znets5;a,o34;aHem0isGyeziu;h23t3O;m0sni4Fus3KvG;ch4O;bay57ch,rh0Usk16vaIwalGzl5;czGsC;yk;cIlG;!cGen4K;huk;!ev4ic,s;e8uiveG;rt;eff0kGl4mu9nnun1;ucF;ll0nnedy;hn,llKminsCne,pIrHstra3Qto,ur,yGzl5;a,s0;j0Rls22;l2oG;or;oe;aPenOha6im14oHuG;ng,r4;e32hInHrge32u6vG;anD;es,ss3;anHnsG;en,on,t3;nesGs1R;en,s1;kiBnings,s1;cJkob4EnGrv0E;kDsG;en,sG;en0Ion;ks3obs2A;brahimDglesi5Nke5Fl0Qno07oneIshikHto,vanoG;u,v54;awa;scu;aVeOiNjaltal8oIrist50uG;!aGb0ghAynh;m2ng;a6dz4fIjgaa3Hk,lHpUrGwe,x3X;ak1Gvat;mAt;er,fm3WmG;ann;ggiBtchcock;iJmingw4BnHrGss;nand7re9;deGriks1;rs3;kkiHnG;on1;la,n1;dz4g1lvoQmOns0ZqNrMsJuIwHyG;asFes;kiB;g1ng;anHhiG;mo14;i,ov0J;di6p0r10t;ue;alaG;in1;rs1;aVeorgUheorghe,iSjonRoLrJuGw3;errGnnar3Co,staf3Ctierr7zm2;a,eG;ro;ayli6ee2Lg4iffithGub0;!s;lIme0UnHodGrbachE;e,m2;calvAzale0S;dGubE;bGs0E;erg;aj,i;bs3l,mGordaO;en7;iev3U;gnMlJmaIndFo,rGsFuthi0;cGdn0za;ia;ge;eaHlG;agh0i,o;no;e,on;aVerQiLjeldsted,lKoIrHuG;chs,entAji41ll0;eem2iedm2;ntaGrt8urni0wl0;na;emi6orA;lipIsHtzgeraG;ld;ch0h0;ovG;!ic;hatDnanIrG;arGei9;a,i;deY;ov4;b0rre1D;dKinsJriksIsGvaB;cob3GpGtra3D;inoza,osiQ;en,s3;te8;er,is3warG;ds;aXePiNjurhuMoKrisco15uHvorakG;!oT;arte,boHmitru,nn,rGt3C;and,ic;is;g2he0Omingu7nErd1ItG;to;us;aGcki2Hmitr2Ossanayake,x3;s,z; JbnaIlHmirGrvisFvi,w2;!ov4;gado,ic;th;bo0groot,jo6lHsilGvriA;va;a cruz,e3uG;ca;hl,mcevsCnIt2WviG;dGes,s;ov,s3;ielsGku22;!en;ki;a0Be06hRiobQlarkPoIrGunningh1H;awfo0RivGuz;elli;h1lKntJoIrGs2Nx;byn,reG;a,ia;ke,p0;i,rer2K;em2liB;ns;!e;anu;aOeMiu,oIristGu6we;eGiaG;ns1;i,ng,p9uHwGy;!dH;dGng;huJ;!n,onGu6;!g;kJnIpm2ttHudhGv7;ry;erjee,o14;!d,g;ma,raboG;rty;bJl0Cng4rG;eghetHnG;a,y;ti;an,ota1C;cerAlder3mpbeLrIstGvadi0B;iGro;llo;doHl0Er,t0uGvalho;so;so,zo;ll;a0Fe01hYiXlUoNrKuIyG;rLtyG;qi;chan2rG;ke,ns;ank5iem,oGyant;oks,wG;ne;gdan5nIruya,su,uchaHyKziG;c,n5;rd;darGik;enG;ko;ov;aGond15;nco,zG;ev4;ancFshw16;a08oGuiy2;umGwmG;ik;ckRethov1gu,ktPnNrG;gJisInG;ascoGds1;ni;ha;er,mG;anG;!n;gtGit7nP;ss3;asF;hi;er,hG;am;b4ch,ez,hRiley,kk0ldw8nMrIshHtAu0;es;ir;bInHtlGua;ett;es,i0;ieYosa;dGik;a9yoG;padhyG;ay;ra;k,ng;ic;bb0Acos09d07g04kht05lZnPrLsl2tJyG;aHd8;in;la;chis3kiG;ns3;aImstro6sl2;an;ng;ujo,ya;dJgelHsaG;ri;ovG;!a;ersJov,reG;aGjEws;ss1;en;en,on,s3;on;eksejEiyEmeiIvG;ar7es;ez;da;ev;arwHuilG;ar;al;ams,l0;er;ta;as",
  "Ordinal": "trueÂ¦eBf7nin5s3t0zeroE;enDhir1we0;lfCn7;d,t3;e0ixt8;cond,vent7;et0th;e6ie7;i2o0;r0urt3;tie4;ft1rst;ight0lev1;e0h,ie1;en0;th",
  "Cardinal": "trueÂ¦bEeBf5mEnine7one,s4t0zero;en,h2rDw0;e0o;lve,n5;irt6ousands,ree;even2ix2;i3o0;r1ur0;!t2;ty;ft0ve;e2y;ight0lev1;!e0y;en;illions",
  "Multiple": "trueÂ¦b3hundred,m3qu2se1t0;housand,r2;pt1xt1;adr0int0;illion",
  "City": "trueÂ¦0:74;1:61;2:6G;3:6J;4:5S;a68b53c4Id48e44f3Wg3Hh39i31j2Wk2Fl23m1Mn1Co19p0Wq0Ur0Os05tRuQvLwDxiBy9z5;a7h5i4Muri4O;a5e5ongsh0;ng3H;greb,nzib5G;ang2e5okoha3Sunfu;katerin3Hrev0;a5n0Q;m5Hn;arsBeAi6roclBu5;h0xi,zh5P;c7n5;d5nipeg,terth4;hoek,s1L;hi5Zkl3A;l63xford;aw;a8e6i5ladivost5Molgogr6L;en3lni6S;ni22r5;o3saill4N;lenc4Wncouv3Sr3ughn;lan bat1Crumqi,trecht;aFbilisi,eEheDiBo9r7u5;l21n63r5;in,ku;i5ondh62;es51poli;kyo,m2Zron1Pulo5;n,uS;an5jua3l2Tmisoa6Bra3;j4Tshui; hag62ssaloni2H;gucigal26hr0l av1U;briz,i6llinn,mpe56ng5rtu,shk2R;i3Esh0;an,chu1n0p2Eyu0;aEeDh8kopje,owe1Gt7u5;ra5zh4X;ba0Ht;aten is55ockholm,rasbou67uttga2V;an8e6i5;jiazhua1llo1m5Xy0;f50n5;ya1zh4H;gh3Kt4Q;att45o1Vv44;cramen16int ClBn5o paulo,ppo3Rrajevo; 7aa,t5;a 5o domin3E;a3fe,m1M;antonio,die3Cfrancisco,j5ped3Nsalvad0J;o5u0;se;em,t lake ci5Fz25;lou58peters24;a9e8i6o5;me,t59;ga,o5yadh;! de janei3F;cife,ims,nn3Jykjavik;b4Sip4lei2Inc2Pwalpindi;ingdao,u5;ez2i0Q;aFeEhDiCo9r7u6yong5;ya1;eb59ya1;a5etor3M;g52to;rt5zn0; 5la4Co;au prin0Melizabe24sa03;ls3Prae5Atts26;iladelph3Gnom pe1Aoenix;ki1tah tik3E;dua,lerYnaji,r4Ot5;na,r32;ak44des0Km1Mr6s5ttawa;a3Vlo;an,d06;a7ew5ing2Fovosibir1Jyc; 5cast36;del24orlea44taip14;g8iro4Wn5pl2Wshv33v0;ch6ji1t5;es,o1;a1o1;a6o5p4;ya;no,sa0W;aEeCi9o6u5;mb2Ani26sc3Y;gadishu,nt6s5;c13ul;evideo,pelli1Rre2Z;ami,l6n14s5;kolc,sissauga;an,waukee;cca,d5lbour2Mmph41ndo1Cssi3;an,ell2Xi3;cau,drAkass2Sl9n8r5shh4A;aca6ib5rakesh,se2L;or;i1Sy;a4EchFdal0Zi47;mo;id;aDeAi8o6u5vSy2;anMckn0Odhia3;n5s angel26;d2g bea1N;brev2Be3Lma5nz,sb2verpo28;!ss27; ma39i5;c5pzig;est16; p6g5ho2Wn0Cusan24;os;az,la33;aHharFiClaipeBo9rak0Du7y5;iv,o5;to;ala lump4n5;mi1sh0;hi0Hlka2Xpavog4si5wlo2;ce;da;ev,n5rkuk;gst2sha5;sa;k5toum;iv;bHdu3llakuric0Qmpa3Fn6ohsiu1ra5un1Iwaguc0Q;c0Pj;d5o,p4;ah1Ty;a7e6i5ohannesV;l1Vn0;dd36rusalem;ip4k5;ar2H;bad0mph1OnArkutUs7taXz5;mir,tapala5;pa;fah0l6tanb5;ul;am2Zi2H;che2d5;ianap2Mo20;aAe7o5yder2W; chi mi5ms,nolulu;nh;f6lsin5rakli2;ki;ei;ifa,lifax,mCn5rb1Dva3;g8nov01oi;aFdanEenDhCiPlasgBo9raz,u5;a5jr23;dal6ng5yaquil;zh1J;aja2Oupe;ld coa1Bthen5;bu2S;ow;ent;e0Uoa;sk;lw7n5za;dhi5gt1E;nag0U;ay;aisal29es,o8r6ukuya5;ma;ankfu5esno;rt;rt5sh0; wor6ale5;za;th;d5indhov0Pl paso;in5mont2;bur5;gh;aBe8ha0Xisp4o7resd0Lu5;b5esseldorf,nkirk,rb0shanbe;ai,l0I;ha,nggu0rtmu13;hradSl6nv5troit;er;hi;donghIe6k09l5masc1Zr es sala1KugavpiY;i0lU;gu,je2;aJebu,hAleve0Vo5raio02uriti1Q;lo7n6penhag0Ar5;do1Ok;akKst0V;gUm5;bo;aBen8i6ongqi1ristchur5;ch;ang m7ca5ttago1;go;g6n5;ai;du,zho1;ng5ttogr14;ch8sha,zh07;gliari,i9lga8mayenJn6pe town,r5tanO;acCdiff;ber1Ac5;un;ry;ro;aWeNhKirmingh0WoJr9u5;chareTdapeTenos air7r5s0tu0;g5sa;as;es;a9is6usse5;ls;ba6t5;ol;ne;sil8tisla7zzav5;il5;le;va;ia;goZst2;op6ubaneshw5;ar;al;iCl9ng8r5;g6l5n;in;en;aluru,hazi;fa6grade,o horizon5;te;st;ji1rut;ghd0BkFn9ot8r7s6yan n4;ur;el,r07;celo3i,ranquil09;ou;du1g6ja lu5;ka;alo6k5;ok;re;ng;ers5u;field;a05b02cc01ddis aba00gartaZhmedXizawl,lSmPnHqa00rEsBt7uck5;la5;nd;he7l5;an5;ta;ns;h5unci2;dod,gab5;at;li5;ngt2;on;a8c5kaOtwerp;hora6o3;na;ge;h7p5;ol5;is;eim;aravati,m0s5;terd5;am; 7buquerq6eppo,giers,ma5;ty;ue;basrah al qadim5mawsil al jadid5;ah;ab5;ad;la;ba;ra;idj0u dha5;bi;an;lbo6rh5;us;rg",
  "Region": "trueÂ¦0:2O;1:2L;2:2U;3:2F;a2Sb2Fc21d1Wes1Vf1Tg1Oh1Ki1Fj1Bk16l13m0Sn09o07pYqVrSsJtEuBverAw6y4zacatec2W;akut0o0Fu4;cat1k09;a5est 4isconsin,yomi1O;bengal,virgin0;rwick3shington4;! dc;acruz,mont;dmurt0t4;ah,tar4; 2Pa12;a6e5laxca1Vripu21u4;scaEva;langa2nnessee,x2J;bas10m4smQtar29;aulip2Hil nadu;a9elang07i7o5taf16u4ylh1J;ff02rr09s1E;me1Gno1Uuth 4;cZdY;ber0c4kkim,naloa;hu1ily;n5rawak,skatchew1xo4;ny; luis potosi,ta catari2;a4hodeA;j4ngp0C;asth1shahi;ingh29u4;e4intana roo;bec,en6retaro;aAe6rince edward4unjab; i4;sl0G;i,n5r4;ak,nambu0F;a0Rnsylv4;an0;ha0Pra4;!na;axa0Zdisha,h4klaho21ntar4reg7ss0Dx0I;io;aLeEo6u4;evo le4nav0X;on;r4tt18va scot0;f9mandy,th4; 4ampton3;c6d5yo4;rk3;ako1O;aroli2;olk;bras1Nva0Dw4; 6foundland4;! and labrad4;or;brunswick,hamp3jers5mexiTyork4;! state;ey;galPyarit;aAeghala0Mi6o4;nta2r4;dov0elos;ch6dlanDn5ss4zor11;issippi,ouri;as geraPneso18;ig1oac1;dhy12harasht0Gine,lac07ni5r4ssachusetts;anhao,i el,ylG;p4toba;ur;anca3e4incoln3ouisI;e4iR;ds;a6e5h4omi;aka06ul2;dah,lant1ntucky,ra01;bardino,lmyk0ns0Qr4;achay,el0nata0X;alis6har4iangxi;kh4;and;co;daho,llino7n4owa;d5gush4;et0;ia2;is;a6ert5i4un1;dalFm0D;ford3;mp3rya2waii;ansu,eorg0lou7oa,u4;an4izhou,jarat;ajuato,gdo4;ng;cester3;lori4uji1;da;sex;ageUe7o5uran4;go;rs4;et;lawaMrby3;aFeaEh9o4rim08umbr0;ahui7l6nnectic5rsi4ventry;ca;ut;i03orado;la;e5hattisgarh,i4uvash0;apRhuahua;chn5rke4;ss0;ya;ra;lGm4;bridge3peche;a9ihar,r8u4;ck4ryat0;ingham3;shi4;re;emen,itish columb0;h0ja cal8lk7s4v7;hkorto4que;st1;an;ar0;iforn0;ia;dygHguascalientes,lBndhr9r5ss4;am;izo2kans5un4;achal 7;as;na;a 4;pradesh;a6ber5t4;ai;ta;ba5s4;ka;ma;ea",
  "Place": "trueÂ¦0:4T;1:4V;2:44;3:4B;4:3I;a4Eb3Gc2Td2Ge26f25g1Vh1Ji1Fk1Cl14m0Vn0No0Jp08r04sTtNuLvJw7y5;a5o0Syz;kut1Bngtze;aDeChitBi9o5upatki,ycom2P;ki26o5;d5l1B;b3Ps5;i4to3Y;c0SllowbroCn5;c2Qgh2;by,chur1P;ed0ntw3Gs22;ke6r3St5;erf1f1; is0Gf3V;auxha3Mirgin is0Jost5;ok;laanbaatar,pto5xb3E;n,wn;a9eotihuac43h7ive49o6ru2Nsarskoe selo,u5;l2Dzigo47;nto,rquay,tt2J;am3e 5orn3E;bronx,hamptons;hiti,j mah0Iu1N;aEcotts bluff,eCfo,herbroQoApring9t7u5yd2F;dbu1Wn5;der03set3B;aff1ock2Nr5;atf1oud;hi37w24;ho,uth5; 1Iam1Zwo3E;a5i2O;f2Tt0;int lawrence riv3Pkhal2D;ayleigh,ed7i5oc1Z;chmo1Eo gran4ver5;be1Dfr09si4; s39cliffe,hi2Y;aCe9h8i5ompeii,utn2;c6ne5tcai2T; 2Pc0G;keri13t0;l,x;k,lh2mbr6n5r2J;n1Hzance;oke;cif38pahanaumokuak30r5;k5then0;si4w1K;ak7r6x5;f1l2X;ange county,d,f1inoco;mTw1G;e8i1Uo5;r5tt2N;th5wi0E; 0Sam19;uschwanste1Pw5; eng6a5h2market,po36;rk;la0P;a8co,e6i5uc;dt1Yll0Z;adow5ko0H;lands;chu picchu,gad2Ridsto1Ql8n7ple6r5;kh2; g1Cw11;hatt2Osf2B;ibu,t0ve1Z;a8e7gw,hr,in5owlOynd02;coln memori5dl2C;al;asi4w3;kefr7mbe1On5s,x;ca2Ig5si05;f1l27t0;ont;azan kreml14e6itchen2Gosrae,rasnoyar5ul;sk;ns0Hs1U;ax,cn,lf1n6ps5st;wiN;d5glew0Lverness;ian27ochina;aDeBi6kg,nd,ov5unti2H;d,enweep;gh6llc5;reL;bu03l5;and5;!s;r5yw0C;ef1tf1;libu24mp6r5stings;f1lem,row;stead,t0;aDodavari,r5uelph;avenAe5imsS;at 8en5; 6f1Fwi5;ch;acr3vall1H;brita0Flak3;hur5;st;ng3y villa0W;airhavHco,ra;aAgli9nf17ppi8u7ver6x5;et1Lf1;glad3t0;rope,st0;ng;nt0;rls1Ls5;t 5;e5si4;nd;aCe9fw,ig8o7ryd6u5xb;mfri3nstab00rh2tt0;en;nca18rcKv19wnt0B;by;n6r5vonpo1D;ry;!h2;nu8r5;l6t5;f1moor;ingt0;be;aLdg,eIgk,hClBo5royd0;l6m5rnwa0B;pt0;c7lingw6osse5;um;ood;he0S;earwat0St;a8el6i5uuk;chen itza,mney ro07natSricahua;m0Zt5;enh2;mor5rlottetPth2;ro;dar 5ntervilA;breaks,faZg5;rove;ld9m8r5versh2;lis6rizo pla5;in;le;bLpbellf1;weQ;aZcn,eNingl01kk,lackLolt0r5uckV;aGiAo5;ckt0ok5wns cany0;lyn,s5;i4to5;ne;de;dge6gh5;am,t0;n6t5;own;or5;th;ceb6m5;lNpt0;rid5;ge;bu5pool,wa8;rn;aconsfEdf1lBr9verly7x5;hi5;ll; hi5;lls;wi5;ck; air,l5;ingh2;am;ie5;ld;ltimore,rnsl6tters5;ea;ey;bLct0driadic,frica,ginJlGmFn9rc8s7tl6yleOzor3;es;!ant8;hcroft,ia; de triomphe,t6;adyr,ca8dov9tarct5;ic5; oce5;an;st5;er;ericas,s;be6dersh5hambra,list0;ot;rt0;cou5;rt;bot7i5;ngd0;on;sf1;ord",
  "Country": "trueÂ¦0:38;1:2L;2:3B;a2Xb2Ec22d1Ye1Sf1Mg1Ch1Ai14j12k0Zl0Um0Gn05om2pZqat1KrXsKtCu7v5wal4yemTz3;a25imbabwe;es,lis and futu2Y;a3enezue32ietnam;nuatu,tican city;gTk6nited 4ruXs3zbeE; 2Ca,sr;arab emirat0Kkingdom,states3;! of am2Y;!raiV;a8haCimor les0Co7rinidad 5u3;nis0rk3valu;ey,me2Zs and caic1V;and t3t3;oba1L;go,kel10nga;iw2ji3nz2T;ki2V;aDcotl1eCi9lov8o6pa2Dri lanka,u5w3yr0;az3edAitzerl1;il1;d2riname;lomon1Xmal0uth 3;afr2KkMsud2;ak0en0;erra leoFn3;gapo1Yt maart3;en;negLrb0ychellZ;int 3moa,n marino,udi arab0;hele26luc0mart21;epublic of ir0Eom2Euss0w3;an27;a4eIhilippinUitcairn1Mo3uerto riN;l1rtugF;ki2Dl4nama,pua new0Vra3;gu7;au,esti3;ne;aBe9i7or3;folk1Ith4w3;ay; k3ern mariana1D;or0O;caragua,ger3ue;!ia;p3ther1Aw zeal1;al;mib0u3;ru;a7exi6icro0Bo3yanm06;ldova,n3roc5zambA;a4gol0t3;enegro,serrat;co;cAdagasc01l7r5urit4yot3;te;an0i16;shall0Xtin3;ique;a4div3i,ta;es;wi,ys0;ao,ed02;a6e5i3uxembourg;b3echtenste12thu1G;er0ya;ban0Isotho;os,tv0;azakh1Fe4iriba04o3uwait,yrgyz1F;rXsovo;eling0Knya;a3erG;ma16p2;c7nd6r4s3taly,vory coast;le of m2rael;a3el1;n,q;ia,oJ;el1;aiTon3ungary;dur0Ng kong;aBermany,ha0QibraltAre8u3;a6ern5inea3ya0P;! biss3;au;sey;deloupe,m,tema0Q;e3na0N;ce,nl1;ar;bUmb0;a7i6r3;ance,ench 3;guia0Epoly3;nes0;ji,nl1;lklandUroeU;ast tim7cu6gypt,l salv6ngl1quatorial4ritr5st3thiop0;on0; guin3;ea;ad3;or;enmark,jibou5ominica4r con3;go;!n C;ti;aBentral african Ah8o5roat0u4yprRzech3; 9ia;ba,racao;c4lo3morQngo brazzaville,okGsta r04te de ivoiL;mb0;osE;i3ristmasG;le,na;republic;m3naUpe verde,ymanA;bod0ero3;on;aGeDhut2o9r5u3;lgar0r3;kina faso,ma,undi;azil,itish 3unei;virgin3; is3;lands;liv0nai5snia and herzegoviHtswaHuvet3; isl1;and;re;l3n8rmuG;ar3gium,ize;us;h4ngladesh,rbad3;os;am4ra3;in;as;fghaGlDmBn6r4ustr3zerbaij2;al0ia;genti3men0uba;na;dorra,g5t3;arct7igua and barbu3;da;o3uil3;la;er3;ica;b3ger0;an0;ia;ni3;st2;an",
  "FirstName": "trueÂ¦aTblair,cQdOfrancoZgabMhinaLilya,jHkClBm6ni4quinn,re3s0;h0umit,yd;ay,e0iloh;a,lby;g9ne;co,ko0;!s;a1el0ina,org6;!okuhF;ds,naia,r1tt0xiB;i,y;ion,lo;ashawn,eif,uca;a3e1ir0rM;an;lsFn0rry;dall,yat5;i,sD;a0essIie,ude;i1m0;ie,mG;me;ta;rie0y;le;arcy,ev0;an,on;as1h0;arl8eyenne;ey,sidy;drien,kira,l4nd1ubr0vi;ey;i,r0;a,e0;a,y;ex2f1o0;is;ie;ei,is",
  "WeekDay": "trueÂ¦fri2mon2s1t0wednesd3;hurs1ues1;aturd1und1;!d0;ay0;!s",
  "Month": "trueÂ¦dec0february,july,nov0octo1sept0;em0;ber",
  "Date": "trueÂ¦ago,on4som4t1week0yesterd5; end,ends;mr1o0;d2morrow;!w;ed0;ay",
  "Duration": "trueÂ¦centurAd8h7m5q4se3w1y0;ear8r8;eek0k7;!end,s;ason,c5;tr,uarter;i0onth3;llisecond2nute2;our1r1;ay0ecade0;!s;ies,y",
  "FemaleName": "trueÂ¦0:J7;1:JB;2:IJ;3:IK;4:J1;5:IO;6:JS;7:JO;8:HB;9:JK;A:H4;B:I2;C:IT;D:JH;E:IX;F:BA;G:I4;aGTbFLcDRdD0eBMfB4gADh9Ti9Gj8Dk7Cl5Wm48n3Lo3Hp33qu32r29s15t0Eu0Cv02wVxiTyOzH;aLeIineb,oHsof3;e3Sf3la,ra;h2iKlIna,ynH;ab,ep;da,ma;da,h2iHra;nab;aKeJi0FolB7uIvH;et8onDP;i0na;le0sen3;el,gm3Hn,rGLs8W;aoHme0nyi;m5XyAD;aMendDZhiDGiH;dele9lJnH;if48niHo0;e,f47;a,helmi0lHma;a,ow;ka0nB;aNeKiHusa5;ck84kIl8oleAviH;anFenJ4;ky,toriBK;da,lA8rHs0;a,nHoniH9;a,iFR;leHnesH9;nILrH;i1y;g9rHs6xHA;su5te;aYeUhRiNoLrIuHy2;i,la;acJ3iHu0J;c3na,sH;hFta;nHr0F;iFya;aJffaEOnHs6;a,gtiH;ng;!nFSra;aIeHomasi0;a,l9Oo8Ares1;l3ndolwethu;g9Fo88rIssH;!a,ie;eHi,ri7;sa,za;bOlMmKnIrHs6tia0wa0;a60yn;iHya;a,ka,s6;arFe2iHm77ra;!ka;a,iH;a,t6;at6it6;a0Ecarlett,e0AhWiSkye,neza0oQri,tNuIyH;bIGlvi1;ha,mayIJniAsIzH;an3Net8ie,y;anHi7;!a,e,nH;aCe;aIeH;fan4l5Dphan6E;cI5r5;b3fiAAm0LnHphi1;d2ia,ja,ya;er2lJmon1nIobh8QtH;a,i;dy;lETv3;aMeIirHo0risFDy5;a,lDM;ba,e0i5lJrH;iHr6Jyl;!d8Ifa;ia,lDZ;hd,iMki2nJrIu0w0yH;la,ma,na;i,le9on,ron,yn;aIda,ia,nHon;a,on;!ya;k6mH;!aa;lJrItaye82vH;da,inj;e0ife;en1i0ma;anA9bLd5Oh1SiBkKlJmInd2rHs6vannaC;aCi0;ant6i2;lDOma,ome;ee0in8Tu2;in1ri0;a05eZhXiUoHuthDM;bScRghQl8LnPsJwIxH;anB3ie,y;an,e0;aIeHie,lD;ann7ll1marDGtA;!lHnn1;iHyn;e,nH;a,dF;da,i,na;ayy8G;hel67io;bDRerAyn;a,cIkHmas,nFta,ya;ki,o;h8Xki;ea,iannGMoH;da,n1P;an0bJemFgi0iInHta,y0;a8Bee;han86na;a,eH;cHkaC;a,ca;bi0chIe,i0mo0nHquETy0;di,ia;aERelHiB;!e,le;een4ia0;aPeOhMiLoJrHute6A;iHudenCV;scil3LyamvaB;lHrt3;i0ly;a,paluk;ilome0oebe,ylH;is,lis;ggy,nelope,r5t2;ige,m0VnKo5rvaDMtIulH;a,et8in1;ricHt4T;a,e,ia;do2i07;ctav3dIfD3is6ksa0lHphD3umC5yunbileg;a,ga,iv3;eHvAF;l3t8;aWeUiMoIurHy5;!ay,ul;a,eJor,rIuH;f,r;aCeEma;ll1mi;aNcLhariBQkKlaJna,sHta,vi;anHha;ur;!y;a,iDZki;hoGk9YolH;a,e4P;!mh;hir,lHna,risDEsreE;!a,lBV;asuMdLh3i6Dl5nKomi7rgEVtH;aHhal4;lHs6;i1ya;cy,et8;e9iF0ya;nngu2X;a0Ackenz4e02iMoJrignayani,uriDJyH;a,rH;a,iOlNna,tG;bi0i2llBJnH;a,iH;ca,ka,qD9;a,cUdo4ZkaTlOmi,nMrItzi,yH;ar;aJiIlH;anET;am;!l,nB;dy,eHh,n4;nhGrva;aKdJe0iCUlH;iHy;cent,e;red;!gros;!e5;ae5hH;ae5el3Z;ag5DgNi,lKrH;edi7AiIjem,on,yH;em,l;em,sCG;an4iHliCF;nHsCJ;a,da;!an,han;b09cASd07e,g05ha,i04ja,l02n00rLsoum5YtKuIv84xBKyHz4;bell,ra,soBB;d7rH;a,eE;h8Gild1t4;a,cUgQiKjor4l7Un4s6tJwa,yH;!aHbe6Xja9lAE;m,nBL;a,ha,in1;!aJbCGeIja,lDna,sHt63;!a,ol,sa;!l1D;!h,mInH;!a,e,n1;!awit,i;arJeIie,oHr48ueri8;!t;!ry;et46i3B;el4Xi7Cy;dHon,ue5;akranAy;ak,en,iHlo3S;a,ka,nB;a,re,s4te;daHg4;!l3E;alDd4elHge,isDJon0;ei9in1yn;el,le;a0Ne0CiXoQuLyH;d3la,nH;!a,dIe2OnHsCT;!a,e2N;a,sCR;aD4cJel0Pis1lIna,pHz;e,iA;a,u,wa;iHy;a0Se,ja,l2NnB;is,l1UrItt1LuHvel4;el5is1;aKeIi7na,rH;aADi7;lHn1tA;ei;!in1;aTbb9HdSepa,lNnKsJvIzH;!a,be5Ret8z4;!ia;a,et8;!a,dH;a,sHy;ay,ey,i,y;a,iJja,lH;iHy;aA8e;!aH;!nF;ia,ya;!nH;!a,ne;aPda,e0iNjYla,nMoKsJtHx93y5;iHt4;c3t3;e2PlCO;la,nHra;a,ie,o2;a,or1;a,gh,laH;!ni;!h,nH;a,d2e,n5V;cOdon9DiNkes6mi9Gna,rMtJurIvHxmi,y5;ern1in3;a,e5Aie,yn;as6iIoH;nya,ya;fa,s6;a,isA9;a,la;ey,ie,y;a04eZhXiOlASoNrJyH;lHra;a,ee,ie;istHy6I;a,en,iIyH;!na;!e,n5F;nul,ri,urtnB8;aOerNlB7mJrHzzy;a,stH;en,in;!berlImernH;aq;eHi,y;e,y;a,stE;!na,ra;aHei2ongordzol;dij1w5;el7UiKjsi,lJnIrH;a,i,ri;d2na,za;ey,i,lBLs4y;ra,s6;biAcARdiat7MeBAiSlQmPnyakuma1DrNss6NtKviAyH;!e,lH;a,eH;e,i8T;!a6HeIhHi4TlDri0y;ar8Her8Hie,leErBAy;!lyn8Ori0;a,en,iHl5Xoli0yn;!ma,nFs95;a5il1;ei8Mi,lH;e,ie;a,tl6O;a0AeZiWoOuH;anMdLlHst88;es,iH;a8NeHs8X;!n9tH;!a,te;e5Mi3My;a,iA;!anNcelDdMelGhan7VleLni,sIva0yH;a,ce;eHie;fHlDph7Y;a,in1;en,n1;i7y;!a,e,n45;lHng;!i1DlH;!i1C;anNle0nKrJsH;i8JsH;!e,i8I;i,ri;!a,elGif2CnH;a,et8iHy;!e,f2A;a,eJiInH;a,eIiH;e,n1;!t8;cMda,mi,nIque4YsminFvie2y9zH;min7;a7eIiH;ce,e,n1s;!lHs82t0F;e,le;inIk6HlDquelH;in1yn;da,ta;da,lRmPnOo0rNsIvaHwo0zaro;!a0lu,na;aJiIlaHob89;!n9R;do2;belHdo2;!a,e,l3B;a7Ben1i0ma;di2es,gr72ji;a9elBogH;en1;a,e9iHo0se;a0na;aSeOiJoHus7Kyacin2C;da,ll4rten24snH;a,i9U;lImaH;ri;aIdHlaI;a,egard;ry;ath1BiJlInrietArmi9sH;sa,t1A;en2Uga,mi;di;bi2Fil8MlNnMrJsItHwa,yl8M;i5Tt4;n60ti;iHmo51ri53;etH;!te;aCnaC;a,ey,l4;a02eWiRlPoNrKunJwH;enHyne1R;!dolD;ay,el;acieIetHiselB;a,chE;!la;ld1CogooH;sh;adys,enHor3yn2K;a,da,na;aKgi,lIna,ov8EselHta;a,e,le;da,liH;an;!n0;mLnJorgIrH;ald5Si,m3Etrud7;et8i4X;a,eHna;s29vieve;ma;bIle,mHrnet,yG;al5Si5;iIrielH;a,l1;!ja;aTeQiPlorOoz3rH;anJeIiH;da,eB;da,ja;!cH;esIiHoi0P;n1s66;!ca;a,enc3;en,o0;lIn0rnH;anB;ec3ic3;jr,nArKtHy7;emIiHma,oumaA;ha,ma,n;eh;ah,iBrah,za0;cr4Rd0Re0Qi0Pk0Ol07mXn54rUsOtNuMvHwa;aKelIiH;!e,ta;inFyn;!a;!ngel4V;geni1ni47;h5Yien9ta;mLperanKtH;eIhHrel5;er;l31r7;za;a,eralB;iHma,ne4Lyn;cHka,n;a,ka;aPeNiKmH;aHe21ie,y;!li9nuH;elG;lHn1;e7iHy;a,e,ja;lHrald;da,y;!nue5;aWeUiNlMma,no2oKsJvH;a,iH;na,ra;a,ie;iHuiH;se;a,en,ie,y;a0c3da,e,f,nMsJzaH;!betHveA;e,h;aHe,ka;!beH;th;!a,or;anor,nH;!a,i;!in1na;ate1Rta;leEs6;vi;eIiHna,wi0;e,th;l,n;aYeMh3iLjeneKoH;lor5Vminiq4Ln3FrHtt4;a,eEis,la,othHthy;ea,y;ba;an09naCon9ya;anQbPde,eOiMlJmetr3nHsir5M;a,iH;ce,se;a,iIla,orHphi9;es,is;a,l6F;dHrdH;re;!d5Ena;!b2ForaCraC;a,d2nH;!a,e;hl3i0l0GmNnLphn1rIvi1WyH;le,na;a,by,cIia,lH;a,en1;ey,ie;a,et8iH;!ca,el1Aka,z;arHia;is;a0Re0Nh04i02lUoJristIynH;di,th3;al,i0;lPnMrIurH;tn1D;aJd2OiHn2Ori9;!nH;a,e,n1;!l4;cepci5Cn4sH;tanHuelo;ce,za;eHleE;en,t8;aJeoIotH;il54;!pat2;ir7rJudH;et8iH;a,ne;a,e,iH;ce,sZ;a2er2ndH;i,y;aReNloe,rH;isJyH;stH;al;sy,tH;a1Sen,iHy;an1e,n1;deJlseIrH;!i7yl;a,y;li9;nMrH;isKlImH;ai9;a,eHot8;n1t8;!sa;d2elGtH;al,elG;cIlH;es8i47;el3ilH;e,ia,y;itlYlXmilWndVrMsKtHy5;aIeIhHri0;er1IleErDy;ri0;a38sH;a37ie;a,iOlLmeJolIrH;ie,ol;!e,in1yn;lHn;!a,la;a,eIie,otHy;a,ta;ne,y;na,s1X;a0Ii0I;a,e,l1;isAl4;in,yn;a0Ke02iZlXoUrH;andi7eRiJoIyH;an0nn;nwDoke;an3HdgMgiLtH;n31tH;!aInH;ey,i,y;ny;d,t8;etH;!t7;an0e,nH;da,na;bbi7glarIlo07nH;iAn4;ka;ancHythe;a,he;an1Clja0nHsm3M;iAtH;ou;aWcVlinUniArPssOtJulaCvH;!erlH;ey,y;hJsy,tH;e,iHy7;e,na;!anH;ie,y;!ie;nItHyl;ha,ie;adIiH;ce;et8i9;ay,da;ca,ky;!triH;ce,z;rbJyaH;rmH;aa;a2o2ra;a2Ub2Od25g21i1Sj5l18m0Zn0Boi,r06sWtVuPvOwa,yIzH;ra,u0;aKes6gJlIn,seH;!l;in;un;!nH;a,na;a,i2K;drLguJrIsteH;ja;el3;stH;in1;a,ey,i,y;aahua,he0;hIi2Gja,miAs2DtrH;id;aMlIraqHt21;at;eIi7yH;!n;e,iHy;gh;!nH;ti;iJleIo6piA;ta;en,n1t8;aHelG;!n1J;a01dje5eZgViTjRnKohito,toHya;inet8nH;el5ia;te;!aKeIiHmJ;e,ka;!mHtt7;ar4;!belIliHmU;sa;!l1;a,eliH;ca;ka,sHta;a,sa;elHie;a,iH;a,ca,n1qH;ue;!tH;a,te;!bImHstasiMya;ar3;el;aLberKeliJiHy;e,l3naH;!ta;a,ja;!ly;hGiIl3nB;da;a,ra;le;aWba,ePiMlKthJyH;a,c3sH;a,on,sa;ea;iHys0N;e,s0M;a,cIn1sHza;a,e,ha,on,sa;e,ia,ja;c3is6jaKksaKna,sJxH;aHia;!nd2;ia,saH;nd2;ra;ia;i0nIyH;ah,na;a,is,naCoud;la;c6da,leEmNnLsH;haClH;inHyY;g,n;!h;a,o,slH;ey;ee;en;at6g4nIusH;ti0;es;ie;aWdiTelMrH;eJiH;anMenH;a,e,ne;an0;na;!aLeKiIyH;nn;a,n1;a,e;!ne;!iH;de;e,lDsH;on;yn;!lH;i9yn;ne;aKbIiHrL;!e,gaK;ey,i7y;!e;gaH;il;dKliyJradhIs6;ha;ya;ah;a,ya",
  "Honorific": "trueÂ¦director1field marsh2lieutenant1rear0sergeant major,vice0; admir1; gener0;al",
  "Adj|Gerund": "trueÂ¦0:3F;1:3H;2:31;3:2X;4:35;5:33;6:3C;7:2Z;8:36;9:29;a33b2Tc2Bd1Te1If19g12h0Zi0Rl0Nm0Gnu0Fo0Ap04rYsKtEuBvAw1Ayiel3;ar6e08;nBpA;l1Rs0B;fol3n1Zsett2;aEeDhrBi4ouc7rAwis0;e0Bif2oub2us0yi1;ea1SiA;l2vi1;l2mp0rr1J;nt1Vxi1;aMcreec7enten2NhLkyrocke0lo0Vmi2oJpHtDuBweA;e0Ul2;pp2ArA;gi1pri5roun3;aBea8iAri2Hun9;mula0r4;gge4rA;t2vi1;ark2eAraw2;e3llb2F;aAot7;ki1ri1;i9oc29;dYtisf6;aEeBive0oAus7;a4l2;assu4defi9fres7ig9juve07mai9s0vAwar3;ea2italiAol1G;si1zi1;gi1ll6mb2vi1;a6eDier23lun1VrAun2C;eBoA;mi5vo1Z;ce3s5vai2;n3rpleA;xi1;ffCpWutBverAwi1;arc7lap04p0Pri3whel8;goi1l6st1J;en3sA;et0;m2Jrtu4;aEeDiCoBuAyst0L;mb2;t1Jvi1;s5tiga0;an1Rl0n3smeri26;dAtu4;de9;aCeaBiAo0U;fesa0Tvi1;di1ni1;c1Fg19s0;llumiGmFnArri0R;cDfurHsCtBviA;go23ti1;e1Oimi21oxica0rig0V;pi4ul0;orpo20r0K;po5;na0;eaBorr02umilA;ia0;li1rtwar8;lFrA;atiDipCoBuelA;i1li1;undbrea10wi1;pi1;f6ng;a4ea8;a3etc7it0lEoCrBulfA;il2;ee1FighXust1L;rAun3;ebo3thco8;aCoA;a0wA;e4i1;mi1tte4;lectrJmHnExA;aCci0hBis0pA;an3lo3;aOila1B;c0spe1A;ab2coura0CdBergi13ga0Clive9ric7s02tA;hral2i0J;ea4u4;barras5er09pA;owe4;if6;aQeIiBrA;if0;sAzz6;aEgDhearCsen0tA;rAur11;ac0es5;te9;us0;ppoin0r8;biliGcDfi9gra3ligh0mBpres5sAvasG;erE;an3ea9orA;ali0L;a6eiBli9rA;ea5;vi1;ta0;maPri1s7un0zz2;aPhMlo5oAripp2ut0;mGnArrespon3;cer9fDspi4tA;inBrA;as0ibu0ol2;ui1;lic0u5;ni1;fDmCpA;eAromi5;l2ti1;an3;or0;aAil2;llenAnAr8;gi1;l8ptAri1;iva0;aff2eGin3lFoDrBuA;d3st2;eathtaAui5;ki1;gg2i2o8ri1unA;ci1;in3;co8wiA;lAtc7;de4;bsorVcOgonMlJmHnno6ppea2rFsA;pi4su4toA;nBun3;di1;is7;hi1;res0;li1;aFu5;si1;ar8lu4;ri1;mi1;iAzi1;zi1;cAhi1;eleDomA;moBpan6;yi1;da0;ra0;ti1;bi1;ng",
  "Comparable": "trueÂ¦0:3C;1:3Q;2:3F;a3Tb3Cc33d2Te2Mf2Ag1Wh1Li1Fj1Ek1Bl13m0Xn0So0Rp0Iqu0Gr07sHtCug0vAw4y3za0Q;el10ouN;ary,e6hi5i3ry;ck0Cde,l3n1ry,se;d,y;ny,te;a3i3R;k,ry;a3erda2ulgar;gue,in,st;a6en2Xhi5i4ouZr3;anqu2Cen1ue;dy,g36me0ny;ck,rs28;ll,me,rt,wd3I;aRcaPeOhMiLkin0BlImGoEpDt6u4w3;eet,ift;b3dd0Wperfi21rre28;sta26t21;a8e7iff,r4u3;pUr1;a4ict,o3;ng;ig2Vn0N;a1ep,rn;le,rk,te0;e1Si2Vright0;ci1Yft,l3on,re;emn,id;a3el0;ll,rt;e4i3y;g2Mm0Z;ek,nd2T;ck24l0mp1L;a3iRrill,y;dy,l01rp;ve0Jxy;n1Jr3;ce,y;d,fe,int0l1Hv0V;a8e6i5o3ude;mantic,o19sy,u3;gh;pe,t1P;a3d,mo0A;dy,l;gg4iFndom,p3re,w;id;ed;ai2i3;ck,et;hoAi1Fl9o8r5u3;ny,r3;e,p11;egna2ic4o3;fouSud;ey,k0;liXor;ain,easa2;ny;dd,i0ld,ranL;aive,e5i4o3u14;b0Sisy,rm0Ysy;bb0ce,mb0R;a3r1w;r,t;ad,e5ild,o4u3;nda12te;ist,o1;a4ek,l3;low;s0ty;a8e7i6o3ucky;f0Jn4o15u3ve0w10y0N;d,sy;e0g;ke0l,mp,tt0Eve0;e1Qwd;me,r3te;ge;e4i3;nd;en;ol0ui19;cy,ll,n3;secu6t3;e3ima4;llege2rmedia3;te;re;aAe7i6o5u3;ge,m3ng1C;bYid;me0t;gh,l0;a3fXsita2;dy,rWv3;en0y;nd13ppy,r3;d3sh;!y;aFenEhCiBlAoofy,r3;a8e6i5o3ue0Z;o3ss;vy;m,s0;at,e3y;dy,n;nd,y;ad,ib,ooD;a2d1;a3o3;st0;tDuiS;u1y;aCeebBi9l8o6r5u3;ll,n3r0N;!ny;aCesh,iend0;a3nd,rmD;my;at,ir7;erce,nan3;ci9;le;r,ul3;ty;a6erie,sse4v3xtre0B;il;nti3;al;r4s3;tern,y;ly,th0;appZe9i5ru4u3;mb;nk;r5vi4z3;zy;ne;e,ty;a3ep,n9;d3f,r;!ly;agey,h8l7o5r4u3;dd0r0te;isp,uel;ar3ld,mmon,st0ward0zy;se;evKou1;e3il0;ap,e3;sy;aHiFlCoAr5u3;ff,r0sy;ly;a6i3oad;g4llia2;nt;ht;sh,ve;ld,un3;cy;a4o3ue;nd,o1;ck,nd;g,tt3;er;d,ld,w1;dy;bsu6ng5we3;so3;me;ry;rd",
  "Adverb": "trueÂ¦a08b05d00eYfSheQinPjustOkinda,likewiZmMnJoEpCquite,r9s5t2u0very,well;ltima01p0; to,wards5;h1iny bit,o0wiO;o,t6;en,us;eldom,o0uch;!me1rt0; of;how,times,w0C;a1e0;alS;ndomRth05;ar excellenEer0oint blank; Lhaps;f3n0utright;ce0ly;! 0;ag05moX; courGten;ewJo0; longWt 0;onHwithstand9;aybe,eanwhiNore0;!ovT;! aboX;deed,steY;lla,n0;ce;or3u0;ck1l9rther0;!moK;ing; 0evK;exampCgood,suH;n mas0vI;se;e0irect2; 2fini0;te0;ly;juAtrop;ackward,y 0;far,no0; means,w; GbroFd nauseam,gEl7ny5part,s4t 2w0;ay,hi0;le;be7l0mo7wor7;arge,ea6; soon,i4;mo0way;re;l 3mo2ongsi1ready,so,togeth0ways;er;de;st;b1t0;hat;ut;ain;ad;lot,posteriori",
  "Conjunction": "trueÂ¦aXbTcReNhowMiEjust00noBo9p8supposing,t5wh0yet;e1il0o3;e,st;n1re0thN; if,by,vM;evL;h0il,o;erefOo0;!uU;lus,rovided th9;r0therwiM;! not; mattEr,w0;! 0;since,th4w7;f4n0; 0asmuch;as mIcaForder t0;h0o;at;! 0;only,t0w0;hen;!ev3;ith2ven0;! 0;if,tB;er;o0uz;s,z;e0ut,y the time;cau1f0;ore;se;lt3nd,s 0;far1if,m0soon1t2;uch0; as;hou0;gh",
  "Currency": "trueÂ¦$,aud,bQcOdJeurIfHgbp,hkd,iGjpy,kElDp8r7s3usd,x2y1z0Â¢,Â£,Â¥,Ð´ÐµÐ½,Ð»Ð²,Ñ€ÑƒÐ±,à¸¿,â‚¡,â‚¨,â‚¬,â‚­,ï·¼;lotyQÅ‚;en,uanP;af,of;h0t5;e0il5;k0q0;elK;oubleJp,upeeJ;e2ound st0;er0;lingG;n0soF;ceEnies;empi7i7;n,r0wanzaCyatC;!onaBw;ls,nr;ori7ranc9;!os;en3i2kk,o0;b0ll2;ra5;me4n0rham4;ar3;e0ny;nt1;aht,itcoin0;!s",
  "Determiner": "trueÂ¦aBboth,d9e6few,le5mu8neiDplenty,s4th2various,wh0;at0ich0;evC;a0e4is,ose;!t;everal,ome;!ast,s;a1l0very;!se;ch;e0u;!s;!n0;!o0y;th0;er",
  "Adj|Present": "trueÂ¦a07b04cVdQeNfJhollIidRlEmCnarrIoBp9qua8r7s3t2uttFw0;aKet,ro0;ng,u08;endChin;e2hort,l1mooth,our,pa9tray,u0;re,speU;i2ow;cu6da02leSpaN;eplica01i02;ck;aHerfePr0;eseUime,omV;bscu1pen,wn;atu0e3odeH;re;a2e1ive,ow0;er;an;st,y;ow;a2i1oul,r0;ee,inge;rm;iIke,ncy,st;l1mpty,x0;emHpress;abo4ic7;amp,e2i1oub0ry,ull;le;ffu9re6;fu8libe0;raE;alm,l5o0;mpleCn3ol,rr1unterfe0;it;e0u7;ct;juga8sum7;ea1o0;se;n,r;ankru1lu0;nt;pt;li2pproxi0rticula1;ma0;te;ght",
  "Person|Adj": "trueÂ¦b3du2earnest,frank,mi2r0san1woo1;an0ich,u1;dy;sty;ella,rown",
  "Modal": "trueÂ¦c5lets,m4ought3sh1w0;ill,o5;a0o4;ll,nt;! to,a;ight,ust;an,o0;uld",
  "Verb": "trueÂ¦born,cannot,gonna,has,keep tabs,msg",
  "Person|Verb": "trueÂ¦b8ch7dr6foster,gra5ja9lan4ma2ni9ollie,p1rob,s0wade;kip,pike,t5ue;at,eg,ier2;ck,r0;k,shal;ce;ce,nt;ew;ase,u1;iff,l1ob,u0;ck;aze,ossom",
  "Person|Date": "trueÂ¦a2j0sep;an0une;!uary;p0ugust,v0;ril"
};

const BASE = 36;
const seq = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ';

const cache = seq.split('').reduce(function (h, c, i) {
  h[c] = i;
  return h
}, {});

// 0, 1, 2, ..., A, B, C, ..., 00, 01, ... AA, AB, AC, ..., AAA, AAB, ...
const toAlphaCode = function (n) {
  if (seq[n] !== undefined) {
    return seq[n]
  }
  let places = 1;
  let range = BASE;
  let s = '';
  for (; n >= range; n -= range, places++, range *= BASE) {}
  while (places--) {
    const d = n % BASE;
    s = String.fromCharCode((d < 10 ? 48 : 55) + d) + s;
    n = (n - d) / BASE;
  }
  return s
};

const fromAlphaCode = function (s) {
  if (cache[s] !== undefined) {
    return cache[s]
  }
  let n = 0;
  let places = 1;
  let range = BASE;
  let pow = 1;
  for (; places < s.length; n += range, places++, range *= BASE) {}
  for (let i = s.length - 1; i >= 0; i--, pow *= BASE) {
    let d = s.charCodeAt(i) - 48;
    if (d > 10) {
      d -= 7;
    }
    n += d * pow;
  }
  return n
};

var encoding = {
  toAlphaCode,
  fromAlphaCode
};

const symbols$1 = function (t) {
  //... process these lines
  const reSymbol = new RegExp('([0-9A-Z]+):([0-9A-Z]+)');
  for (let i = 0; i < t.nodes.length; i++) {
    const m = reSymbol.exec(t.nodes[i]);
    if (!m) {
      t.symCount = i;
      break
    }
    t.syms[encoding.fromAlphaCode(m[1])] = encoding.fromAlphaCode(m[2]);
  }
  //remove from main node list
  t.nodes = t.nodes.slice(t.symCount, t.nodes.length);
};

// References are either absolute (symbol) or relative (1 - based)
const indexFromRef = function (trie, ref, index) {
  const dnode = encoding.fromAlphaCode(ref);
  if (dnode < trie.symCount) {
    return trie.syms[dnode]
  }
  return index + dnode + 1 - trie.symCount
};

const toArray$2 = function (trie) {
  const all = [];
  const crawl = (index, pref) => {
    let node = trie.nodes[index];
    if (node[0] === '!') {
      all.push(pref);
      node = node.slice(1); //ok, we tried. remove it.
    }
    const matches = node.split(/([A-Z0-9,]+)/g);
    for (let i = 0; i < matches.length; i += 2) {
      const str = matches[i];
      const ref = matches[i + 1];
      if (!str) {
        continue
      }
      const have = pref + str;
      //branch's end
      if (ref === ',' || ref === undefined) {
        all.push(have);
        continue
      }
      const newIndex = indexFromRef(trie, ref, index);
      crawl(newIndex, have);
    }
  };
  crawl(0, '');
  return all
};

//PackedTrie - Trie traversal of the Trie packed-string representation.
const unpack$1 = function (str) {
  const trie = {
    nodes: str.split(';'),
    syms: [],
    symCount: 0
  };
  //process symbols, if they have them
  if (str.match(':')) {
    symbols$1(trie);
  }
  return toArray$2(trie)
};

const unpack = function (str) {
  if (!str) {
    return {}
  }
  //turn the weird string into a key-value object again
  const obj = str.split('|').reduce((h, s) => {
    const arr = s.split('Â¦');
    h[arr[0]] = arr[1];
    return h
  }, {});
  const all = {};
  Object.keys(obj).forEach(function (cat) {
    const arr = unpack$1(obj[cat]);
    //special case, for botched-boolean
    if (cat === 'true') {
      cat = true;
    }
    for (let i = 0; i < arr.length; i++) {
      const k = arr[i];
      if (all.hasOwnProperty(k) === true) {
        if (Array.isArray(all[k]) === false) {
          all[k] = [all[k], cat];
        } else {
          all[k].push(cat);
        }
      } else {
        all[k] = cat;
      }
    }
  });
  return all
};

const prp = ['Possessive', 'Pronoun'];
//words that can't be compressed, for whatever reason
let misc$5 = {
  // numbers
  '20th century fox': 'Organization',
  '7 eleven': 'Organization',
  'motel 6': 'Organization',
  g8: 'Organization',
  vh1: 'Organization',
  '76ers': 'SportsTeam',
  '49ers': 'SportsTeam',

  q1: 'Date',
  q2: 'Date',
  q3: 'Date',
  q4: 'Date',

  km2: 'Unit',
  m2: 'Unit',
  dm2: 'Unit',
  cm2: 'Unit',
  mm2: 'Unit',
  mile2: 'Unit',
  in2: 'Unit',
  yd2: 'Unit',
  ft2: 'Unit',
  m3: 'Unit',
  dm3: 'Unit',
  cm3: 'Unit',
  in3: 'Unit',
  ft3: 'Unit',
  yd3: 'Unit',

  // ampersands
  'at&t': 'Organization',
  'black & decker': 'Organization',
  'h & m': 'Organization',
  'johnson & johnson': 'Organization',
  'procter & gamble': 'Organization',
  "ben & jerry's": 'Organization',
  '&': 'Conjunction',

  //pronouns
  i: ['Pronoun', 'Singular'],
  he: ['Pronoun', 'Singular'],
  she: ['Pronoun', 'Singular'],
  it: ['Pronoun', 'Singular'],
  they: ['Pronoun', 'Plural'],
  we: ['Pronoun', 'Plural'],
  was: ['Copula', 'PastTense'],
  is: ['Copula', 'PresentTense'],
  are: ['Copula', 'PresentTense'],
  am: ['Copula', 'PresentTense'],
  were: ['Copula', 'PastTense'],

  // possessive pronouns
  her: prp,
  his: prp,
  hers: prp,
  their: prp,
  theirs: prp,
  themselves: prp,
  your: prp,
  our: prp,
  ours: prp,
  my: prp,
  its: prp,

  // misc
  vs: ['Conjunction', 'Abbreviation'],
  if: ['Condition', 'Preposition'],
  closer: 'Comparative',
  closest: 'Superlative',
  much: 'Adverb',
  may: 'Modal',

  // irregular conjugations with two forms
  babysat: 'PastTense',
  blew: 'PastTense',
  drank: 'PastTense',
  drove: 'PastTense',
  forgave: 'PastTense',
  skiied: 'PastTense',
  spilt: 'PastTense',
  stung: 'PastTense',
  swam: 'PastTense',
  swung: 'PastTense',
  guaranteed: 'PastTense',
  shrunk: 'PastTense',

  // support 'near', 'nears', 'nearing'
  nears: 'PresentTense',
  nearing: 'Gerund',
  neared: 'PastTense',

  no: ['Negative', 'Expression'],

  // '-': 'Preposition', //june - july

  // there: 'There'
};

var frozenLex = {
  '20th century fox': 'Organization',
  '7 eleven': 'Organization',
  'motel 6': 'Organization',
  'excuse me': 'Expression',
  'financial times': 'Organization',
  'guns n roses': 'Organization',
  'la z boy': 'Organization',
  'labour party': 'Organization',
  'new kids on the block': 'Organization',
  'new york times': 'Organization',
  'the guess who': 'Organization',
  'thin lizzy': 'Organization',

  'prime minister': 'Actor',
  'free market': 'Singular',
  'lay up': 'Singular',
  'living room': 'Singular',
  'living rooms': 'Plural',
  'spin off': 'Singular',
  'appeal court': 'Uncountable',
  'cold war': 'Uncountable',
  'gene pool': 'Uncountable',
  'machine learning': 'Uncountable',
  'nail polish': 'Uncountable',
  'time off': 'Uncountable',
  'take part': 'Infinitive',

  'bill gates': 'Person',
  'doctor who': 'Person',
  'dr who': 'Person',
  'he man': 'Person',
  'iron man': 'Person',
  'kid cudi': 'Person',
  'run dmc': 'Person',
  'rush limbaugh': 'Person',
  'snow white': 'Person',
  'tiger woods': 'Person',

  'brand new': 'Adjective',
  'en route': 'Adjective',
  'left wing': 'Adjective',
  'off guard': 'Adjective',
  'on board': 'Adjective',
  'part time': 'Adjective',
  'right wing': 'Adjective',
  'so called': 'Adjective',
  'spot on': 'Adjective',
  'straight forward': 'Adjective',
  'super duper': 'Adjective',
  'tip top': 'Adjective',
  'top notch': 'Adjective',
  'up to date': 'Adjective',
  'win win': 'Adjective',

  'brooklyn nets': 'SportsTeam',
  'chicago bears': 'SportsTeam',
  'houston astros': 'SportsTeam',
  'houston dynamo': 'SportsTeam',
  'houston rockets': 'SportsTeam',
  'houston texans': 'SportsTeam',
  'minnesota twins': 'SportsTeam',
  'orlando magic': 'SportsTeam',
  'san antonio spurs': 'SportsTeam',
  'san diego chargers': 'SportsTeam',
  'san diego padres': 'SportsTeam',

  'iron maiden': 'ProperNoun',
  'isle of man': 'Country',
  'united states': 'Country',
  'united states of america': 'Country',
  'prince edward island': 'Region',
  'cedar breaks': 'Place',
  'cedar falls': 'Place',

  'point blank': 'Adverb',
  'tiny bit': 'Adverb',
  'by the time': 'Conjunction',
  'no matter': 'Conjunction',

  'civil wars': 'Plural',
  'credit cards': 'Plural',
  'default rates': 'Plural',
  'free markets': 'Plural',
  'head starts': 'Plural',
  'home runs': 'Plural',
  'lay ups': 'Plural',
  'phone calls': 'Plural',
  'press releases': 'Plural',
  'record labels': 'Plural',
  'soft serves': 'Plural',
  'student loans': 'Plural',
  'tax returns': 'Plural',
  'tv shows': 'Plural',
  'video games': 'Plural',

  'took part': 'PastTense',
  'takes part': 'PresentTense',
  'taking part': 'Gerund',
  'taken part': 'Participle',

  'light bulb': 'Noun',
  'rush hour': 'Noun',
  'fluid ounce': 'Unit',
  'the rolling stones': 'Organization',
};

//just some of the most common emoticons
//faster than
//http://stackoverflow.com/questions/28077049/regex-matching-emoticons
var emoticons = [
  ':(',
  ':)',
  ':P',
  ':p',
  ':O',
  ';(',
  ';)',
  ';P',
  ';p',
  ';O',
  ':3',
  ':|',
  ':/',
  ':\\',
  ':$',
  ':*',
  ':@',
  ':-(',
  ':-)',
  ':-P',
  ':-p',
  ':-O',
  ':-3',
  ':-|',
  ':-/',
  ':-\\',
  ':-$',
  ':-*',
  ':-@',
  ':^(',
  ':^)',
  ':^P',
  ':^p',
  ':^O',
  ':^3',
  ':^|',
  ':^/',
  ':^\\',
  ':^$',
  ':^*',
  ':^@',
  '):',
  '(:',
  '$:',
  '*:',
  ')-:',
  '(-:',
  '$-:',
  '*-:',
  ')^:',
  '(^:',
  '$^:',
  '*^:',
  '<3',
  '</3',
  '<\\3',
  '=('
];

/** patterns for turning 'bus' to 'buses'*/
const suffixes$3 = {
  a: [
    [/(antenn|formul|nebul|vertebr|vit)a$/i, '$1ae'],
    [/ia$/i, 'ia'],
  ],
  e: [
    [/(kn|l|w)ife$/i, '$1ives'],
    [/(hive)$/i, '$1s'],
    [/([m|l])ouse$/i, '$1ice'],
    [/([m|l])ice$/i, '$1ice'],
  ],
  f: [
    [/^(dwar|handkerchie|hoo|scar|whar)f$/i, '$1ves'],
    [/^((?:ca|e|ha|(?:our|them|your)?se|she|wo)l|lea|loa|shea|thie)f$/i, '$1ves'],
  ],
  i: [[/(octop|vir)i$/i, '$1i']],
  m: [[/([ti])um$/i, '$1a']],
  n: [[/^(oxen)$/i, '$1']],
  o: [[/(al|ad|at|er|et|ed)o$/i, '$1oes']],
  s: [
    [/(ax|test)is$/i, '$1es'],
    [/(alias|status)$/i, '$1es'],
    [/sis$/i, 'ses'],
    [/(bu)s$/i, '$1ses'],
    [/(sis)$/i, 'ses'],
    [/^(?!talis|.*hu)(.*)man$/i, '$1men'],
    [/(octop|vir|radi|nucle|fung|cact|stimul)us$/i, '$1i'],
  ],
  x: [
    [/(matr|vert|ind|cort)(ix|ex)$/i, '$1ices'],
    [/^(ox)$/i, '$1en'],
  ],
  y: [[/([^aeiouy]|qu)y$/i, '$1ies']],
  z: [[/(quiz)$/i, '$1zes']],
};

const addE = /([xsz]|ch|sh)$/;

const trySuffix = function (str) {
  let c = str[str.length - 1];
  if (suffixes$3.hasOwnProperty(c) === true) {
    for (let i = 0; i < suffixes$3[c].length; i += 1) {
      let reg = suffixes$3[c][i][0];
      if (reg.test(str) === true) {
        return str.replace(reg, suffixes$3[c][i][1])
      }
    }
  }
  return null
};
/** Turn a singular noun into a plural
 * assume the given string is singular
 */
const pluralize = function (str = '', model) {
  let { irregularPlurals, uncountable } = model.two;
  // is it a word without a plural form?
  if (uncountable.hasOwnProperty(str)) {
    return str
  }
  // check irregulars list
  if (irregularPlurals.hasOwnProperty(str)) {
    return irregularPlurals[str]
  }
  //we have some rules to try-out
  let plural = trySuffix(str);
  if (plural !== null) {
    return plural
  }
  //like 'church'
  if (addE.test(str)) {
    return str + 'es'
  }
  // Â¯\_(ãƒ„)_/Â¯
  return str + 's'
};

// unpack our lexicon of words
// (found in ./lexicon/)

// more clever things are done on the data later
//  - once the plugin is applied
const hasSwitch = /\|/;
let lexicon = misc$5;
let switches = {};

const tmpModel$1 = { two: { irregularPlurals, uncountable: {} } };

Object.keys(lexData).forEach(tag => {
  let wordsObj = unpack(lexData[tag]);
  // POS tag, or something fancier?
  if (!hasSwitch.test(tag)) {
    // set them as simple word key-value lookup
    Object.keys(wordsObj).forEach(w => {
      lexicon[w] = tag;
    });
    return
  }
  // add them as seperate key-val object
  Object.keys(wordsObj).forEach(w => {
    switches[w] = tag;
    // pluralize Noun|Verb switches
    if (tag === 'Noun|Verb') {
      let plural = pluralize(w, tmpModel$1);
      switches[plural] = 'Plural|Verb';
    }
  });
});
// add ':)'
emoticons.forEach(str => (lexicon[str] = 'Emoticon'));

// misc cleanup
delete lexicon[''];
delete lexicon[null];
delete lexicon[' '];

const n$1 = 'Singular';
var noun$1 = {
  beforeTags: {
    Determiner: n$1, //the date
    Possessive: n$1, //his date
    Acronym: n$1, //u.s. state
    // ProperNoun:n,
    Noun: n$1, //nasa funding
    Adjective: n$1, //whole bottles
    // Verb:true, //save storm victims
    PresentTense: n$1, //loves hiking
    Gerund: n$1, //uplifting victims
    PastTense: n$1, //saved storm victims
    Infinitive: n$1, //profess love
    Date: n$1, //9pm show
    Ordinal: n$1, //first date
    Demonym: n$1, //dutch map
  },
  afterTags: {
    Value: n$1, //date nine  -?
    Modal: n$1, //date would
    Copula: n$1, //fear is
    PresentTense: n$1, //babysitting sucks
    PastTense: n$1, //babysitting sucked
    // Noun:n, //talking therapy, planning process
    Demonym: n$1, //american touch
    Actor: n$1, //dance therapist
  },
  // ownTags: { ProperNoun: n },
  beforeWords: {
    the: n$1, //the brands
    with: n$1, //with cakes
    without: n$1, //
    // was:n, //was time  -- was working
    // is:n, //
    of: n$1, //of power
    for: n$1, //for rats
    any: n$1, //any rats
    all: n$1, //all tips
    on: n$1, //on time
    // thing-ish verbs
    cut: n$1, //cut spending
    cuts: n$1, //cut spending
    increase: n$1, // increase funding
    decrease: n$1, //
    raise: n$1, //
    drop: n$1, //
    // give: n,//give parents
    save: n$1, //
    saved: n$1, //
    saves: n$1, //
    make: n$1, //
    makes: n$1, //
    made: n$1, //
    minus: n$1, //minus laughing
    plus: n$1, //
    than: n$1, //more than age
    another: n$1, //
    versus: n$1, //
    neither: n$1, //
    about: n$1, //about claims
    // strong adjectives
    favorite: n$1, //
    best: n$1, //
    daily: n$1, //
    weekly: n$1, //
    linear: n$1, //
    binary: n$1, //
    mobile: n$1, //
    lexical: n$1, //
    technical: n$1, //
    computer: n$1, //
    scientific: n$1, //
    security: n$1, //
    government: n$1, //
    popular: n$1, //
    formal: n$1,
    no: n$1, //no worries
    more: n$1, //more details
    one: n$1, //one flood
    let: n$1, //let fear
    her: n$1, //her boots
    his: n$1, //
    their: n$1, //
    our: n$1, //
    us: n$1, //served us drinks
    sheer: n$1,

    monthly: n$1,
    yearly: n$1,
    current: n$1,
    previous: n$1,
    upcoming: n$1,
    last: n$1,
    next: n$1,
    main: n$1,
    initial: n$1,
    final: n$1,
    beginning: n$1,
    end: n$1,
    top: n$1,
    bottom: n$1,
    future: n$1,
    past: n$1,
    major: n$1,
    minor: n$1,
    side: n$1,
    central: n$1,
    peripheral: n$1,
    public: n$1,
    private: n$1,
  },
  afterWords: {
    of: n$1, //date of birth (preposition)
    system: n$1,
    aid: n$1,
    method: n$1,
    utility: n$1,
    tool: n$1,
    reform: n$1,
    therapy: n$1,
    philosophy: n$1,
    room: n$1,
    authority: n$1,
    says: n$1,
    said: n$1,
    wants: n$1,
    wanted: n$1,
    is: n$1,
    did: n$1,
    do: n$1,
    can: n$1, //parents can
    wise: n$1, //service-wise
    // they: n,//snakes they
  },
};

const v = 'Infinitive';

var verb = {
  beforeTags: {
    Modal: v, //would date
    Adverb: v, //quickly date
    Negative: v, //not date
    Plural: v, //characters drink
    // ProperNoun: vb,//google thought
  },
  afterTags: {
    Determiner: v, //flash the
    Adverb: v, //date quickly
    Possessive: v, //date his
    Reflexive: v, //resolve yourself
    // Noun:true, //date spencer
    Preposition: v, //date around, dump onto, grumble about
    // Conjunction: v, // dip to, dip through
    Cardinal: v, //cut 3 squares
    Comparative: v, //feel greater
    Superlative: v, //feel greatest
  },
  beforeWords: {
    i: v, //i date
    we: v, //we date
    you: v, //you date
    they: v, //they date
    to: v, //to date
    please: v, //please check
    will: v, //will check
    have: v,
    had: v,
    would: v,
    could: v,
    should: v,
    do: v,
    did: v,
    does: v,
    can: v,
    must: v,
    us: v,
    me: v,
    let: v,
    even: v,
    when: v,
    help: v, //help combat
    // them: v,
    he: v,
    she: v,
    it: v,
    being: v,
    // prefixes
    bi: v,
    co: v,
    contra: v,
    de: v,
    inter: v,
    intra: v,
    mis: v,
    pre: v,
    out: v,
    counter: v,
    nobody: v,
    somebody: v,
    anybody: v,
    everybody: v,
    // un: v,
    // over: v,
    // under: v,
  },
  afterWords: {
    the: v, //echo the
    me: v, //date me
    you: v, //date you
    him: v, //loves him
    us: v, //cost us
    her: v, //
    his: v, //
    them: v, //
    they: v, //
    it: v, //hope it
    himself: v,
    herself: v,
    itself: v,
    myself: v,
    ourselves: v,
    themselves: v,
    something: v,
    anything: v,

    a: v, //covers a
    an: v, //covers an
    // from: v, //ranges from
    up: v, //serves up
    down: v, //serves up
    by: v,
    // in: v, //bob in
    out: v,
    // on: v,
    off: v,
    under: v,
    what: v, //look what
    // when: v,//starts when
    // for:true, //settled for
    all: v, //shiver all night
    // conjunctions
    to: v, //dip to
    because: v, //
    although: v, //
    // after: v,
    // before: v,//
    how: v, //
    otherwise: v, //
    together: v, //fit together
    though: v, //
    into: v, //
    yet: v, //
    more: v, //kill more
    here: v, // look here
    there: v, //
    away: v, //float away
  },
};

// 'the pilot' vs 'pilot the plane'
const clue$7 = {
  beforeTags: Object.assign({}, verb.beforeTags, noun$1.beforeTags, {
  }),
  afterTags: Object.assign({}, verb.afterTags, noun$1.afterTags, {}),
  beforeWords: Object.assign({}, verb.beforeWords, noun$1.beforeWords, {}),
  afterWords: Object.assign({}, verb.afterWords, noun$1.afterWords, {}),
};

const jj$2 = 'Adjective';

var adj$1 = {
  beforeTags: {
    Determiner: jj$2, //the detailed
    // Copula: jj, //is detailed
    Possessive: jj$2, //spencer's detailed
    Hyphenated: jj$2, //rapidly-changing
  },

  afterTags: {
    // Noun: jj, //detailed plan, overwhelming evidence
    Adjective: jj$2, //intoxicated little
  },

  beforeWords: {
    seem: jj$2, //seem prepared
    seemed: jj$2,
    seems: jj$2,
    feel: jj$2, //feel prepared
    feels: jj$2,
    felt: jj$2,
    stay: jj$2,
    appear: jj$2,
    appears: jj$2,
    appeared: jj$2,
    also: jj$2,
    over: jj$2, //over cooked
    under: jj$2,
    too: jj$2, //too insulting
    it: jj$2, //find it insulting
    but: jj$2, //nothing but frustrating
    still: jj$2, //still scared
    // adverbs that are adjective-ish
    really: jj$2, //really damaged
    quite: jj$2,
    well: jj$2,
    very: jj$2,
    truly: jj$2,
    how: jj$2, //how slow
    deeply: jj$2,
    hella: jj$2,
    // always: jj,
    // never: jj,
    profoundly: jj$2,
    extremely: jj$2,
    so: jj$2,
    badly: jj$2,
    mostly: jj$2,
    totally: jj$2,
    awfully: jj$2,
    rather: jj$2,
    nothing: jj$2, //nothing secret,
    something: jj$2, //something wrong
    anything: jj$2,
    not: jj$2, //not swell
    me: jj$2, //called me swell
    is: jj$2,

    face: jj$2, //faces shocking revelations
    faces: jj$2,
    faced: jj$2,

    look: jj$2,
    looks: jj$2,
    looked: jj$2,

    reveal: jj$2,
    reveals: jj$2,
    revealed: jj$2,

    sound: jj$2,
    sounded: jj$2,
    sounds: jj$2,
    remains: jj$2,
    remained: jj$2,
    prove: jj$2, //would prove shocking
    proves: jj$2,
    proved: jj$2,

    becomes: jj$2,
    stays: jj$2,
    tastes: jj$2,
    taste: jj$2,
    smells: jj$2,
    smell: jj$2,
    gets: jj$2, //gets shocking snowfall
    grows: jj$2,
    as: jj$2,
    rings: jj$2,
    radiates: jj$2,
    conveys: jj$2,
    convey: jj$2,
    conveyed: jj$2,
    of: jj$2,
    // 'smacks of': jj,
    // 'reeks of': jj,
  },
  afterWords: {
    too: jj$2, //insulting too
    also: jj$2, //insulting too
    or: jj$2, //insulting or
    enough: jj$2, //cool enough
    as: jj$2, //as shocking as
    //about: jj, //cool about
  },
};

const g$1 = 'Gerund';

// Adj|Gerund
// Noun|Gerund

var gerund = {
  beforeTags: {
    // Verb: g, // loves shocking
    Adverb: g$1, //quickly shocking
    Preposition: g$1, //by insulting
    Conjunction: g$1, //to insulting
  },
  afterTags: {
    Adverb: g$1, //shocking quickly
    Possessive: g$1, //shocking spencer's
    Person: g$1, //telling spencer
    Pronoun: g$1, //shocking him
    Determiner: g$1, //shocking the
    Copula: g$1, //shocking is
    Preposition: g$1, //dashing by, swimming in
    Conjunction: g$1, //insulting to
    Comparative: g$1, //growing shorter
  },
  beforeWords: {
    been: g$1,
    keep: g$1,//keep going
    continue: g$1,//
    stop: g$1,//
    am: g$1,//am watching
    be: g$1,//be timing
    me: g$1,//got me thinking
    // action-words
    began: g$1,
    start: g$1,
    starts: g$1,
    started: g$1,
    stops: g$1,
    stopped: g$1,
    help: g$1,
    helps: g$1,
    avoid: g$1,
    avoids: g$1,
    love: g$1,//love painting
    loves: g$1,
    loved: g$1,
    hate: g$1,
    hates: g$1,
    hated: g$1,
    // was:g,//was working
    // is:g,
    // be:g,
  },
  afterWords: {
    you: g$1, //telling you
    me: g$1, //
    her: g$1, //
    him: g$1, //
    his: g$1, //
    them: g$1, //
    their: g$1, // fighting their
    it: g$1, //dumping it
    this: g$1, //running this
    there: g$1, // swimming there
    on: g$1, // landing on
    about: g$1, // talking about
    for: g$1, // paying for
    up: g$1, //speeding up
    down: g$1, //
  },
};

const g = 'Gerund';
const jj$1 = 'Adjective';

// rallying the troops
// her rallying cry
const clue$6 = {
  beforeTags: Object.assign({}, adj$1.beforeTags, gerund.beforeTags, {
    // Copula: jj,
    Imperative: g, //recommend living in
    Infinitive: jj$1, //say charming things
    // PresentTense: g,
    Plural: g, //kids cutting
  }),

  afterTags: Object.assign({}, adj$1.afterTags, gerund.afterTags, {
    Noun: jj$1, //shocking ignorance
    // Plural: jj, //shocking lies
  }),

  beforeWords: Object.assign({}, adj$1.beforeWords, gerund.beforeWords, {
    is: jj$1,
    are: g, //is overflowing: JJ, are overflowing : VB ??
    was: jj$1,
    of: jj$1, //of varying
    suggest: g,
    suggests: g,
    suggested: g,

    recommend: g,
    recommends: g,
    recommended: g,

    imagine: g,
    imagines: g,
    imagined: g,

    consider: g,
    considered: g,
    considering: g,

    resist: g,
    resists: g,
    resisted: g,

    avoid: g,
    avoided: g,
    avoiding: g,

    except: jj$1,
    accept: jj$1,
    assess: g,
    explore: g,
    fear: g,
    fears: g,
    appreciate: g,
    question: g,
    help: g,
    embrace: g,
    with: jj$1, //filled with daring
  }),

  afterWords: Object.assign({}, adj$1.afterWords, gerund.afterWords, {
    to: g,
    not: g, //trying not to car
    the: g, //sweeping the country
  }),
};

// the commercial market
// watching the commercial

const misc$4 = {
  beforeTags: {
    Determiner: undefined, //the premier university
    Cardinal: 'Noun',//1950 convertable
    PhrasalVerb: 'Adjective'//starts out fine
  },
  afterTags: {
    // Pronoun: 'Noun'//as an adult i
  }
};
const clue$5 = {
  beforeTags: Object.assign({}, adj$1.beforeTags, noun$1.beforeTags, misc$4.beforeTags),
  afterTags: Object.assign({}, adj$1.afterTags, noun$1.afterTags, misc$4.afterTags),
  beforeWords: Object.assign({}, adj$1.beforeWords, noun$1.beforeWords, {
    // are representative
    are: 'Adjective', is: 'Adjective', was: 'Adjective', be: 'Adjective',
    // phrasals
    off: 'Adjective',//start off fine
    out: 'Adjective',//comes out fine
  }),
  afterWords: Object.assign({}, adj$1.afterWords, noun$1.afterWords),
};

// the boiled egg
// boiled the water
let past$1 = 'PastTense';
let jj = 'Adjective';

const adjPast = {
  beforeTags: {
    Adverb: past$1, //quickly detailed
    Pronoun: past$1, //he detailed
    ProperNoun: past$1, //toronto closed
    Auxiliary: past$1,
    Noun: past$1, //eye closed  -- i guess.
  },
  afterTags: {
    Possessive: past$1, //hooked him
    Pronoun: past$1, //hooked me
    Determiner: past$1, //hooked the
    Adverb: past$1, //cooked perfectly
    Comparative: past$1, //closed higher
    Date: past$1, // alleged thursday
    Gerund: past$1, //left dancing
  },
  beforeWords: {
    be: past$1, //be hooked vs be embarrassed
    who: past$1, //who lost
    get: jj, //get charged
    had: past$1,
    has: past$1,
    have: past$1,
    been: past$1,
    it: past$1, //it intoxicated him
    as: past$1, //as requested
    for: jj, //for discounted items
    more: jj, //more broken promises
    always: jj,
  },
  afterWords: {
    by: past$1, //damaged by
    back: past$1, //charged back
    out: past$1, //charged out
    in: past$1, //crowded in
    up: past$1, //heated up
    down: past$1, //hammered down
    before: past$1, //
    after: past$1, //
    for: past$1, //settled for
    the: past$1, //settled the
    with: past$1, //obsessed with
    as: past$1, //known as
    on: past$1, //focused on
    at: past$1, //recorded at
    between: past$1, //settled between
    to: past$1, //dedicated to
    into: past$1, //pumped into
    us: past$1, //charged us
    them: past$1, //charged us
    his: past$1, //shared his
    her: past$1, //
    their: past$1, //
    our: past$1, //
    me: past$1, //
    about: jj,
  },
};

var adjPast$1 = {
  beforeTags: Object.assign({}, adj$1.beforeTags, adjPast.beforeTags),
  afterTags: Object.assign({}, adj$1.afterTags, adjPast.afterTags),
  beforeWords: Object.assign({}, adj$1.beforeWords, adjPast.beforeWords),
  afterWords: Object.assign({}, adj$1.afterWords, adjPast.afterWords),
};

// 'would mean' vs 'is mean'
const misc$3 = {
  afterTags: {
    Noun: 'Adjective',//ruling party
    Conjunction: undefined //clean and excellent
  }
};
const clue$4 = {
  beforeTags: Object.assign({}, adj$1.beforeTags, verb.beforeTags, {
    // always clean
    Adverb: undefined, Negative: undefined
  }),
  afterTags: Object.assign({}, adj$1.afterTags, verb.afterTags, misc$3.afterTags),
  beforeWords: Object.assign({}, adj$1.beforeWords, verb.beforeWords, {
    // have seperate contracts
    have: undefined, had: undefined, not: undefined,
    //went wrong, got wrong
    went: 'Adjective', goes: 'Adjective', got: 'Adjective',
    // be sure
    be: 'Adjective'
  }),
  afterWords: Object.assign({}, adj$1.afterWords, verb.afterWords, {
    to: undefined,//slick to the touch
    as: 'Adjective',//pale as
  }),
};

// 'operating the crane', or 'operating room'
const misc$2 = {
  beforeTags: {
    Copula: 'Gerund',
    PastTense: 'Gerund',
    PresentTense: 'Gerund',
    Infinitive: 'Gerund',
  },
  afterTags: {
    Value: 'Gerund', //maintaining 500
  },
  beforeWords: {
    are: 'Gerund',
    were: 'Gerund',
    be: 'Gerund',
    no: 'Gerund',
    without: 'Gerund',
    //are you playing
    you: 'Gerund',
    we: 'Gerund',
    they: 'Gerund',
    he: 'Gerund',
    she: 'Gerund',
    //stop us playing
    us: 'Gerund',
    them: 'Gerund',
  },
  afterWords: {
    // offering the
    the: 'Gerund',
    this: 'Gerund',
    that: 'Gerund',
    //got me thinking
    me: 'Gerund',
    us: 'Gerund',
    them: 'Gerund',
  },
};
const clue$3 = {
  beforeTags: Object.assign({}, gerund.beforeTags, noun$1.beforeTags, misc$2.beforeTags),
  afterTags: Object.assign({}, gerund.afterTags, noun$1.afterTags, misc$2.afterTags),
  beforeWords: Object.assign({}, gerund.beforeWords, noun$1.beforeWords, misc$2.beforeWords),
  afterWords: Object.assign({}, gerund.afterWords, noun$1.afterWords, misc$2.afterWords),
};

const nn$1 = 'Singular';
const vb$1 = 'Infinitive';
// 'boot the ball'   -  'the red boot'
// 'boots the ball'  -   'the red boots'
const clue$2 = {
  beforeTags: Object.assign({}, verb.beforeTags, noun$1.beforeTags, {
    // Noun: undefined
    Adjective: nn$1,//great name
    Particle: nn$1//brought under control
  }),
  afterTags: Object.assign({}, verb.afterTags, noun$1.afterTags, {
    ProperNoun: vb$1, Gerund: vb$1, Adjective: vb$1,
    Copula: nn$1,
  }),
  beforeWords: Object.assign({}, verb.beforeWords, noun$1.beforeWords, {
    // is time
    is: nn$1, was: nn$1,
    //balance of power
    of: nn$1,
    have: null //have cash
  }),
  afterWords: Object.assign({}, verb.afterWords, noun$1.afterWords, {
    // for: vb,//work for
    instead: vb$1,
    // that: nn,//subject that was
    // for: vb,//work for
    about: vb$1,//talk about
    his: vb$1,//shot his
    her: vb$1,//
    to: null,
    by: null,
    in: null
  }),
};

const p$3 = 'Person';

var person$1 = {
  beforeTags: {
    Honorific: p$3,
    Person: p$3,
    // Preposition: p, //with sue
  },
  afterTags: {
    Person: p$3,
    ProperNoun: p$3,
    Verb: p$3, //bob could
    // Modal:true, //bob could
    // Copula:true, //bob is
    // PresentTense:true, //bob seems
  },
  beforeWords: {
    hi: p$3,
    hey: p$3,
    yo: p$3,
    dear: p$3,
    hello: p$3,
  },
  afterWords: {
    // person-usually verbs
    said: p$3,
    says: p$3,
    told: p$3,
    tells: p$3,
    feels: p$3,
    felt: p$3,
    seems: p$3,
    thinks: p$3,
    thought: p$3,
    spends: p$3,
    spendt: p$3,
    plays: p$3,
    played: p$3,
    sing: p$3,
    sang: p$3,
    learn: p$3,
    learned: p$3,
    wants: p$3,
    wanted: p$3
    // and:true, //sue and jeff
  },
};

// 'april o'neil'  -  'april 1st'

const m$1 = 'Month';
const p$2 = 'Person';
const month = {
  beforeTags: {
    Date: m$1,
    Value: m$1,
  },
  afterTags: {
    Date: m$1,
    Value: m$1,
  },
  beforeWords: {
    by: m$1,
    in: m$1,
    on: m$1,
    during: m$1,
    after: m$1,
    before: m$1,
    between: m$1,
    until: m$1,
    til: m$1,
    sometime: m$1,
    of: m$1, //5th of april
    this: m$1, //this april
    next: m$1,
    last: m$1,
    previous: m$1,
    following: m$1,
    with: p$2,
    // for: p,
  },
  afterWords: {
    sometime: m$1,
    in: m$1,
    of: m$1,
    until: m$1,
    the: m$1, //june the 4th
  },
};
var personDate = {
  beforeTags: Object.assign({}, person$1.beforeTags, month.beforeTags),
  afterTags: Object.assign({}, person$1.afterTags, month.afterTags),
  beforeWords: Object.assign({}, person$1.beforeWords, month.beforeWords),
  afterWords: Object.assign({}, person$1.afterWords, month.afterWords),
};

// 'babling brook' vs 'brook sheilds'

const clue$1 = {
  beforeTags: Object.assign({}, noun$1.beforeTags, person$1.beforeTags),
  afterTags: Object.assign({}, noun$1.afterTags, person$1.afterTags),
  beforeWords: Object.assign({}, noun$1.beforeWords, person$1.beforeWords, { i: 'Infinitive', we: 'Infinitive' }),
  afterWords: Object.assign({}, noun$1.afterWords, person$1.afterWords),
};

// 'rob the store'   -  'rob lowe'
// can be a noun too - 'losing hope'
const clues$3 = {
  beforeTags: Object.assign({}, noun$1.beforeTags, person$1.beforeTags, verb.beforeTags),
  afterTags: Object.assign({}, noun$1.afterTags, person$1.afterTags, verb.afterTags),
  beforeWords: Object.assign({}, noun$1.beforeWords, person$1.beforeWords, verb.beforeWords),
  afterWords: Object.assign({}, noun$1.afterWords, person$1.afterWords, verb.afterWords),
};

const p$1 = 'Place';

// 'paris hilton' vs 'paris france'
const place = {
  beforeTags: {
    Place: p$1
  },
  afterTags: {
    Place: p$1,
    Abbreviation: p$1
  },
  beforeWords: {
    in: p$1,
    by: p$1,
    near: p$1,
    from: p$1,
    to: p$1,
  },
  afterWords: {
    in: p$1,
    by: p$1,
    near: p$1,
    from: p$1,
    to: p$1,
    government: p$1,
    council: p$1,
    region: p$1,
    city: p$1,
  },
};

const clue = {
  beforeTags: Object.assign({}, place.beforeTags, person$1.beforeTags),
  afterTags: Object.assign({}, place.afterTags, person$1.afterTags),
  beforeWords: Object.assign({}, place.beforeWords, person$1.beforeWords),
  afterWords: Object.assign({}, place.afterWords, person$1.afterWords),
};

// 'rusty nail'   -  'rusty smith'
const clues$2 = {
  beforeTags: Object.assign({}, person$1.beforeTags, adj$1.beforeTags),
  afterTags: Object.assign({}, person$1.afterTags, adj$1.afterTags),
  beforeWords: Object.assign({}, person$1.beforeWords, adj$1.beforeWords),
  afterWords: Object.assign({}, person$1.afterWords, adj$1.afterWords),
};

// '5 oz'   -  'dr oz'
let un = 'Unit';
const clues$1 = {
  beforeTags: { Value: un },
  afterTags: {},
  beforeWords: {
    per: un,
    every: un,
    each: un,
    square: un, //square km
    cubic: un,
    sq: un,
    metric: un //metric ton
  },
  afterWords: {
    per: un,
    squared: un,
    cubed: un,
    long: un //foot long
  },
};

const clues = {
  'Actor|Verb': clue$7,
  'Adj|Gerund': clue$6,
  'Adj|Noun': clue$5,
  'Adj|Past': adjPast$1,
  'Adj|Present': clue$4,
  'Noun|Verb': clue$2,
  'Noun|Gerund': clue$3,
  'Person|Noun': clue$1,
  'Person|Date': personDate,
  'Person|Verb': clues$3,
  'Person|Place': clue,
  'Person|Adj': clues$2,
  'Unit|Noun': clues$1,
};

const copy = (obj, more) => {
  let res = Object.keys(obj).reduce((h, k) => {
    h[k] = obj[k] === 'Infinitive' ? 'PresentTense' : 'Plural';
    return h
  }, {});
  return Object.assign(res, more)
};

// make a copy of this one
clues['Plural|Verb'] = {
  beforeWords: copy(clues['Noun|Verb'].beforeWords, {
    had: 'Plural', //had tears
    have: 'Plural',
  }),
  afterWords: copy(clues['Noun|Verb'].afterWords, {
    his: 'PresentTense', her: 'PresentTense', its: 'PresentTense',
    in: null, to: null,
    is: 'PresentTense', //the way it works is
    by: 'PresentTense', //it works by
  }),
  beforeTags: copy(clues['Noun|Verb'].beforeTags, {
    Conjunction: 'PresentTense', //and changes
    Noun: undefined, //the century demands
    ProperNoun: 'PresentTense'//john plays
  }),
  afterTags: copy(clues['Noun|Verb'].afterTags, {
    Gerund: 'Plural',//ice caps disappearing
    Noun: 'PresentTense', //changes gears
    Value: 'PresentTense' //changes seven gears
  }),
};

//just a foolish lookup of known suffixes
const Adj$2 = 'Adjective';
const Inf$1 = 'Infinitive';
const Pres$1 = 'PresentTense';
const Sing$1 = 'Singular';
const Past$1 = 'PastTense';
const Avb = 'Adverb';
const Plrl = 'Plural';
const Actor$1 = 'Actor';
const Vb = 'Verb';
const Noun$2 = 'Noun';
const Prop = 'ProperNoun';
const Last$1 = 'LastName';
const Modal = 'Modal';
const Place = 'Place';
const Prt = 'Participle';

var suffixPatterns = [
  null,
  null,
  {
    //2-letter
    ea: Sing$1,
    ia: Noun$2,
    ic: Adj$2,
    ly: Avb,
    "'n": Vb,
    "'t": Vb,
  },
  {
    //3-letter
    oed: Past$1,
    ued: Past$1,
    xed: Past$1,
    ' so': Avb,
    "'ll": Modal,
    "'re": 'Copula',
    azy: Adj$2,
    eer: Noun$2,
    end: Vb,
    ped: Past$1,
    ffy: Adj$2,
    ify: Inf$1,
    ing: 'Gerund',
    ize: Inf$1,
    ibe: Inf$1,
    lar: Adj$2,
    mum: Adj$2,
    nes: Pres$1,
    nny: Adj$2,
    // oid: Adj,
    ous: Adj$2,
    que: Adj$2,
    ger: Noun$2,
    ber: Noun$2,
    rol: Sing$1,
    sis: Sing$1,
    ogy: Sing$1,
    oid: Sing$1,
    ian: Sing$1,
    zes: Pres$1,
    eld: Past$1,
    ken: Prt, //awoken
    ven: Prt, //woven
    ten: Prt, //brighten
    ect: Inf$1,
    ict: Inf$1,
    // ide: Inf,
    ign: Inf$1,
    oze: Inf$1,
    ful: Adj$2,
    bal: Adj$2,
    ton: Noun$2,
    pur: Place,
  },
  {
    //4-letter
    amed: Past$1,
    aped: Past$1,
    ched: Past$1,
    lked: Past$1,
    rked: Past$1,
    reed: Past$1,
    nded: Past$1,
    mned: Adj$2,
    cted: Past$1,
    dged: Past$1,
    ield: Sing$1,
    akis: Last$1,
    cede: Inf$1,
    chuk: Last$1,
    czyk: Last$1,
    ects: Pres$1,
    iend: Sing$1,
    ends: Vb,
    enko: Last$1,
    ette: Sing$1,
    iary: Sing$1,
    wner: Sing$1, //owner
    fies: Pres$1,
    fore: Avb,
    gate: Inf$1,
    gone: Adj$2,
    ices: Plrl,
    ints: Plrl,
    ruct: Inf$1,
    ines: Plrl,
    ions: Plrl,
    ners: Plrl,
    pers: Plrl,
    lers: Plrl,
    less: Adj$2,
    llen: Adj$2,
    made: Adj$2,
    nsen: Last$1,
    oses: Pres$1,
    ould: Modal,
    some: Adj$2,
    sson: Last$1,
    ians: Plrl,
    // tage: Inf,
    tion: Sing$1,
    tage: Noun$2,
    ique: Sing$1,
    tive: Adj$2,
    tors: Noun$2,
    vice: Sing$1,
    lier: Sing$1,
    fier: Sing$1,
    wned: Past$1,
    gent: Sing$1,
    tist: Actor$1,
    pist: Actor$1,
    rist: Actor$1,
    mist: Actor$1,
    yist: Actor$1,
    vist: Actor$1,
    ists: Actor$1,
    lite: Sing$1,
    site: Sing$1,
    rite: Sing$1,
    mite: Sing$1,
    bite: Sing$1,
    mate: Sing$1,
    date: Sing$1,
    ndal: Sing$1,
    vent: Sing$1,
    uist: Actor$1,
    gist: Actor$1,
    note: Sing$1,
    cide: Sing$1, //homicide
    ence: Sing$1, //absence
    wide: Adj$2, //nationwide
    // side: Adj,//alongside
    vide: Inf$1, //provide
    ract: Inf$1,
    duce: Inf$1,
    pose: Inf$1,
    eive: Inf$1,
    lyze: Inf$1,
    lyse: Inf$1,
    iant: Adj$2,
    nary: Adj$2,
    ghty: Adj$2,
    uent: Adj$2,
    erer: Actor$1, //caterer
    bury: Place,
    dorf: Noun$2,
    esty: Noun$2,
    wych: Place,
    dale: Place,
    folk: Place,
    vale: Place,
    abad: Place,
    sham: Place,
    wick: Place,
    view: Place,
  },
  {
    //5-letter
    elist: Actor$1,
    holic: Sing$1,
    phite: Sing$1,
    tized: Past$1,
    urned: Past$1,
    eased: Past$1,
    ances: Plrl,
    bound: Adj$2,
    ettes: Plrl,
    fully: Avb,
    ishes: Pres$1,
    ities: Plrl,
    marek: Last$1,
    nssen: Last$1,
    ology: Noun$2,
    osome: Sing$1,
    tment: Sing$1,
    ports: Plrl,
    rough: Adj$2,
    tches: Pres$1,
    tieth: 'Ordinal',
    tures: Plrl,
    wards: Avb,
    where: Avb,
    archy: Noun$2,
    pathy: Noun$2,
    opoly: Noun$2,
    embly: Noun$2,
    phate: Noun$2,
    ndent: Sing$1,
    scent: Sing$1,
    onist: Actor$1,
    anist: Actor$1,
    alist: Actor$1,
    olist: Actor$1,
    icist: Actor$1,
    ounce: Inf$1,
    iable: Adj$2,
    borne: Adj$2,
    gnant: Adj$2,
    inant: Adj$2,
    igent: Adj$2,
    atory: Adj$2,
    // ctory: Adj,
    rient: Sing$1,
    dient: Sing$1,
    maker: Actor$1,
    burgh: Place,
    mouth: Place,
    ceter: Place,
    ville: Place,
    hurst: Place,
    stead: Place,
    endon: Place,
    brook: Place,
    shire: Place,
    worth: Noun$2,
    field: Prop,
    ridge: Place,
  },
  {
    //6-letter
    auskas: Last$1,
    parent: Sing$1,
    cedent: Sing$1,
    ionary: Sing$1,
    cklist: Sing$1,
    brooke: Place,
    keeper: Actor$1,
    logist: Actor$1,
    teenth: 'Value',
    worker: Actor$1,
    master: Actor$1,
    writer: Actor$1,
    brough: Place,
    cester: Place,
    ington: Place,
    cliffe: Place,
    ingham: Place,
  },
  {
    //7-letter
    chester: Place,
    logists: Actor$1,
    opoulos: Last$1,
    borough: Place,
    sdottir: Last$1, //swedish female
  },
];

//prefixes give very-little away, in general.
// more-often for scientific terms, etc.
const Adj$1 = 'Adjective';
const Noun$1 = 'Noun';
const Verb$1 = 'Verb';

var prefixPatterns = [
  null,
  null,
  {
    // 2-letter
  },
  {
    // 3-letter
    neo: Noun$1,
    bio: Noun$1,
    // pre: Noun,
    'de-': Verb$1,
    're-': Verb$1,
    'un-': Verb$1,
    'ex-': Noun$1,
  },
  {
    // 4-letter
    anti: Noun$1,
    auto: Noun$1,
    faux: Adj$1,
    hexa: Noun$1,
    kilo: Noun$1,
    mono: Noun$1,
    nano: Noun$1,
    octa: Noun$1,
    poly: Noun$1,
    semi: Adj$1,
    tele: Noun$1,
    'pro-': Adj$1,
    'mis-': Verb$1,
    'dis-': Verb$1,
    'pre-': Adj$1, //hmm
  },
  {
    // 5-letter
    anglo: Noun$1,
    centi: Noun$1,
    ethno: Noun$1,
    ferro: Noun$1,
    grand: Noun$1,
    hepta: Noun$1,
    hydro: Noun$1,
    intro: Noun$1,
    macro: Noun$1,
    micro: Noun$1,
    milli: Noun$1,
    nitro: Noun$1,
    penta: Noun$1,
    quasi: Adj$1,
    radio: Noun$1,
    tetra: Noun$1,
    'omni-': Adj$1,
    'post-': Adj$1,
  },
  {
    // 6-letter
    pseudo: Adj$1,
    'extra-': Adj$1,
    'hyper-': Adj$1,
    'inter-': Adj$1,
    'intra-': Adj$1,
    'deca-': Adj$1,
    // 'trans-': Noun,
  },
  {
    // 7-letter
    electro: Noun$1,
  },
];

//regex suffix patterns and their most common parts of speech,
//built using wordnet, by spencer kelly.
//this mapping shrinks-down the uglified build
const Adj = 'Adjective';
const Inf = 'Infinitive';
const Pres = 'PresentTense';
const Sing = 'Singular';
const Past = 'PastTense';
const Adverb = 'Adverb';
const Exp = 'Expression';
const Actor = 'Actor';
const Verb = 'Verb';
const Noun = 'Noun';
const Last = 'LastName';

var endsWith = {
  a: [
    [/.[aeiou]na$/, Noun, 'tuna'],
    [/.[oau][wvl]ska$/, Last],
    [/.[^aeiou]ica$/, Sing, 'harmonica'],
    [/^([hyj]a+)+$/, Exp, 'haha'], //hahah
  ],
  c: [[/.[^aeiou]ic$/, Adj]],
  d: [
    //==-ed==
    //double-consonant
    [/[aeiou](pp|ll|ss|ff|gg|tt|rr|bb|nn|mm)ed$/, Past, 'popped'],
    //double-vowel
    [/.[aeo]{2}[bdgmnprvz]ed$/, Past, 'rammed'],
    //-hed
    [/.[aeiou][sg]hed$/, Past, 'gushed'],
    //-rd
    [/.[aeiou]red$/, Past, 'hired'],
    [/.[aeiou]r?ried$/, Past, 'hurried'],
    // ard
    [/[^aeiou]ard$/, Sing, 'steward'],
    // id
    [/[aeiou][^aeiou]id$/, Adj, ''],
    [/.[vrl]id$/, Adj, 'livid'],

    // ===== -ed ======
    //-led
    [/..led$/, Past, 'hurled'],
    //-sed
    [/.[iao]sed$/, Past, ''],
    [/[aeiou]n?[cs]ed$/, Past, ''],
    //-med
    [/[aeiou][rl]?[mnf]ed$/, Past, ''],
    //-ked
    [/[aeiou][ns]?c?ked$/, Past, 'bunked'],
    //-gned
    [/[aeiou]gned$/, Past],
    //-ged
    [/[aeiou][nl]?ged$/, Past],
    //-ted
    [/.[tdbwxyz]ed$/, Past],
    [/[^aeiou][aeiou][tvx]ed$/, Past],
    //-ied
    [/.[cdflmnprstv]ied$/, Past, 'emptied'],
  ],
  e: [
    [/.[lnr]ize$/, Inf, 'antagonize'],
    [/.[^aeiou]ise$/, Inf, 'antagonise'],
    [/.[aeiou]te$/, Inf, 'bite'],
    [/.[^aeiou][ai]ble$/, Adj, 'fixable'],
    [/.[^aeiou]eable$/, Adj, 'maleable'],
    [/.[ts]ive$/, Adj, 'festive'],
    [/[a-z]-like$/, Adj, 'woman-like'],
  ],
  h: [
    [/.[^aeiouf]ish$/, Adj, 'cornish'],
    [/.v[iy]ch$/, Last, '..ovich'],
    [/^ug?h+$/, Exp, 'ughh'],
    [/^uh[ -]?oh$/, Exp, 'uhoh'],
    [/[a-z]-ish$/, Adj, 'cartoon-ish'],
  ],
  i: [[/.[oau][wvl]ski$/, Last, 'polish-male']],
  k: [
    [/^(k){2}$/, Exp, 'kkkk'], //kkkk
  ],
  l: [
    [/.[gl]ial$/, Adj, 'familial'],
    [/.[^aeiou]ful$/, Adj, 'fitful'],
    [/.[nrtumcd]al$/, Adj, 'natal'],
    [/.[^aeiou][ei]al$/, Adj, 'familial'],
  ],
  m: [
    [/.[^aeiou]ium$/, Sing, 'magnesium'],
    [/[^aeiou]ism$/, Sing, 'schism'],
    [/^[hu]m+$/, Exp, 'hmm'],
    [/^\d+ ?[ap]m$/, 'Date', '3am'],
  ],
  n: [
    [/.[lsrnpb]ian$/, Adj, 'republican'],
    [/[^aeiou]ician$/, Actor, 'musician'],
    [/[aeiou][ktrp]in'$/, 'Gerund', "cookin'"], // 'cookin', 'hootin'
  ],
  o: [
    [/^no+$/, Exp, 'noooo'],
    [/^(yo)+$/, Exp, 'yoo'],
    [/^wo{2,}[pt]?$/, Exp, 'woop'], //woo
  ],
  r: [
    [/.[bdfklmst]ler$/, 'Noun'],
    [/[aeiou][pns]er$/, Sing],
    [/[^i]fer$/, Inf],
    [/.[^aeiou][ao]pher$/, Actor],
    [/.[lk]er$/, 'Noun'],
    [/.ier$/, 'Comparative'],
  ],
  t: [
    [/.[di]est$/, 'Superlative'],
    [/.[icldtgrv]ent$/, Adj],
    [/[aeiou].*ist$/, Adj],
    [/^[a-z]et$/, Verb],
  ],
  s: [
    [/.[^aeiou]ises$/, Pres],
    [/.[rln]ates$/, Pres],
    [/.[^z]ens$/, Verb],
    [/.[lstrn]us$/, Sing],
    [/.[aeiou]sks$/, Pres],
    [/.[aeiou]kes$/, Pres],
    [/[aeiou][^aeiou]is$/, Sing],
    [/[a-z]'s$/, Noun],
    [/^yes+$/, Exp], //yessss
  ],
  v: [
    [/.[^aeiou][ai][kln]ov$/, Last], //east-europe
  ],
  y: [
    [/.[cts]hy$/, Adj],
    [/.[st]ty$/, Adj],
    [/.[tnl]ary$/, Adj],
    [/.[oe]ry$/, Sing],
    [/[rdntkbhs]ly$/, Adverb],
    [/.(gg|bb|zz)ly$/, Adj],
    [/...lly$/, Adverb],
    [/.[gk]y$/, Adj],
    [/[bszmp]{2}y$/, Adj],
    [/.[ai]my$/, Adj],
    [/[ea]{2}zy$/, Adj],
    [/.[^aeiou]ity$/, Sing],
  ],
};

const vb = 'Verb';
const nn = 'Noun';

var neighbours$1 = {
  // looking at the previous word's tags:
  leftTags: [
    ['Adjective', nn],
    ['Possessive', nn],
    ['Determiner', nn],
    ['Adverb', vb],
    ['Pronoun', vb],
    ['Value', nn],
    ['Ordinal', nn],
    ['Modal', vb],
    ['Superlative', nn],
    ['Demonym', nn],
    ['Honorific', 'Person'], //dr. Smith
  ],
  // looking at the previous word:
  leftWords: [
    ['i', vb],
    ['first', nn],
    ['it', vb],
    ['there', vb],
    ['not', vb],
    ['because', nn],
    ['if', nn],
    ['but', nn],
    ['who', vb],
    ['this', nn],
    ['his', nn],
    ['when', nn],
    ['you', vb],
    ['very', 'Adjective'],
    ['old', nn],
    ['never', vb],
    ['before', nn],
    ['a', nn],
    ['the', nn],
    ['been', vb],
  ],

  // looking at the next word's tags:
  rightTags: [
    ['Copula', nn],
    ['PastTense', nn],
    ['Conjunction', nn],
    ['Modal', nn],
  ],
  // looking at the next word:
  rightWords: [
    ['there', vb],
    ['me', vb],
    ['man', 'Adjective'],
    // ['only', vb],
    ['him', vb],
    ['it', vb],//relaunch it
    ['were', nn],
    ['took', nn],
    ['himself', vb],
    ['went', nn],
    ['who', nn],
    ['jr', 'Person'],
  ],
};

// generated in ./lib/pairs
var data = {
  "Comparative": {
    "fwd": "3:ser,ierÂ¦1er:h,t,f,l,nÂ¦1r:eÂ¦2er:ss,or,om",
    "both": "3er:ver,ear,almÂ¦3ner:hinÂ¦3ter:latÂ¦2mer:imÂ¦2er:ng,rm,mbÂ¦2ber:ibÂ¦2ger:igÂ¦1er:w,p,k,dÂ¦ier:y",
    "rev": "1:tter,yerÂ¦2:uer,ver,ffer,oner,eler,ller,iler,ster,cer,uler,sher,ener,gher,aner,adder,nter,eter,rter,hter,rner,fterÂ¦3:oser,ooler,eafer,user,airer,bler,maler,tler,eater,uger,rger,ainer,urer,ealer,icher,pler,emner,icter,nser,iserÂ¦4:arser,viner,ucher,rosser,somer,ndomer,moter,oother,uarer,hiterÂ¦5:nuiner,esser,emierÂ¦ar:urther",
    "ex": "worse:badÂ¦better:goodÂ¦4er:fair,gray,poorÂ¦1urther:farÂ¦3ter:fat,hot,wetÂ¦3der:mad,sadÂ¦3er:shy,funÂ¦4der:gladÂ¦:Â¦4r:cute,dire,fake,fine,free,lame,late,pale,rare,ripe,rude,safe,sore,tame,wideÂ¦5r:eerie,stale"
  },
  "Gerund": {
    "fwd": "1:nning,tting,rring,pping,eing,mming,gging,dding,bbing,kkingÂ¦2:eking,oling,eling,emingÂ¦3:velling,siting,uiting,fiting,loting,geting,ialing,cellingÂ¦4:graming",
    "both": "1:aing,iing,fing,xing,ying,oing,hing,wingÂ¦2:tzing,rping,izzing,bting,mning,sping,wling,rling,wding,rbing,uping,lming,wning,mping,oning,lting,mbing,lking,fting,hting,sking,gning,pting,cking,ening,nking,iling,eping,ering,rting,rming,cting,lping,ssing,nting,nding,lding,sting,rning,rding,rkingÂ¦3:belling,siping,toming,yaking,uaking,oaning,auling,ooping,aiding,naping,euring,tolling,uzzing,ganing,haning,ualing,halling,iasing,auding,ieting,ceting,ouling,voring,ralling,garing,joring,oaming,oaking,roring,nelling,ooring,uelling,eaming,ooding,eaping,eeting,ooting,ooming,xiting,keting,ooking,ulling,airing,oaring,biting,outing,oiting,earing,naling,oading,eeding,ouring,eaking,aiming,illing,oining,eaning,onging,ealing,aining,eadingÂ¦4:thoming,melling,aboring,ivoting,weating,dfilling,onoring,eriting,imiting,tialling,rgining,otoring,linging,winging,lleting,louding,spelling,mpelling,heating,feating,opelling,choring,welling,ymaking,ctoring,calling,peating,iloring,laiting,utoring,uditing,mmaking,loating,iciting,waiting,mbating,voiding,otalling,nsoring,nselling,ocusing,itoring,elopingÂ¦5:rselling,umpeting,atrolling,treating,tselling,rpreting,pringing,ummeting,ossoming,elmaking,eselling,rediting,totyping,onmaking,rfeiting,ntrollingÂ¦5e:chmaking,dkeeping,severing,erouting,ecreting,ephoning,uthoring,ravening,reathing,pediting,erfering,eotyping,fringing,entoring,ombining,ompetingÂ¦4e:emaking,eething,twining,rruling,chuting,xciting,rseding,scoping,edoring,pinging,lunging,agining,craping,pleting,eleting,nciting,nfining,ncoding,tponing,ecoding,writing,esaling,nvening,gnoring,evoting,mpeding,rvening,dhering,mpiling,storing,nviting,ploringÂ¦3e:tining,nuring,saking,miring,haling,ceding,xuding,rining,nuting,laring,caring,miling,riding,hoking,piring,lading,curing,uading,noting,taping,futing,paring,hading,loding,siring,guring,vading,voking,during,niting,laning,caping,luting,muting,ruding,ciding,juring,laming,caling,hining,uoting,liding,ciling,duling,tuting,puting,cuting,coring,uiding,tiring,turing,siding,rading,enging,haping,buting,lining,taking,anging,haring,uiring,coming,mining,moting,suring,viding,ludingÂ¦2e:tring,zling,uging,oging,gling,iging,vring,fling,lging,obing,psing,pling,ubing,cling,dling,wsing,iking,rsing,dging,kling,ysing,tling,rging,eging,nsing,uning,osing,uming,using,ibing,bling,aging,ising,asing,atingÂ¦2ie:rlyingÂ¦1e:zing,uing,cing,ving",
    "rev": "ying:ieÂ¦1ing:se,ke,te,we,ne,re,de,pe,me,le,c,heÂ¦2ing:ll,ng,dd,ee,ye,oe,rg,usÂ¦2ning:unÂ¦2ging:og,ag,ug,ig,egÂ¦2ming:umÂ¦2bing:ub,ab,eb,obÂ¦3ning:lan,can,hin,pin,winÂ¦3ring:cur,lur,tir,tar,pur,carÂ¦3ing:ait,del,eel,fin,eat,oat,eem,lel,ool,ein,uinÂ¦3ping:rop,rap,top,uip,wap,hip,hop,lap,rip,capÂ¦3ming:tem,wim,rim,kim,limÂ¦3ting:mat,cut,pot,lit,lot,hat,set,pit,putÂ¦3ding:hed,bed,bidÂ¦3king:rekÂ¦3ling:cil,pelÂ¦3bing:ribÂ¦4ning:eginÂ¦4ing:isit,ruit,ilot,nsit,dget,rkel,ival,rcelÂ¦4ring:efer,nferÂ¦4ting:rmit,mmit,ysit,dmit,emit,bmit,tfit,gretÂ¦4ling:evel,xcel,ivelÂ¦4ding:hredÂ¦5ing:arget,posit,rofitÂ¦5ring:nsferÂ¦5ting:nsmit,orget,cquitÂ¦5ling:ancel,istil",
    "ex": "3:adding,eating,aiming,aiding,airing,outing,gassing,setting,getting,putting,cutting,winning,sitting,betting,mapping,tapping,letting,bidding,hitting,tanning,netting,popping,fitting,capping,lapping,barring,banning,vetting,topping,rotting,tipping,potting,wetting,pitting,dipping,budding,hemming,pinning,jetting,kidding,padding,podding,sipping,wedding,bedding,donning,warring,penning,gutting,cueing,wadding,petting,ripping,napping,matting,tinning,binning,dimming,hopping,mopping,nodding,panning,rapping,ridding,sinningÂ¦4:selling,falling,calling,waiting,editing,telling,rolling,heating,boating,hanging,beating,coating,singing,tolling,felling,polling,discing,seating,voiding,gelling,yelling,baiting,reining,ruining,seeking,spanning,stepping,knitting,emitting,slipping,quitting,dialing,omitting,clipping,shutting,skinning,abutting,flipping,trotting,cramming,fretting,suitingÂ¦5:bringing,treating,spelling,stalling,trolling,expelling,rivaling,wringing,deterring,singeing,befitting,refittingÂ¦6:enrolling,distilling,scrolling,strolling,caucusing,travellingÂ¦7:installing,redefining,stencilling,recharging,overeating,benefiting,unraveling,programingÂ¦9:reprogrammingÂ¦is:beingÂ¦2e:using,aging,owingÂ¦3e:making,taking,coming,noting,hiring,filing,coding,citing,doping,baking,coping,hoping,lading,caring,naming,voting,riding,mining,curing,lining,ruling,typing,boring,dining,firing,hiding,piling,taping,waning,baling,boning,faring,honing,wiping,luring,timing,wading,piping,fading,biting,zoning,daring,waking,gaming,raking,ceding,tiring,coking,wining,joking,paring,gaping,poking,pining,coring,liming,toting,roping,wiring,achingÂ¦4e:writing,storing,eroding,framing,smoking,tasting,wasting,phoning,shaking,abiding,braking,flaking,pasting,priming,shoring,sloping,withing,hingingÂ¦5e:defining,refining,renaming,swathing,fringing,recitingÂ¦1ie:dying,tying,lying,vyingÂ¦7e:sunbathing"
  },
  "Participle": {
    "fwd": "1:mtÂ¦2:llenÂ¦3:iven,akenÂ¦:neÂ¦y:in",
    "both": "1:wnÂ¦2:me,atenÂ¦3:seen,bidden,isenÂ¦4:roven,astenÂ¦3l:piltÂ¦3d:uiltÂ¦2e:ittenÂ¦1im:wumÂ¦1eak:pokenÂ¦1ine:honeÂ¦1ose:osenÂ¦1in:gunÂ¦1ake:wokenÂ¦ear:ornÂ¦eal:olenÂ¦eeze:ozenÂ¦et:ottenÂ¦ink:unkÂ¦ing:ung",
    "rev": "2:unÂ¦oken:eakÂ¦ought:eekÂ¦oven:eaveÂ¦1ne:oÂ¦1own:lyÂ¦1den:deÂ¦1in:ayÂ¦2t:amÂ¦2n:eeÂ¦3en:allÂ¦4n:rive,sake,takeÂ¦5n:rgive",
    "ex": "2:beenÂ¦3:seen,runÂ¦4:given,takenÂ¦5:shakenÂ¦2eak:brokenÂ¦1ive:doveÂ¦2y:flownÂ¦3e:hidden,riddenÂ¦1eek:soughtÂ¦1ake:wokenÂ¦1eave:woven"
  },
  "PastTense": {
    "fwd": "1:tted,wed,gged,nned,een,rred,pped,yed,bbed,oed,dded,rd,wn,mmedÂ¦2:eed,nded,et,hted,st,oled,ut,emed,eled,lded,ken,rt,nked,apt,ant,eped,ekedÂ¦3:eared,eat,eaded,nelled,ealt,eeded,ooted,eaked,eaned,eeted,mited,bid,uit,ead,uited,ealed,geted,velled,ialed,belledÂ¦4:ebuted,hined,comedÂ¦y:iedÂ¦ome:ameÂ¦ear:oreÂ¦ind:oundÂ¦ing:ung,angÂ¦ep:ptÂ¦ink:ank,unkÂ¦ig:ugÂ¦all:ellÂ¦ee:awÂ¦ive:aveÂ¦eeze:ozeÂ¦old:eldÂ¦ave:ftÂ¦ake:ookÂ¦ell:oldÂ¦ite:oteÂ¦ide:odeÂ¦ine:oneÂ¦in:un,onÂ¦eal:oleÂ¦im:amÂ¦ie:ayÂ¦and:oodÂ¦1ise:roseÂ¦1eak:rokeÂ¦1ing:roughtÂ¦1ive:roveÂ¦1el:eltÂ¦1id:badeÂ¦1et:gotÂ¦1y:aidÂ¦1it:satÂ¦3e:lidÂ¦3d:pent",
    "both": "1:aed,fed,xed,hedÂ¦2:sged,xted,wled,rped,lked,kied,lmed,lped,uped,bted,rbed,rked,wned,rled,mped,fted,mned,mbed,zzed,omed,ened,cked,gned,lted,sked,ued,zed,nted,ered,rted,rmed,ced,sted,rned,ssed,rded,pted,ved,ctedÂ¦3:cled,eined,siped,ooned,uked,ymed,jored,ouded,ioted,oaned,lged,asped,iged,mured,oided,eiled,yped,taled,moned,yled,lit,kled,oaked,gled,naled,fled,uined,oared,valled,koned,soned,aided,obed,ibed,meted,nicked,rored,micked,keted,vred,ooped,oaded,rited,aired,auled,filled,ouled,ooded,ceted,tolled,oited,bited,aped,tled,vored,dled,eamed,nsed,rsed,sited,owded,pled,sored,rged,osed,pelled,oured,psed,oated,loned,aimed,illed,eured,tred,ioned,celled,bled,wsed,ooked,oiled,itzed,iked,iased,onged,ased,ailed,uned,umed,ained,auded,nulled,ysed,eged,ised,aged,oined,ated,used,dged,donedÂ¦4:ntied,efited,uaked,caded,fired,roped,halled,roked,himed,culed,tared,lared,tuted,uared,routed,pited,naked,miled,houted,helled,hared,cored,caled,tired,peated,futed,ciled,called,tined,moted,filed,sided,poned,iloted,honed,lleted,huted,ruled,cured,named,preted,vaded,sured,talled,haled,peded,gined,nited,uided,ramed,feited,laked,gured,ctored,unged,pired,cuted,voked,eloped,ralled,rined,coded,icited,vided,uaded,voted,mined,sired,noted,lined,nselled,luted,jured,fided,puted,piled,pared,olored,cided,hoked,enged,tured,geoned,cotted,lamed,uiled,waited,udited,anged,luded,mired,uired,radedÂ¦5:modelled,izzled,eleted,umpeted,ailored,rseded,treated,eduled,ecited,rammed,eceded,atrolled,nitored,basted,twined,itialled,ncited,gnored,ploded,xcited,nrolled,namelled,plored,efeated,redited,ntrolled,nfined,pleted,llided,lcined,eathed,ibuted,lloted,dhered,ccededÂ¦3ad:sledÂ¦2aw:drewÂ¦2ot:hotÂ¦2ke:madeÂ¦2ow:hrew,grewÂ¦2ose:hoseÂ¦2d:iltÂ¦2in:eganÂ¦1un:ranÂ¦1ink:houghtÂ¦1ick:tuckÂ¦1ike:ruckÂ¦1eak:poke,nuckÂ¦1it:patÂ¦1o:didÂ¦1ow:newÂ¦1ake:wokeÂ¦go:went",
    "rev": "3:rst,hed,hut,cut,setÂ¦4:tbidÂ¦5:dcast,eread,pread,erbidÂ¦ought:uy,eekÂ¦1ied:ny,ly,dy,ry,fy,py,vy,by,ty,cyÂ¦1ung:ling,ting,wingÂ¦1pt:eepÂ¦1ank:rinkÂ¦1ore:bear,wearÂ¦1ave:giveÂ¦1oze:reezeÂ¦1ound:rind,windÂ¦1ook:take,hakeÂ¦1aw:seeÂ¦1old:sellÂ¦1ote:riteÂ¦1ole:tealÂ¦1unk:tinkÂ¦1am:wimÂ¦1ay:lieÂ¦1ood:tandÂ¦1eld:holdÂ¦2d:he,ge,re,le,leed,ne,reed,be,ye,lee,pe,weÂ¦2ed:dd,oy,or,ey,gg,rr,us,ew,toÂ¦2ame:ecome,rcomeÂ¦2ped:apÂ¦2ged:ag,og,ug,egÂ¦2bed:ub,ab,ib,obÂ¦2lt:neelÂ¦2id:payÂ¦2ang:pringÂ¦2ove:triveÂ¦2med:umÂ¦2ode:rrideÂ¦2at:ysitÂ¦3ted:mit,hat,mat,lat,pot,rot,batÂ¦3ed:low,end,tow,und,ond,eem,lay,cho,dow,xit,eld,ald,uld,law,lel,eat,oll,ray,ank,fin,oam,out,how,iek,tay,haw,ait,vet,say,cay,bowÂ¦3d:ste,ede,ode,ete,ree,ude,ame,oke,ote,ime,ute,adeÂ¦3red:lur,cur,pur,carÂ¦3ped:hop,rop,uip,rip,lip,tep,topÂ¦3ded:bed,rod,kidÂ¦3ade:orbidÂ¦3led:uelÂ¦3ned:lan,can,kin,pan,tunÂ¦3med:rim,limÂ¦4ted:quit,llotÂ¦4ed:pear,rrow,rand,lean,mand,anel,pand,reet,link,abel,evel,imit,ceed,ruit,mind,peal,veal,hool,head,pell,well,mell,uell,band,hear,weakÂ¦4led:nnel,qual,ebel,ivelÂ¦4red:nfer,efer,sferÂ¦4n:sake,trewÂ¦4d:nteeÂ¦4ded:hredÂ¦4ned:rpinÂ¦5ed:light,nceal,right,ndear,arget,hread,eight,rtial,ebootÂ¦5d:edite,nviteÂ¦5ted:egretÂ¦5led:ravel",
    "ex": "2:been,uppedÂ¦3:added,aged,aided,aimed,aired,bid,died,dyed,egged,erred,eyed,fit,gassed,hit,lied,owed,pent,pied,tied,used,vied,oiled,outed,banned,barred,bet,canned,cut,dipped,donned,ended,feed,inked,jarred,let,manned,mowed,netted,padded,panned,pitted,popped,potted,put,set,sewn,sowed,tanned,tipped,topped,vowed,weed,bowed,jammed,binned,dimmed,hopped,mopped,nodded,pinned,rigged,sinned,towed,vettedÂ¦4:ached,baked,baled,boned,bored,called,caned,cared,ceded,cited,coded,cored,cubed,cured,dared,dined,edited,exited,faked,fared,filed,fined,fired,fuelled,gamed,gelled,hired,hoped,joked,lined,mined,named,noted,piled,poked,polled,pored,pulled,reaped,roamed,rolled,ruled,seated,shed,sided,timed,tolled,toned,voted,waited,walled,waned,winged,wiped,wired,zoned,yelled,tamed,lubed,roped,faded,mired,caked,honed,banged,culled,heated,raked,welled,banded,beat,cast,cooled,cost,dealt,feared,folded,footed,handed,headed,heard,hurt,knitted,landed,leaked,leapt,linked,meant,minded,molded,neared,needed,peaked,plodded,plotted,pooled,quit,read,rooted,sealed,seeded,seeped,shipped,shunned,skimmed,slammed,sparred,stemmed,stirred,suited,thinned,twinned,swayed,winked,dialed,abutted,blotted,fretted,healed,heeded,peeled,reeledÂ¦5:basted,cheated,equalled,eroded,exiled,focused,opined,pleated,primed,quoted,scouted,shored,sloped,smoked,sniped,spelled,spouted,routed,staked,stored,swelled,tasted,treated,wasted,smelled,dwelled,honored,prided,quelled,eloped,scared,coveted,sweated,breaded,cleared,debuted,deterred,freaked,modeled,pleaded,rebutted,speededÂ¦6:anchored,defined,endured,impaled,invited,refined,revered,strolled,cringed,recast,thrust,unfoldedÂ¦7:authored,combined,competed,conceded,convened,excreted,extruded,redefined,restored,secreted,rescinded,welcomedÂ¦8:expedited,infringedÂ¦9:interfered,intervened,perseveredÂ¦10:contravenedÂ¦eat:ateÂ¦is:wasÂ¦go:wentÂ¦are:wereÂ¦3d:bent,lent,rent,sentÂ¦3e:bit,fled,hid,lostÂ¦3ed:bled,bredÂ¦2ow:blew,grewÂ¦1uy:boughtÂ¦2tch:caughtÂ¦1o:didÂ¦1ive:dove,gaveÂ¦2aw:drewÂ¦2ed:fedÂ¦2y:flew,laid,paid,saidÂ¦1ight:foughtÂ¦1et:gotÂ¦2ve:hadÂ¦1ang:hungÂ¦2ad:ledÂ¦2ght:litÂ¦2ke:madeÂ¦2et:metÂ¦1un:ranÂ¦1ise:roseÂ¦1it:satÂ¦1eek:soughtÂ¦1each:taughtÂ¦1ake:woke,tookÂ¦1eave:woveÂ¦2ise:aroseÂ¦1ear:bore,tore,woreÂ¦1ind:bound,found,woundÂ¦2eak:brokeÂ¦2ing:brought,wrungÂ¦1ome:cameÂ¦2ive:droveÂ¦1ig:dugÂ¦1all:fellÂ¦2el:feltÂ¦4et:forgotÂ¦1old:heldÂ¦2ave:leftÂ¦1ing:rang,sangÂ¦1ide:rodeÂ¦1ink:sankÂ¦1ee:sawÂ¦2ine:shoneÂ¦4e:slidÂ¦1ell:sold,toldÂ¦4d:spentÂ¦2in:spunÂ¦1in:won"
  },
  "PresentTense": {
    "fwd": "1:oesÂ¦1ve:as",
    "both": "1:xesÂ¦2:zzes,ches,shes,ssesÂ¦3:iasesÂ¦2y:llies,pliesÂ¦1y:cies,bies,ties,vies,nies,pies,dies,ries,fiesÂ¦:s",
    "rev": "1ies:lyÂ¦2es:us,go,doÂ¦3es:cho,eto",
    "ex": "2:does,goesÂ¦3:gassesÂ¦5:focusesÂ¦is:areÂ¦3y:reliesÂ¦2y:fliesÂ¦2ve:has"
  },
  "Superlative": {
    "fwd": "1st:eÂ¦1est:l,m,f,sÂ¦1iest:ceyÂ¦2est:or,irÂ¦3est:ver",
    "both": "4:eastÂ¦5:hwestÂ¦5lest:erfulÂ¦4est:weet,lgar,tter,oungÂ¦4most:uterÂ¦3est:ger,der,rey,iet,ong,earÂ¦3test:latÂ¦3most:nerÂ¦2est:pt,ft,nt,ct,rt,htÂ¦2test:itÂ¦2gest:igÂ¦1est:b,k,n,p,h,d,wÂ¦iest:y",
    "rev": "1:ttest,nnest,yestÂ¦2:sest,stest,rmest,cest,vest,lmest,olest,ilest,ulest,ssest,imest,uestÂ¦3:rgest,eatest,oorest,plest,allest,urest,iefest,uelest,blest,ugest,amest,yalest,ealest,illest,tlest,itestÂ¦4:cerest,eriest,somest,rmalest,ndomest,motest,uarest,tiffestÂ¦5:leverest,rangestÂ¦ar:urthestÂ¦3ey:riciest",
    "ex": "best:goodÂ¦worst:badÂ¦5est:greatÂ¦4est:fast,full,fair,dullÂ¦3test:hot,wet,fatÂ¦4nest:thinÂ¦1urthest:farÂ¦3est:gay,shy,illÂ¦4test:neatÂ¦4st:late,wide,fine,safe,cute,fake,pale,rare,rude,sore,ripe,direÂ¦6st:severe"
  },
  "AdjToNoun": {
    "fwd": "1:tistic,eable,lful,sful,ting,ttyÂ¦2:onate,rtable,geous,ced,seful,ctfulÂ¦3:ortive,entedÂ¦arity:earÂ¦y:eticÂ¦fulness:begoneÂ¦1ity:reÂ¦1y:tiful,gicÂ¦2ity:ile,imous,ilous,imeÂ¦2ion:atedÂ¦2eness:ivingÂ¦2y:triousÂ¦2ation:iringÂ¦2tion:vantÂ¦3ion:ectÂ¦3ce:mant,manticÂ¦3tion:irableÂ¦3y:est,esticÂ¦3m:mistic,listicÂ¦3ess:ningÂ¦4n:utiousÂ¦4on:rative,native,vative,ectiveÂ¦4ce:erant",
    "both": "1:king,wingÂ¦2:alous,ltuous,oyful,rdousÂ¦3:gorous,ectable,werful,amaticÂ¦4:oised,usical,agical,raceful,ocused,lined,ightfulÂ¦5ness:stful,lding,itous,nuous,ulous,otous,nable,gious,ayful,rvous,ntous,lsive,peful,entle,ciful,osive,leful,isive,ncise,reful,miousÂ¦5ty:ivaciousÂ¦5ties:ubtleÂ¦5ce:ilient,adiant,atientÂ¦5cy:icientÂ¦5sm:gmaticÂ¦5on:sessive,dictiveÂ¦5ity:pular,sonal,eative,enticÂ¦5sity:uminousÂ¦5ism:conicÂ¦5nce:mperateÂ¦5ility:mitableÂ¦5ment:xcitedÂ¦5n:bitiousÂ¦4cy:brant,etent,curateÂ¦4ility:erable,acable,icable,ptableÂ¦4ty:nacious,aive,oyal,daciousÂ¦4n:iciousÂ¦4ce:vient,erent,stent,ndent,dient,quent,identÂ¦4ness:adic,ound,hing,pant,sant,oing,oist,tuteÂ¦4icity:impleÂ¦4ment:fined,musedÂ¦4ism:oticÂ¦4ry:danticÂ¦4ity:tund,eralÂ¦4edness:handÂ¦4on:uitiveÂ¦4lity:pitableÂ¦4sm:eroic,namicÂ¦4sity:nerousÂ¦3th:armÂ¦3ility:pable,bable,dable,iableÂ¦3cy:hant,nant,icateÂ¦3ness:red,hin,nse,ict,iet,ite,oud,ind,ied,rceÂ¦3ion:luteÂ¦3ity:ual,gal,volous,ialÂ¦3ce:sent,fensive,lant,gant,gent,lent,dantÂ¦3on:asiveÂ¦3m:fist,sistic,iasticÂ¦3y:terious,xurious,ronic,tasticÂ¦3ur:amorousÂ¦3e:tunateÂ¦3ation:minedÂ¦3sy:rteousÂ¦3ty:ainÂ¦3ry:aveÂ¦3ment:azedÂ¦2ness:de,on,ue,rn,ur,ft,rp,pe,om,ge,rd,od,ay,ss,er,ll,oy,ap,ht,ld,ad,rtÂ¦2inousness:umousÂ¦2ity:neous,ene,id,aneÂ¦2cy:bate,lateÂ¦2ation:izedÂ¦2ility:oble,ibleÂ¦2y:odicÂ¦2e:oving,aringÂ¦2s:ostÂ¦2itude:ptÂ¦2dom:eeÂ¦2ance:uringÂ¦2tion:reetÂ¦2ion:otedÂ¦2sion:endingÂ¦2liness:anÂ¦2or:rdentÂ¦1th:ungÂ¦1e:uableÂ¦1ness:w,h,k,fÂ¦1ility:mbleÂ¦1or:ventÂ¦1ement:gingÂ¦1tiquity:ncientÂ¦1ment:hedÂ¦verty:orÂ¦ength:ongÂ¦eat:otÂ¦pth:epÂ¦iness:y",
    "rev": "",
    "ex": "5:forceful,humorousÂ¦8:charismaticÂ¦13:understandingÂ¦5ity:activeÂ¦11ness:adventurous,inquisitive,resourcefulÂ¦8on:aggressive,automatic,perceptiveÂ¦7ness:amorous,fatuous,furtive,ominous,seriousÂ¦5ness:ample,sweetÂ¦12ness:apprehensive,cantankerous,contemptuous,ostentatiousÂ¦13ness:argumentative,conscientiousÂ¦9ness:assertive,facetious,imperious,inventive,oblivious,rapacious,receptive,seditious,whimsicalÂ¦10ness:attractive,expressive,impressive,loquacious,salubrious,thoughtfulÂ¦3edom:boringÂ¦4ness:calm,fast,keen,tameÂ¦8ness:cheerful,gracious,specious,spurious,timorous,unctuousÂ¦5sity:curiousÂ¦9ion:deliberateÂ¦8ion:desperateÂ¦6e:expensiveÂ¦7ce:fragrantÂ¦3y:furiousÂ¦9ility:ineluctableÂ¦6ism:mysticalÂ¦8ity:physical,proactive,sensitive,verticalÂ¦5cy:pliantÂ¦7ity:positiveÂ¦9ity:practicalÂ¦12ism:professionalÂ¦6ce:prudentÂ¦3ness:redÂ¦6cy:vagrantÂ¦3dom:wise"
  }
};

// 01- full-word exceptions
const checkEx = function (str, ex = {}) {
  if (ex.hasOwnProperty(str)) {
    return ex[str]
  }
  return null
};

// 02- suffixes that pass our word through
const checkSame = function (str, same = []) {
  for (let i = 0; i < same.length; i += 1) {
    if (str.endsWith(same[i])) {
      return str
    }
  }
  return null
};

// 03- check rules - longest first
const checkRules = function (str, fwd, both = {}) {
  fwd = fwd || {};
  let max = str.length - 1;
  // look for a matching suffix
  for (let i = max; i >= 1; i -= 1) {
    let size = str.length - i;
    let suff = str.substring(size, str.length);
    // check fwd rules, first
    if (fwd.hasOwnProperty(suff) === true) {
      return str.slice(0, size) + fwd[suff]
    }
    // check shared rules
    if (both.hasOwnProperty(suff) === true) {
      return str.slice(0, size) + both[suff]
    }
  }
  // try a fallback transform
  if (fwd.hasOwnProperty('')) {
    return str += fwd['']
  }
  if (both.hasOwnProperty('')) {
    return str += both['']
  }
  return null
};

//sweep-through all suffixes
const convert = function (str = '', model = {}) {
  // 01- check exceptions
  let out = checkEx(str, model.ex);
  // 02 - check same
  out = out || checkSame(str, model.same);
  // check forward and both rules
  out = out || checkRules(str, model.fwd, model.both);
  //return unchanged
  out = out || str;
  return out
};

const flipObj = function (obj) {
  return Object.entries(obj).reduce((h, a) => {
    h[a[1]] = a[0];
    return h
  }, {})
};

const reverse = function (model = {}) {
  return {
    reversed: true,
    // keep these two
    both: flipObj(model.both),
    ex: flipObj(model.ex),
    // swap this one in
    fwd: model.rev || {}
  }
};

const prefix$2 = /^([0-9]+)/;

const toObject = function (txt) {
  let obj = {};
  txt.split('Â¦').forEach(str => {
    let [key, vals] = str.split(':');
    vals = (vals || '').split(',');
    vals.forEach(val => {
      obj[val] = key;
    });
  });
  return obj
};

const growObject = function (key = '', val = '') {
  val = String(val);
  let m = val.match(prefix$2);
  if (m === null) {
    return val
  }
  let num = Number(m[1]) || 0;
  let pre = key.substring(0, num);
  let full = pre + val.replace(prefix$2, '');
  return full
};

const unpackOne = function (str) {
  let obj = toObject(str);
  return Object.keys(obj).reduce((h, k) => {
    h[k] = growObject(k, obj[k]);
    return h
  }, {})
};

const uncompress = function (model = {}) {
  if (typeof model === 'string') {
    model = JSON.parse(model);
  }
  model.fwd = unpackOne(model.fwd || '');
  model.both = unpackOne(model.both || '');
  model.rev = unpackOne(model.rev || '');
  model.ex = unpackOne(model.ex || '');
  return model
};

// import { reverse, uncompress } from '/Users/spencer/mountain/suffix-thumb'
// const uncompress = function () { }
// const reverse = function () { }
const fromPast = uncompress(data.PastTense);
const fromPresent = uncompress(data.PresentTense);
const fromGerund = uncompress(data.Gerund);
const fromParticiple = uncompress(data.Participle);

const toPast$3 = reverse(fromPast);
const toPresent$2 = reverse(fromPresent);
const toGerund$2 = reverse(fromGerund);
const toParticiple = reverse(fromParticiple);

const toComparative$1 = uncompress(data.Comparative);
const toSuperlative$1 = uncompress(data.Superlative);
const fromComparative$1 = reverse(toComparative$1);
const fromSuperlative$1 = reverse(toSuperlative$1);

const adjToNoun = uncompress(data.AdjToNoun);

var models = {
  fromPast,
  fromPresent,
  fromGerund,
  fromParticiple,
  toPast: toPast$3,
  toPresent: toPresent$2,
  toGerund: toGerund$2,
  toParticiple,
  // adjectives
  toComparative: toComparative$1,
  toSuperlative: toSuperlative$1,
  fromComparative: fromComparative$1,
  fromSuperlative: fromSuperlative$1,
  adjToNoun
};
// console.log(convert('collide', toPast))

var regexNormal = [
  //web tags
  [/^[\w.]+@[\w.]+\.[a-z]{2,3}$/, 'Email'],
  [/^(https?:\/\/|www\.)+\w+\.[a-z]{2,3}/, 'Url', 'http..'],
  [/^[a-z0-9./].+\.(com|net|gov|org|ly|edu|info|biz|dev|ru|jp|de|in|uk|br|io|ai)/, 'Url', '.com'],

  // timezones
  [/^[PMCE]ST$/, 'Timezone', 'EST'],

  //names
  [/^ma?c'[a-z]{3}/, 'LastName', "mc'neil"],
  [/^o'[a-z]{3}/, 'LastName', "o'connor"],
  [/^ma?cd[aeiou][a-z]{3}/, 'LastName', 'mcdonald'],

  //slang things
  [/^(lol)+[sz]$/, 'Expression', 'lol'],
  [/^wo{2,}a*h?$/, 'Expression', 'wooah'],
  [/^(hee?){2,}h?$/, 'Expression', 'hehe'],
  [/^(un|de|re)\\-[a-z\u00C0-\u00FF]{2}/, 'Verb', 'un-vite'],

  // m/h
  [/^(m|k|cm|km)\/(s|h|hr)$/, 'Unit', '5 k/m'],
  // Î¼g/g
  [/^(ug|ng|mg)\/(l|m3|ft3)$/, 'Unit', 'ug/L'],

  // love/hate
  [/[^:/]\/\p{Letter}/u, 'SlashedTerm', 'love/hate'],
];

var regexText = [
  // #coolguy
  [/^#[\p{Number}_]*\p{Letter}/u, 'HashTag'], // can't be all numbers

  // @spencermountain
  [/^@\w{2,}$/, 'AtMention'],

  // period-ones acronyms - f.b.i.
  [/^([A-Z]\.){2}[A-Z]?/i, ['Acronym', 'Noun'], 'F.B.I'], //ascii-only

  // ending-apostrophes
  [/.{3}[lkmnp]in['â€˜â€™â€›â€µâ€²`Â´]$/, 'Gerund', "chillin'"],
  [/.{4}s['â€˜â€™â€›â€µâ€²`Â´]$/, 'Possessive', "flanders'"],

  //from https://www.regextester.com/106421
  // [/^([\u00a9\u00ae\u2319-\u3300]|\ud83c[\ud000-\udfff]|\ud83d[\ud000-\udfff]|\ud83e[\ud000-\udfff])/, 'Emoji', 'emoji-range']
  // unicode character range
  [/^[\p{Emoji_Presentation}\p{Extended_Pictographic}]/u, 'Emoji', 'emoji-class'],
];

var regexNumbers = [
  [/^@1?[0-9](am|pm)$/i, 'Time', '3pm'],
  [/^@1?[0-9]:[0-9]{2}(am|pm)?$/i, 'Time', '3:30pm'],
  [/^'[0-9]{2}$/, 'Year'],
  // times
  [/^[012]?[0-9](:[0-5][0-9])(:[0-5][0-9])$/, 'Time', '3:12:31'],
  [/^[012]?[0-9](:[0-5][0-9])?(:[0-5][0-9])? ?(am|pm)$/i, 'Time', '1:12pm'],
  [/^[012]?[0-9](:[0-5][0-9])(:[0-5][0-9])? ?(am|pm)?$/i, 'Time', '1:12:31pm'], //can remove?

  // iso-dates
  [/^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}/i, 'Date', 'iso-date'],
  [/^[0-9]{1,4}-[0-9]{1,2}-[0-9]{1,4}$/, 'Date', 'iso-dash'],
  [/^[0-9]{1,4}\/[0-9]{1,2}\/([0-9]{4}|[0-9]{2})$/, 'Date', 'iso-slash'],
  [/^[0-9]{1,4}\.[0-9]{1,2}\.[0-9]{1,4}$/, 'Date', 'iso-dot'],
  [/^[0-9]{1,4}-[a-z]{2,9}-[0-9]{1,4}$/i, 'Date', '12-dec-2019'],

  // timezones
  [/^utc ?[+-]?[0-9]+$/, 'Timezone', 'utc-9'],
  [/^(gmt|utc)[+-][0-9]{1,2}$/i, 'Timezone', 'gmt-3'],

  //phone numbers
  [/^[0-9]{3}-[0-9]{4}$/, 'PhoneNumber', '421-0029'],
  [/^(\+?[0-9][ -])?[0-9]{3}[ -]?[0-9]{3}-[0-9]{4}$/, 'PhoneNumber', '1-800-'],

  //money
  //like $5.30
  [/^[-+]?\p{Currency_Symbol}[-+]?[0-9]+(,[0-9]{3})*(\.[0-9]+)?([kmb]|bn)?\+?$/u, ['Money', 'Value'], '$5.30'],
  //like 5.30$
  [/^[-+]?[0-9]+(,[0-9]{3})*(\.[0-9]+)?\p{Currency_Symbol}\+?$/u, ['Money', 'Value'], '5.30Â£'],
  //like
  [/^[-+]?[$Â£]?[0-9]([0-9,.])+(usd|eur|jpy|gbp|cad|aud|chf|cny|hkd|nzd|kr|rub)$/i, ['Money', 'Value'], '$400usd'],

  //numbers
  // 50 | -50 | 3.23  | 5,999.0  | 10+
  [/^[-+]?[0-9]+(,[0-9]{3})*(\.[0-9]+)?\+?$/, ['Cardinal', 'NumericValue'], '5,999'],
  [/^[-+]?[0-9]+(,[0-9]{3})*(\.[0-9]+)?(st|nd|rd|r?th)$/, ['Ordinal', 'NumericValue'], '53rd'],
  // .73th
  [/^\.[0-9]+\+?$/, ['Cardinal', 'NumericValue'], '.73th'],
  //percent
  [/^[-+]?[0-9]+(,[0-9]{3})*(\.[0-9]+)?%\+?$/, ['Percent', 'Cardinal', 'NumericValue'], '-4%'],
  [/^\.[0-9]+%$/, ['Percent', 'Cardinal', 'NumericValue'], '.3%'],
  //fraction
  [/^[0-9]{1,4}\/[0-9]{1,4}(st|nd|rd|th)?s?$/, ['Fraction', 'NumericValue'], '2/3rds'],
  //range
  [/^[0-9.]{1,3}[a-z]{0,2}[-â€“â€”][0-9]{1,3}[a-z]{0,2}$/, ['Value', 'NumberRange'], '3-4'],
  //time-range
  [/^[0-9]{1,2}(:[0-9][0-9])?(am|pm)? ?[-â€“â€”] ?[0-9]{1,2}(:[0-9][0-9])?(am|pm)$/, ['Time', 'NumberRange'], '3-4pm'],
  //number with unit
  [/^[0-9.]+([a-zÂ°]{1,4})$/, 'NumericValue', '9km'],
];

//nouns that also signal the title of an unknown organization
//todo remove/normalize plural forms
var orgWords = [
  'academy',
  'administration',
  'agence',
  'agences',
  'agencies',
  'agency',
  'airlines',
  'airways',
  'army',
  'assoc',
  'associates',
  'association',
  'assurance',
  'authority',
  'autorite',
  'aviation',
  'bank',
  'banque',
  'board',
  'boys',
  'brands',
  'brewery',
  'brotherhood',
  'brothers',
  'bureau',
  'cafe',
  'co',
  'caisse',
  'capital',
  'care',
  'cathedral',
  'center',
  'centre',
  'chemicals',
  'choir',
  'chronicle',
  'church',
  'circus',
  'clinic',
  'clinique',
  'club',
  'co',
  'coalition',
  'coffee',
  'collective',
  'college',
  'commission',
  'committee',
  'communications',
  'community',
  'company',
  'comprehensive',
  'computers',
  'confederation',
  'conference',
  'conseil',
  'consulting',
  'containers',
  'corporation',
  'corps',
  'corp',
  'council',
  'crew',
  'data',
  'departement',
  'department',
  'departments',
  'design',
  'development',
  'directorate',
  'division',
  'drilling',
  'education',
  'eglise',
  'electric',
  'electricity',
  'energy',
  'ensemble',
  'enterprise',
  'enterprises',
  'entertainment',
  'estate',
  'etat',
  'faculty',
  'faction',
  'federation',
  'financial',
  'fm',
  'foundation',
  'fund',
  'gas',
  'gazette',
  'girls',
  'government',
  'group',
  'guild',
  'herald',
  'holdings',
  'hospital',
  'hotel',
  'hotels',
  'inc',
  'industries',
  'institut',
  'institute',
  'institutes',
  'insurance',
  'international',
  'interstate',
  'investment',
  'investments',
  'investors',
  'journal',
  'laboratory',
  'labs',
  'llc',
  'ltd',
  'limited',
  'machines',
  'magazine',
  'management',
  'marine',
  'marketing',
  'markets',
  'media',
  'memorial',
  'ministere',
  'ministry',
  'military',
  'mobile',
  'motor',
  'motors',
  'musee',
  'museum',
  'news',
  'observatory',
  'office',
  'oil',
  'optical',
  'orchestra',
  'organization',
  'partners',
  'partnership',
  'petrol',
  'petroleum',
  'pharmacare',
  'pharmaceutical',
  'pharmaceuticals',
  'pizza',
  'plc',
  'police',
  'politburo',
  'polytechnic',
  'post',
  'power',
  'press',
  'productions',
  'quartet',
  'radio',
  'reserve',
  'resources',
  'restaurant',
  'restaurants',
  'savings',
  'school',
  'securities',
  'service',
  'services',
  'societe',
  'subsidiary',
  'society',
  'sons',
  // 'standard',
  'subcommittee',
  'syndicat',
  'systems',
  'telecommunications',
  'telegraph',
  'television',
  'times',
  'tribunal',
  'tv',
  'union',
  'university',
  'utilities',
  'workers',
].reduce((h, str) => {
  h[str] = true;
  return h
}, {});

var placeWords = [
  // geology
  'atoll',
  'basin',
  'bay',
  'beach',
  'bluff',
  'bog',
  'camp',
  'canyon',
  'canyons',
  'cape',
  'cave',
  'caves',
  // 'cliff',
  'cliffs',
  'coast',
  'cove',
  'coves',
  'crater',
  'crossing',
  'creek',
  'desert',
  'dune',
  'dunes',
  'downs',
  'estates',
  'escarpment',
  'estuary',
  'falls',
  'fjord',
  'fjords',
  'forest',
  'forests',
  'glacier',
  'gorge',
  'gorges',
  'grove',
  'gulf',
  'gully',
  'highland',
  'heights',
  'hollow',
  'hill',
  'hills',
  'inlet',
  'island',
  'islands',
  'isthmus',
  'junction',
  'knoll',
  'lagoon',
  'lake',
  'lakeshore',
  'marsh',
  'marshes',
  'mount',
  'mountain',
  'mountains',
  'narrows',
  'peninsula',
  'plains',
  'plateau',
  'pond',
  'rapids',
  'ravine',
  'reef',
  'reefs',
  'ridge',
  // 'river delta',
  'river',
  'rivers',
  'sandhill',
  'shoal',
  'shore',
  'shoreline',
  'shores',
  'strait',
  'straits',
  'springs',
  'stream',
  'swamp',
  'tombolo',
  'trail',
  'trails',
  'trench',
  'valley',
  'vallies',
  'village',
  'volcano',
  'waterfall',
  'watershed',
  'wetland',
  'woods',
  'acres',

  // districts
  'burough',
  'county',
  'district',
  'municipality',
  'prefecture',
  'province',
  'region',
  'reservation',
  'state',
  'territory',
  'borough',
  'metropolis',
  'downtown',
  'uptown',
  'midtown',
  'city',
  'town',
  'township',
  'hamlet',
  'country',
  'kingdom',
  'enclave',
  'neighbourhood',
  'neighborhood',
  'kingdom',
  'ward',
  'zone',
  // 'range',

  //building/ complex
  'airport',
  'amphitheater',
  'arch',
  'arena',
  'auditorium',
  'bar',
  'barn',
  'basilica',
  'battlefield',
  'bridge',
  'building',
  'castle',
  'centre',
  'coliseum',
  'cineplex',
  'complex',
  'dam',
  'farm',
  'field',
  'fort',
  'garden',
  'gardens',
  // 'grounds',
  'gymnasium',
  'hall',
  'house',
  'levee',
  'library',
  'manor',
  'memorial',
  'monument',
  'museum',
  'gallery',
  'palace',
  'pillar',
  'pits',
  // 'pit',
  // 'place',
  // 'point',
  // 'room',
  'plantation',
  'playhouse',
  'quarry',
  // 'ruins',
  'sportsfield',
  'sportsplex',
  'stadium',
  // 'statue',
  'terrace',
  'terraces',
  'theater',
  'tower',
  'park',
  'parks',
  'site',
  'ranch',
  'raceway',
  'sportsplex',

  // 'sports centre',
  // 'sports field',
  // 'soccer complex',
  // 'soccer centre',
  // 'sports complex',
  // 'civic centre',

  // roads
  'ave',
  'st',
  'street',
  'rd',
  'road',
  'lane',
  'landing',
  'crescent',
  'cr',
  'way',
  'tr',
  'terrace',
  'avenue',
].reduce((h, str) => {
  h[str] = true;
  return h
}, {});

var rules$1 = [
  [/([^v])ies$/i, '$1y'],
  [/(ise)s$/i, '$1'],//promises
  [/(kn|[^o]l|w)ives$/i, '$1ife'],
  [/^((?:ca|e|ha|(?:our|them|your)?se|she|wo)l|lea|loa|shea|thie)ves$/i, '$1f'],
  [/^(dwar|handkerchie|hoo|scar|whar)ves$/i, '$1f'],
  [/(antenn|formul|nebul|vertebr|vit)ae$/i, '$1a'],
  [/(octop|vir|radi|nucle|fung|cact|stimul)(i)$/i, '$1us'],
  [/(buffal|tomat|tornad)(oes)$/i, '$1o'],

  [/(ause)s$/i, '$1'],//causes
  [/(ease)s$/i, '$1'],//diseases
  [/(ious)es$/i, '$1'],//geniouses
  [/(ouse)s$/i, '$1'],//houses
  [/(ose)s$/i, '$1'],//roses

  [/(..ase)s$/i, '$1'],
  [/(..[aeiu]s)es$/i, '$1'],
  [/(vert|ind|cort)(ices)$/i, '$1ex'],
  [/(matr|append)(ices)$/i, '$1ix'],
  [/([xo]|ch|ss|sh)es$/i, '$1'],
  [/men$/i, 'man'],
  [/(n)ews$/i, '$1ews'],
  [/([ti])a$/i, '$1um'],
  [/([^aeiouy]|qu)ies$/i, '$1y'],
  [/(s)eries$/i, '$1eries'],
  [/(m)ovies$/i, '$1ovie'],
  [/(cris|ax|test)es$/i, '$1is'],
  [/(alias|status)es$/i, '$1'],
  [/(ss)$/i, '$1'],
  [/(ic)s$/i, '$1'],
  [/s$/i, ''],
];

const invertObj = function (obj) {
  return Object.keys(obj).reduce((h, k) => {
    h[obj[k]] = k;
    return h
  }, {})
};

const toSingular = function (str, model) {
  const { irregularPlurals } = model.two;
  let invert = invertObj(irregularPlurals); //(not very efficient)
  // check irregulars list
  if (invert.hasOwnProperty(str)) {
    return invert[str]
  }
  // go through our regexes
  for (let i = 0; i < rules$1.length; i++) {
    if (rules$1[i][0].test(str) === true) {
      // console.log(rules[i])
      str = str.replace(rules$1[i][0], rules$1[i][1]);
      return str
    }
  }
  return str
};

const all$3 = function (str, model) {
  let arr = [str];
  let p = pluralize(str, model);
  if (p !== str) {
    arr.push(p);
  }
  let s = toSingular(str, model);
  if (s !== str) {
    arr.push(s);
  }
  return arr
};

var nouns$2 = { toPlural: pluralize, toSingular, all: all$3 };

let guessVerb = {
  Gerund: ['ing'],
  Actor: ['erer'],
  Infinitive: [
    'ate',
    'ize',
    'tion',
    'rify',
    'then',
    'ress',
    'ify',
    'age',
    'nce',
    'ect',
    'ise',
    'ine',
    'ish',
    'ace',
    'ash',
    'ure',
    'tch',
    'end',
    'ack',
    'and',
    'ute',
    'ade',
    'ock',
    'ite',
    'ase',
    'ose',
    'use',
    'ive',
    'int',
    'nge',
    'lay',
    'est',
    'ain',
    'ant',
    'ent',
    'eed',
    'er',
    'le',
    'unk',
    'ung',
    'upt',
    'en',
  ],
  PastTense: ['ept', 'ed', 'lt', 'nt', 'ew', 'ld'],
  PresentTense: [
    'rks',
    'cks',
    'nks',
    'ngs',
    'mps',
    'tes',
    'zes',
    'ers',
    'les',
    'acks',
    'ends',
    'ands',
    'ocks',
    'lays',
    'eads',
    'lls',
    'els',
    'ils',
    'ows',
    'nds',
    'ays',
    'ams',
    'ars',
    'ops',
    'ffs',
    'als',
    'urs',
    'lds',
    'ews',
    'ips',
    'es',
    'ts',
    'ns',
  ],
  Participle: ['ken', 'wn']
};
//flip it into a lookup object
guessVerb = Object.keys(guessVerb).reduce((h, k) => {
  guessVerb[k].forEach(a => (h[a] = k));
  return h
}, {});

/** it helps to know what we're conjugating from */
const getTense$1 = function (str) {
  let three = str.substring(str.length - 3);
  if (guessVerb.hasOwnProperty(three) === true) {
    return guessVerb[three]
  }
  let two = str.substring(str.length - 2);
  if (guessVerb.hasOwnProperty(two) === true) {
    return guessVerb[two]
  }
  let one = str.substring(str.length - 1);
  if (one === 's') {
    return 'PresentTense'
  }
  return null
};

const toParts = function (str, model) {
  let prefix = '';
  let prefixes = {};
  if (model.one && model.one.prefixes) {
    prefixes = model.one.prefixes;
  }
  // pull-apart phrasal verb 'fall over'
  let [verb, particle] = str.split(/ /);
  // support 'over cleaned'
  if (particle && prefixes[verb] === true) {
    prefix = verb;
    verb = particle;
    particle = '';
  }
  return {
    prefix, verb, particle
  }
};


// dunno about these..
const copulaMap = {
  are: 'be',
  were: 'be',
  been: 'be',
  is: 'be',
  am: 'be',
  was: 'be',
  be: 'be',
  being: 'be',
};

const toInfinitive$1 = function (str, model, tense) {
  const { fromPast, fromPresent, fromGerund, fromParticiple } = model.two.models;
  let { prefix, verb, particle } = toParts(str, model);
  let inf = '';
  if (!tense) {
    tense = getTense$1(str);
  }
  if (copulaMap.hasOwnProperty(str)) {
    inf = copulaMap[str];
  } else if (tense === 'Participle') {
    inf = convert(verb, fromParticiple);
  } else if (tense === 'PastTense') {
    inf = convert(verb, fromPast);
  } else if (tense === 'PresentTense') {
    inf = convert(verb, fromPresent);
  } else if (tense === 'Gerund') {
    inf = convert(verb, fromGerund);
  } else {
    return str
  }

  // stitch phrasal back on
  if (particle) {
    inf += ' ' + particle;
  }
  // stitch prefix back on
  if (prefix) {
    inf = prefix + ' ' + inf;
  }
  return inf
};

// console.log(toInfinitive('snarled', { one: {} }))
// console.log(convert('snarled', fromPast))

// import { toPast, toPresent, toGerund, toParticiple } from '../../../../model/models/index.js'

// pull-apart phrasal verb 'fall over'
const parse$4 = (inf) => {
  if (/ /.test(inf)) {
    return inf.split(/ /)
  }
  return [inf, '']
};

//we run this on every verb in the lexicon, so please keep it fast
//we assume the input word is a proper infinitive
const conjugate = function (inf, model) {
  const { toPast, toPresent, toGerund, toParticiple } = model.two.models;
  // ad-hoc Copula response
  if (inf === 'be') {
    return {
      Infinitive: inf,
      Gerund: 'being',
      PastTense: 'was',
      PresentTense: 'is',
    }
  }
  let [str, particle] = parse$4(inf);
  let found = {
    Infinitive: str,
    PastTense: convert(str, toPast),
    PresentTense: convert(str, toPresent),
    Gerund: convert(str, toGerund),
    FutureTense: 'will ' + str
  };
  // add past-participle if it's interesting
  // drive -> driven (not drove)
  let pastPrt = convert(str, toParticiple);
  if (pastPrt !== inf && pastPrt !== found.PastTense) {
    // ensure it's a known participle
    let lex = model.one.lexicon || {};
    if (lex[pastPrt] === 'Participle' || lex[pastPrt] === 'Adjective') {
      // one exception
      if (inf === 'play') {
        pastPrt = 'played';
      }
      found.Participle = pastPrt;
    }
  }
  // put phrasal-verbs back together again
  if (particle) {
    Object.keys(found).forEach(k => {
      found[k] += ' ' + particle;
    });
  }
  return found
};

// console.log(toPresent.rules.y)
// console.log(convert('buy', toPresent))

const all$2 = function (str, model) {
  let res = conjugate(str, model);
  delete res.FutureTense;
  return Object.values(res).filter(s => s)
};
var verbs$3 = {
  toInfinitive: toInfinitive$1, conjugate, all: all$2
};

// import toAdverb from './adverbs/toAdverb.js'


const toSuperlative = function (adj, model) {
  const mod = model.two.models.toSuperlative;
  return convert(adj, mod)
};
const toComparative = function (adj, model) {
  const mod = model.two.models.toComparative;
  return convert(adj, mod)
};
const fromComparative = function (adj, model) {
  const mod = model.two.models.fromComparative;
  return convert(adj, mod)
};
const fromSuperlative = function (adj, model) {
  const mod = model.two.models.fromSuperlative;
  return convert(adj, mod)
};
const toNoun = function (adj, model) {
  const mod = model.two.models.adjToNoun;
  return convert(adj, mod)
};

//sweep-through all suffixes
const suffixLoop$1 = function (str = '', suffixes = []) {
  const len = str.length;
  let max = len <= 6 ? len - 1 : 6;
  for (let i = max; i >= 1; i -= 1) {
    let suffix = str.substring(len - i, str.length);
    if (suffixes[suffix.length].hasOwnProperty(suffix) === true) {
      let pre = str.slice(0, len - i);
      let post = suffixes[suffix.length][suffix];
      return pre + post
    }
  }
  return null
};

const s$1 = 'ically';
const ical = new Set([
  'analyt' + s$1, //analytical
  'chem' + s$1,// chemical
  'class' + s$1, //classical
  'clin' + s$1, // clinical
  'crit' + s$1,// critical
  'ecolog' + s$1,// ecological
  'electr' + s$1,// electrical
  'empir' + s$1, // empirical
  'frant' + s$1, // frantical
  'grammat' + s$1,// grammatical
  'ident' + s$1, // identical
  'ideolog' + s$1, // ideological
  'log' + s$1, // logical
  'mag' + s$1, //magical
  'mathemat' + s$1,// mathematical
  'mechan' + s$1,// mechanical
  'med' + s$1,// medical
  'method' + s$1, // methodical
  'method' + s$1,// methodical
  'mus' + s$1, // musical
  'phys' + s$1, // physical
  'phys' + s$1,// physical
  'polit' + s$1,// political
  'pract' + s$1,// practical
  'rad' + s$1, //radical
  'satir' + s$1, // satirical
  'statist' + s$1, // statistical
  'techn' + s$1,// technical
  'technolog' + s$1, // technological
  'theoret' + s$1,// theoretical
  'typ' + s$1,// typical
  'vert' + s$1,// vertical
  'whims' + s$1,// whimsical
]);

const suffixes$2 = [
  null,
  {},
  { 'ly': '' },
  {
    'ily': 'y',
    'bly': 'ble',
    'ply': 'ple',
  },
  {
    'ally': 'al',
    'rply': 'rp',
  },
  {
    'ually': 'ual',
    'ially': 'ial',
    'cally': 'cal',
    'eally': 'eal',
    'rally': 'ral',
    'nally': 'nal',
    'mally': 'mal',
    'eeply': 'eep',
    'eaply': 'eap',
  },
  {
    ically: 'ic',
  }
];

const noAdj = new Set([
  'early',
  'only',
  'hourly',
  'daily',
  'weekly',
  'monthly',
  'yearly',
  'mostly',
  'duly',
  'unduly',
  'especially',
  'undoubtedly',
  'conversely',
  'namely',
  'exceedingly',
  'presumably',
  'accordingly',
  'overly',
  'best',
  'latter',
  'little',
  'long',
  'low'
]);

// exceptions to rules
const exceptions$2 = {
  wholly: 'whole',
  fully: 'full',
  truly: 'true',
  gently: 'gentle',
  singly: 'single',
  customarily: 'customary',
  idly: 'idle',
  publically: 'public',
  quickly: 'quick',
  superbly: 'superb',
  cynically: 'cynical',
  well: 'good',// -?
};


const toAdjective = function (str) {
  if (!str.endsWith('ly')) {
    return null
  }
  // 'electronic' vs 'electronical'
  if (ical.has(str)) {
    return str.replace(/ically/, 'ical')
  }
  if (noAdj.has(str)) {
    return null
  }
  if (exceptions$2.hasOwnProperty(str)) {
    return exceptions$2[str]
  }
  return suffixLoop$1(str, suffixes$2) || str
};

// console.log(toAdjective('emphatically'))
// console.log(toAdjective('usually'))
// console.log(toAdjective('mechanically'))
// console.log(toAdjective('vertically'))

const suffixes$1 = [
  null,
  {
    y: 'ily'
  },
  {
    ly: 'ly',//unchanged
    ic: 'ically'
  },
  {
    ial: 'ially',
    ual: 'ually',
    tle: 'tly',
    ble: 'bly',
    ple: 'ply',
    ary: 'arily',
  },
  {},
  {},
  {},
];

const exceptions$1 = {
  cool: 'cooly',
  whole: 'wholly',
  full: 'fully',
  good: 'well',
  idle: 'idly',
  public: 'publicly',
  single: 'singly',
  special: 'especially',
};

// a lot of adjectives *don't really* have a adverb
// 'roomy' -> 'roomily'
// but here, conjugate what it would be, if it made sense to
const toAdverb = function (str) {
  if (exceptions$1.hasOwnProperty(str)) {
    return exceptions$1[str]
  }
  let adv = suffixLoop$1(str, suffixes$1);
  if (!adv) {
    adv = str + 'ly';
  }
  // only return this if it exists in lexicon?
  // console.log(model.one.lexicon[adv])
  return adv
};
// console.log(toAdverb('unsightly'))

// import toNoun from './conjugate/toNoun.js'

const all$1 = function (str, model) {
  let arr = [str];
  arr.push(toSuperlative(str, model));
  arr.push(toComparative(str, model));
  arr.push(toAdverb(str));
  arr = arr.filter(s => s);
  arr = new Set(arr);
  return Array.from(arr)
};


var adjectives$1 = {
  toSuperlative, toComparative, toAdverb, toNoun,
  fromAdverb: toAdjective, fromSuperlative, fromComparative,
  all: all$1,
};

var transform = {
  noun: nouns$2,
  verb: verbs$3,
  adjective: adjectives$1
};

// transformations to make on our lexicon
var byTag = {
  // add plural forms of singular nouns
  Singular: (word, lex, methods, model) => {
    let already = model.one.lexicon;
    let plural = methods.two.transform.noun.toPlural(word, model);
    if (!already[plural]) {
      lex[plural] = lex[plural] || 'Plural';
    }
  },
  // 'lawyer', 'manager' plural forms
  Actor: (word, lex, methods, model) => {
    let already = model.one.lexicon;
    let plural = methods.two.transform.noun.toPlural(word, model);
    if (!already[plural]) {
      lex[plural] = lex[plural] || ['Plural', 'Actor'];
    }
  },

  // superlative/ comparative forms for adjectives
  Comparable: (word, lex, methods, model) => {
    let already = model.one.lexicon;
    let { toSuperlative, toComparative } = methods.two.transform.adjective;
    // fast -> fastest
    let sup = toSuperlative(word, model);
    if (!already[sup]) {
      lex[sup] = lex[sup] || 'Superlative';
    }
    // fast -> faster
    let comp = toComparative(word, model);
    if (!already[comp]) {
      lex[comp] = lex[comp] || 'Comparative';
    }
    // overwrite
    lex[word] = 'Adjective';
  },

  // 'german' -> 'germans'
  Demonym: (word, lex, methods, model) => {
    let plural = methods.two.transform.noun.toPlural(word, model);
    lex[plural] = lex[plural] || ['Demonym', 'Plural'];
  },

  // conjugate all forms of these verbs
  Infinitive: (word, lex, methods, model) => {
    let already = model.one.lexicon;
    let all = methods.two.transform.verb.conjugate(word, model);
    Object.entries(all).forEach(a => {
      if (!already[a[1]] && !lex[a[1]] && a[0] !== 'FutureTense') {
        lex[a[1]] = a[0];
      }
    });
  },

  // 'walk up' should conjugate, too
  PhrasalVerb: (word, lex, methods, model) => {
    let already = model.one.lexicon;
    lex[word] = ['PhrasalVerb', 'Infinitive'];
    let _multi = model.one._multiCache;
    let [inf, rest] = word.split(' ');
    // add root verb
    if (!already[inf]) {
      lex[inf] = lex[inf] || 'Infinitive';
    }
    // conjugate it
    let all = methods.two.transform.verb.conjugate(inf, model);
    delete all.FutureTense;
    Object.entries(all).forEach(a => {
      // not 'walker up', or 'had taken up'
      if (a[0] === 'Actor' || a[1] === '') {
        return
      }
      // add the root verb, alone
      if (!lex[a[1]] && !already[a[1]]) {
        lex[a[1]] = a[0];
      }
      _multi[a[1]] = 2;
      let str = a[1] + ' ' + rest;
      lex[str] = lex[str] || [a[0], 'PhrasalVerb'];
    });
  },

  // expand 'million'
  Multiple: (word, lex) => {
    lex[word] = ['Multiple', 'Cardinal'];
    // 'millionth'
    lex[word + 'th'] = ['Multiple', 'Ordinal'];
    // 'millionths'
    lex[word + 'ths'] = ['Multiple', 'Fraction'];
  },
  // expand number-words
  Cardinal: (word, lex) => {
    lex[word] = ['TextValue', 'Cardinal'];
  },

  // 'millionth'
  Ordinal: (word, lex) => {
    lex[word] = ['TextValue', 'Ordinal'];
    lex[word + 's'] = ['TextValue', 'Fraction'];
  },
  // 'thames'
  Place: (word, lex) => {
    lex[word] = ['Place', 'ProperNoun'];
  },
  // 'ontario'
  Region: (word, lex) => {
    lex[word] = ['Region', 'ProperNoun'];
  },
};

// derive clever things from our lexicon key-value pairs
// this method runs as the pre-tagger plugin gets loaded
const expand$1 = function (words, world) {
  const { methods, model } = world;
  let lex = {};
  // console.log('start:', Object.keys(lex).length)
  let _multi = {};
  // go through each word in this key-value obj:
  Object.keys(words).forEach(word => {
    let tag = words[word];
    // normalize lexicon a little bit
    word = word.toLowerCase().trim();
    word = word.replace(/'s\b/, '');
    // cache multi-word terms
    let split = word.split(/ /);
    if (split.length > 1) {
      // prefer longer ones
      if (_multi[split[0]] === undefined || split.length > _multi[split[0]]) {
        _multi[split[0]] = split.length;
      }
    }
    // do any clever-business, by it's tag
    if (byTag.hasOwnProperty(tag) === true) {
      byTag[tag](word, lex, methods, model);
    }
    lex[word] = lex[word] || tag;
  });
  // cleanup
  delete lex[''];
  delete lex[null];
  delete lex[' '];
  return { lex, _multi }
};

// roughly, split a document by comma or semicolon

const splitOn = function (terms, i) {
  const isNum = /^[0-9]+$/;
  let term = terms[i];
  // early on, these may not be dates yet:
  if (!term) {
    return false
  }
  const maybeDate = new Set(['may', 'april', 'august', 'jan']);
  // veggies, like figs
  if (term.normal === 'like' || maybeDate.has(term.normal)) {
    return false
  }
  // toronto, canada  - tuesday, march
  if (term.tags.has('Place') || term.tags.has('Date')) {
    return false
  }
  if (terms[i - 1]) {
    let lastTerm = terms[i - 1];
    // thursday, june
    if (lastTerm.tags.has('Date') || maybeDate.has(lastTerm.normal)) {
      return false
    }
    // pretty, nice, and fun
    if (lastTerm.tags.has('Adjective') || term.tags.has('Adjective')) {
      return false
    }
  }
  // don't split numbers, yet
  let str = term.normal;
  if (str.length === 1 || str.length === 2 || str.length === 4) {
    if (isNum.test(str)) {
      return false
    }
  }
  return true
};

// kind-of a dirty sentence chunker
const quickSplit = function (document) {
  const splitHere = /[,:;]/;
  let arr = [];
  document.forEach(terms => {
    let start = 0;
    terms.forEach((term, i) => {
      // does it have a comma/semicolon ?
      if (splitHere.test(term.post) && splitOn(terms, i + 1)) {
        arr.push(terms.slice(start, i + 1));
        start = i + 1;
      }
    });
    if (start < terms.length) {
      arr.push(terms.slice(start, terms.length));
    }
  });
  return arr
};

//similar to plural/singularize rules, but not the same
const isPlural$3 = {
  e: ['mice', 'louse', 'antennae', 'formulae', 'nebulae', 'vertebrae', 'vitae'],
  i: ['tia', 'octopi', 'viri', 'radii', 'nuclei', 'fungi', 'cacti', 'stimuli'],
  n: ['men'],
  t: ['feet'],
};
// plural words as exceptions to suffix-rules
const exceptions = new Set([
  // 'formulas',
  // 'umbrellas',
  // 'gorillas',
  // 'koalas',
  'israelis',
  'menus',
  'logos',
]);

const notPlural$1 = [
  'bus',
  'mas', //christmas
  'was',
  // 'las',
  'ias', //alias
  'xas',
  'vas',
  'cis', //probocis
  'lis',
  'nis', //tennis
  'ois',
  'ris',
  'sis', //thesis
  'tis', //mantis, testis
  'xis',
  'aus',
  'cus',
  'eus', //nucleus
  'fus', //doofus
  'gus', //fungus
  'ius', //radius
  'lus', //stimulus
  'nus',
  'das',
  'ous',
  'pus', //octopus
  'rus', //virus
  'sus', //census
  'tus', //status,cactus
  'xus',
  'aos', //chaos
  'igos',
  'ados', //barbados
  'ogos',
  "'s",
  'ss',
];

const looksPlural = function (str) {
  // not long enough to be plural
  if (!str || str.length <= 3) {
    return false
  }
  // 'menus' etc
  if (exceptions.has(str)) {
    return true
  }
  let end = str[str.length - 1];
  // look at 'firemen'
  if (isPlural$3.hasOwnProperty(end)) {
    return isPlural$3[end].find(suff => str.endsWith(suff))
  }
  if (end !== 's') {
    return false
  }
  // look for 'virus'
  if (notPlural$1.find(suff => str.endsWith(suff))) {
    return false
  }
  // ends with an s, seems plural i guess.
  return true
};

var methods$1 = {
  two: {
    quickSplit,
    expandLexicon: expand$1,
    transform,
    looksPlural
  },
};

// import irregularVerbs from './conjugations.js'
// harvest list of irregulars for any juicy word-data
const expandIrregulars = function (model) {
  const { irregularPlurals } = model.two;
  const { lexicon } = model.one;
  Object.entries(irregularPlurals).forEach(a => {
    lexicon[a[0]] = lexicon[a[0]] || 'Singular';
    lexicon[a[1]] = lexicon[a[1]] || 'Plural';
  });
  return model
};

let tmpModel = {
  one: { lexicon: {} },
  two: { models }
};

// defaults for switches
const switchDefaults = {
  // 'pilot'
  'Actor|Verb': 'Actor', //
  // 'amusing'
  'Adj|Gerund': 'Adjective', //+conjugations
  // 'standard'
  'Adj|Noun': 'Adjective',
  // 'boiled'
  'Adj|Past': 'Adjective', //+conjugations
  // 'smooth'
  'Adj|Present': 'Adjective',//+conjugations
  // 'box'
  'Noun|Verb': 'Singular', //+conjugations (no-present)
  //'singing'
  'Noun|Gerund': 'Gerund', //+conjugations
  // 'hope'
  'Person|Noun': 'Noun',
  // 'April'
  'Person|Date': 'Month',
  // 'rob'
  'Person|Verb': 'FirstName',//+conjugations
  // 'victoria'
  'Person|Place': 'Person',
  // 'rusty'
  'Person|Adj': 'Comparative',
  // 'boxes'
  'Plural|Verb': 'Plural', //(these are already derivative)
  // 'miles'
  'Unit|Noun': 'Noun',
};

const expandLexicon = function (words, model) {
  // do clever tricks to grow the words
  const world = { model, methods: methods$1 };
  let { lex, _multi } = methods$1.two.expandLexicon(words, world);
  // store multiple-word terms in a cache
  Object.assign(model.one.lexicon, lex);
  Object.assign(model.one._multiCache, _multi);
  return model
};

// these words have no singular/plural conjugation
const addUncountables = function (words, model) {
  Object.keys(words).forEach(k => {
    if (words[k] === 'Uncountable') {
      model.two.uncountable[k] = true;
      words[k] = 'Uncountable';
    }
  });
  return model
};

const expandVerb = function (str, words, doPresent) {
  let obj = conjugate(str, tmpModel);
  words[obj.PastTense] = words[obj.PastTense] || 'PastTense';
  words[obj.Gerund] = words[obj.Gerund] || 'Gerund';
  if (doPresent === true) {
    // is this plural noun, or present-tense?
    words[obj.PresentTense] = words[obj.PresentTense] || 'PresentTense';
  }
};

const expandAdjective = function (str, words, model) {
  let sup = toSuperlative(str, model);
  words[sup] = words[sup] || 'Superlative';
  let comp = toComparative(str, model);
  words[comp] = words[comp] || 'Comparative';
};

const expandNoun = function (str, words, model) {
  let plur = pluralize(str, model);
  words[plur] = words[plur] || 'Plural';
};

// harvest ambiguous words for any conjugations
const expandVariable = function (switchWords, model) {
  let words = {};
  const lex = model.one.lexicon;
  //add first tag as an assumption for each variable word
  Object.keys(switchWords).forEach(w => {
    const name = switchWords[w];
    words[w] = switchDefaults[name];
    // conjugate some verbs
    if (name === 'Noun|Verb' || name === 'Person|Verb' || name === 'Actor|Verb') {
      expandVerb(w, lex, false);
    }
    if (name === 'Adj|Present') {
      expandVerb(w, lex, true);
      expandAdjective(w, lex, model);
    }
    if (name === 'Person|Adj') {
      expandAdjective(w, lex, model);
    }
    // add infinitives for gerunds
    if (name === 'Adj|Gerund' || name === 'Noun|Gerund') {
      let inf = toInfinitive$1(w, tmpModel, 'Gerund');
      if (!lex[inf]) {
        words[inf] = 'Infinitive'; //expand it later
      }
    }
    // add plurals for nouns
    if (name === 'Noun|Gerund' || name === 'Adj|Noun' || name === 'Person|Noun') {
      expandNoun(w, lex, model);
    }
    if (name === 'Adj|Past') {
      let inf = toInfinitive$1(w, tmpModel, 'PastTense');
      if (!lex[inf]) {
        words[inf] = 'Infinitive'; //expand it later
      }
    }
  });
  // add conjugations
  model = expandLexicon(words, model);
  return model
};

const expand = function (model) {
  model = expandLexicon(model.one.lexicon, model);
  model = addUncountables(model.one.lexicon, model);
  model = expandVariable(model.two.switches, model);
  model = expandIrregulars(model);
  return model
};

let model$1 = {
  one: {
    _multiCache: {},
    lexicon,
    frozenLex,
  },
  two: {
    irregularPlurals,
    models,

    suffixPatterns,
    prefixPatterns,
    endsWith,
    neighbours: neighbours$1,

    regexNormal,
    regexText,
    regexNumbers,

    switches,
    clues,

    uncountable: {},

    orgWords,
    placeWords,
  },
};
model$1 = expand(model$1);

// console.log(model.one.lexicon.see)

const byPunctuation = function (terms, i, model, world) {
  const setTag = world.methods.one.setTag;
  // colon following first word
  // edit: foo
  // breaking: foobar
  if (terms.length >= 3) {
    const hasColon = /:/;
    let post = terms[0].post;
    if (post.match(hasColon)) {
      // phone: 555-2938
      let nextTerm = terms[1];
      if (nextTerm.tags.has('Value') || nextTerm.tags.has('Email') || nextTerm.tags.has('PhoneNumber')) {
        return
      }
      //
      setTag([terms[0]], 'Expression', world, null, `2-punct-colon''`);
    }
  }
};

const byHyphen = function (terms, i, model, world) {
  const setTag = world.methods.one.setTag;
  // two words w/ a dash
  if (terms[i].post === '-' && terms[i + 1]) {
    setTag([terms[i], terms[i + 1]], 'Hyphenated', world, null, `1-punct-hyphen''`);

    // bone-headed, man-made, good-tempered, coursely-ground
    // if (terms[i + 1].tags.has('PastTense')) {
    //   let tags = terms[i].tags
    //   if (tags.has('Noun') || tags.has('Adverb')) {
    //     setTag([terms[i], terms[i + 1]], 'Adjective', world, null, `2-punct-dash''`)
    //   }

    // }
  }
};

const prefix$1 = /^(under|over|mis|re|un|dis|semi)-?/;

const tagSwitch = function (terms, i, model) {
  const switches = model.two.switches;
  let term = terms[i];
  if (switches.hasOwnProperty(term.normal)) {
    term.switch = switches[term.normal];
    return
  }
  // support 'restrike' -> 'strike'
  if (prefix$1.test(term.normal)) {
    let stem = term.normal.replace(prefix$1, '');
    if (stem.length > 3 && switches.hasOwnProperty(stem)) {
      term.switch = switches[stem];
    }
  }
};

// verbose-mode tagger debuging
const log = (term, tag, reason = '') => {
  const yellow = str => '\x1b[33m\x1b[3m' + str + '\x1b[0m';
  const i = str => '\x1b[3m' + str + '\x1b[0m';
  let word = term.text || '[' + term.implicit + ']';
  if (typeof tag !== 'string' && tag.length > 2) {
    tag = tag.slice(0, 2).join(', #') + ' +'; //truncate the list of tags
  }
  tag = typeof tag !== 'string' ? tag.join(', #') : tag;
  console.log(` ${yellow(word).padEnd(24)} \x1b[32mâ†’\x1b[0m #${tag.padEnd(22)}  ${i(reason)}`); // eslint-disable-line
};

// a faster version than the user-facing one in ./methods
const fastTag = function (term, tag, reason) {
  if (!tag || tag.length === 0) {
    return
  }
  if (term.frozen === true) {
    return
  }
  // some logging for debugging
  const env = typeof process === 'undefined' || !process.env ? self.env || {} : process.env;
  if (env && env.DEBUG_TAGS) {
    log(term, tag, reason);
  }
  term.tags = term.tags || new Set();
  if (typeof tag === 'string') {
    term.tags.add(tag);
  } else {
    tag.forEach(tg => term.tags.add(tg));
  }
};

// tags that are neither plural or singular
const uncountable = [
  'Acronym',
  'Abbreviation',
  'ProperNoun',
  'Uncountable',
  'Possessive',
  'Pronoun',
  'Activity',
  'Honorific',
  'Month',
];
// try to guess if each noun is a plural/singular
const setPluralSingular = function (term) {
  if (!term.tags.has('Noun') || term.tags.has('Plural') || term.tags.has('Singular')) {
    return
  }
  if (uncountable.find(tag => term.tags.has(tag))) {
    return
  }
  if (looksPlural(term.normal)) {
    fastTag(term, 'Plural', '3-plural-guess');
  } else {
    fastTag(term, 'Singular', '3-singular-guess');
  }
};

// try to guess the tense of a naked verb
const setTense = function (term) {
  let tags = term.tags;
  if (tags.has('Verb') && tags.size === 1) {
    let guess = getTense$1(term.normal);
    if (guess) {
      fastTag(term, guess, '3-verb-tense-guess');
    }
  }
};

//add deduced parent tags to our terms
const fillTags = function (terms, i, model) {
  let term = terms[i];
  //there is probably just one tag, but we'll allow more
  let tags = Array.from(term.tags);
  for (let k = 0; k < tags.length; k += 1) {
    if (model.one.tagSet[tags[k]]) {
      let toAdd = model.one.tagSet[tags[k]].parents;
      fastTag(term, toAdd, ` -inferred by #${tags[k]}`);
    }
  }
  // turn 'Noun' into Plural/Singular
  setPluralSingular(term);
  // turn 'Verb' into Present/PastTense
  setTense(term);
};

const titleCase$1 = /^\p{Lu}[\p{Ll}'â€™]/u;
const hasNumber = /[0-9]/;
const notProper = ['Date', 'Month', 'WeekDay', 'Unit', 'Expression'];

// roman numeral by regex
const hasIVX = /[IVX]/; // does it ~look like~ a roman numeral?
// quick-version
const romanNumeral = /^[IVXLCDM]{2,}$/;
// https://stackoverflow.com/a/267405/168877
const romanNumValid = /^M{0,4}(CM|CD|D?C{0,3})(XC|XL|L?X{0,3})(IX|IV|V?I{0,3})$/;
const nope = {
  li: true,
  dc: true,
  md: true,
  dm: true,
  ml: true,
};

// if it's a unknown titlecase word, it's a propernoun
const checkCase = function (terms, i, model) {
  let term = terms[i];
  // assume terms are already indexed
  term.index = term.index || [0, 0];
  let index = term.index[1];
  let str = term.text || ''; //need case info
  // titlecase and not first word of sentence
  if (index !== 0 && titleCase$1.test(str) === true && hasNumber.test(str) === false) {
    // skip Dates and stuff
    if (notProper.find(tag => term.tags.has(tag))) {
      return null
    }
    // first word in a quotation?
    if (term.pre.match(/["']$/)) {
      return null
    }
    if (term.normal === 'the') {
      return null
    }
    fillTags(terms, i, model);
    if (!term.tags.has('Noun') && !term.frozen) {
      term.tags.clear();
    }
    fastTag(term, 'ProperNoun', '2-titlecase');
    return true
  }
  //roman numberals - XVII
  if (str.length >= 2 && romanNumeral.test(str) && hasIVX.test(str) && romanNumValid.test(str) && !nope[term.normal]) {
    fastTag(term, 'RomanNumeral', '2-xvii');
    return true
  }

  return null
};

//sweep-through all suffixes
const suffixLoop = function (str = '', suffixes = []) {
  const len = str.length;
  let max = 7;
  if (len <= max) {
    max = len - 1;
  }
  for (let i = max; i > 1; i -= 1) {
    let suffix = str.substring(len - i, len);
    if (suffixes[suffix.length].hasOwnProperty(suffix) === true) {
      // console.log(suffix)
      let tag = suffixes[suffix.length][suffix];
      return tag
    }
  }
  return null
};

// decide tag from the ending of the word
const tagBySuffix = function (terms, i, model) {
  let term = terms[i];
  if (term.tags.size === 0) {
    let tag = suffixLoop(term.normal, model.two.suffixPatterns);
    if (tag !== null) {
      fastTag(term, tag, '2-suffix');
      term.confidence = 0.7;
      return true
    }
    // try implicit form of word, too
    if (term.implicit) {
      tag = suffixLoop(term.implicit, model.two.suffixPatterns);
      if (tag !== null) {
        fastTag(term, tag, '2-implicit-suffix');
        term.confidence = 0.7;
        return true
      }
    }
    // Infinitive suffix + 's' can be PresentTense
    // if (term.normal[term.normal.length - 1] === 's') {
    //   let str = term.normal.replace(/s$/, '')
    //   if (suffixLoop(str, model.two.suffixPatterns) === 'Infinitive') {
    //     console.log(str)
    //     fastTag(term, 'PresentTense', '2-implied-present')
    //     term.confidence = 0.5
    //     return true
    //   }
    // }
  }
  return null
};

const hasApostrophe = /['â€˜â€™â€›â€µâ€²`Â´]/;

// normal regexes
const doRegs = function (str, regs) {
  for (let i = 0; i < regs.length; i += 1) {
    if (regs[i][0].test(str) === true) {
      return regs[i]
    }
  }
  return null
};
// suffix-regexes, indexed by last-character
const doEndsWith = function (str = '', byEnd) {
  let char = str[str.length - 1];
  if (byEnd.hasOwnProperty(char) === true) {
    let regs = byEnd[char] || [];
    for (let r = 0; r < regs.length; r += 1) {
      if (regs[r][0].test(str) === true) {
        return regs[r]
      }
    }
  }
  return null
};

const checkRegex = function (terms, i, model, world) {
  const setTag = world.methods.one.setTag;
  let { regexText, regexNormal, regexNumbers, endsWith } = model.two;
  let term = terms[i];
  let normal = term.machine || term.normal;
  let text = term.text;
  // keep dangling apostrophe?
  if (hasApostrophe.test(term.post) && !hasApostrophe.test(term.pre)) {
    text += term.post.trim();
  }
  let arr = doRegs(text, regexText) || doRegs(normal, regexNormal);
  // hide a bunch of number regexes behind this one
  if (!arr && /[0-9]/.test(normal)) {
    arr = doRegs(normal, regexNumbers);
  }
  // only run endsWith if we're desperate
  if (!arr && term.tags.size === 0) {
    arr = doEndsWith(normal, endsWith);
  }
  if (arr) {
    // console.log(arr)
    setTag([term], arr[1], world, null, `2-regex-'${arr[2] || arr[0]}'`);
    term.confidence = 0.6;
    return true
  }
  return null
};

// const prefixes = /^(anti|re|un|non|extra|inter|intra|over)([a-z-]{3})/

//sweep-through all prefixes
const prefixLoop = function (str = '', prefixes = []) {
  const len = str.length;
  let max = 7;
  if (max > len - 3) {
    max = len - 3;
  }
  for (let i = max; i > 2; i -= 1) {
    let prefix = str.substring(0, i);
    if (prefixes[prefix.length].hasOwnProperty(prefix) === true) {
      let tag = prefixes[prefix.length][prefix];
      return tag
    }
  }
  return null
};

// give 'overwork' the same tag as 'work'
const checkPrefix = function (terms, i, model) {
  let term = terms[i];
  if (term.tags.size === 0) {
    let tag = prefixLoop(term.normal, model.two.prefixPatterns);
    if (tag !== null) {
      // console.log(term.normal, '->', tag)
      fastTag(term, tag, '2-prefix');
      term.confidence = 0.5;
      return true
    }
  }
  return null
};

const min = 1400;
const max = 2100;

const dateWords = new Set([
  'in',
  'on',
  'by',
  'until',
  'for',
  'to',
  'during',
  'throughout',
  'through',
  'within',
  'before',
  'after',
  'of',
  'this',
  'next',
  'last',
  'circa',
  'around',
  'post',
  'pre',
  'budget',
  'classic',
  'plan',
  'may',
]);

const seemsGood = function (term) {
  if (!term) {
    return false
  }
  let str = term.normal || term.implicit;
  if (dateWords.has(str)) {
    return true
  }
  if (term.tags.has('Date') || term.tags.has('Month') || term.tags.has('WeekDay') || term.tags.has('Year')) {
    return true
  }
  // 1999 Film Festival
  if (term.tags.has('ProperNoun')) {
    return true
  }
  return false
};

const seemsOkay = function (term) {
  if (!term) {
    return false
  }
  if (term.tags.has('Ordinal')) {
    return true
  }
  // untagged 'june 13 2007'
  if (term.tags.has('Cardinal') && term.normal.length < 3) {
    return true
  }
  // 2020 was ..
  if (term.normal === 'is' || term.normal === 'was') {
    return true
  }
  return false
};

const seemsFine = function (term) {
  return term && (term.tags.has('Date') || term.tags.has('Month') || term.tags.has('WeekDay') || term.tags.has('Year'))
};

// recognize '1993' as a year
const tagYear = function (terms, i) {
  const term = terms[i];
  if (term.tags.has('NumericValue') && term.tags.has('Cardinal') && term.normal.length === 4) {
    let num = Number(term.normal);
    // number between 1400 and 2100
    if (num && !isNaN(num)) {
      if (num > min && num < max) {
        let lastTerm = terms[i - 1];
        let nextTerm = terms[i + 1];
        if (seemsGood(lastTerm) || seemsGood(nextTerm)) {
          return fastTag(term, 'Year', '2-tagYear')
        }
        // or is it really-close to a year?
        if (num >= 1920 && num < 2025) {
          // look at neighbours
          if (seemsOkay(lastTerm) || seemsOkay(nextTerm)) {
            return fastTag(term, 'Year', '2-tagYear-close')
          }
          // look at far-neighbours
          if (seemsFine(terms[i - 2]) || seemsFine(terms[i + 2])) {
            return fastTag(term, 'Year', '2-tagYear-far')
          }
          // 'the 2002 hit', 'my 1950 convertable'
          if (lastTerm && (lastTerm.tags.has('Determiner') || lastTerm.tags.has('Possessive'))) {
            if (nextTerm && nextTerm.tags.has('Noun') && !nextTerm.tags.has('Plural')) {
              return fastTag(term, 'Year', '2-tagYear-noun')
            }
          }
        }
      }
    }
  }
  return null
};

const verbType = function (terms, i, model, world) {
  const setTag = world.methods.one.setTag;
  const term = terms[i];
  const types = ['PastTense', 'PresentTense', 'Auxiliary', 'Modal', 'Particle'];
  if (term.tags.has('Verb')) {
    let type = types.find(typ => term.tags.has(typ));
    // is it a bare #Verb tag?
    if (!type) {
      setTag([term], 'Infinitive', world, null, `2-verb-type''`);
    }
  }
};

const oneLetterAcronym = /^[A-Z]('s|,)?$/;
const isUpperCase = /^[A-Z-]+$/;
const upperThenS = /^[A-Z]+s$/;
const periodAcronym = /([A-Z]\.)+[A-Z]?,?$/;
const noPeriodAcronym = /[A-Z]{2,}('s|,)?$/;
const lowerCaseAcronym = /([a-z]\.)+[a-z]\.?$/;

const oneLetterWord = {
  I: true,
  A: true,
};

// only assume these are places if they are uppercased
const places$1 = {
  la: true,
  ny: true,
  us: true,
  dc: true,
  gb: true,
};

// just uppercase acronyms, no periods - 'UNOCHA'
const isNoPeriodAcronym = function (term, model) {
  let str = term.text;
  // ensure it's all upper-case
  if (isUpperCase.test(str) === false) {
    // allow lower-case plural - 'MMVAs'
    if (str.length > 3 && upperThenS.test(str) === true) {
      str = str.replace(/s$/, '');
    } else {
      return false
    }
  }
  // long capitalized words are not usually either
  if (str.length > 5) {
    return false
  }
  // 'I' is not a acronym
  if (oneLetterWord.hasOwnProperty(str)) {
    return false
  }
  // known-words, like 'PIZZA' is not an acronym.
  if (model.one.lexicon.hasOwnProperty(term.normal)) {
    return false
  }
  //like N.D.A
  if (periodAcronym.test(str) === true) {
    return true
  }
  //like c.e.o
  if (lowerCaseAcronym.test(str) === true) {
    return true
  }
  //like 'F.'
  if (oneLetterAcronym.test(str) === true) {
    return true
  }
  //like NDA
  if (noPeriodAcronym.test(str) === true) {
    return true
  }
  return false
};

const isAcronym = function (terms, i, model) {
  let term = terms[i];
  //these are not acronyms
  if (term.tags.has('RomanNumeral') || term.tags.has('Acronym') || term.frozen) {
    return null
  }
  //non-period ones are harder
  if (isNoPeriodAcronym(term, model)) {
    term.tags.clear();
    fastTag(term, ['Acronym', 'Noun'], '3-no-period-acronym');
    // ny, la
    if (places$1[term.normal] === true) {
      fastTag(term, 'Place', '3-place-acronym');
    }
    // UFOs
    if (upperThenS.test(term.text) === true) {
      fastTag(term, 'Plural', '3-plural-acronym');
    }
    // if(term.normal
    return true
  }
  // one-letter acronyms
  if (!oneLetterWord.hasOwnProperty(term.text) && oneLetterAcronym.test(term.text)) {
    term.tags.clear();
    fastTag(term, ['Acronym', 'Noun'], '3-one-letter-acronym');
    return true
  }
  //if it's a very-short organization?
  if (term.tags.has('Organization') && term.text.length <= 3) {
    fastTag(term, 'Acronym', '3-org-acronym');
    return true
  }
  // upper-case org, like UNESCO
  if (term.tags.has('Organization') && isUpperCase.test(term.text) && term.text.length <= 6) {
    fastTag(term, 'Acronym', '3-titlecase-acronym');
    return true
  }
  return null
};

const lookAtWord = function (term, words) {
  if (!term) {
    return null
  }
  // look at prev word <-
  let found = words.find(a => term.normal === a[0]);
  if (found) {
    return found[1]
  }
  return null
};

const lookAtTag = function (term, tags) {
  if (!term) {
    return null
  }
  let found = tags.find(a => term.tags.has(a[0]));
  if (found) {
    return found[1]
  }
  return null
};

// look at neighbours for hints on unknown words
const neighbours = function (terms, i, model) {
  const { leftTags, leftWords, rightWords, rightTags } = model.two.neighbours;
  let term = terms[i];
  if (term.tags.size === 0) {
    let tag = null;
    // look left <-
    tag = tag || lookAtWord(terms[i - 1], leftWords);
    // look right ->
    tag = tag || lookAtWord(terms[i + 1], rightWords);
    // look left <-
    tag = tag || lookAtTag(terms[i - 1], leftTags);
    // look right ->
    tag = tag || lookAtTag(terms[i + 1], rightTags);
    if (tag) {
      fastTag(term, tag, '3-[neighbour]');
      fillTags(terms, i, model);
      terms[i].confidence = 0.2;
      return true
    }
  }
  return null
};

const isTitleCase$2 = (str) => /^\p{Lu}[\p{Ll}'â€™]/u.test(str);

const isOrg = function (term, i, yelling) {
  if (!term) {
    return false
  }
  if (term.tags.has('FirstName') || term.tags.has('Place')) {
    return false
  }
  if (term.tags.has('ProperNoun') || term.tags.has('Organization') || term.tags.has('Acronym')) {
    return true
  }
  // allow anything titlecased to be an org
  if (!yelling && isTitleCase$2(term.text)) {
    // only tag a titlecased first-word, if it checks-out
    if (i === 0) {
      return term.tags.has('Singular')
    }
    return true
  }
  return false
};

const tagOrgs$1 = function (terms, i, world, yelling) {
  const orgWords = world.model.two.orgWords;
  const setTag = world.methods.one.setTag;
  let term = terms[i];
  let str = term.machine || term.normal;
  if (orgWords[str] === true && isOrg(terms[i - 1], i - 1, yelling)) {
    setTag([terms[i]], 'Organization', world, null, '3-[org-word]');
    // loop backwards, tag organization-like things
    for (let t = i; t >= 0; t -= 1) {
      if (isOrg(terms[t], t, yelling)) {
        setTag([terms[t]], 'Organization', world, null, '3-[org-word]');
      } else {
        break
      }
    }
  }
  return null
};

const isTitleCase$1 = str => /^\p{Lu}[\p{Ll}'â€™]/u.test(str);
const isPossessive$1 = /'s$/;

// words that can fit inside a place
const placeCont = new Set([
  'athletic',
  'city',
  'community',
  'eastern',
  'federal',
  'financial',
  'great',
  'historic',
  'historical',
  'local',
  'memorial',
  'municipal',
  'national',
  'northern',
  'provincial',
  'southern',
  'state',
  'western',
  'spring',
  'pine',
  'sunset',
  'view',
  'oak',
  'maple',
  'spruce',
  'cedar',
  'willow',
]);
// center of...
const noBefore = new Set(['center', 'centre', 'way', 'range', 'bar', 'bridge', 'field', 'pit']);

const isPlace = function (term, i, yelling) {
  if (!term) {
    return false
  }
  let tags = term.tags;
  if (tags.has('Organization') || tags.has('Possessive') || isPossessive$1.test(term.normal)) {
    return false
  }
  if (tags.has('ProperNoun') || tags.has('Place')) {
    return true
  }
  // allow anything titlecased to be an org
  if (!yelling && isTitleCase$1(term.text)) {
    // only tag a titlecased first-word, if it checks-out
    if (i === 0) {
      return tags.has('Singular')
    }
    return true
  }
  return false
};

const tagOrgs = function (terms, i, world, yelling) {
  const placeWords = world.model.two.placeWords;
  const setTag = world.methods.one.setTag;
  let term = terms[i];
  let str = term.machine || term.normal;

  // 'river', delta, street, etc
  if (placeWords[str] === true) {
    //loop backward - 'Foo River ...'
    for (let n = i - 1; n >= 0; n -= 1) {
      // 'municipal ...'
      if (placeCont.has(terms[n].normal)) {
        continue
      }
      if (isPlace(terms[n], n, yelling)) {
        setTag(terms.slice(n, i + 1), 'Place', world, null, '3-[place-of-foo]');
        continue
      }
      break
    }
    //loop forward - 'River of Foo...'
    // 'center of x'
    if (noBefore.has(str)) {
      return false
    }
    for (let n = i + 1; n < terms.length; n += 1) {
      if (isPlace(terms[n], n, yelling)) {
        setTag(terms.slice(i, n + 1), 'Place', world, null, '3-[foo-place]');
        return true
      }
      // 'municipal ...'
      if (terms[n].normal === 'of' || placeCont.has(terms[n].normal)) {
        continue
      }
      break
    }
  }
  return null
};

const nounFallback = function (terms, i, model) {
  let isEmpty = false;
  let tags = terms[i].tags;
  if (tags.size === 0) {
    isEmpty = true;
  } else if (tags.size === 1) {
    // weaker tags to ignore
    if (tags.has('Hyphenated') || tags.has('HashTag') || tags.has('Prefix') || tags.has('SlashedTerm')) {
      isEmpty = true;
    }
  }
  if (isEmpty) {
    fastTag(terms[i], 'Noun', '3-[fallback]');
    // try to give it singluar/plural tags, too
    fillTags(terms, i, model);
    terms[i].confidence = 0.1;
  }
};

const isTitleCase = /^[A-Z][a-z]/;

const isCapital = (terms, i) => {
  if (terms[i].tags.has('ProperNoun') && isTitleCase.test(terms[i].text)) {// 'Comfort Inn'
    return 'Noun'
  }
  return null
};

const isAlone = (terms, i, tag) => {
  if (i === 0 && !terms[1]) {// 'Help'
    return tag
  }
  return null
};

// 'a rental'
const isEndNoun = function (terms, i) {
  if (!terms[i + 1] && terms[i - 1] && terms[i - 1].tags.has('Determiner')) {
    return 'Noun'
  }
  return null
};

// the first word in the sentence
const isStart = function (terms, i, tag) {
  if (i === 0 && terms.length > 3) {
    return tag
  }
  return null
};

const adhoc = {
  'Adj|Gerund': (terms, i) => {
    return isCapital(terms, i)
  },
  'Adj|Noun': (terms, i) => {
    return isCapital(terms, i) || isEndNoun(terms, i)
  },
  'Actor|Verb': (terms, i) => {
    return isCapital(terms, i)
  },
  'Adj|Past': (terms, i) => {
    return isCapital(terms, i)
  },
  'Adj|Present': (terms, i) => {
    return isCapital(terms, i)
  },
  'Noun|Gerund': (terms, i) => {
    return isCapital(terms, i)
  },
  'Noun|Verb': (terms, i) => {
    return (i > 0 && isCapital(terms, i)) || isAlone(terms, i, 'Infinitive')
  },
  'Plural|Verb': (terms, i) => {
    return isCapital(terms, i) || isAlone(terms, i, 'PresentTense') || isStart(terms, i, 'Plural')
  },
  'Person|Noun': (terms, i) => {
    return isCapital(terms, i)
  },
  'Person|Verb': (terms, i) => {
    if (i !== 0) {
      return isCapital(terms, i)
    }
    return null
  },
  'Person|Adj': (terms, i) => {
    if (i === 0 && terms.length > 1) {
      return 'Person'
    }
    return isCapital(terms, i) ? 'Person' : null
  },
};

/* eslint-disable no-console */
const env = typeof process === 'undefined' || !process.env ? self.env || {} : process.env;
const prefix = /^(under|over|mis|re|un|dis|semi)-?/;

const checkWord = (term, obj) => {
  if (!term || !obj) {
    return null
  }
  let str = term.normal || term.implicit;
  let found = null;
  if (obj.hasOwnProperty(str)) {
    found = obj[str];
  }
  if (found && env.DEBUG_TAGS) {
    console.log(`\n  \x1b[2m\x1b[3m     â†“ - '${str}' \x1b[0m`);
  }
  return found
};

const checkTag = (term, obj = {}, tagSet) => {
  if (!term || !obj) {
    return null
  }
  // rough sort, so 'Noun' is after ProperNoun, etc
  let tags = Array.from(term.tags).sort((a, b) => {
    let numA = tagSet[a] ? tagSet[a].parents.length : 0;
    let numB = tagSet[b] ? tagSet[b].parents.length : 0;
    return numA > numB ? -1 : 1
  });
  let found = tags.find(tag => obj[tag]);
  if (found && env.DEBUG_TAGS) {
    console.log(`  \x1b[2m\x1b[3m      â†“ - '${term.normal || term.implicit}' (#${found})  \x1b[0m`);
  }
  found = obj[found];
  return found
};

const pickTag = function (terms, i, clues, model) {
  if (!clues) {
    return null
  }
  const beforeIndex = terms[i - 1]?.text !== 'also' ? i - 1 : Math.max(0, i - 2);
  const tagSet = model.one.tagSet;
  // look -> right word, first
  let tag = checkWord(terms[i + 1], clues.afterWords);
  // look <- left word, second
  tag = tag || checkWord(terms[beforeIndex], clues.beforeWords);
  // look <- left tag
  tag = tag || checkTag(terms[beforeIndex], clues.beforeTags, tagSet);
  // look -> right tag
  tag = tag || checkTag(terms[i + 1], clues.afterTags, tagSet);
  // console.log(clues)
  return tag
};

// words like 'bob' that can change between two tags
const doSwitches = function (terms, i, world) {
  const model = world.model;
  const setTag = world.methods.one.setTag;
  const { switches, clues } = model.two;
  const term = terms[i];
  let str = term.normal || term.implicit || '';
  // support prefixes for switching words
  if (prefix.test(str) && !switches[str]) {
    str = str.replace(prefix, ''); // could use some guards, here
  }
  if (term.switch) {
    let form = term.switch;
    // skip propernouns, acronyms, etc
    if (term.tags.has('Acronym') || term.tags.has('PhrasalVerb')) {
      return
    }
    let tag = pickTag(terms, i, clues[form], model);
    // lean-harder on some variable forms
    if (adhoc[form]) {
      tag = adhoc[form](terms, i) || tag;
    }
    // did we find anything?
    if (tag) {
      // tag it
      setTag([term], tag, world, null, `3-[switch] (${form})`);
      // add plural/singular etc.
      fillTags(terms, i, model);
    } else if (env.DEBUG_TAGS) {
      console.log(`\n -> X  - '${str}'  : (${form})  `);
    }
  }
};

const beside = {
  there: true, //go there
  this: true, //try this
  it: true, //do it
  him: true,
  her: true,
  us: true, //tell us
};

// '[place] tea bags in hot water'
const imperative$1 = function (terms, world) {
  const setTag = world.methods.one.setTag;
  const multiWords = world.model.one._multiCache || {};
  let t = terms[0];
  let isRight = t.switch === 'Noun|Verb' || t.tags.has('Infinitive');
  if (isRight && terms.length >= 2) {
    // ensure rest of sentence is ok
    if (terms.length < 4 && !beside[terms[1].normal]) {
      return
    }
    // avoid multi-noun words like '[board] room'
    if (!t.tags.has('PhrasalVerb') && multiWords.hasOwnProperty(t.normal)) {
      return
    }
    // is the next word a noun? - 'compile information ..'
    let nextNoun = terms[1].tags.has('Noun') || terms[1].tags.has('Determiner');
    if (nextNoun) {
      // ensure no soon-verb -  'waste materials are ..'
      let soonVerb = terms.slice(1, 3).some(term => term.tags.has('Verb'));
      if (!soonVerb || t.tags.has('#PhrasalVerb')) {
        setTag([t], 'Imperative', world, null, '3-[imperative]');
      }
    }
  }
};

// is it all yelling-case?
const ignoreCase = function (terms) {
  // allow 'John F Kennedy'
  if (terms.filter(t => !t.tags.has('ProperNoun')).length <= 3) {
    return false
  }
  const lowerCase = /^[a-z]/;
  return terms.every(t => !lowerCase.test(t.text))
};

// taggers with no clause-splitting
const firstPass = function (docs, model, world) {
  docs.forEach(terms => {
    // check whitespace/punctuation
    byPunctuation(terms, 0, model, world);
  });
};

// these methods don't care about word-neighbours
const secondPass = function (terms, model, world, isYelling) {
  for (let i = 0; i < terms.length; i += 1) {
    // skip frozen terms, for now
    if (terms[i].frozen === true) {
      continue
    }
    // mark Noun|Verb on term metadata
    tagSwitch(terms, i, model);
    //  is it titlecased?
    if (isYelling === false) {
      checkCase(terms, i, model);
    }
    // look at word ending
    tagBySuffix(terms, i, model);
    // try look-like rules
    checkRegex(terms, i, model, world);
    // check for recognized prefix, like 'micro-'
    checkPrefix(terms, i, model);
    // turn '1993' into a year
    tagYear(terms, i);
  }
};

// neighbour-based tagging
const thirdPass = function (terms, model, world, isYelling) {
  for (let i = 0; i < terms.length; i += 1) {
    // let these tags get layered
    let found = isAcronym(terms, i, model);
    // deduce parent tags
    fillTags(terms, i, model);
    // look left+right for hints
    found = found || neighbours(terms, i, model);
    //  Â¯\_(ãƒ„)_/Â¯ - found nothing
    found = found || nounFallback(terms, i, model);
  }
  for (let i = 0; i < terms.length; i += 1) {
    // skip these
    if (terms[i].frozen === true) {
      continue
    }
    // Johnson LLC
    tagOrgs$1(terms, i, world, isYelling);
    // Wawel Castle
    tagOrgs(terms, i, world, isYelling);
    // verb-noun disambiguation, etc
    doSwitches(terms, i, world);
    // give bare verbs more tags
    verbType(terms, i, model, world);
    // hard-nosed
    byHyphen(terms, i, model, world);
  }
  // place tea bags
  imperative$1(terms, world);
};

const preTagger = function (view) {
  const { methods, model, world } = view;
  let docs = view.docs;
  // try some early stuff
  firstPass(docs, model, world);
  // roughly split sentences up by clause
  let document = methods.two.quickSplit(docs);
  // start with all terms
  for (let n = 0; n < document.length; n += 1) {
    let terms = document[n];
    // is it all upper-case?
    const isYelling = ignoreCase(terms);
    // guess by the letters
    secondPass(terms, model, world, isYelling);
    // guess by the neighbours
    thirdPass(terms, model, world, isYelling);
  }
  return document
};

const toRoot$2 = {
  // 'spencer's' -> 'spencer'
  'Possessive': (term) => {
    let str = term.machine || term.normal || term.text;
    str = str.replace(/'s$/, '');
    return str
  },
  // 'drinks' -> 'drink'
  'Plural': (term, world) => {
    let str = term.machine || term.normal || term.text;
    return world.methods.two.transform.noun.toSingular(str, world.model)
  },
  // ''
  'Copula': () => {
    return 'is'
  },
  // 'walked' -> 'walk'
  'PastTense': (term, world) => {
    let str = term.machine || term.normal || term.text;
    return world.methods.two.transform.verb.toInfinitive(str, world.model, 'PastTense')
  },
  // 'walking' -> 'walk'
  'Gerund': (term, world) => {
    let str = term.machine || term.normal || term.text;
    return world.methods.two.transform.verb.toInfinitive(str, world.model, 'Gerund')
  },
  // 'walks' -> 'walk'
  'PresentTense': (term, world) => {
    let str = term.machine || term.normal || term.text;
    if (term.tags.has('Infinitive')) {
      return str
    }
    return world.methods.two.transform.verb.toInfinitive(str, world.model, 'PresentTense')
  },
  // 'quieter' -> 'quiet'
  'Comparative': (term, world) => {
    let str = term.machine || term.normal || term.text;
    return world.methods.two.transform.adjective.fromComparative(str, world.model)
  },
  // 'quietest' -> 'quiet'
  'Superlative': (term, world) => {
    let str = term.machine || term.normal || term.text;
    return world.methods.two.transform.adjective.fromSuperlative(str, world.model)
  },
  // 'suddenly' -> 'sudden'
  'Adverb': (term, world) => {
    const { fromAdverb } = world.methods.two.transform.adjective;
    let str = term.machine || term.normal || term.text;
    return fromAdverb(str)
  },
};

const getRoot$1 = function (view) {
  const world = view.world;
  const keys = Object.keys(toRoot$2);
  view.docs.forEach(terms => {
    for (let i = 0; i < terms.length; i += 1) {
      const term = terms[i];
      for (let k = 0; k < keys.length; k += 1) {
        if (term.tags.has(keys[k])) {
          const fn = toRoot$2[keys[k]];
          let root = fn(term, world);
          if (term.normal !== root) {
            term.root = root;
          }
          break
        }
      }
    }
  });
};

// rough connection between compromise tagset and Penn Treebank
// https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html

const mapping$1 = {
  // adverbs
  // 'Comparative': 'RBR',
  // 'Superlative': 'RBS',
  Adverb: 'RB',

  // adjectives
  Comparative: 'JJR',
  Superlative: 'JJS',
  Adjective: 'JJ',
  TO: 'Conjunction',

  // verbs
  Modal: 'MD',
  Auxiliary: 'MD',
  Gerund: 'VBG', //throwing
  PastTense: 'VBD', //threw
  Participle: 'VBN', //thrown
  PresentTense: 'VBZ', //throws
  Infinitive: 'VB', //throw
  Particle: 'RP', //phrasal particle
  Verb: 'VB', // throw

  // pronouns
  Pronoun: 'PRP',

  // misc
  Cardinal: 'CD',
  Conjunction: 'CC',
  Determiner: 'DT',
  Preposition: 'IN',
  // 'Determiner': 'WDT',
  // 'Expression': 'FW',
  QuestionWord: 'WP',
  Expression: 'UH',

  //nouns
  Possessive: 'POS',
  ProperNoun: 'NNP',
  Person: 'NNP',
  Place: 'NNP',
  Organization: 'NNP',
  Singular: 'NN',
  Plural: 'NNS',
  Noun: 'NN',

  There: 'EX', //'there'
  // 'Adverb':'WRB',
  // 'Noun':'PDT', //predeterminer
  // 'Noun':'SYM', //symbol
  // 'Noun':'NFP', //

  //  WDT 	Wh-determiner
  // 	WP 	Wh-pronoun
  // 	WP$ 	Possessive wh-pronoun
  // 	WRB 	Wh-adverb
};

const toPenn = function (term) {
  // try some ad-hoc ones
  if (term.tags.has('ProperNoun') && term.tags.has('Plural')) {
    return 'NNPS'
  }
  if (term.tags.has('Possessive') && term.tags.has('Pronoun')) {
    return 'PRP$'
  }
  if (term.normal === 'there') {
    return 'EX'
  }
  if (term.normal === 'to') {
    return 'TO'
  }
  // run through an ordered list of tags
  let arr = term.tagRank || [];
  for (let i = 0; i < arr.length; i += 1) {
    if (mapping$1.hasOwnProperty(arr[i])) {
      return mapping$1[arr[i]]
    }
  }
  return null
};

const pennTag = function (view) {
  view.compute('tagRank');
  view.docs.forEach(terms => {
    terms.forEach(term => {
      term.penn = toPenn(term);
    });
  });
};

var compute$3 = { preTagger, root: getRoot$1, penn: pennTag };

const entity = ['Person', 'Place', 'Organization'];

var nouns$1 = {
  Noun: {
    not: ['Verb', 'Adjective', 'Adverb', 'Value', 'Determiner'],
  },
  Singular: {
    is: 'Noun',
    not: ['Plural', 'Uncountable'],
  },
  // 'Canada'
  ProperNoun: {
    is: 'Noun',
  },
  Person: {
    is: 'Singular',
    also: ['ProperNoun'],
    not: ['Place', 'Organization', 'Date'],
  },
  FirstName: {
    is: 'Person',
  },
  MaleName: {
    is: 'FirstName',
    not: ['FemaleName', 'LastName'],
  },
  FemaleName: {
    is: 'FirstName',
    not: ['MaleName', 'LastName'],
  },
  LastName: {
    is: 'Person',
    not: ['FirstName'],
  },
  // 'dr.'
  Honorific: {
    is: 'Person',
    not: ['FirstName', 'LastName', 'Value'],
  },
  Place: {
    is: 'Singular',
    not: ['Person', 'Organization'],
  },
  Country: {
    is: 'Place',
    also: ['ProperNoun'],
    not: ['City'],
  },
  City: {
    is: 'Place',
    also: ['ProperNoun'],
    not: ['Country'],
  },
  // 'california'
  Region: {
    is: 'Place',
    also: ['ProperNoun'],
  },
  Address: {
    // is: 'Place',
  },
  Organization: {
    is: 'ProperNoun',
    not: ['Person', 'Place'],
  },
  SportsTeam: {
    is: 'Organization',
  },
  School: {
    is: 'Organization',
  },
  Company: {
    is: 'Organization',
  },
  Plural: {
    is: 'Noun',
    not: ['Singular', 'Uncountable'],
  },
  // 'gravity'
  Uncountable: {
    is: 'Noun',
  },
  // 'it'
  Pronoun: {
    is: 'Noun',
    not: entity,
  },
  // 'swimmer'
  Actor: {
    is: 'Noun',
    not: ['Place', 'Organization'],
  },
  // walking
  Activity: {
    is: 'Noun',
    not: ['Person', 'Place'],
  },
  // kilometres
  Unit: {
    is: 'Noun',
    not: entity,
  },
  // canadian
  Demonym: {
    is: 'Noun',
    also: ['ProperNoun'],
    not: entity,
  },
  // [spencer's] hat
  Possessive: {
    is: 'Noun',
  },
  // 'yourself'
  Reflexive: {
    is: 'Pronoun',
  },
};

var verbs$2 = {
  Verb: {
    not: ['Noun', 'Adjective', 'Adverb', 'Value', 'Expression'],
  },
  // 'he [walks]'
  PresentTense: {
    is: 'Verb',
    not: ['PastTense', 'FutureTense'],
  },
  // 'will [walk]'
  Infinitive: {
    is: 'PresentTense',
    not: ['Gerund'],
  },
  // '[walk] now!'
  Imperative: {
    is: 'Verb',
    not: ['PastTense', 'Gerund', 'Copula'],
  },
  // walking
  Gerund: {
    is: 'PresentTense',
    not: ['Copula'],
  },
  // walked
  PastTense: {
    is: 'Verb',
    not: ['PresentTense', 'Gerund', 'FutureTense'],
  },
  // will walk
  FutureTense: {
    is: 'Verb',
    not: ['PresentTense', 'PastTense'],
  },
  // is/was
  Copula: {
    is: 'Verb',
  },
  // '[could] walk'
  Modal: {
    is: 'Verb',
    not: ['Infinitive'],
  },
  // 'awaken'
  Participle: {
    is: 'PastTense',
  },
  // '[will have had] walked'
  Auxiliary: {
    is: 'Verb',
    not: ['PastTense', 'PresentTense', 'Gerund', 'Conjunction'],
  },
  // 'walk out'
  PhrasalVerb: {
    is: 'Verb',
  },
  // 'walk [out]'
  Particle: {
    is: 'PhrasalVerb',
    not: ['PastTense', 'PresentTense', 'Copula', 'Gerund'],
  },
  // 'walked by'
  Passive: {
    is: 'Verb',
  },
};

var values = {
  Value: {
    not: ['Verb', 'Adjective', 'Adverb'],
  },
  Ordinal: {
    is: 'Value',
    not: ['Cardinal'],
  },
  Cardinal: {
    is: 'Value',
    not: ['Ordinal'],
  },
  Fraction: {
    is: 'Value',
    not: ['Noun'],
  },
  Multiple: {
    is: 'TextValue',
  },
  RomanNumeral: {
    is: 'Cardinal',
    not: ['TextValue'],
  },
  TextValue: {
    is: 'Value',
    not: ['NumericValue'],
  },
  NumericValue: {
    is: 'Value',
    not: ['TextValue'],
  },
  Money: {
    is: 'Cardinal',
  },
  Percent: {
    is: 'Value',
  },
};

var dates$1 = {
  Date: {
    not: ['Verb', 'Adverb', 'Adjective'],
  },
  Month: {
    is: 'Date',
    also: ['Noun'],
    not: ['Year', 'WeekDay', 'Time'],
  },
  WeekDay: {
    is: 'Date',
    also: ['Noun'],
  },
  Year: {
    is: 'Date',
    not: ['RomanNumeral'],
  },
  FinancialQuarter: {
    is: 'Date',
    not: 'Fraction',
  },
  // 'easter'
  Holiday: {
    is: 'Date',
    also: ['Noun'],
  },
  // 'summer'
  Season: {
    is: 'Date',
  },
  Timezone: {
    is: 'Date',
    also: ['Noun'],
    not: ['ProperNoun'],
  },
  Time: {
    is: 'Date',
    not: ['AtMention'],
  },
  // 'months'
  Duration: {
    is: 'Date',
    also: ['Noun'],
  },
};

const anything = ['Noun', 'Verb', 'Adjective', 'Adverb', 'Value', 'QuestionWord'];

var misc$1 = {
  Adjective: {
    not: ['Noun', 'Verb', 'Adverb', 'Value'],
  },
  Comparable: {
    is: 'Adjective',
  },
  Comparative: {
    is: 'Adjective',
  },
  Superlative: {
    is: 'Adjective',
    not: ['Comparative'],
  },
  NumberRange: {},
  Adverb: {
    not: ['Noun', 'Verb', 'Adjective', 'Value'],
  },

  Determiner: {
    not: ['Noun', 'Verb', 'Adjective', 'Adverb', 'QuestionWord', 'Conjunction'], //allow 'a' to be a Determiner/Value
  },
  Conjunction: {
    not: anything,
  },
  Preposition: {
    not: ['Noun', 'Verb', 'Adjective', 'Adverb', 'QuestionWord', 'Determiner'],
  },
  QuestionWord: {
    not: ['Determiner'],
  },
  Currency: {
    is: 'Noun',
  },
  Expression: {
    not: ['Noun', 'Adjective', 'Verb', 'Adverb'],
  },
  Abbreviation: {},
  Url: {
    not: ['HashTag', 'PhoneNumber', 'Verb', 'Adjective', 'Value', 'AtMention', 'Email', 'SlashedTerm'],
  },
  PhoneNumber: {
    not: ['HashTag', 'Verb', 'Adjective', 'Value', 'AtMention', 'Email'],
  },
  HashTag: {},
  AtMention: {
    is: 'Noun',
    not: ['HashTag', 'Email'],
  },
  Emoji: {
    not: ['HashTag', 'Verb', 'Adjective', 'Value', 'AtMention'],
  },
  Emoticon: {
    not: ['HashTag', 'Verb', 'Adjective', 'Value', 'AtMention', 'SlashedTerm'],
  },
  SlashedTerm: {
    not: ['Emoticon', 'Url', 'Value']
  },
  Email: {
    not: ['HashTag', 'Verb', 'Adjective', 'Value', 'AtMention'],
  },
  Acronym: {
    not: ['Plural', 'RomanNumeral', 'Pronoun', 'Date'],
  },
  Negative: {
    not: ['Noun', 'Adjective', 'Value', 'Expression'],
  },
  Condition: {
    not: ['Verb', 'Adjective', 'Noun', 'Value'],
  },
  // existential 'there'
  There: {
    not: ['Verb', 'Adjective', 'Noun', 'Value', 'Conjunction', 'Preposition'],
  },
  // 'co-wrote'
  Prefix: {
    not: ['Abbreviation', 'Acronym', 'ProperNoun'],
  },
  // hard-nosed, bone-headed
  Hyphenated: {},
};

let allTags = Object.assign({}, nouns$1, verbs$2, values, dates$1, misc$1);

var preTag = {
  compute: compute$3,
  methods: methods$1,
  model: model$1,
  tags: allTags,
  hooks: ['preTagger'],
};

const postPunct = /[,)"';:\-â€“â€”.â€¦]/;

const setContraction = function (m, suffix) {
  if (!m.found) {
    return
  }
  let terms = m.termList();
  //avoid any problematic punctuation
  for (let i = 0; i < terms.length - 1; i++) {
    const t = terms[i];
    if (postPunct.test(t.post)) {
      return
    }
  }
  // set first word as full text
  terms[0].implicit = terms[0].normal;
  terms[0].text += suffix;
  terms[0].normal += suffix;
  // clean-up the others
  terms.slice(1).forEach(t => {
    t.implicit = t.normal;
    t.text = '';
    t.normal = '';
  });
  for (let i = 0; i < terms.length - 1; i++) {
    terms[i].post = terms[i].post.replace(/ /, '');
  }
};

/** turn 'i am' into i'm */
const contract = function () {
  let doc = this.not('@hasContraction');
  // we are -> we're
  let m = doc.match('(we|they|you) are');
  setContraction(m, `'re`);
  // they will -> they'll
  m = doc.match('(he|she|they|it|we|you) will');
  setContraction(m, `'ll`);
  // she is -> she's
  m = doc.match('(he|she|they|it|we) is');
  setContraction(m, `'s`);
  // spencer is -> spencer's
  m = doc.match('#Person is');
  setContraction(m, `'s`);
  // spencer would -> spencer'd
  m = doc.match('#Person would');
  setContraction(m, `'d`);
  // would not -> wouldn't
  m = doc.match('(is|was|had|would|should|could|do|does|have|has|can) not');
  setContraction(m, `n't`);
  // i have -> i've
  m = doc.match('(i|we|they) have');
  setContraction(m, `'ve`);
  // would have -> would've
  m = doc.match('(would|should|could) have');
  setContraction(m, `'ve`);
  // i am -> i'm
  m = doc.match('i am');
  setContraction(m, `'m`);
  // going to -> gonna
  m = doc.match('going to');
  return this
};

const titleCase = /^\p{Lu}[\p{Ll}'â€™]/u; //upercase, then lowercase

const toTitleCase = function (str = '') {
  str = str.replace(/^ *[a-z\u00C0-\u00FF]/, x => x.toUpperCase()); //TODO: support unicode
  return str
};

const api$j = function (View) {
  /** */
  class Contractions extends View {
    constructor(document, pointer, groups) {
      super(document, pointer, groups);
      this.viewType = 'Contraction';
    }
    /** i've -> 'i have' */
    expand() {
      this.docs.forEach(terms => {
        let isTitleCase = titleCase.test(terms[0].text);
        terms.forEach((t, i) => {
          t.text = t.implicit || '';
          delete t.implicit;
          //add whitespace
          if (i < terms.length - 1 && t.post === '') {
            t.post += ' ';
          }
          // flag it as dirty
          t.dirty = true;
        });
        // make the first word title-case?
        if (isTitleCase) {
          terms[0].text = toTitleCase(terms[0].text);
        }
      });
      this.compute('normal'); //re-set normalized text
      return this
    }
  }
  // add fn to View
  View.prototype.contractions = function () {
    let m = this.match('@hasContraction+');
    return new Contractions(this.document, m.pointer)
  };
  View.prototype.contract = contract;
};

// put n new words where 1 word was
const insertContraction = function (document, point, words) {
  let [n, w] = point;
  if (!words || words.length === 0) {
    return
  }
  words = words.map((word, i) => {
    word.implicit = word.text;
    word.machine = word.text;
    word.pre = '';
    word.post = '';
    word.text = '';
    word.normal = '';
    word.index = [n, w + i];
    return word
  });
  if (words[0]) {
    // move whitespace over
    words[0].pre = document[n][w].pre;
    words[words.length - 1].post = document[n][w].post;
    // add the text/normal to the first term
    words[0].text = document[n][w].text;
    words[0].normal = document[n][w].normal; // move tags too?
  }
  // do the splice
  document[n].splice(w, 1, ...words);
};

const hasContraction$1 = /'/;

const hasWords = new Set([
  'been', //the meeting's been ..
  'become', //my son's become
]);
const isWords = new Set([
  'what', //it's what
  'how', //it's how
  'when',
  'if', //it's if
  'too',
]);
let adjLike$1 = new Set(['too', 'also', 'enough']);

// the big clue is the tense of the following verb
const isOrHas = (terms, i) => {
  // scan ahead for the next verb or adjective
  for (let o = i + 1; o < terms.length; o += 1) {
    let t = terms[o];
    if (hasWords.has(t.normal)) {
      return 'has'
    }
    if (isWords.has(t.normal)) {
      return 'is'
    }
    // the cat's sleeping
    if (t.tags.has('Gerund')) {
      return 'is'
    }
    // she's the one
    if (t.tags.has('Determiner')) {
      return 'is'
    }
    // the food's ready
    if (t.tags.has('Adjective')) {
      return 'is'
    }
    // the car's parked
    if (t.switch === 'Adj|Past') {
      if (terms[o + 1]) {
        // car's parked too ..
        if (adjLike$1.has(terms[o + 1].normal)) {
          return 'is'
        }
        // car's parked on ..
        if (terms[o + 1].tags.has('Preposition')) {
          return 'is'
        }
      }
      // return 'is'
    }
    // The meeting's scheduled vs The plane's landed
    if (t.tags.has('PastTense')) {
      // meeting's scheduled for
      if (terms[o + 1] && terms[o + 1].normal === 'for') {
        return 'is'
      }
      return 'has'
    }
  }
  return 'is'
};

// 's -> [possessive, 'has', 'is', 'are', 'us']
const apostropheS$1 = function (terms, i) {
  // possessive, is/has
  let before = terms[i].normal.split(hasContraction$1)[0];
  // let's - >[let, us]
  if (before === 'let') {
    return [before, 'us']
  }
  // allow slang "there's cookies" -> there are
  if (before === 'there') {
    let t = terms[i + 1];
    if (t && t.tags.has('Plural')) {
      return [before, 'are']
    }
  }
  // spencer's got -> spencer has got
  if (isOrHas(terms, i) === 'has') {
    return [before, 'has']
  }
  return [before, 'is']
};

const hasContraction = /'/;

const hadWords = new Set([
  'better', //had better
  'done', //had done
  'before', // he'd _ before
  'it', // he'd _ it
  'had', //she'd had -> she would have..
]);

const wouldWords = new Set([
  'have', // 'i'd have' -> i would have..
  'be', //' she'd be'
]);

//look for a past-tense verb
// You'd mentioned -> you had mentioned
// You'd mention -> you would mention
const hadOrWould = (terms, i) => {
  // scan ahead
  for (let o = i + 1; o < terms.length; o += 1) {
    let t = terms[o];
    // you'd better go
    if (hadWords.has(t.normal)) {
      return 'had'
    }
    // we'd have
    if (wouldWords.has(t.normal)) {
      return 'would'
    }
    // You'd mentioned -> you had mentioned
    if (t.tags.has('PastTense') || t.switch === 'Adj|Past') {
      return 'had'
    }
    // You'd mention -> you would mention
    if (t.tags.has('PresentTense') || t.tags.has('Infinitive')) {
      return 'would'
    }
    // i'd an issue
    if (t.tags.has('#Determiner')) {
      return 'had'
    }
    if (t.tags.has('Adjective')) {
      return 'would'
    }
  }
  return false
};

// he'd walked -> had
// how'd -> did
// he'd go -> would
const _apostropheD = function (terms, i) {
  let before = terms[i].normal.split(hasContraction)[0];
  // what'd, how'd
  if (before === 'how' || before === 'what') {
    return [before, 'did']
  }
  if (hadOrWould(terms, i) === 'had') {
    return [before, 'had']
  }
  // had/would/did
  return [before, 'would']
};

const lastNoun$1 = function (terms, i) {
  for (let n = i - 1; n >= 0; n -= 1) {
    if (
      terms[n].tags.has('Noun') ||
      terms[n].tags.has('Pronoun') ||
      terms[n].tags.has('Plural') ||
      terms[n].tags.has('Singular')
    ) {
      return terms[n]
    }
  }
  return null
};

//ain't -> are/is not
const apostropheT = function (terms, i) {
  if (terms[i].normal === "ain't" || terms[i].normal === 'aint') {
    // "ain't never" -> have never (?)
    if (terms[i + 1] && terms[i + 1].normal === 'never') {
      return ['have']
    }
    // we aint -> are not,   she aint -> is not
    let noun = lastNoun$1(terms, i);
    if (noun) {
      // plural/singular pronouns
      if (noun.normal === 'we' || noun.normal === 'they') {
        return ['are', 'not']
      }
      if (noun.normal === 'i') {
        return ['am', 'not']
      }
      // plural/singular tags
      if (noun.tags && noun.tags.has('Plural')) {
        return ['are', 'not']
      }
    }
    return ['is', 'not']
  }
  let before = terms[i].normal.replace(/n't/, '');
  return [before, 'not']
};

const banList = {
  that: true,
  there: true,
  let: true,
  here: true,
  everywhere: true,
};

const beforePossessive = {
  in: true, //in sunday's
  by: true, //by sunday's
  for: true, //for sunday's
};
let adjLike = new Set(['too', 'also', 'enough', 'about']);
let nounLike = new Set(['is', 'are', 'did', 'were', 'could', 'should', 'must', 'had', 'have']);

const isPossessive = (terms, i) => {
  let term = terms[i];
  // these can't be possessive
  if (banList.hasOwnProperty(term.machine || term.normal)) {
    return false
  }
  // if we already know it
  if (term.tags.has('Possessive')) {
    return true
  }
  // who's
  if (term.tags.has('QuestionWord')) {
    return false
  }
  // some pronouns are never possessive
  if (term.normal === `he's` || term.normal === `she's`) {
    return false
  }
  //if end of sentence, it is possessive - "was spencer's"
  let nextTerm = terms[i + 1];
  if (!nextTerm) {
    return true
  }
  // "it's a life" vs "run it's business"
  if (term.normal === `it's`) {
    if (nextTerm.tags.has('#Noun')) {
      return true
    }
    return false
  }
  // the sun's setting vs the artist's painting
  // gerund = is,  noun = possessive
  // (we are doing some dupe-work of the switch classifier here)
  if (nextTerm.switch == 'Noun|Gerund') {
    let next2 = terms[i + 2];
    // the artist's painting.
    if (!next2) {
      if (term.tags.has('Actor') || term.tags.has('ProperNoun')) {
        return true
      }
      return false
    }
    // the artist's painting is..
    if (next2.tags.has('Copula')) {
      return true
    }
    // the cat's sleeping on ..
    if (next2.normal === 'on' || next2.normal === 'in') {
      return false
    }
    return false
  }
  //a gerund suggests 'is walking'
  if (nextTerm.tags.has('Verb')) {
    //fix 'jamie's bite'
    if (nextTerm.tags.has('Infinitive')) {
      return true
    }
    //'jamaica's growing'
    if (nextTerm.tags.has('Gerund')) {
      return false
    }
    //fix 'spencer's runs'
    if (nextTerm.tags.has('PresentTense')) {
      return true
    }
    return false
  }

  // john's nuts
  if (nextTerm.switch === 'Adj|Noun') {
    let twoTerm = terms[i + 2];
    if (!twoTerm) {
      return false //adj
    }
    // john's nuts were..
    if (nounLike.has(twoTerm.normal)) {
      return true
    }
    // john's nuts about..
    if (adjLike.has(twoTerm.normal)) {
      return false //adj
    }
  }
  //spencer's house
  if (nextTerm.tags.has('Noun')) {
    let nextStr = nextTerm.machine || nextTerm.normal;
    // 'spencer's here'
    if (nextStr === 'here' || nextStr === 'there' || nextStr === 'everywhere') {
      return false
    }
    // the chair's his
    if (nextTerm.tags.has('Possessive')) {
      return false
    }
    // the captain's John
    if (nextTerm.tags.has('ProperNoun') && !term.tags.has('ProperNoun')) {
      return false
    }
    return true
  }

  // by sunday's final
  if (terms[i - 1] && beforePossessive[terms[i - 1].normal] === true) {
    return true
  }

  // spencer's tired
  if (nextTerm.tags.has('Adjective')) {
    let twoTerm = terms[i + 2];
    //the rocket's red
    if (!twoTerm) {
      return false
    }
    // rocket's red nozzle
    if (twoTerm.tags.has('Noun') && !twoTerm.tags.has('Pronoun')) {
      //project's behind schedule
      let str = nextTerm.normal;
      if (str === 'above' || str === 'below' || str === 'behind') {
        return false
      }
      return true
    }
    // rocket's red glare
    if (twoTerm.switch === 'Noun|Verb') {
      return true
    }
    //othwerwise, an adjective suggests 'is good'
    return false
  }
  // baby's first steps
  if (nextTerm.tags.has('Value')) {
    return true
  }
  // otherwise not possessive
  return false
};

const byApostrophe = /'/;

// poor-mans reindexing of this sentence only
const reIndex = function (terms) {
  terms.forEach((t, i) => {
    if (t.index) {
      t.index[1] = i;
    }
  });
};

// run tagger on our new implicit terms
const reTag = function (terms, view, start, len) {
  let tmp = view.update();
  tmp.document = [terms];
  // offer to re-tag neighbours, too
  let end = start + len;
  if (start > 0) {
    start -= 1;
  }
  if (terms[end]) {
    end += 1;
  }
  tmp.ptrs = [[0, start, end]];
  tmp.compute(['freeze', 'lexicon', 'preTagger', 'unfreeze']);
  // don't for a reindex of the whole document
  reIndex(terms);
};

const byEnd = {
  // how'd
  d: (terms, i) => _apostropheD(terms, i),
  // we ain't
  t: (terms, i) => apostropheT(terms, i),
  // bob's
  s: (terms, i, world) => {
    // [bob's house] vs [bob's cool]
    if (isPossessive(terms, i)) {
      return world.methods.one.setTag([terms[i]], 'Possessive', world, null, '2-contraction')
    }
    return apostropheS$1(terms, i)
  },
};

const toDocs = function (words, view) {
  let doc = view.fromText(words.join(' '));
  doc.compute('id');
  return doc.docs[0]
};

//really easy ones
const contractionTwo$1 = view => {
  let { world, document } = view;
  // each sentence
  document.forEach((terms, n) => {
    // loop through terms backwards
    for (let i = terms.length - 1; i >= 0; i -= 1) {
      // is it already a contraction
      if (terms[i].implicit) {
        continue
      }
      let after = null;
      if (byApostrophe.test(terms[i].normal) === true) {
        after = terms[i].normal.split(byApostrophe)[1];
      }
      let words = null;
      // any known-ones, like 'dunno'?
      if (byEnd.hasOwnProperty(after)) {
        words = byEnd[after](terms, i, world);
      }
      // actually insert the new terms
      if (words) {
        words = toDocs(words, view);
        insertContraction(document, [n, i], words);
        reTag(document[n], view, i, words.length);
        continue
      }
    }
  });
};
var compute$2 = { contractionTwo: contractionTwo$1 };

var contractionTwo = {
  compute: compute$2,
  api: api$j,
  hooks: ['contractionTwo']
};

var adj = [
  // all fell apart
  { match: '[(all|both)] #Determiner #Noun', group: 0, tag: 'Noun', reason: 'all-noun' },
  //sometimes not-adverbs
  { match: '#Copula [(just|alone)]$', group: 0, tag: 'Adjective', reason: 'not-adverb' },
  //jack is guarded
  { match: '#Singular is #Adverb? [#PastTense$]', group: 0, tag: 'Adjective', reason: 'is-filled' },
  // smoked poutine is
  { match: '[#PastTense] #Singular is', group: 0, tag: 'Adjective', reason: 'smoked-poutine' },
  // baked onions are
  { match: '[#PastTense] #Plural are', group: 0, tag: 'Adjective', reason: 'baked-onions' },
  // well made
  { match: 'well [#PastTense]', group: 0, tag: 'Adjective', reason: 'well-made' },
  // is f*ed up
  { match: '#Copula [fucked up?]', group: 0, tag: 'Adjective', reason: 'swears-adjective' },
  //jack seems guarded
  { match: '#Singular (seems|appears) #Adverb? [#PastTense$]', group: 0, tag: 'Adjective', reason: 'seems-filled' },
  // jury is out - preposition âž” adjective
  { match: '#Copula #Adjective? [(out|in|through)]$', group: 0, tag: 'Adjective', reason: 'still-out' },
  // shut the door
  { match: '^[#Adjective] (the|your) #Noun', group: 0, notIf: '(all|even)', tag: 'Infinitive', reason: 'shut-the' },
  // the said card
  { match: 'the [said] #Noun', group: 0, tag: 'Adjective', reason: 'the-said-card' },
  // faith-based, much-appreciated, soft-boiled
  { match: '[#Hyphenated (#Hyphenated && #PastTense)] (#Noun|#Conjunction)', group: 0, tag: 'Adjective', notIf: '#Adverb', reason: 'faith-based' },
  //self-driving
  { match: '[#Hyphenated (#Hyphenated && #Gerund)] (#Noun|#Conjunction)', group: 0, tag: 'Adjective', notIf: '#Adverb', reason: 'self-driving' },
  //dammed-up
  { match: '[#PastTense (#Hyphenated && #PhrasalVerb)] (#Noun|#Conjunction)', group: 0, tag: 'Adjective', reason: 'dammed-up' },
  //two-fold
  { match: '(#Hyphenated && #Value) fold', tag: 'Adjective', reason: 'two-fold' },
  //must-win
  { match: 'must (#Hyphenated && #Infinitive)', tag: 'Adjective', reason: 'must-win' },
  // vacuum-sealed
  { match: `(#Hyphenated && #Infinitive) #Hyphenated`, tag: 'Adjective', notIf: '#PhrasalVerb', reason: 'vacuum-sealed' },

  { match: 'too much', tag: 'Adverb Adjective', reason: 'bit-4' },
  { match: 'a bit much', tag: 'Determiner Adverb Adjective', reason: 'bit-3' },

  // adjective-prefixes - 'un skilled'
  { match: '[(un|contra|extra|inter|intra|macro|micro|mid|mis|mono|multi|pre|sub|tri|ex)] #Adjective', group: 0, tag: ['Adjective', 'Prefix'], reason: 'un-skilled' },

];

const adverbAdj = `(dark|bright|flat|light|soft|pale|dead|dim|faux|little|wee|sheer|most|near|good|extra|all)`;
const noLy = '(hard|fast|late|early|high|right|deep|close|direct)';

var advAdj = [
  // kinda sparkly
  { match: `#Adverb [#Adverb] (and|or|then)`, group: 0, tag: 'Adjective', reason: 'kinda-sparkly-and' },
  // dark green
  { match: `[${adverbAdj}] #Adjective`, group: 0, tag: 'Adverb', reason: 'dark-green' },
  // far too
  { match: `#Copula [far too] #Adjective`, group: 0, tag: 'Adverb', reason: 'far-too' },
  // was still in
  { match: `#Copula [still] (in|#Gerund|#Adjective)`, group: 0, tag: 'Adverb', reason: 'was-still-walking' },
  // studies hard
  { match: `#Plural ${noLy}`, tag: '#PresentTense #Adverb', reason: 'studies-hard' },
  // shops direct
  {
    match: `#Verb [${noLy}] !#Noun?`,
    group: 0,
    notIf: '(#Copula|get|got|getting|become|became|becoming|feel|feels|feeling|#Determiner|#Preposition)',
    tag: 'Adverb',
    reason: 'shops-direct',
  },
  // studies a lot
  { match: `[#Plural] a lot`, tag: 'PresentTense', reason: 'studies-a-lot' },
];

// Gerund-Adjectives - 'amusing, annoying'
var gerundAdj = [
  //a staggering cost
  // { match: '(a|an) [#Gerund]', group: 0, tag: 'Adjective', reason: 'a|an' },
  //as amusing as
  { match: 'as [#Gerund] as', group: 0, tag: 'Adjective', reason: 'as-gerund-as' },
  // more amusing than
  { match: 'more [#Gerund] than', group: 0, tag: 'Adjective', reason: 'more-gerund-than' },
  // very amusing
  { match: '(so|very|extremely) [#Gerund]', group: 0, tag: 'Adjective', reason: 'so-gerund' },
  // found it amusing
  { match: '(found|found) it #Adverb? [#Gerund]', group: 0, tag: 'Adjective', reason: 'found-it-gerund' },
  // a bit amusing
  { match: 'a (little|bit|wee) bit? [#Gerund]', group: 0, tag: 'Adjective', reason: 'a-bit-gerund' },
  // looking annoying
  {
    match: '#Gerund [#Gerund]',
    group: 0,
    tag: 'Adjective',
    notIf: '(impersonating|practicing|considering|assuming)',
    reason: 'looking-annoying',
  },
  // looked amazing
  {
    match: '(looked|look|looks) #Adverb? [%Adj|Gerund%]',
    group: 0,
    tag: 'Adjective',
    notIf: '(impersonating|practicing|considering|assuming)',
    reason: 'looked-amazing',
  },
  // were really amazing
  // { match: '(looked|look|looks) #Adverb [%Adj|Gerund%]', group: 0, tag: 'Adjective', notIf: '(impersonating|practicing|considering|assuming)', reason: 'looked-amazing' },
  // developing a
  { match: '[%Adj|Gerund%] #Determiner', group: 0, tag: 'Gerund', reason: 'developing-a' },
  // world's leading manufacturer
  { match: '#Possessive [%Adj|Gerund%] #Noun', group: 0, tag: 'Adjective', reason: 'leading-manufacturer' },
  // meaning alluring
  { match: '%Noun|Gerund% %Adj|Gerund%', tag: 'Gerund #Adjective', reason: 'meaning-alluring' },

  // face shocking revelations
  {
    match: '(face|embrace|reveal|stop|start|resume) %Adj|Gerund%',
    tag: '#PresentTense #Adjective',
    reason: 'face-shocking',
  },
  // are enduring symbols
  { match: '(are|were) [%Adj|Gerund%] #Plural', group: 0, tag: 'Adjective', reason: 'are-enduring-symbols' },
];

var nounAdj = [
  //the above is clear
  { match: '#Determiner [#Adjective] #Copula', group: 0, tag: 'Noun', reason: 'the-adj-is' },
  //real evil is
  { match: '#Adjective [#Adjective] #Copula', group: 0, tag: 'Noun', reason: 'adj-adj-is' },
  //his fine
  { match: '(his|its) [%Adj|Noun%]', group: 0, tag: 'Noun', notIf: '#Hyphenated', reason: 'his-fine' },
  //is all
  { match: '#Copula #Adverb? [all]', group: 0, tag: 'Noun', reason: 'is-all' },
  // have fun
  { match: `(have|had) [#Adjective] #Preposition .`, group: 0, tag: 'Noun', reason: 'have-fun' },
  // brewing giant
  { match: `#Gerund (giant|capital|center|zone|application)`, tag: 'Noun', reason: 'brewing-giant' },
  // in an instant
  { match: `#Preposition (a|an) [#Adjective]$`, group: 0, tag: 'Noun', reason: 'an-instant' },
  // no golden would
  { match: `no [#Adjective] #Modal`, group: 0, tag: 'Noun', reason: 'no-golden' },
  // brand new
  { match: `[brand #Gerund?] new`, group: 0, tag: 'Adverb', reason: 'brand-new' },
  // some kind
  { match: `(#Determiner|#Comparative|new|different) [kind]`, group: 0, tag: 'Noun', reason: 'some-kind' },
  // her favourite sport
  { match: `#Possessive [%Adj|Noun%] #Noun`, group: 0, tag: 'Adjective', reason: 'her-favourite' },
  // must-win
  { match: `must && #Hyphenated .`, tag: 'Adjective', reason: 'must-win' },
  // the present
  {
    match: `#Determiner [#Adjective]$`,
    tag: 'Noun',
    notIf: '(this|that|#Comparative|#Superlative)',
    reason: 'the-south',
  }, //are that crazy.
  // company-wide
  {
    match: `(#Noun && #Hyphenated) (#Adjective && #Hyphenated)`,
    tag: 'Adjective',
    notIf: '(this|that|#Comparative|#Superlative)',
    reason: 'company-wide',
  },
  // the poor were
  {
    match: `#Determiner [#Adjective] (#Copula|#Determiner)`,
    notIf: '(#Comparative|#Superlative)',
    group: 0,
    tag: 'Noun',
    reason: 'the-poor',
  },
  // professional bodybuilder
  {
    match: `[%Adj|Noun%] #Noun`,
    notIf: '(#Pronoun|#ProperNoun)',
    group: 0,
    tag: 'Adjective',
    reason: 'stable-foundations',
  },
];

var adjVerb = [
  // amusing his aunt
  // { match: '[#Adjective] #Possessive #Noun', group: 0, tag: 'Verb', reason: 'gerund-his-noun' },
  // loving you
  // { match: '[#Adjective] (us|you)', group: 0, tag: 'Gerund', reason: 'loving-you' },
  // slowly stunning
  { match: '(slowly|quickly) [#Adjective]', group: 0, tag: 'Verb', reason: 'slowly-adj' },
  // does mean
  { match: 'does (#Adverb|not)? [#Adjective]', group: 0, tag: 'PresentTense', reason: 'does-mean' },
  // okay by me
  { match: '[(fine|okay|cool|ok)] by me', group: 0, tag: 'Adjective', reason: 'okay-by-me' },
  // i mean
  { match: 'i (#Adverb|do)? not? [mean]', group: 0, tag: 'PresentTense', reason: 'i-mean' },
  //will secure our
  { match: 'will #Adjective', tag: 'Auxiliary Infinitive', reason: 'will-adj' },
  //he disguised the thing
  { match: '#Pronoun [#Adjective] #Determiner #Adjective? #Noun', group: 0, tag: 'Verb', reason: 'he-adj-the' },
  //is eager to go
  { match: '#Copula [%Adj|Present%] to #Verb', group: 0, tag: 'Verb', reason: 'adj-to' },
  //is done well
  { match: '#Copula [#Adjective] (well|badly|quickly|slowly)', group: 0, tag: 'Verb', reason: 'done-well' },
  // rude and insulting
  { match: '#Adjective and [#Gerund] !#Preposition?', group: 0, tag: 'Adjective', reason: 'rude-and-x' },
  // were over cooked
  { match: '#Copula #Adverb? (over|under) [#PastTense]', group: 0, tag: 'Adjective', reason: 'over-cooked' },
  // was bland and overcooked
  { match: '#Copula #Adjective+ (and|or) [#PastTense]$', group: 0, tag: 'Adjective', reason: 'bland-and-overcooked' },
  // got tired of
  { match: 'got #Adverb? [#PastTense] of', group: 0, tag: 'Adjective', reason: 'got-tired-of' },
  //felt loved
  {
    match:
      '(seem|seems|seemed|appear|appeared|appears|feel|feels|felt|sound|sounds|sounded) (#Adverb|#Adjective)? [#PastTense]',
    group: 0,
    tag: 'Adjective',
    reason: 'felt-loved',
  },
  // seem confused
  { match: '(seem|feel|seemed|felt) [#PastTense #Particle?]', group: 0, tag: 'Adjective', reason: 'seem-confused' },
  // a bit confused
  { match: 'a (bit|little|tad) [#PastTense #Particle?]', group: 0, tag: 'Adjective', reason: 'a-bit-confused' },
  // do not be embarrassed
  { match: 'not be [%Adj|Past% #Particle?]', group: 0, tag: 'Adjective', reason: 'do-not-be-confused' },
  // is just right
  { match: '#Copula just [%Adj|Past% #Particle?]', group: 0, tag: 'Adjective', reason: 'is-just-right' },
  // as pale as
  { match: 'as [#Infinitive] as', group: 0, tag: 'Adjective', reason: 'as-pale-as' },
  //failed and oppressive
  { match: '[%Adj|Past%] and #Adjective', group: 0, tag: 'Adjective', reason: 'faled-and-oppressive' },
  // or heightened emotion
  {
    match: 'or [#PastTense] #Noun',
    group: 0,
    tag: 'Adjective',
    notIf: '(#Copula|#Pronoun)',
    reason: 'or-heightened-emotion',
  },
  // became involved
  { match: '(become|became|becoming|becomes) [#Verb]', group: 0, tag: 'Adjective', reason: 'become-verb' },
  // their declared intentions
  { match: '#Possessive [#PastTense] #Noun', group: 0, tag: 'Adjective', reason: 'declared-intentions' },
  // is he cool
  { match: '#Copula #Pronoun [%Adj|Present%]', group: 0, tag: 'Adjective', reason: 'is-he-cool' },
  // is crowded with
  {
    match: '#Copula [%Adj|Past%] with',
    group: 0,
    tag: 'Adjective',
    notIf: '(associated|worn|baked|aged|armed|bound|fried|loaded|mixed|packed|pumped|filled|sealed)',
    reason: 'is-crowded-with',
  },
  // is empty$
  { match: '#Copula #Adverb? [%Adj|Present%]$', group: 0, tag: 'Adjective', reason: 'was-empty$' },
];

// const adverbAdj = '(dark|bright|flat|light|soft|pale|dead|dim|faux|little|wee|sheer|most|near|good|extra|all)'

var adv = [
  //still good
  { match: '[still] #Adjective', group: 0, tag: 'Adverb', reason: 'still-advb' },
  //still make
  { match: '[still] #Verb', group: 0, tag: 'Adverb', reason: 'still-verb' },
  // so hot
  { match: '[so] #Adjective', group: 0, tag: 'Adverb', reason: 'so-adv' },
  // way hotter
  { match: '[way] #Comparative', group: 0, tag: 'Adverb', reason: 'way-adj' },
  // way too hot
  { match: '[way] #Adverb #Adjective', group: 0, tag: 'Adverb', reason: 'way-too-adj' },
  // all singing
  { match: '[all] #Verb', group: 0, tag: 'Adverb', reason: 'all-verb' },
  // sing like an angel
  { match: '#Verb  [like]', group: 0, notIf: '(#Modal|#PhrasalVerb)', tag: 'Adverb', reason: 'verb-like' },
  //barely even walk
  { match: '(barely|hardly) even', tag: 'Adverb', reason: 'barely-even' },
  //even held
  { match: '[even] #Verb', group: 0, tag: 'Adverb', reason: 'even-walk' },
  //even worse
  { match: '[even] #Comparative', group: 0, tag: 'Adverb', reason: 'even-worse' },
  // even the greatest
  { match: '[even] (#Determiner|#Possessive)', group: 0, tag: '#Adverb', reason: 'even-the' },
  // even left
  { match: 'even left', tag: '#Adverb #Verb', reason: 'even-left' },
  // way over
  { match: '[way] #Adjective', group: 0, tag: '#Adverb', reason: 'way-over' },
  //cheering hard - dropped -ly's
  {
    match: '#PresentTense [(hard|quick|bright|slow|fast|backwards|forwards)]',
    notIf: '#Copula',
    group: 0,
    tag: 'Adverb',
    reason: 'lazy-ly',
  },
  // much appreciated
  { match: '[much] #Adjective', group: 0, tag: 'Adverb', reason: 'bit-1' },
  // is well
  { match: '#Copula [#Adverb]$', group: 0, tag: 'Adjective', reason: 'is-well' },
  // a bit cold
  { match: 'a [(little|bit|wee) bit?] #Adjective', group: 0, tag: 'Adverb', reason: 'a-bit-cold' },
  // super strong
  { match: `[(super|pretty)] #Adjective`, group: 0, tag: 'Adverb', reason: 'super-strong' },
  // become overly weakened
  { match: '(become|fall|grow) #Adverb? [#PastTense]', group: 0, tag: 'Adjective', reason: 'overly-weakened' },
  // a completely beaten man
  { match: '(a|an) #Adverb [#Participle] #Noun', group: 0, tag: 'Adjective', reason: 'completely-beaten' },
  //a close
  { match: '#Determiner #Adverb? [close]', group: 0, tag: 'Adjective', reason: 'a-close' },
  //walking close
  { match: '#Gerund #Adverb? [close]', group: 0, tag: 'Adverb', notIf: '(getting|becoming|feeling)', reason: 'being-close' },
  // a blown motor
  { match: '(the|those|these|a|an) [#Participle] #Noun', group: 0, tag: 'Adjective', reason: 'blown-motor' },
  // charged back
  { match: '(#PresentTense|#PastTense) [back]', group: 0, tag: 'Adverb', notIf: '(#PhrasalVerb|#Copula)', reason: 'charge-back' },
  // send around
  { match: '#Verb [around]', group: 0, tag: 'Adverb', notIf: '#PhrasalVerb', reason: 'send-around' },
  // later say
  { match: '[later] #PresentTense', group: 0, tag: 'Adverb', reason: 'later-say' },
  // the well
  { match: '#Determiner [well] !#PastTense?', group: 0, tag: 'Noun', reason: 'the-well' },
  // high enough
  { match: '#Adjective [enough]', group: 0, tag: 'Adverb', reason: 'high-enough' },
];

var dates = [
  // ==== Holiday ====
  { match: '#Holiday (day|eve)', tag: 'Holiday', reason: 'holiday-day' },
  //5th of March
  { match: '#Value of #Month', tag: 'Date', reason: 'value-of-month' },
  //5 March
  { match: '#Cardinal #Month', tag: 'Date', reason: 'cardinal-month' },
  //march 5 to 7
  { match: '#Month #Value to #Value', tag: 'Date', reason: 'value-to-value' },
  //march the 12th
  { match: '#Month the #Value', tag: 'Date', reason: 'month-the-value' },
  //june 7
  { match: '(#WeekDay|#Month) #Value', tag: 'Date', reason: 'date-value' },
  //7 june
  { match: '#Value (#WeekDay|#Month)', tag: 'Date', reason: 'value-date' },
  //may twenty five
  { match: '(#TextValue && #Date) #TextValue', tag: 'Date', reason: 'textvalue-date' },
  // 'aug 20-21'
  { match: `#Month #NumberRange`, tag: 'Date', reason: 'aug 20-21' },
  // wed march 5th
  { match: `#WeekDay #Month #Ordinal`, tag: 'Date', reason: 'week mm-dd' },
  // aug 5th 2021
  { match: `#Month #Ordinal #Cardinal`, tag: 'Date', reason: 'mm-dd-yyy' },

  // === timezones ===
  // china standard time
  { match: `(#Place|#Demonmym|#Time) (standard|daylight|central|mountain)? time`, tag: 'Timezone', reason: 'std-time' },
  // eastern time
  {
    match: `(eastern|mountain|pacific|central|atlantic) (standard|daylight|summer)? time`,
    tag: 'Timezone',
    reason: 'eastern-time',
  },
  // 5pm central
  { match: `#Time [(eastern|mountain|pacific|central|est|pst|gmt)]`, group: 0, tag: 'Timezone', reason: '5pm-central' },
  // central european time
  { match: `(central|western|eastern) european time`, tag: 'Timezone', reason: 'cet' },
];

var ambigDates = [
  // ==== WeekDay ====
  // sun the 5th
  { match: '[sun] the #Ordinal', tag: 'WeekDay', reason: 'sun-the-5th' },
  //sun feb 2
  { match: '[sun] #Date', group: 0, tag: 'WeekDay', reason: 'sun-feb' },
  //1pm next sun
  { match: '#Date (on|this|next|last|during)? [sun]', group: 0, tag: 'WeekDay', reason: '1pm-sun' },
  //this sat
  { match: `(in|by|before|during|on|until|after|of|within|all) [sat]`, group: 0, tag: 'WeekDay', reason: 'sat' },
  { match: `(in|by|before|during|on|until|after|of|within|all) [wed]`, group: 0, tag: 'WeekDay', reason: 'wed' },
  { match: `(in|by|before|during|on|until|after|of|within|all) [march]`, group: 0, tag: 'Month', reason: 'march' },
  //sat november
  { match: '[sat] #Date', group: 0, tag: 'WeekDay', reason: 'sat-feb' },

  // ==== Month ====
  //all march
  { match: `#Preposition [(march|may)]`, group: 0, tag: 'Month', reason: 'in-month' },
  //this march
  { match: `(this|next|last) (march|may) !#Infinitive?`, tag: '#Date #Month', reason: 'this-month' },
  // march 5th
  { match: `(march|may) the? #Value`, tag: '#Month #Date #Date', reason: 'march-5th' },
  // 5th of march
  { match: `#Value of? (march|may)`, tag: '#Date #Date #Month', reason: '5th-of-march' },
  // march and feb
  { match: `[(march|may)] .? #Date`, group: 0, tag: 'Month', reason: 'march-and-feb' },
  // feb to march
  { match: `#Date .? [(march|may)]`, group: 0, tag: 'Month', reason: 'feb-and-march' },
  //quickly march
  { match: `#Adverb [(march|may)]`, group: 0, tag: 'Verb', reason: 'quickly-march' },
  //march quickly
  { match: `[(march|may)] #Adverb`, group: 0, tag: 'Verb', reason: 'march-quickly' },
  //12 am
  { match: `#Value (am|pm)`, tag: 'Time', reason: '2-am' },
];

const infNouns =
  '(feel|sense|process|rush|side|bomb|bully|challenge|cover|crush|dump|exchange|flow|function|issue|lecture|limit|march|process)';
var noun = [
  //'more' is not always an adverb
  // any more
  { match: '(the|any) [more]', group: 0, tag: 'Singular', reason: 'more-noun' },
  // more players
  { match: '[more] #Noun', group: 0, tag: 'Adjective', reason: 'more-noun' },
  // rights of man
  { match: '(right|rights) of .', tag: 'Noun', reason: 'right-of' },
  // a bit
  { match: 'a [bit]', group: 0, tag: 'Singular', reason: 'bit-2' },
  // a must
  { match: 'a [must]', group: 0, tag: 'Singular', reason: 'must-2' },
  // we all
  { match: '(we|us) [all]', group: 0, tag: 'Noun', reason: 'we all' },
  // due to weather
  { match: 'due to [#Verb]', group: 0, tag: 'Noun', reason: 'due-to' },

  //some pressing issues
  { match: 'some [#Verb] #Plural', group: 0, tag: 'Noun', reason: 'determiner6' },
  // my first thought
  { match: '#Possessive #Ordinal [#PastTense]', group: 0, tag: 'Noun', reason: 'first-thought' },
  //the nice swim
  {
    match: '(the|this|those|these) #Adjective [%Verb|Noun%]',
    group: 0,
    tag: 'Noun',
    notIf: '#Copula',
    reason: 'the-adj-verb',
  },
  // the truly nice swim
  { match: '(the|this|those|these) #Adverb #Adjective [#Verb]', group: 0, tag: 'Noun', reason: 'determiner4' },
  //the wait to vote
  { match: 'the [#Verb] #Preposition .', group: 0, tag: 'Noun', reason: 'determiner1' },
  //a sense of
  { match: '(a|an|the) [#Verb] of', group: 0, tag: 'Noun', reason: 'the-verb-of' },
  //the threat of force
  { match: '#Determiner #Noun of [#Verb]', group: 0, tag: 'Noun', notIf: '#Gerund', reason: 'noun-of-noun' },
  // ended in ruins
  {
    match: '#PastTense #Preposition [#PresentTense]',
    group: 0,
    notIf: '#Gerund',
    tag: 'Noun',
    reason: 'ended-in-ruins',
  },
  //'u' as pronoun
  { match: '#Conjunction [u]', group: 0, tag: 'Pronoun', reason: 'u-pronoun-2' },
  { match: '[u] #Verb', group: 0, tag: 'Pronoun', reason: 'u-pronoun-1' },
  //the western line
  {
    match: '#Determiner [(western|eastern|northern|southern|central)] #Noun',
    group: 0,
    tag: 'Noun',
    reason: 'western-line',
  },
  //air-flow
  { match: '(#Singular && @hasHyphen) #PresentTense', tag: 'Noun', reason: 'hyphen-verb' },
  //is no walk
  { match: 'is no [#Verb]', group: 0, tag: 'Noun', reason: 'is-no-verb' },
  //do so
  { match: 'do [so]', group: 0, tag: 'Noun', reason: 'so-noun' },
  // what the hell
  { match: '#Determiner [(shit|damn|hell)]', group: 0, tag: 'Noun', reason: 'swears-noun' },
  // go to shit
  { match: 'to [(shit|hell)]', group: 0, tag: 'Noun', reason: 'to-swears' },
  // the staff were
  { match: '(the|these) [#Singular] (were|are)', group: 0, tag: 'Plural', reason: 'singular-were' },
  // a comdominium, or simply condo
  { match: `a #Noun+ or #Adverb+? [#Verb]`, group: 0, tag: 'Noun', reason: 'noun-or-noun' },
  // walk the walk
  {
    match: '(the|those|these|a|an) #Adjective? [#PresentTense #Particle?]',
    group: 0,
    tag: 'Noun',
    notIf: '(seem|appear|include|#Gerund|#Copula)',
    reason: 'det-inf',
  },
  // { match: '(the|those|these|a|an) #Adjective? [#PresentTense #Particle?]', group: 0, tag: 'Noun', notIf: '(#Gerund|#Copula)', reason: 'det-pres' },

  // ==== Actor ====
  //Aircraft designer
  { match: '#Noun #Actor', tag: 'Actor', notIf: '(#Person|#Pronoun)', reason: 'thing-doer' },
  //lighting designer
  { match: '#Gerund #Actor', tag: 'Actor', reason: 'gerund-doer' },
  // captain sanders
  // { match: '[#Actor+] #ProperNoun', group: 0, tag: 'Honorific', reason: 'sgt-kelly' },
  // co-founder
  { match: `co #Singular`, tag: 'Actor', reason: 'co-noun' },
  // co-founder
  {
    match: `[#Noun+] #Actor`,
    group: 0,
    tag: 'Actor',
    notIf: '(#Honorific|#Pronoun|#Possessive)',
    reason: 'air-traffic-controller',
  },
  // fine-artist
  {
    match: `(urban|cardiac|cardiovascular|respiratory|medical|clinical|visual|graphic|creative|dental|exotic|fine|certified|registered|technical|virtual|professional|amateur|junior|senior|special|pharmaceutical|theoretical)+ #Noun? #Actor`,
    tag: 'Actor',
    reason: 'fine-artist',
  },
  // dance coach
  {
    match: `#Noun+ (coach|chef|king|engineer|fellow|personality|boy|girl|man|woman|master)`,
    tag: 'Actor',
    reason: 'dance-coach',
  },
  // chief design officer
  { match: `chief . officer`, tag: 'Actor', reason: 'chief-x-officer' },
  // chief of police
  { match: `chief of #Noun+`, tag: 'Actor', reason: 'chief-of-police' },
  // president of marketing
  { match: `senior? vice? president of #Noun+`, tag: 'Actor', reason: 'president-of' },

  // ==== Singular ====
  //the sun
  { match: '#Determiner [sun]', group: 0, tag: 'Singular', reason: 'the-sun' },
  //did a 900, paid a 20
  { match: '#Verb (a|an) [#Value]$', group: 0, tag: 'Singular', reason: 'did-a-value' },
  //'the can'
  { match: 'the [(can|will|may)]', group: 0, tag: 'Singular', reason: 'the can' },

  // ==== Possessive ====
  //spencer kelly's
  { match: '#FirstName #Acronym? (#Possessive && #LastName)', tag: 'Possessive', reason: 'name-poss' },
  //Super Corp's fundraiser
  { match: '#Organization+ #Possessive', tag: 'Possessive', reason: 'org-possessive' },
  //Los Angeles's fundraiser
  { match: '#Place+ #Possessive', tag: 'Possessive', reason: 'place-possessive' },
  // Ptolemy's experiments
  { match: '#Possessive #PresentTense #Particle?', notIf: '(#Gerund|her)', tag: 'Noun', reason: 'possessive-verb' }, // anna's eating vs anna's eating lunch
  // my presidents house
  { match: '(my|our|their|her|his|its) [(#Plural && #Actor)] #Noun', tag: 'Possessive', reason: 'my-dads' },

  // 10th of a second
  { match: '#Value of a [second]', group: 0, unTag: 'Value', tag: 'Singular', reason: '10th-of-a-second' },
  // 10 seconds
  { match: '#Value [seconds]', group: 0, unTag: 'Value', tag: 'Plural', reason: '10-seconds' },
  // in time
  { match: 'in [#Infinitive]', group: 0, tag: 'Singular', reason: 'in-age' },
  // a minor in
  { match: 'a [#Adjective] #Preposition', group: 0, tag: 'Noun', reason: 'a-minor-in' },
  //the repairer said
  { match: '#Determiner [#Singular] said', group: 0, tag: 'Actor', reason: 'the-actor-said' },
  //the euro sense
  {
    match: `#Determiner #Noun [${infNouns}] !(#Preposition|to|#Adverb)?`,
    group: 0,
    tag: 'Noun',
    reason: 'the-noun-sense',
  },
  // photographs of a computer are
  { match: '[#PresentTense] (of|by|for) (a|an|the) #Noun #Copula', group: 0, tag: 'Plural', reason: 'photographs-of' },
  // fight and win
  { match: '#Infinitive and [%Noun|Verb%]', group: 0, tag: 'Infinitive', reason: 'fight and win' },
  // peace and flowers and love
  { match: '#Noun and [#Verb] and #Noun', group: 0, tag: 'Noun', reason: 'peace-and-flowers' },
  // the 1992 classic
  { match: 'the #Cardinal [%Adj|Noun%]', group: 0, tag: 'Noun', reason: 'the-1992-classic' },
  // the premier university
  { match: '#Copula the [%Adj|Noun%] #Noun', group: 0, tag: 'Adjective', reason: 'the-premier-university' },

  // scottish - i ate me sandwich
  { match: 'i #Verb [me] #Noun', group: 0, tag: 'Possessive', reason: 'scottish-me' },
  // dance music
  {
    match: '[#PresentTense] (music|class|lesson|night|party|festival|league|ceremony)',
    group: 0,
    tag: 'Noun',
    reason: 'dance-music',
  },
  // wit it
  { match: '[wit] (me|it)', group: 0, tag: 'Presposition', reason: 'wit-me' },
  //left-her-boots, shoved her hand
  { match: '#PastTense #Possessive [#Verb]', group: 0, tag: 'Noun', notIf: '(saw|made)', reason: 'left-her-boots' },
  //35 signs
  { match: '#Value [%Plural|Verb%]', group: 0, tag: 'Plural', notIf: '(one|1|a|an)', reason: '35-signs' },
  //had time
  { match: 'had [#PresentTense]', group: 0, tag: 'Noun', notIf: '(#Gerund|come|become)', reason: 'had-time' },
  //instant access
  { match: '%Adj|Noun% %Noun|Verb%', tag: '#Adjective #Noun', notIf: '#ProperNoun #Noun', reason: 'instant-access' },
  // a representative to
  { match: '#Determiner [%Adj|Noun%] #Conjunction', group: 0, tag: 'Noun', reason: 'a-rep-to' },
  // near death experiences, ambitious sales targets
  {
    match: '#Adjective #Noun [%Plural|Verb%]$',
    group: 0,
    tag: 'Plural',
    notIf: '#Pronoun',
    reason: 'near-death-experiences',
  },
  // your guild colors
  { match: '#Possessive #Noun [%Plural|Verb%]$', group: 0, tag: 'Plural', reason: 'your-guild-colors' },
];

var gerundNouns = [
  // the planning processes
  { match: '(this|that|the|a|an) [#Gerund #Infinitive]', group: 0, tag: 'Singular', reason: 'the-planning-process' },
  // the paving stones
  { match: '(that|the) [#Gerund #PresentTense]', group: 0, ifNo: '#Copula', tag: 'Plural', reason: 'the-paving-stones' },
  // this swimming
  // { match: '(this|that|the) [#Gerund]', group: 0, tag: 'Noun', reason: 'this-gerund' },
  // the remaining claims
  { match: '#Determiner [#Gerund] #Noun', group: 0, tag: 'Adjective', reason: 'the-gerund-noun' },
  // i think tipping sucks
  { match: `#Pronoun #Infinitive [#Gerund] #PresentTense`, group: 0, tag: 'Noun', reason: 'tipping-sucks' },
  // early warning
  { match: '#Adjective [#Gerund]', group: 0, tag: 'Noun', notIf: '(still|even|just)', reason: 'early-warning' },
  //walking is cool
  { match: '[#Gerund] #Adverb? not? #Copula', group: 0, tag: 'Activity', reason: 'gerund-copula' },
  //are doing is
  { match: '#Copula [(#Gerund|#Activity)] #Copula', group: 0, tag: 'Gerund', reason: 'are-doing-is' },
  //walking should be fun
  { match: '[#Gerund] #Modal', group: 0, tag: 'Activity', reason: 'gerund-modal' },
  // finish listening
  // { match: '#Infinitive [#Gerund]', group: 0, tag: 'Activity', reason: 'finish-listening' },
  // the ruling party

  // responsibility for setting
  { match: '#Singular for [%Noun|Gerund%]', group: 0, tag: 'Gerund', reason: 'noun-for-gerund' },
  // better for training
  { match: '#Comparative (for|at) [%Noun|Gerund%]', group: 0, tag: 'Gerund', reason: 'better-for-gerund' },
  // keep the touching
  { match: '#PresentTense the [#Gerund]', group: 0, tag: 'Noun', reason: 'keep-the-touching' },
];

var presNouns = [
  // do the dance
  { match: '#Infinitive (this|that|the) [#Infinitive]', group: 0, tag: 'Noun', reason: 'do-this-dance' },
  //running-a-show
  { match: '#Gerund #Determiner [#Infinitive]', group: 0, tag: 'Noun', reason: 'running-a-show' },
  //the-only-reason
  { match: '#Determiner (only|further|just|more|backward) [#Infinitive]', group: 0, tag: 'Noun', reason: 'the-only-reason' },
  // a stream runs
  { match: '(the|this|a|an) [#Infinitive] #Adverb? #Verb', group: 0, tag: 'Noun', reason: 'determiner5' },
  //a nice deal
  { match: '#Determiner #Adjective #Adjective? [#Infinitive]', group: 0, tag: 'Noun', reason: 'a-nice-inf' },
  // the mexican train
  { match: '#Determiner #Demonym [#PresentTense]', group: 0, tag: 'Noun', reason: 'mexican-train' },
  //next career move
  { match: '#Adjective #Noun+ [#Infinitive] #Copula', group: 0, tag: 'Noun', reason: 'career-move' },
  // at some point
  { match: 'at some [#Infinitive]', group: 0, tag: 'Noun', reason: 'at-some-inf' },
  // goes to sleep
  { match: '(go|goes|went) to [#Infinitive]', group: 0, tag: 'Noun', reason: 'goes-to-verb' },
  //a close watch on
  { match: '(a|an) #Adjective? #Noun [#Infinitive] (#Preposition|#Noun)', group: 0, notIf: 'from', tag: 'Noun', reason: 'a-noun-inf' },
  //a tv show
  { match: '(a|an) #Noun [#Infinitive]$', group: 0, tag: 'Noun', reason: 'a-noun-inf2' },
  //is mark hughes
  // { match: '#Copula [#Infinitive] #Noun', group: 0, tag: 'Noun', reason: 'is-pres-noun' },
  // good wait staff
  // { match: '#Adjective [#Infinitive] #Noun', group: 0, tag: 'Noun', reason: 'good-wait-staff' },
  // running for congress
  { match: '#Gerund #Adjective? for [#Infinitive]', group: 0, tag: 'Noun', reason: 'running-for' },
  // running to work
  // { match: '#Gerund #Adjective to [#Infinitive]', group: 0, tag: 'Noun', reason: 'running-to' },
  // about love
  { match: 'about [#Infinitive]', group: 0, tag: 'Singular', reason: 'about-love' },
  // singers on stage
  { match: '#Plural on [#Infinitive]', group: 0, tag: 'Noun', reason: 'on-stage' },
  // any charge
  { match: 'any [#Infinitive]', group: 0, tag: 'Noun', reason: 'any-charge' },
  // no doubt
  { match: 'no [#Infinitive]', group: 0, tag: 'Noun', reason: 'no-doubt' },
  // number of seats
  { match: 'number of [#PresentTense]', group: 0, tag: 'Noun', reason: 'number-of-x' },
  // teaches/taught
  { match: '(taught|teaches|learns|learned) [#PresentTense]', group: 0, tag: 'Noun', reason: 'teaches-x' },
  // use reverse
  { match: '(try|use|attempt|build|make) [#Verb #Particle?]', notIf: '(#Copula|#Noun|sure|fun|up)', group: 0, tag: 'Noun', reason: 'do-verb' },//make sure of
  // checkmate is
  { match: '^[#Infinitive] (is|was)', group: 0, tag: 'Noun', reason: 'checkmate-is' },
  // get much sleep
  { match: '#Infinitive much [#Infinitive]', group: 0, tag: 'Noun', reason: 'get-much' },
  // cause i gotta
  { match: '[cause] #Pronoun #Verb', group: 0, tag: 'Conjunction', reason: 'cause-cuz' },
  // the cardio dance party
  { match: 'the #Singular [#Infinitive] #Noun', group: 0, tag: 'Noun', notIf: '#Pronoun', reason: 'cardio-dance' },

  // that should smoke
  { match: '#Determiner #Modal [#Noun]', group: 0, tag: 'PresentTense', reason: 'should-smoke' },
  //this rocks
  { match: 'this [#Plural]', group: 0, tag: 'PresentTense', notIf: '(#Preposition|#Date)', reason: 'this-verbs' },
  //voice that rocks
  { match: '#Noun that [#Plural]', group: 0, tag: 'PresentTense', notIf: '(#Preposition|#Pronoun|way)', reason: 'voice-that-rocks' },
  //that leads to
  { match: 'that [#Plural] to', group: 0, tag: 'PresentTense', notIf: '#Preposition', reason: 'that-leads-to' },
  //let him glue
  {
    match: '(let|make|made) (him|her|it|#Person|#Place|#Organization)+ [#Singular] (a|an|the|it)',
    group: 0,
    tag: 'Infinitive',
    reason: 'let-him-glue',
  },

  // assign all tasks
  { match: '#Verb (all|every|each|most|some|no) [#PresentTense]', notIf: '#Modal', group: 0, tag: 'Noun', reason: 'all-presentTense' },  // PresentTense/Noun ambiguities
  // big dreams, critical thinking
  // have big dreams
  { match: '(had|have|#PastTense) #Adjective [#PresentTense]', group: 0, tag: 'Noun', notIf: 'better', reason: 'adj-presentTense' },
  // excellent answer spencer
  // { match: '^#Adjective [#PresentTense]', group: 0, tag: 'Noun', reason: 'start adj-presentTense' },
  // one big reason
  { match: '#Value #Adjective [#PresentTense]', group: 0, tag: 'Noun', notIf: '#Copula', reason: 'one-big-reason' },
  // won widespread support
  { match: '#PastTense #Adjective+ [#PresentTense]', group: 0, tag: 'Noun', notIf: '(#Copula|better)', reason: 'won-wide-support' },
  // many poses
  { match: '(many|few|several|couple) [#PresentTense]', group: 0, tag: 'Noun', notIf: '#Copula', reason: 'many-poses' },
  // very big dreams
  { match: '#Determiner #Adverb #Adjective [%Noun|Verb%]', group: 0, tag: 'Noun', notIf: '#Copula', reason: 'very-big-dream' },
  // from start to finish
  { match: 'from #Noun to [%Noun|Verb%]', group: 0, tag: 'Noun', reason: 'start-to-finish' },
  // for comparison or contrast
  { match: '(for|with|of) #Noun (and|or|not) [%Noun|Verb%]', group: 0, tag: 'Noun', notIf: '#Pronoun', reason: 'for-food-and-gas' },
  // adorable little store
  { match: '#Adjective #Adjective [#PresentTense]', group: 0, tag: 'Noun', notIf: '#Copula', reason: 'adorable-little-store' },
  // of basic training
  // { match: '#Preposition #Adjective [#PresentTense]', group: 0, tag: 'Noun', reason: 'of-basic-training' },
  // justifiying higher costs
  { match: '#Gerund #Adverb? #Comparative [#PresentTense]', group: 0, tag: 'Noun', notIf: '#Copula', reason: 'higher-costs' },

  { match: '(#Noun && @hasComma) #Noun (and|or) [#PresentTense]', group: 0, tag: 'Noun', notIf: '#Copula', reason: 'noun-list' },

  // any questions for
  { match: '(many|any|some|several) [#PresentTense] for', group: 0, tag: 'Noun', reason: 'any-verbs-for' },
  // to facilitate gas exchange with
  { match: `to #PresentTense #Noun [#PresentTense] #Preposition`, group: 0, tag: 'Noun', reason: 'gas-exchange' },
  // waited until release
  { match: `#PastTense (until|as|through|without) [#PresentTense]`, group: 0, tag: 'Noun', reason: 'waited-until-release' },
  // selling like hot cakes
  { match: `#Gerund like #Adjective? [#PresentTense]`, group: 0, tag: 'Plural', reason: 'like-hot-cakes' },
  // some valid reason
  { match: `some #Adjective [#PresentTense]`, group: 0, tag: 'Noun', reason: 'some-reason' },
  // for some reason
  { match: `for some [#PresentTense]`, group: 0, tag: 'Noun', reason: 'for-some-reason' },
  // same kind of shouts
  { match: `(same|some|the|that|a) kind of [#PresentTense]`, group: 0, tag: 'Noun', reason: 'some-kind-of' },
  // a type of shout
  { match: `(same|some|the|that|a) type of [#PresentTense]`, group: 0, tag: 'Noun', reason: 'some-type-of' },
  // doing better for fights
  { match: `#Gerund #Adjective #Preposition [#PresentTense]`, group: 0, tag: 'Noun', reason: 'doing-better-for-x' },
  // get better aim
  { match: `(get|got|have) #Comparative [#PresentTense]`, group: 0, tag: 'Noun', reason: 'got-better-aim' },
  // whose name was
  { match: 'whose [#PresentTense] #Copula', group: 0, tag: 'Noun', reason: 'whos-name-was' },
  // give up on reason
  { match: `#PhrasalVerb #Particle #Preposition [#PresentTense]`, group: 0, tag: 'Noun', reason: 'given-up-on-x' },
  //there are reasons
  { match: 'there (are|were) #Adjective? [#PresentTense]', group: 0, tag: 'Plural', reason: 'there-are' },
  // 30 trains
  { match: '#Value [#PresentTense] of', group: 0, notIf: '(one|1|#Copula|#Infinitive)', tag: 'Plural', reason: '2-trains' },
  // compromises are possible
  { match: '[#PresentTense] (are|were) #Adjective', group: 0, tag: 'Plural', reason: 'compromises-are-possible' },
  // hope i helped
  { match: '^[(hope|guess|thought|think)] #Pronoun #Verb', group: 0, tag: 'Infinitive', reason: 'suppose-i' },
  //pursue its dreams
  // { match: '#PresentTense #Possessive [#PresentTense]', notIf: '#Gerund', group: 0, tag: 'Plural', reason: 'pursue-its-dreams' },
  // our unyielding support
  { match: '#Possessive #Adjective [#Verb]', group: 0, tag: 'Noun', notIf: '#Copula', reason: 'our-full-support' },
  // tastes good
  { match: '[(tastes|smells)] #Adverb? #Adjective', group: 0, tag: 'PresentTense', reason: 'tastes-good' },
  // are you playing golf
  // { match: '^are #Pronoun [#Noun]', group: 0, notIf: '(here|there)', tag: 'Verb', reason: 'are-you-x' },
  // ignoring commute
  { match: '#Copula #Gerund [#PresentTense] !by?', group: 0, tag: 'Noun', notIf: 'going', reason: 'ignoring-commute' },
  // noun-pastTense variables
  { match: '#Determiner #Adjective? [(shed|thought|rose|bid|saw|spelt)]', group: 0, tag: 'Noun', reason: 'noun-past' },

  // 'verb-to'
  // how to watch
  { match: 'how to [%Noun|Verb%]', group: 0, tag: 'Infinitive', reason: 'how-to-noun' },
  // which boost it
  { match: 'which [%Noun|Verb%] #Noun', group: 0, tag: 'Infinitive', reason: 'which-boost-it' },
  // asking questions
  { match: '#Gerund [%Plural|Verb%]', group: 0, tag: 'Plural', reason: 'asking-questions' },
  // ready to stream
  { match: '(ready|available|difficult|hard|easy|made|attempt|try) to [%Noun|Verb%]', group: 0, tag: 'Infinitive', reason: 'ready-to-noun' },
  // bring to market
  { match: '(bring|went|go|drive|run|bike) to [%Noun|Verb%]', group: 0, tag: 'Noun', reason: 'bring-to-noun' },
  // can i sleep, would you look
  { match: '#Modal #Noun [%Noun|Verb%]', group: 0, tag: 'Infinitive', reason: 'would-you-look' },
  // is just spam
  { match: '#Copula just [#Infinitive]', group: 0, tag: 'Noun', reason: 'is-just-spam' },
  // request copies
  { match: '^%Noun|Verb% %Plural|Verb%', tag: 'Imperative #Plural', reason: 'request-copies' },
  // homemade pickles and drinks
  { match: '#Adjective #Plural and [%Plural|Verb%]', group: 0, tag: '#Plural', reason: 'pickles-and-drinks' },
  // the 1968 film
  { match: '#Determiner #Year [#Verb]', group: 0, tag: 'Noun', reason: 'the-1968-film' },
  // the break up
  { match: '#Determiner [#PhrasalVerb #Particle]', group: 0, tag: 'Noun', reason: 'the-break-up' },
  // the individual goals
  { match: '#Determiner [%Adj|Noun%] #Noun', group: 0, tag: 'Adjective', notIf: '(#Pronoun|#Possessive|#ProperNoun)', reason: 'the-individual-goals' },
  // work or prepare
  { match: '[%Noun|Verb%] or #Infinitive', group: 0, tag: 'Infinitive', reason: 'work-or-prepare' },
  // to give thanks
  { match: 'to #Infinitive [#PresentTense]', group: 0, tag: 'Noun', notIf: '(#Gerund|#Copula|help)', reason: 'to-give-thanks' },
  // kills me
  { match: '[#Noun] me', group: 0, tag: 'Verb', reason: 'kills-me' },
  // removes wrinkles
  { match: '%Plural|Verb% %Plural|Verb%', tag: '#PresentTense #Plural', reason: 'removes-wrinkles' },
];

var money = [
  { match: '#Money and #Money #Currency?', tag: 'Money', reason: 'money-and-money' },
  // 6 dollars and 5 cents
  { match: '#Value #Currency [and] #Value (cents|ore|centavos|sens)', group: 0, tag: 'money', reason: 'and-5-cents' },
  // maybe currencies
  { match: '#Value (mark|rand|won|rub|ore)', tag: '#Money #Currency', reason: '4-mark' },
  // 3 pounds
  { match: 'a pound', tag: '#Money #Unit', reason: 'a-pound' },
  { match: '#Value (pound|pounds)', tag: '#Money #Unit', reason: '4-pounds' },
];

var fractions = [
  // half a penny
  { match: '[(half|quarter)] of? (a|an)', group: 0, tag: 'Fraction', reason: 'millionth' },
  // nearly half
  { match: '#Adverb [half]', group: 0, tag: 'Fraction', reason: 'nearly-half' },
  // half the
  { match: '[half] the', group: 0, tag: 'Fraction', reason: 'half-the' },
  // and a half
  { match: '#Cardinal and a half', tag: 'Fraction', reason: 'and-a-half' },
  // two-halves
  { match: '#Value (halves|halfs|quarters)', tag: 'Fraction', reason: 'two-halves' },

  // ---ordinals as fractions---
  // a fifth
  { match: 'a #Ordinal', tag: 'Fraction', reason: 'a-quarter' },
  // seven fifths
  { match: '[#Cardinal+] (#Fraction && /s$/)', tag: 'Fraction', reason: 'seven-fifths' },
  // doc.match('(#Fraction && /s$/)').lookBefore('#Cardinal+$').tag('Fraction')
  // one third of ..
  { match: '[#Cardinal+ #Ordinal] of .', group: 0, tag: 'Fraction', reason: 'ordinal-of' },
  // 100th of
  { match: '[(#NumericValue && #Ordinal)] of .', group: 0, tag: 'Fraction', reason: 'num-ordinal-of' },
  // a twenty fifth
  { match: '(a|one) #Cardinal?+ #Ordinal', tag: 'Fraction', reason: 'a-ordinal' },

  // //  '3 out of 5'
  { match: '#Cardinal+ out? of every? #Cardinal', tag: 'Fraction', reason: 'out-of' },
];

// {match:'', tag:'',reason:''},

var numbers$1 = [
  // ==== Ambiguous numbers ====
  // 'second'
  { match: `#Cardinal [second]`, tag: 'Unit', reason: 'one-second' },
  //'a/an' can mean 1 - "a hour"
  {
    match: '!once? [(a|an)] (#Duration|hundred|thousand|million|billion|trillion)',
    group: 0,
    tag: 'Value',
    reason: 'a-is-one',
  },
  // ==== PhoneNumber ====
  //1 800 ...
  { match: '1 #Value #PhoneNumber', tag: 'PhoneNumber', reason: '1-800-Value' },
  //(454) 232-9873
  { match: '#NumericValue #PhoneNumber', tag: 'PhoneNumber', reason: '(800) PhoneNumber' },

  // ==== Currency ====
  // chinese yuan
  { match: '#Demonym #Currency', tag: 'Currency', reason: 'demonym-currency' },
  // ten bucks
  { match: '#Value [(buck|bucks|grand)]', group: 0, tag: 'Currency', reason: 'value-bucks' },
  // ==== Money ====
  { match: '[#Value+] #Currency', group: 0, tag: 'Money', reason: '15 usd' },

  // ==== Ordinal ====
  { match: '[second] #Noun', group: 0, tag: 'Ordinal', reason: 'second-noun' },

  // ==== Units ====
  //5 yan
  { match: '#Value+ [#Currency]', group: 0, tag: 'Unit', reason: '5-yan' },
  { match: '#Value [(foot|feet)]', group: 0, tag: 'Unit', reason: 'foot-unit' },
  //5 kg.
  { match: '#Value [#Abbreviation]', group: 0, tag: 'Unit', reason: 'value-abbr' },
  { match: '#Value [k]', group: 0, tag: 'Unit', reason: 'value-k' },
  { match: '#Unit an hour', tag: 'Unit', reason: 'unit-an-hour' },

  // ==== Magnitudes ====
  //minus 7
  { match: '(minus|negative) #Value', tag: 'Value', reason: 'minus-value' },
  //seven point five
  { match: '#Value (point|decimal) #Value', tag: 'Value', reason: 'value-point-value' },
  //quarter million
  { match: '#Determiner [(half|quarter)] #Ordinal', group: 0, tag: 'Value', reason: 'half-ordinal' },
  // thousand and two
  { match: `#Multiple+ and #Value`, tag: 'Value', reason: 'magnitude-and-value' },
  // ambiguous units like 'gb'
  // { match: '#Value square? [(kb|mb|gb|tb|ml|pt|qt|tbl|tbsp|km|cm|mm|mi|ft|yd|kg|hg|mg|oz|lb|mph|pa|miles|yard|yards|pound|pounds)]', group: 0, tag: 'Unit', reason: '12-gb' },
  // 5 miles per hour
  { match: '#Value #Unit [(per|an) (hr|hour|sec|second|min|minute)]', group: 0, tag: 'Unit', reason: '12-miles-per-second' },
  // 5 square miles
  { match: '#Value [(square|cubic)] #Unit', group: 0, tag: 'Unit', reason: 'square-miles' },
  // 5) The expenses
  // { match: '^[#Value] (#Determiner|#Gerund)', group: 0, tag: 'Expression', unTag: 'Value', reason: 'numbered-list' },
];

var person = [
  // ==== FirstNames ====
  //is foo Smith
  { match: '#Copula [(#Noun|#PresentTense)] #LastName', group: 0, tag: 'FirstName', reason: 'copula-noun-lastname' },
  //pope francis
  {
    match: '(sister|pope|brother|father|aunt|uncle|grandpa|grandfather|grandma) #ProperNoun',
    tag: 'Person',
    reason: 'lady-titlecase',
    safe: true,
  },

  // ==== Nickname ====
  // Dwayne 'the rock' Johnson
  { match: '#FirstName [#Determiner #Noun] #LastName', group: 0, tag: 'Person', reason: 'first-noun-last' },
  {
    match: '#ProperNoun (b|c|d|e|f|g|h|j|k|l|m|n|o|p|q|r|s|t|u|v|w|x|y|z) #ProperNoun',
    tag: 'Person',
    reason: 'titlecase-acronym-titlecase',
    safe: true,
  },
  { match: '#Acronym #LastName', tag: 'Person', reason: 'acronym-lastname', safe: true },
  { match: '#Person (jr|sr|md)', tag: 'Person', reason: 'person-honorific' },
  //remove single 'mr'
  { match: '#Honorific #Acronym', tag: 'Person', reason: 'Honorific-TitleCase' },
  { match: '#Person #Person the? #RomanNumeral', tag: 'Person', reason: 'roman-numeral' },
  { match: '#FirstName [/^[^aiurck]$/]', group: 0, tag: ['Acronym', 'Person'], reason: 'john-e' },
  //j.k Rowling
  { match: '#Noun van der? #Noun', tag: 'Person', reason: 'van der noun', safe: true },
  //king of spain
  { match: '(king|queen|prince|saint|lady) of #Noun', tag: 'Person', reason: 'king-of-noun', safe: true },
  //lady Florence
  { match: '(prince|lady) #Place', tag: 'Person', reason: 'lady-place' },
  //saint Foo
  { match: '(king|queen|prince|saint) #ProperNoun', tag: 'Person', notIf: '#Place', reason: 'saint-foo' },

  // al sharpton
  { match: 'al (#Person|#ProperNoun)', tag: 'Person', reason: 'al-borlen', safe: true },
  //ferdinand de almar
  { match: '#FirstName de #Noun', tag: 'Person', reason: 'bill-de-noun' },
  //Osama bin Laden
  { match: '#FirstName (bin|al) #Noun', tag: 'Person', reason: 'bill-al-noun' },
  //John L. Foo
  { match: '#FirstName #Acronym #ProperNoun', tag: 'Person', reason: 'bill-acronym-title' },
  //Andrew Lloyd Webber
  { match: '#FirstName #FirstName #ProperNoun', tag: 'Person', reason: 'bill-firstname-title' },
  //Mr Foo
  { match: '#Honorific #FirstName? #ProperNoun', tag: 'Person', reason: 'dr-john-Title' },
  //peter the great
  { match: '#FirstName the #Adjective', tag: 'Person', reason: 'name-the-great' },

  // dick van dyke
  { match: '#ProperNoun (van|al|bin) #ProperNoun', tag: 'Person', reason: 'title-van-title', safe: true },
  //jose de Sucre
  { match: '#ProperNoun (de|du) la? #ProperNoun', tag: 'Person', notIf: '#Place', reason: 'title-de-title' },
  //Jani K. Smith
  { match: '#Singular #Acronym #LastName', tag: '#FirstName #Person .', reason: 'title-acro-noun', safe: true },
  //Foo Ford
  { match: '[#ProperNoun] #Person', group: 0, tag: 'Person', reason: 'proper-person', safe: true },
  // john keith jones
  {
    match: '#Person [#ProperNoun #ProperNoun]',
    group: 0,
    tag: 'Person',
    notIf: '#Possessive',
    reason: 'three-name-person',
    safe: true,
  },
  //John Foo
  {
    match: '#FirstName #Acronym? [#ProperNoun]',
    group: 0,
    tag: 'LastName',
    notIf: '#Possessive',
    reason: 'firstname-titlecase',
  },
  // john stewart
  { match: '#FirstName [#FirstName]', group: 0, tag: 'LastName', reason: 'firstname-firstname' },
  //Joe K. Sombrero
  { match: '#FirstName #Acronym #Noun', tag: 'Person', reason: 'n-acro-noun', safe: true },
  //Anthony de Marco
  { match: '#FirstName [(de|di|du|van|von)] #Person', group: 0, tag: 'LastName', reason: 'de-firstname' },

  // baker jenna smith
  // { match: '[#Actor+] #Person', group: 0, tag: 'Person', reason: 'baker-sam-smith' },
  // sergeant major Harold
  {
    match:
      '[(lieutenant|corporal|sergeant|captain|qeen|king|admiral|major|colonel|marshal|president|queen|king)+] #ProperNoun',
    group: 0,
    tag: 'Honorific',
    reason: 'seargeant-john',
  },
  // ==== Honorics ====
  {
    match: '[(private|general|major|rear|prime|field|count|miss)] #Honorific? #Person',
    group: 0,
    tag: ['Honorific', 'Person'],
    reason: 'ambg-honorifics',
  },
  // dr john foobar
  {
    match: '#Honorific #FirstName [#Singular]',
    group: 0,
    tag: 'LastName',
    notIf: '#Possessive',
    reason: 'dr-john-foo',
    safe: true,
  },
  //his-excellency
  {
    match: '[(his|her) (majesty|honour|worship|excellency|honorable)] #Person',
    group: 0,
    tag: 'Honorific',
    reason: 'his-excellency',
  },
  // Lieutenant colonel
  { match: '#Honorific #Actor', tag: 'Honorific', reason: 'Lieutenant colonel' },
  // first lady, second admiral
  { match: '(first|second|third|1st|2nd|3rd) #Actor', tag: 'Honorific', reason: 'first lady' },
  // Louis IV
  { match: '#Person #RomanNumeral', tag: 'Person', reason: 'louis-IV' },
];

// const personAdj = '(misty|rusty|dusty|rich|randy|sandy|young|earnest|frank|brown)'

var personName = [
  // ebenezer scrooge
  {
    match: '#FirstName #Noun$',
    tag: '. #LastName',
    notIf: '(#Possessive|#Organization|#Place|#Pronoun|@hasTitleCase)',
    reason: 'firstname-noun',
  },

  // ===person-date===
  { match: '%Person|Date% #Acronym? #ProperNoun', tag: 'Person', reason: 'jan-thierson' },
  // ===person-noun===
  //Cliff Clavin
  { match: '%Person|Noun% #Acronym? #ProperNoun', tag: 'Person', reason: 'switch-person', safe: true },
  // olive garden
  { match: '%Person|Noun% #Organization', tag: 'Organization', reason: 'olive-garden' },
  // ===person-verb===
  // ollie faroo
  { match: '%Person|Verb% #Acronym? #ProperNoun', tag: 'Person', reason: 'verb-propernoun', ifNo: '#Actor' },
  // chuck will ...
  {
    match: `[%Person|Verb%] (will|had|has|said|says|told|did|learned|wants|wanted)`,
    group: 0,
    tag: 'Person',
    reason: 'person-said',
  },

  // ===person-place===
  //sydney harbour
  {
    match: `[%Person|Place%] (harbor|harbour|pier|town|city|place|dump|landfill)`,
    group: 0,
    tag: 'Place',
    reason: 'sydney-harbour',
  },
  // east sydney
  { match: `(west|east|north|south) [%Person|Place%]`, group: 0, tag: 'Place', reason: 'east-sydney' },

  // ===person-adjective===
  // rusty smith
  // { match: `${personAdj} #Person`, tag: 'Person', reason: 'randy-smith' },
  // rusty a. smith
  // { match: `${personAdj} #Acronym? #ProperNoun`, tag: 'Person', reason: 'rusty-smith' },
  // very rusty
  // { match: `#Adverb [${personAdj}]`, group: 0, tag: 'Adjective', reason: 'really-rich' },

  // ===person-verb===
  // would wade
  { match: `#Modal [%Person|Verb%]`, group: 0, tag: 'Verb', reason: 'would-mark' },
  // really wade
  { match: `#Adverb [%Person|Verb%]`, group: 0, tag: 'Verb', reason: 'really-mark' },
  // drew closer
  { match: `[%Person|Verb%] (#Adverb|#Comparative)`, group: 0, tag: 'Verb', reason: 'drew-closer' },
  // wade smith
  { match: `%Person|Verb% #Person`, tag: 'Person', reason: 'rob-smith' },
  // wade m. Cooper
  { match: `%Person|Verb% #Acronym #ProperNoun`, tag: 'Person', reason: 'rob-a-smith' },
  // will go
  { match: '[will] #Verb', group: 0, tag: 'Modal', reason: 'will-verb' },
  // will Pharell
  { match: '(will && @isTitleCase) #ProperNoun', tag: 'Person', reason: 'will-name' },
  // jack layton won
  {
    match: '(#FirstName && !#Possessive) [#Singular] #Verb',
    group: 0,
    safe: true,
    tag: 'LastName',
    reason: 'jack-layton',
  },
  // sherwood anderson told
  { match: '^[#Singular] #Person #Verb', group: 0, safe: true, tag: 'Person', reason: 'sherwood-anderson' },
  // bought a warhol
  { match: '(a|an) [#Person]$', group: 0, unTag: 'Person', reason: 'a-warhol' },
];

var verbs$1 = [
  //sometimes adverbs - 'pretty good','well above'
  {
    match: '#Copula (pretty|dead|full|well|sure) (#Adjective|#Noun)',
    tag: '#Copula #Adverb #Adjective',
    reason: 'sometimes-adverb',
  },
  //i better ..
  { match: '(#Pronoun|#Person) (had|#Adverb)? [better] #PresentTense', group: 0, tag: 'Modal', reason: 'i-better' },
  // adj -> gerund
  // like
  { match: '(#Modal|i|they|we|do) not? [like]', group: 0, tag: 'PresentTense', reason: 'modal-like' },
  // ==== Tense ====
  //he left
  { match: '#Noun #Adverb? [left]', group: 0, tag: 'PastTense', reason: 'left-verb' },

  // ==== Copula ====
  //will be running (not copula)
  { match: 'will #Adverb? not? #Adverb? [be] #Gerund', group: 0, tag: 'Copula', reason: 'will-be-copula' },
  //for more complex forms, just tag 'be'
  { match: 'will #Adverb? not? #Adverb? [be] #Adjective', group: 0, tag: 'Copula', reason: 'be-copula' },
  // ==== Infinitive ====
  //march to
  { match: '[march] (up|down|back|toward)', notIf: '#Date', group: 0, tag: 'Infinitive', reason: 'march-to' },
  //must march
  { match: '#Modal [march]', group: 0, tag: 'Infinitive', reason: 'must-march' },
  // may be
  { match: `[may] be`, group: 0, tag: 'Verb', reason: 'may-be' },
  // subject to
  { match: `[(subject|subjects|subjected)] to`, group: 0, tag: 'Verb', reason: 'subject to' },
  // subject to
  { match: `[home] to`, group: 0, tag: 'PresentTense', reason: 'home to' },

  // === misc==
  // side with
  // { match: '[(side|fool|monkey)] with', group: 0, tag: 'Infinitive', reason: 'fool-with' },
  // open the door
  { match: '[open] #Determiner', group: 0, tag: 'Infinitive', reason: 'open-the' },
  //were being run
  { match: `(were|was) being [#PresentTense]`, group: 0, tag: 'PastTense', reason: 'was-being' },
  //had been broken
  { match: `(had|has|have) [been /en$/]`, group: 0, tag: 'Auxiliary Participle', reason: 'had-been-broken' },
  //had been smoked
  { match: `(had|has|have) [been /ed$/]`, group: 0, tag: 'Auxiliary PastTense', reason: 'had-been-smoked' },
  //were being run
  { match: `(had|has) #Adverb? [been] #Adverb? #PastTense`, group: 0, tag: 'Auxiliary', reason: 'had-been-adj' },
  //had to walk
  { match: `(had|has) to [#Noun] (#Determiner|#Possessive)`, group: 0, tag: 'Infinitive', reason: 'had-to-noun' },
  // have read
  { match: `have [#PresentTense]`, group: 0, tag: 'PastTense', notIf: '(come|gotten)', reason: 'have-read' },
  // does that work
  { match: `(does|will|#Modal) that [work]`, group: 0, tag: 'PastTense', reason: 'does-that-work' },
  // sounds fun
  { match: `[(sound|sounds)] #Adjective`, group: 0, tag: 'PresentTense', reason: 'sounds-fun' },
  // look good
  { match: `[(look|looks)] #Adjective`, group: 0, tag: 'PresentTense', reason: 'looks-good' },
  // stops thinking
  { match: `[(start|starts|stop|stops|begin|begins)] #Gerund`, group: 0, tag: 'Verb', reason: 'starts-thinking' },
  // have read
  { match: `(have|had) read`, tag: 'Modal #PastTense', reason: 'read-read' },
  //were under cooked
  {
    match: `(is|was|were) [(under|over) #PastTense]`,
    group: 0,
    tag: 'Adverb Adjective',
    reason: 'was-under-cooked',
  },

  // damn them
  { match: '[shit] (#Determiner|#Possessive|them)', group: 0, tag: 'Verb', reason: 'swear1-verb' },
  { match: '[damn] (#Determiner|#Possessive|them)', group: 0, tag: 'Verb', reason: 'swear2-verb' },
  { match: '[fuck] (#Determiner|#Possessive|them)', group: 0, tag: 'Verb', reason: 'swear3-verb' },

  // jobs that fit
  { match: '#Plural that %Noun|Verb%', tag: '. #Preposition #Infinitive', reason: 'jobs-that-work' },
  // works for me
  { match: '[works] for me', group: 0, tag: 'PresentTense', reason: 'works-for-me' },
  // as we please
  { match: 'as #Pronoun [please]', group: 0, tag: 'Infinitive', reason: 'as-we-please' },
  // verb-prefixes - 'co write'
  { match: '[(co|mis|de|inter|intra|pre|re|un|out|under|over|counter)] #Verb', group: 0, tag: ['Verb', 'Prefix'], notIf: '(#Copula|#PhrasalVerb)', reason: 'co-write' },
  // dressed and left
  { match: '#PastTense and [%Adj|Past%]', group: 0, tag: 'PastTense', reason: 'dressed-and-left' },
  // melted and fallen
  { match: '[%Adj|Past%] and #PastTense', group: 0, tag: 'PastTense', reason: 'dressed-and-left' },
  // is he stoked
  { match: '#Copula #Pronoun [%Adj|Past%]', group: 0, tag: 'Adjective', reason: 'is-he-stoked' },
  // to dream of
  { match: 'to [%Noun|Verb%] #Preposition', group: 0, tag: 'Infinitive', reason: 'to-dream-of' },
];

// these are some of our heaviest-used matches
var auxiliary = [
  // ==== Auxiliary ====
  // have been
  { match: `will (#Adverb|not)+? [have] (#Adverb|not)+? #Verb`, group: 0, tag: 'Auxiliary', reason: 'will-have-vb' },
  //was walking
  { match: `[#Copula] (#Adverb|not)+? (#Gerund|#PastTense)`, group: 0, tag: 'Auxiliary', reason: 'copula-walking' },
  //would walk
  { match: `[(#Modal|did)+] (#Adverb|not)+? #Verb`, group: 0, tag: 'Auxiliary', reason: 'modal-verb' },
  //would have had
  { match: `#Modal (#Adverb|not)+? [have] (#Adverb|not)+? [had] (#Adverb|not)+? #Verb`, group: 0, tag: 'Auxiliary', reason: 'would-have' },
  //support a splattering of auxillaries before a verb
  { match: `[(has|had)] (#Adverb|not)+? #PastTense`, group: 0, tag: 'Auxiliary', reason: 'had-walked' },
  // will walk
  { match: '[(do|does|did|will|have|had|has|got)] (not|#Adverb)+? #Verb', group: 0, tag: 'Auxiliary', reason: 'have-had' },
  // about to go
  { match: '[about to] #Adverb? #Verb', group: 0, tag: ['Auxiliary', 'Verb'], reason: 'about-to' },
  //would be walking
  { match: `#Modal (#Adverb|not)+? [be] (#Adverb|not)+? #Verb`, group: 0, tag: 'Auxiliary', reason: 'would-be' },
  //had been walking
  { match: `[(#Modal|had|has)] (#Adverb|not)+? [been] (#Adverb|not)+? #Verb`, group: 0, tag: 'Auxiliary', reason: 'had-been' },
  // was being driven
  { match: '[(be|being|been)] #Participle', group: 0, tag: 'Auxiliary', reason: 'being-driven' },
  // may want
  { match: '[may] #Adverb? #Infinitive', group: 0, tag: 'Auxiliary', reason: 'may-want' },
  // was being walked
  { match: '#Copula (#Adverb|not)+? [(be|being|been)] #Adverb+? #PastTense', group: 0, tag: 'Auxiliary', reason: 'being-walked' },
  // will be walked
  { match: 'will [be] #PastTense', group: 0, tag: 'Auxiliary', reason: 'will-be-x' },
  // been walking
  { match: '[(be|been)] (#Adverb|not)+? #Gerund', group: 0, tag: 'Auxiliary', reason: 'been-walking' },
  // used to walk
  { match: '[used to] #PresentTense', group: 0, tag: 'Auxiliary', reason: 'used-to-walk' },
  // was going to walk
  { match: '#Copula (#Adverb|not)+? [going to] #Adverb+? #PresentTense', group: 0, tag: 'Auxiliary', reason: 'going-to-walk' },
  // tell me
  { match: '#Imperative [(me|him|her)]', group: 0, tag: 'Reflexive', reason: 'tell-him' },
  // there is no x
  { match: '(is|was) #Adverb? [no]', group: 0, tag: 'Negative', reason: 'is-no' },
  // been told
  { match: '[(been|had|became|came)] #PastTense', group: 0, notIf: '#PhrasalVerb', tag: 'Auxiliary', reason: 'been-told' },
  // being born
  { match: '[(being|having|getting)] #Verb', group: 0, tag: 'Auxiliary', reason: 'being-born' },
  // be walking
  { match: '[be] #Gerund', group: 0, tag: 'Auxiliary', reason: 'be-walking' },
  // better go
  { match: '[better] #PresentTense', group: 0, tag: 'Modal', notIf: '(#Copula|#Gerund)', reason: 'better-go' },
  // even better
  { match: 'even better', tag: 'Adverb #Comparative', reason: 'even-better' },
];

var phrasal = [
  // ==== Phrasal ====
  //'foo-up'
  { match: '(#Verb && @hasHyphen) up', tag: 'PhrasalVerb', reason: 'foo-up' },
  { match: '(#Verb && @hasHyphen) off', tag: 'PhrasalVerb', reason: 'foo-off' },
  { match: '(#Verb && @hasHyphen) over', tag: 'PhrasalVerb', reason: 'foo-over' },
  { match: '(#Verb && @hasHyphen) out', tag: 'PhrasalVerb', reason: 'foo-out' },
  // walk in on
  {
    match: '[#Verb (in|out|up|down|off|back)] (on|in)',
    notIf: '#Copula',
    tag: 'PhrasalVerb Particle',
    reason: 'walk-in-on',
  },
  // went on for
  { match: '(lived|went|crept|go) [on] for', group: 0, tag: 'PhrasalVerb', reason: 'went-on' },
  // the curtains come down
  { match: '#Verb (up|down|in|on|for)$', tag: 'PhrasalVerb #Particle', notIf: '#PhrasalVerb', reason: 'come-down$' },
  // got me thinking
  // { match: '(got|had) me [#Noun]', group: 0, tag: 'Verb', reason: 'got-me-gerund' },
  // help stop
  { match: 'help [(stop|end|make|start)]', group: 0, tag: 'Infinitive', reason: 'help-stop' },
  // work in the office
  { match: '#PhrasalVerb (in && #Particle) #Determiner', tag: '#Verb #Preposition #Determiner', unTag: 'PhrasalVerb', reason: 'work-in-the' },
  // start listening
  { match: '[(stop|start|finish|help)] #Gerund', group: 0, tag: 'Infinitive', reason: 'start-listening' },
  // mis-fired
  // { match: '[(mis)] #Verb', group: 0, tag: 'Verb', reason: 'mis-firedsa' },
  //back it up
  {
    match: '#Verb (him|her|it|us|himself|herself|itself|everything|something) [(up|down)]',
    group: 0,
    tag: 'Adverb',
    reason: 'phrasal-pronoun-advb',
  },
];

// this is really hard to do
const notIf = '(i|we|they)'; //we do not go
var imperative = [
  // do not go
  { match: '^do not? [#Infinitive #Particle?]', notIf, group: 0, tag: 'Imperative', reason: 'do-eat' },
  // please go
  { match: '^please do? not? [#Infinitive #Particle?]', group: 0, tag: 'Imperative', reason: 'please-go' },
  // just go
  { match: '^just do? not? [#Infinitive #Particle?]', group: 0, tag: 'Imperative', reason: 'just-go' },
  // do it better
  { match: '^[#Infinitive] it #Comparative', notIf, group: 0, tag: 'Imperative', reason: 'do-it-better' },
  // do it again
  { match: '^[#Infinitive] it (please|now|again|plz)', notIf, group: 0, tag: 'Imperative', reason: 'do-it-please' },
  // go quickly.
  { match: '^[#Infinitive] (#Adjective|#Adverb)$', group: 0, tag: 'Imperative', notIf: '(so|such|rather|enough)', reason: 'go-quickly' },
  // turn down the noise
  { match: '^[#Infinitive] (up|down|over) #Determiner', group: 0, tag: 'Imperative', reason: 'turn-down' },
  // eat my shorts
  { match: '^[#Infinitive] (your|my|the|a|an|any|each|every|some|more|with|on)', group: 0, notIf: 'like', tag: 'Imperative', reason: 'eat-my-shorts' },
  // tell him the story
  { match: '^[#Infinitive] (him|her|it|us|me|there)', group: 0, tag: 'Imperative', reason: 'tell-him' },
  // avoid loud noises
  { match: '^[#Infinitive] #Adjective #Noun$', group: 0, tag: 'Imperative', reason: 'avoid-loud-noises' },
  // call and reserve
  { match: '^[#Infinitive] (#Adjective|#Adverb)? and #Infinitive', group: 0, tag: 'Imperative', reason: 'call-and-reserve' },
  // one-word imperatives
  { match: '^(go|stop|wait|hurry) please?$', tag: 'Imperative', reason: 'go' },
  // somebody call
  { match: '^(somebody|everybody) [#Infinitive]', group: 0, tag: 'Imperative', reason: 'somebody-call' },
  // let's leave
  { match: '^let (us|me) [#Infinitive]', group: 0, tag: 'Imperative', reason: 'lets-leave' },
  // shut the door
  { match: '^[(shut|close|open|start|stop|end|keep)] #Determiner #Noun', group: 0, tag: 'Imperative', reason: 'shut-the-door' },
  // turn off the light
  { match: '^[#PhrasalVerb #Particle] #Determiner #Noun', group: 0, tag: 'Imperative', reason: 'turn-off-the-light' },
  // go to toronto
  { match: '^[go] to .', group: 0, tag: 'Imperative', reason: 'go-to-toronto' },
  // would you recommend
  { match: '^#Modal you [#Infinitive]', group: 0, tag: 'Imperative', reason: 'would-you-' },
  // never say
  { match: '^never [#Infinitive]', group: 0, tag: 'Imperative', reason: 'never-stop' },
  // come have a drink
  { match: '^come #Infinitive', tag: 'Imperative', notIf: 'on', reason: 'come-have' },
  // come and have a drink
  { match: '^come and? #Infinitive', tag: 'Imperative . Imperative', notIf: '#PhrasalVerb', reason: 'come-and-have' },
  // stay away
  { match: '^stay (out|away|back)', tag: 'Imperative', reason: 'stay-away' },
  // stay cool
  { match: '^[(stay|be|keep)] #Adjective', group: 0, tag: 'Imperative', reason: 'stay-cool' },
  // keep it silent
  { match: '^[keep it] #Adjective', group: 0, tag: 'Imperative', reason: 'keep-it-cool' },
  // don't be late
  { match: '^do not [#Infinitive]', group: 0, tag: 'Imperative', reason: 'do-not-be' },
  // allow yourself
  { match: '[#Infinitive] (yourself|yourselves)', group: 0, tag: 'Imperative', reason: 'allow-yourself' },
  // look what
  { match: '[#Infinitive] what .', group: 0, tag: 'Imperative', reason: 'look-what' },
  // continue playing
  { match: '^[#Infinitive] #Gerund', group: 0, tag: 'Imperative', reason: 'keep-playing' },
  // go to it
  { match: '^[#Infinitive] (to|for|into|toward|here|there)', group: 0, tag: 'Imperative', reason: 'go-to' },
  // relax and unwind
  { match: '^[#Infinitive] (and|or) #Infinitive', group: 0, tag: 'Imperative', reason: 'inf-and-inf' },

  // commit to
  { match: '^[%Noun|Verb%] to', group: 0, tag: 'Imperative', reason: 'commit-to' },
  // maintain eye contact
  { match: '^[#Infinitive] #Adjective? #Singular #Singular', group: 0, tag: 'Imperative', reason: 'maintain-eye-contact' },
  // don't forget to clean
  { match: 'do not (forget|omit|neglect) to [#Infinitive]', group: 0, tag: 'Imperative', reason: 'do-not-forget' },
  // pay attention
  { match: '^[(ask|wear|pay|look|help|show|watch|act|fix|kill|stop|start|turn|try|win)] #Noun', group: 0, tag: 'Imperative', reason: 'pay-attention' },

];

var adjGerund = [
  // that were growing
  { match: '(that|which) were [%Adj|Gerund%]', group: 0, tag: 'Gerund', reason: 'that-were-growing' },
  // was dissapointing
  // { match: '#Copula [%Adj|Gerund%]$', group: 0, tag: 'Adjective', reason: 'was-disappointing$' },

  // repairing crubling roads
  { match: '#Gerund [#Gerund] #Plural', group: 0, tag: 'Adjective', reason: 'hard-working-fam' },

  // { match: '(that|which) were [%Adj|Gerund%]', group: 0, tag: 'Gerund', reason: 'that-were-growing' },
];

// ==== Passive voice ===
var passive$1 = [
  // got walked, was walked, were walked
  { match: '(got|were|was|is|are|am) (#PastTense|#Participle)', tag: 'Passive', reason: 'got-walked' },
  // was being walked
  { match: '(was|were|is|are|am) being (#PastTense|#Participle)', tag: 'Passive', reason: 'was-being' },
  // had been walked, have been eaten
  { match: '(had|have|has) been (#PastTense|#Participle)', tag: 'Passive', reason: 'had-been' },
  // will be cleaned
  { match: 'will be being? (#PastTense|#Participle)', tag: 'Passive', reason: 'will-be-cleaned' },
  // suffered by the country
  { match: '#Noun [(#PastTense|#Participle)] by (the|a) #Noun', group: 0, tag: 'Passive', reason: 'suffered-by' },

];

// order matters
let matches$1 = [
  // u r cool
  { match: 'u r', tag: '#Pronoun #Copula', reason: 'u r' },
  { match: '#Noun [(who|whom)]', group: 0, tag: 'Determiner', reason: 'captain-who' },

  // ==== Conditions ====
  // had he survived,
  { match: '[had] #Noun+ #PastTense', group: 0, tag: 'Condition', reason: 'had-he' },
  // were he to survive
  { match: '[were] #Noun+ to #Infinitive', group: 0, tag: 'Condition', reason: 'were-he' },

  // some sort of
  { match: 'some sort of', tag: 'Adjective Noun Conjunction', reason: 'some-sort-of' },
  // some of
  // { match: 'some of', tag: 'Noun Conjunction', reason: 'some-of' },
  // of some sort
  { match: 'of some sort', tag: 'Conjunction Adjective Noun', reason: 'of-some-sort' },
  // such skill
  { match: '[such] (a|an|is)? #Noun', group: 0, tag: 'Determiner', reason: 'such-skill' },
  // another one
  // { match: '[another] (#Noun|#Value)', group: 0, tag: 'Adjective', reason: 'another-one' },
  // right after
  { match: '[right] (before|after|in|into|to|toward)', group: 0, tag: '#Adverb', reason: 'right-into' },
  // at about
  { match: '#Preposition [about]', group: 0, tag: 'Adjective', reason: 'at-about' },
  // are ya
  { match: '(are|#Modal|see|do|for) [ya]', group: 0, tag: 'Pronoun', reason: 'are-ya' },
  // long live
  { match: '[long live] .', group: 0, tag: '#Adjective #Infinitive', reason: 'long-live' },
  // plenty of
  { match: '[plenty] of', group: 0, tag: '#Uncountable', reason: 'plenty-of' },
  // 'there' as adjective
  { match: '(always|nearly|barely|practically) [there]', group: 0, tag: 'Adjective', reason: 'always-there' },
  // existential 'there'
  // there she is
  { match: '[there] (#Adverb|#Pronoun)? #Copula', group: 0, tag: 'There', reason: 'there-is' },
  // is there food
  { match: '#Copula [there] .', group: 0, tag: 'There', reason: 'is-there' },
  // should there
  { match: '#Modal #Adverb? [there]', group: 0, tag: 'There', reason: 'should-there' },
  // do you
  { match: '^[do] (you|we|they)', group: 0, tag: 'QuestionWord', reason: 'do-you' },
  // does he
  { match: '^[does] (he|she|it|#ProperNoun)', group: 0, tag: 'QuestionWord', reason: 'does-he' },
  // the person who
  { match: '#Determiner #Noun+ [who] #Verb', group: 0, tag: 'Preposition', reason: 'the-x-who' },
  // the person which
  { match: '#Determiner #Noun+ [which] #Verb', group: 0, tag: 'Preposition', reason: 'the-x-which' },
  // a while
  { match: 'a [while]', group: 0, tag: 'Noun', reason: 'a-while' },
  // guess who
  { match: 'guess who', tag: '#Infinitive #QuestionWord', reason: 'guess-who' },
  // swear words
  { match: '[fucking] !#Verb', group: 0, tag: '#Gerund', reason: 'f-as-gerund' },
];

// import orgWords from './_orgWords.js'
// let orgMap = `(${orgWords.join('|')})`

/*
const multi = [
  'building society',
  'central bank',
  'department store',
  'institute of technology',
  'liberation army',
  'people party',
  'social club',
  'state police',
  'state university',
]
*/

var orgs = [
  // Foo University
  // { match: `#Noun ${orgMap}`, tag: 'Organization', safe: true, reason: 'foo-university' },
  // // University of Toronto
  // { match: `${orgMap} of #Place`, tag: 'Organization', safe: true, reason: 'university-of-foo' },

  // // foo regional health authority
  // { match: `${orgMap} (health|local|regional)+ authority`, tag: 'Organization', reason: 'regional-health' },
  // // foo stock exchange
  // { match: `${orgMap} (stock|mergantile)+ exchange`, tag: 'Organization', reason: 'stock-exchange' },
  // // foo news service
  // { match: `${orgMap} (daily|evening|local)+ news service?`, tag: 'Organization', reason: 'foo-news' },
  //University of Foo
  { match: 'university of #Place', tag: 'Organization', reason: 'university-of-Foo' },
  //John & Joe's
  { match: '#Noun (&|n) #Noun', tag: 'Organization', reason: 'Noun-&-Noun' },
  // teachers union of Ontario
  { match: '#Organization of the? #ProperNoun', tag: 'Organization', reason: 'org-of-place', safe: true },
  //walmart USA
  { match: '#Organization #Country', tag: 'Organization', reason: 'org-country' },
  //organization
  { match: '#ProperNoun #Organization', tag: 'Organization', notIf: '#FirstName', reason: 'titlecase-org' },
  //FitBit Inc
  { match: '#ProperNoun (ltd|co|inc|dept|assn|bros)', tag: 'Organization', reason: 'org-abbrv' },
  // the OCED
  { match: 'the [#Acronym]', group: 0, tag: 'Organization', reason: 'the-acronym', safe: true },
  // government of india
  { match: 'government of the? [#Place+]', tag: 'Organization', reason: 'government-of-x' },
  // school board
  { match: '(health|school|commerce) board', tag: 'Organization', reason: 'school-board' },
  // special comittee
  {
    match: '(nominating|special|conference|executive|steering|central|congressional) committee',
    tag: 'Organization',
    reason: 'special-comittee',
  },
  // global trade union
  {
    match: '(world|global|international|national|#Demonym) #Organization',
    tag: 'Organization',
    reason: 'global-org',
  },
  // schools
  { match: '#Noun+ (public|private) school', tag: 'School', reason: 'noun-public-school' },
  // new york yankees
  { match: '#Place+ #SportsTeam', tag: 'SportsTeam', reason: 'place-sportsteam' },
  // 'manchester united'
  {
    match: '(dc|atlanta|minnesota|manchester|newcastle|sheffield) united',
    tag: 'SportsTeam',
    reason: 'united-sportsteam',
  },
  // 'toronto fc'
  { match: '#Place+ fc', tag: 'SportsTeam', reason: 'fc-sportsteam' },

  // baltimore quilting club
  {
    match: '#Place+ #Noun{0,2} (club|society|group|team|committee|commission|association|guild|crew)',
    tag: 'Organization',
    reason: 'place-noun-society',
  },
];

var places = [
  // ==== Region ====
  // West Norforlk
  { match: '(west|north|south|east|western|northern|southern|eastern)+ #Place', tag: 'Region', reason: 'west-norfolk' },
  //some us-state acronyms (exlude: al, in, la, mo, hi, me, md, ok..)
  {
    match: '#City [(al|ak|az|ar|ca|ct|dc|fl|ga|id|il|nv|nh|nj|ny|oh|pa|sc|tn|tx|ut|vt|pr)]',
    group: 0,
    tag: 'Region',
    reason: 'us-state',
  },
  // portland oregon
  { match: 'portland [or]', group: 0, tag: 'Region', reason: 'portland-or' },
  //words removed from preTagger/placeWords
  {
    match: '#ProperNoun+ (cliff|place|range|pit|place|point|room|grounds|ruins)',
    tag: 'Place',
    reason: 'foo-point',
  },
  // in Foo California
  { match: 'in [#ProperNoun] #Place', group: 0, tag: 'Place', reason: 'propernoun-place' },
  // Address
  {
    match: '#Value #Noun (st|street|rd|road|crescent|cr|way|tr|terrace|avenue|ave)',
    tag: 'Address',
    reason: 'address-st',
  },
  // port dover
  { match: '(port|mount|mt) #ProperName', tag: 'Place', reason: 'port-name' },
  // generic 'oak ridge' names
  // { match: '(oak|maple|spruce|pine|cedar|willow|green|sunset|sunrise) #Place', tag: 'Place', reason: 'tree-name' },
  // generic 'sunset view' names
  // { match: '() #Place', tag: 'Place', reason: 'tree-name' },

  // Sports Arenas and Complexs
  // {
  //   match:
  //     '(#Place+|#Place|#ProperNoun) (memorial|athletic|community|financial)? (sportsplex|stadium|sports centre|sports field|soccer complex|soccer centre|sports complex|civic centre|centre|arena|gardens|complex|coliseum|auditorium|place|building)',
  //   tag: 'Place',
  //   reason: 'sport-complex',
  // },
];

var conjunctions = [
  // ==== Conjunctions ====
  { match: '[so] #Noun', group: 0, tag: 'Conjunction', reason: 'so-conj' },
  //how he is driving
  {
    match: '[(who|what|where|why|how|when)] #Noun #Copula #Adverb? (#Verb|#Adjective)',
    group: 0,
    tag: 'Conjunction',
    reason: 'how-he-is-x',
  },
  // when he
  { match: '#Copula [(who|what|where|why|how|when)] #Noun', group: 0, tag: 'Conjunction', reason: 'when-he' },
  // says that he..
  { match: '#Verb [that] #Pronoun', group: 0, tag: 'Conjunction', reason: 'said-that-he' },
  // things that are required
  { match: '#Noun [that] #Copula', group: 0, tag: 'Conjunction', reason: 'that-are' },
  // things that seem cool
  { match: '#Noun [that] #Verb #Adjective', group: 0, tag: 'Conjunction', reason: 'that-seem' },
  // wasn't that wide..
  { match: '#Noun #Copula not? [that] #Adjective', group: 0, tag: 'Adverb', reason: 'that-adj' },

  // ==== Prepositions ====
  //all students
  { match: '#Verb #Adverb? #Noun [(that|which)]', group: 0, tag: 'Preposition', reason: 'that-prep' },
  //work, which has been done.
  { match: '@hasComma [which] (#Pronoun|#Verb)', group: 0, tag: 'Preposition', reason: 'which-copula' },
  //folks like her
  { match: '#Noun [like] #Noun', group: 0, tag: 'Preposition', reason: 'noun-like' },
  //like the time
  { match: '^[like] #Determiner', group: 0, tag: 'Preposition', reason: 'like-the' },
  //a day like this
  { match: 'a #Noun [like] (#Noun|#Determiner)', group: 0, tag: 'Preposition', reason: 'a-noun-like' },
  // really like
  { match: '#Adverb [like]', group: 0, tag: 'Verb', reason: 'really-like' },
  // nothing like
  { match: '(not|nothing|never) [like]', group: 0, tag: 'Preposition', reason: 'nothing-like' },
  // treat them like
  { match: '#Infinitive #Pronoun [like]', group: 0, tag: 'Preposition', reason: 'treat-them-like' },




  // ==== Questions ====
  // where
  // why
  // when
  // who
  // whom
  // whose
  // what
  // which
  //the word 'how many'
  // { match: '^(how|which)', tag: 'QuestionWord', reason: 'how-question' },
  // how-he, when the
  { match: '[#QuestionWord] (#Pronoun|#Determiner)', group: 0, tag: 'Preposition', reason: 'how-he' },
  // when stolen
  { match: '[#QuestionWord] #Participle', group: 0, tag: 'Preposition', reason: 'when-stolen' },
  // how is
  { match: '[how] (#Determiner|#Copula|#Modal|#PastTense)', group: 0, tag: 'QuestionWord', reason: 'how-is' },
  // children who dance
  { match: '#Plural [(who|which|when)] .', group: 0, tag: 'Preposition', reason: 'people-who' },
];

var expressions = [

  //swear-words as non-expression POS
  { match: 'holy (shit|fuck|hell)', tag: 'Expression', reason: 'swears-expression' },
  // well..
  { match: '^[(well|so|okay|now)] !#Adjective?', group: 0, tag: 'Expression', reason: 'well-' },
  // well..
  { match: '^come on', tag: 'Expression', reason: 'come-on' },
  // sorry
  { match: '(say|says|said) [sorry]', group: 0, tag: 'Expression', reason: 'say-sorry' },
  // ok,
  { match: '^(ok|alright|shoot|hell|anyways)', tag: 'Expression', reason: 'ok-' },
  // c'mon marge..
  // { match: '^[come on] #Noun', group: 0, tag: 'Expression', reason: 'come-on' },
  // say,
  { match: '^(say && @hasComma)', tag: 'Expression', reason: 'say-' },
  { match: '^(like && @hasComma)', tag: 'Expression', reason: 'like-' },
  // dude we should
  { match: '^[(dude|man|girl)] #Pronoun', group: 0, tag: 'Expression', reason: 'dude-i' },
];

let matches = [].concat(
  // order matters top-matches can get overwritten
  passive$1,
  adj,
  advAdj,
  gerundAdj,
  nounAdj,
  adv,
  ambigDates,
  dates,
  noun,
  gerundNouns,
  presNouns,
  money,
  fractions,
  numbers$1,
  person,
  personName,
  verbs$1,
  adjVerb,
  auxiliary,
  phrasal,
  imperative,
  adjGerund,
  matches$1,
  orgs,
  places,
  conjunctions,
  expressions
);
var model = {
  two: {
    matches,
  },
};

let net$1 = null;

// runs all match/tag patterns in model.two.matches
const postTagger = function (view) {
  const { world } = view;
  const { model, methods } = world;
  net$1 = net$1 || methods.one.buildNet(model.two.matches, world);
  // perform these matches on a comma-seperated document
  let document = methods.two.quickSplit(view.document);
  let ptrs = document.map(terms => {
    let t = terms[0];
    return [t.index[0], t.index[1], t.index[1] + terms.length]
  });
  let m = view.update(ptrs);
  m.cache();
  m.sweep(net$1);
  view.uncache();
  view.unfreeze();
  return view
};

// helper function for compute('tagger')
const tagger = view => view.compute(['freeze', 'lexicon', 'preTagger', 'postTagger', 'unfreeze']);

var compute$1 = { postTagger, tagger };

const round$1 = n => Math.round(n * 100) / 100;

function api$i (View) {
  // average tagger score
  View.prototype.confidence = function () {
    let sum = 0;
    let count = 0;
    this.docs.forEach(terms => {
      terms.forEach(term => {
        count += 1;
        sum += term.confidence || 1;
      });
    });
    if (count === 0) {
      return 1
    }
    return round$1(sum / count)
  };

  // (re-) run the POS-tagger
  View.prototype.tagger = function () {
    return this.compute(['tagger'])
  };
}

const plugin$2 = {
  api: api$i,
  compute: compute$1,
  model,
  hooks: ['postTagger'],
};

const getWords = function (net) {
  return Object.keys(net.hooks).filter(w => !w.startsWith('#') && !w.startsWith('%'))
};

const maybeMatch = function (doc, net) {
  // must have *atleast* one of these words
  let words = getWords(net);
  if (words.length === 0) {
    return doc
  }
  if (!doc._cache) {
    doc.cache();
  }
  let cache = doc._cache;
  // return sentences that have one of our needed words
  return doc.filter((_m, i) => {
    return words.some(str => cache[i].has(str))
  })
};

// tokenize first, then only tag sentences required
const lazyParse = function (input, reg) {
  let net = reg;
  if (typeof reg === 'string') {
    net = this.buildNet([{ match: reg }]);
  }
  let doc = this.tokenize(input);
  let m = maybeMatch(doc, net);
  if (m.found) {
    m.compute(['index', 'tagger']);
    return m.match(reg)
  }
  return doc.none()
};

var lazy = {
  lib: {
    lazy: lazyParse
  }
};

const matchVerb = function (m, lemma) {
  const conjugate = m.methods.two.transform.verb.conjugate;
  let all = conjugate(lemma, m.model);
  if (m.has('#Gerund')) {
    return all.Gerund
  }
  if (m.has('#PastTense')) {
    return all.PastTense
  }
  if (m.has('#PresentTense')) {
    return all.PresentTense
  }
  if (m.has('#Gerund')) {
    return all.Gerund
  }
  return lemma
};

const swapVerb = function (vb, lemma) {
  let str = lemma;
  vb.forEach(m => {
    if (!m.has('#Infinitive')) {
      str = matchVerb(m, lemma);
    }
    m.replaceWith(str);
  });
  return vb
};

const swapNoun = function (m, lemma) {
  let str = lemma;
  if (m.has('#Plural')) {
    const toPlural = m.methods.two.transform.noun.toPlural;
    str = toPlural(lemma, m.model);
  }
  m.replaceWith(str, { possessives: true });
};

const swapAdverb = function (m, lemma) {
  const { toAdverb } = m.methods.two.transform.adjective;
  let str = lemma;
  let adv = toAdverb(str);
  if (adv) {
    m.replaceWith(adv);
  }
};
const swapAdjective = function (m, lemma) {
  const { toComparative, toSuperlative } = m.methods.two.transform.adjective;
  let str = lemma;
  if (m.has('#Comparative')) {
    str = toComparative(str, m.model);
  } else if (m.has('#Superlative')) {
    str = toSuperlative(str, m.model);
  }
  if (str) {
    m.replaceWith(str);
  }
};

const swap$1 = function (from, to, tag) {
  let reg = from.split(/ /g).map(str => str.toLowerCase().trim());
  reg = reg.filter(str => str);
  reg = reg.map(str => `{${str}}`).join(' ');
  let m = this.match(reg);
  // guard against some homonyms
  if (tag) {
    m = m.if(tag);
  }
  if (m.has('#Verb')) {
    return swapVerb(m, to)
  }
  if (m.has('#Noun')) {
    return swapNoun(m, to)
  }
  if (m.has('#Adverb')) {
    return swapAdverb(m, to)
  }
  if (m.has('#Adjective')) {
    return swapAdjective(m, to)
  }
  return this
};

const api$h = function (View) {
  View.prototype.swap = swap$1;
};

var swap = {
  api: api$h
};

nlp.plugin(preTag); //~103kb
nlp.plugin(contractionTwo); //
nlp.plugin(plugin$2); //~33kb
nlp.plugin(lazy); //
nlp.plugin(swap); //

// guard against superlative+comparative forms
const toRoot$1 = function (adj) {
  const { fromComparative, fromSuperlative } = adj.methods.two.transform.adjective;
  let str = adj.text('normal');
  if (adj.has('#Comparative')) {
    return fromComparative(str, adj.model)
  }
  if (adj.has('#Superlative')) {
    return fromSuperlative(str, adj.model)
  }
  return str
};

const api$g = function (View) {

  class Adjectives extends View {
    constructor(document, pointer, groups) {
      super(document, pointer, groups);
      this.viewType = 'Adjectives';
    }
    json(opts = {}) {
      const { toAdverb, toNoun, toSuperlative, toComparative } = this.methods.two.transform.adjective;
      opts.normal = true;
      return this.map(m => {
        let json = m.toView().json(opts)[0] || {};
        let str = toRoot$1(m);
        json.adjective = {
          adverb: toAdverb(str, this.model),
          noun: toNoun(str, this.model),
          superlative: toSuperlative(str, this.model),
          comparative: toComparative(str, this.model),
        };
        return json
      }, [])
    }
    adverbs() {
      return this.before('#Adverb+$').concat(this.after('^#Adverb+'))
    }
    conjugate(n) {
      const { toComparative, toSuperlative, toNoun, toAdverb } = this.methods.two.transform.adjective;
      return this.getNth(n).map(adj => {
        let root = toRoot$1(adj);
        return {
          Adjective: root,
          Comparative: toComparative(root, this.model),
          Superlative: toSuperlative(root, this.model),
          Noun: toNoun(root, this.model),
          Adverb: toAdverb(root, this.model),
        }
      }, [])
    }
    toComparative(n) {
      const { toComparative } = this.methods.two.transform.adjective;
      return this.getNth(n).map(adj => {
        let root = toRoot$1(adj);
        let str = toComparative(root, this.model);
        return adj.replaceWith(str)
      })
    }
    toSuperlative(n) {
      const { toSuperlative } = this.methods.two.transform.adjective;
      return this.getNth(n).map(adj => {
        let root = toRoot$1(adj);
        let str = toSuperlative(root, this.model);
        return adj.replaceWith(str)
      })
    }
    toAdverb(n) {
      const { toAdverb } = this.methods.two.transform.adjective;
      return this.getNth(n).map(adj => {
        let root = toRoot$1(adj);
        let str = toAdverb(root, this.model);
        return adj.replaceWith(str)
      })
    }
    toNoun(n) {
      const { toNoun } = this.methods.two.transform.adjective;
      return this.getNth(n).map(adj => {
        let root = toRoot$1(adj);
        let str = toNoun(root, this.model);
        return adj.replaceWith(str)
      })
    }
  }

  View.prototype.adjectives = function (n) {
    let m = this.match('#Adjective');
    m = m.getNth(n);
    return new Adjectives(m.document, m.pointer)
  };
  View.prototype.superlatives = function (n) {
    let m = this.match('#Superlative');
    m = m.getNth(n);
    return new Adjectives(m.document, m.pointer)
  };
  View.prototype.comparatives = function (n) {
    let m = this.match('#Comparative');
    m = m.getNth(n);
    return new Adjectives(m.document, m.pointer)
  };
};
var adjectives = { api: api$g };

// guard against superlative+comparative forms
const toRoot = function (adj) {
  let str = adj.compute('root').text('root');
  return str
};

// return the nth elem of a doc
const api$f = function (View) {

  class Adverbs extends View {
    constructor(document, pointer, groups) {
      super(document, pointer, groups);
      this.viewType = 'Adverbs';
    }
    conjugate(n) {
      return this.getNth(n).map(adv => {
        let adj = toRoot(adv);
        return {
          Adverb: adv.text('normal'),
          Adjective: adj,
        }
      }, [])
    }
    json(opts = {}) {
      const fromAdverb = this.methods.two.transform.adjective.fromAdverb;
      opts.normal = true;
      return this.map(m => {
        let json = m.toView().json(opts)[0] || {};
        json.adverb = {
          adjective: fromAdverb(json.normal)
        };
        return json
      }, [])
    }
  }

  View.prototype.adverbs = function (n) {
    let m = this.match('#Adverb');
    m = m.getNth(n);
    return new Adverbs(m.document, m.pointer)
  };
};
var adverbs = { api: api$f };

const byComma = function (doc) {
  let commas = doc.match('@hasComma');
  // remove any non-clause uses
  commas = commas.filter(m => {
    // don't split the first word
    if (m.growLeft('.').wordCount() === 1) {
      return false
    }
    // don't split the last word
    if (m.growRight('. .').wordCount() === 1) {
      return false
    }
    let more = m.grow('.'); // grow by 1 word in either direction
    more = more.ifNo('@hasComma @hasComma'); //fun, cool...
    more = more.ifNo('@hasComma (and|or) .'); //cool, and fun
    more = more.ifNo('(#City && @hasComma) #Country'); //'toronto, canada'
    more = more.ifNo('(#WeekDay && @hasComma) #Date'); //'tuesday, march 2nd'
    more = more.ifNo('(#Date+ && @hasComma) #Value'); //'july 6, 1992'
    more = more.ifNo('(#Adjective && @hasComma) #Adjective'); //nice, pretty
    // more = more.ifNo('@hasComma (too|also)$') //at end of sentence
    return more.found
  });
  return doc.splitAfter(commas)
};

// should we split-out a clause (in brackets)?
const splitParentheses = function (doc) {
  let matches = doc.parentheses();
  matches = matches.filter(m => {
    return m.wordCount() >= 3 && m.has('#Verb') && m.has('#Noun')
  });
  return doc.splitOn(matches)
};

// split-out a long quotion, but not 'inline quotes'.
const splitQuotes = function (doc) {
  let matches = doc.quotations();
  matches = matches.filter(m => {
    return m.wordCount() >= 3 && m.has('#Verb') && m.has('#Noun')
  });
  return doc.splitOn(matches)
};

const clauses = function (n) {
  let found = this;

  found = splitParentheses(found);
  found = splitQuotes(found);

  found = byComma(found);

  found = found.splitAfter('(@hasEllipses|@hasSemicolon|@hasDash|@hasColon)');

  // i said
  found = found.splitAfter('^#Pronoun (said|says)');
  // ... said John.
  found = found.splitBefore('(said|says) #ProperNoun$');

  // ... if it was
  found = found.splitBefore('. . if .{4}');

  // various conjunctions
  found = found.splitBefore('and while');
  found = found.splitBefore('now that');
  found = found.splitBefore('ever since');
  found = found.splitBefore('(supposing|although)');
  found = found.splitBefore('even (while|if|though)');
  found = found.splitBefore('(whereas|whose)');
  // found = found.splitBefore('as (far|long|much|soon) as')
  found = found.splitBefore('as (though|if)');
  found = found.splitBefore('(til|until)');

  // it is cool but it is ..
  let m = found.match('#Verb .* [but] .* #Verb', 0);
  if (m.found) {
    found = found.splitBefore(m);
  }
  // it is cool and it is ..
  // let conjunctions = found.if('#Copula #Adjective #Conjunction (#Pronoun|#Determiner) #Verb').match('#Conjunction')
  // found = found.splitBefore(conjunctions)

  // if it is this then that
  let condition = found.if('if .{2,9} then .').match('then');
  found = found.splitBefore(condition);

  // // misc clause partitions
  // found = found.splitBefore('as well as .')
  // found = found.splitBefore('such as .')
  // found = found.splitBefore('in addition to .')

  // // semicolons, dashes
  // found = found.splitAfter('@hasSemicolon')
  // found = found.splitAfter('@hasDash')

  // //
  // found = found.splitBefore('which (were|are|will)')

  // // he said [...]
  // found = found.splitAfter('#Noun (said|say|says)')

  // passive voice verb - '.. which was robbed is empty'
  // let passive = found.match('#Noun (which|that) (was|is) #Adverb? #PastTense #Adverb?')
  // if (passive.found) {
  //   found = found.splitAfter(passive)
  // }
  // //which the boy robbed
  // passive = found.match('#Noun (which|that) the? #Noun+ #Adverb? #PastTense #Adverb?')
  // if (passive.found) {
  //   found = found.splitAfter(passive)
  // }
  // does there appear to have relative/subordinate clause still?
  // let tooLong = found.filter(d => d.wordCount() > 5 && d.match('#Verb+').length >= 2)
  // if (tooLong.found) {
  //   // and after the ..
  //   found = found.splitBefore('#Conjunction #Preposition')

  //   // let m = tooLong.splitAfter('#Noun .* #Verb .* #Noun+')
  //   // found = found.splitOn(m.eq(0))
  // }
  if (typeof n === 'number') {
    found = found.get(n);
  }
  return found
};

// split terms into Nounphrase, verbphrase, etc groups
const chunks = function (doc) {
  let all = [];
  let lastOne = null;
  // first, split by comma, etc
  let m = doc.clauses();
  // loop through each clause
  m.docs.forEach(terms => {
    terms.forEach(term => {
      // new chunk
      if (!term.chunk || term.chunk !== lastOne) {
        lastOne = term.chunk;
        all.push([term.index[0], term.index[1], term.index[1] + 1]);
      } else {
        // keep the chunk going
        all[all.length - 1][2] = term.index[1] + 1;
      }
    });
    lastOne = null;
  });
  let parts = doc.update(all);
  return parts
};

const api$e = function (View) {

  class Chunks extends View {
    constructor(document, pointer, groups) {
      super(document, pointer, groups);
      this.viewType = 'Chunks';
    }
    isVerb() {
      return this.filter(c => c.has('<Verb>'))
    }
    isNoun() {
      return this.filter(c => c.has('<Noun>'))
    }
    isAdjective() {
      return this.filter(c => c.has('<Adjective>'))
    }
    isPivot() {
      return this.filter(c => c.has('<Pivot>'))
    }
    // chunk-friendly debug
    debug() {
      this.toView().debug('chunks');
      return this
    }
    // overloaded - keep Sentences class
    update(pointer) {
      let m = new Chunks(this.document, pointer);
      m._cache = this._cache; // share this full thing
      return m
    }
  }

  View.prototype.chunks = function (n) {
    let m = chunks(this);
    m = m.getNth(n);
    return new Chunks(this.document, m.pointer)
  };
  View.prototype.clauses = clauses;
};

const byWord = {
  this: 'Noun',
  then: 'Pivot'
};

// simply chunk Nouns as <Noun>
const easyMode = function (document) {
  for (let n = 0; n < document.length; n += 1) {
    for (let t = 0; t < document[n].length; t += 1) {
      let term = document[n][t];

      if (byWord.hasOwnProperty(term.normal) === true) {
        term.chunk = byWord[term.normal];
        continue
      }
      if (term.tags.has('Verb')) {
        term.chunk = 'Verb';
        continue
      }
      if (term.tags.has('Noun') || term.tags.has('Determiner')) {
        term.chunk = 'Noun';
        continue
      }
      // 100 cats
      if (term.tags.has('Value')) {
        term.chunk = 'Noun';
        continue
      }
      //
      if (term.tags.has('QuestionWord')) {
        term.chunk = 'Pivot';
        continue
      }

    }
  }
};

// simply chunk Nouns as <Noun>
const byNeighbour = function (document) {
  for (let n = 0; n < document.length; n += 1) {
    for (let t = 0; t < document[n].length; t += 1) {
      let term = document[n][t];
      if (term.chunk) {
        continue
      }
      // based on next-term
      let onRight = document[n][t + 1];
      // based on last-term
      let onLeft = document[n][t - 1];

      //'is cool' vs 'the cool dog'
      if (term.tags.has('Adjective')) {
        // 'is cool'
        if (onLeft && onLeft.tags.has('Copula')) {
          term.chunk = 'Adjective';
          continue
        }
        // 'the cool'
        if (onLeft && onLeft.tags.has('Determiner')) {
          term.chunk = 'Noun';
          continue
        }
        // 'cool dog'
        if (onRight && onRight.tags.has('Noun')) {
          term.chunk = 'Noun';
          continue
        }
        continue
      }
      // 'really swimming' vs 'really cool'
      if (term.tags.has('Adverb') || term.tags.has('Negative')) {
        if (onLeft && onLeft.tags.has('Adjective')) {
          term.chunk = 'Adjective';
          continue
        }
        if (onLeft && onLeft.tags.has('Verb')) {
          term.chunk = 'Verb';
          continue
        }

        if (onRight && onRight.tags.has('Adjective')) {
          term.chunk = 'Adjective';
          continue
        }
        if (onRight && onRight.tags.has('Verb')) {
          term.chunk = 'Verb';
          continue
        }
      }
    }
  }
};

const rules = [
  // === Conjunction ===
  // that the houses
  { match: '[that] #Determiner #Noun', group: 0, chunk: 'Pivot' },
  // estimated that
  { match: '#PastTense [that]', group: 0, chunk: 'Pivot' },
  // so the
  { match: '[so] #Determiner', group: 0, chunk: 'Pivot' },

  // === Adjective ===
  // was really nice
  { match: '#Copula #Adverb+? [#Adjective]', group: 0, chunk: 'Adjective' },
  // was nice
  // { match: '#Copula [#Adjective]', group: 0, chunk: 'Adjective' },
  // nice and cool
  { match: '#Adjective and #Adjective', chunk: 'Adjective' },
  // really nice
  // { match: '#Adverb+ #Adjective', chunk: 'Adjective' },

  // === Verb ===
  // quickly and suddenly run
  { match: '#Adverb+ and #Adverb #Verb', chunk: 'Verb' },
  // sitting near
  { match: '#Gerund #Adjective$', chunk: 'Verb' },
  // going to walk
  { match: '#Gerund to #Verb', chunk: 'Verb' },
  // come and have a drink
  { match: '#PresentTense and #PresentTense', chunk: 'Verb' },
  // really not
  { match: '#Adverb #Negative', chunk: 'Verb' },
  // want to see
  { match: '(want|wants|wanted) to #Infinitive', chunk: 'Verb' },
  // walk ourselves
  { match: '#Verb #Reflexive', chunk: 'Verb' },
  // tell him the story
  // { match: '#PresentTense [#Pronoun] #Determiner', group: 0, chunk: 'Verb' },
  // tries to walk
  { match: '#Verb [to] #Adverb? #Infinitive', group: 0, chunk: 'Verb' },
  // upon seeing
  { match: '[#Preposition] #Gerund', group: 0, chunk: 'Verb' },
  // ensure that
  { match: '#Infinitive [that] <Noun>', group: 0, chunk: 'Verb' },

  // === Noun ===
  // the brown fox
  // { match: '#Determiner #Adjective+ #Noun', chunk: 'Noun' },
  // the fox
  // { match: '(the|this) <Noun>', chunk: 'Noun' },
  // brown fox
  // { match: '#Adjective+ <Noun>', chunk: 'Noun' },
  // --- of ---
  // son of a gun
  { match: '#Noun of #Determiner? #Noun', chunk: 'Noun' },
  // 3 beautiful women
  { match: '#Value+ #Adverb? #Adjective', chunk: 'Noun' },
  // the last russian tsar
  { match: 'the [#Adjective] #Noun', chunk: 'Noun' },
  // breakfast in bed
  { match: '#Singular in #Determiner? #Singular', chunk: 'Noun' },
  // Some citizens in this Canadian capital
  { match: '#Plural [in] #Determiner? #Noun', group: 0, chunk: 'Pivot' },
  // indoor and outdoor seating
  { match: '#Noun and #Determiner? #Noun', notIf: '(#Possessive|#Pronoun)', chunk: 'Noun' },
  //  boys and girls
  // { match: '#Plural and #Determiner? #Plural', chunk: 'Noun' },
  // tomatoes and cheese
  // { match: '#Noun and #Determiner? #Noun', notIf: '#Pronoun', chunk: 'Noun' },
  // that is why
  // { match: '[that] (is|was)', group: 0, chunk: 'Noun' },
];

let net = null;
const matcher = function (view, _, world) {
  const { methods } = world;
  net = net || methods.one.buildNet(rules, world);
  view.sweep(net);
};

const setChunk = function (term, chunk) {
  const env = typeof process === 'undefined' || !process.env ? self.env || {} : process.env;
  if (env.DEBUG_CHUNKS) {
    let str = (term.normal + "'").padEnd(8);
    console.log(`  | '${str}  â†’  \x1b[34m${chunk.padEnd(12)}\x1b[0m \x1b[2m -fallback- \x1b[0m`); // eslint-disable-line
  }
  term.chunk = chunk;
};

// ensure everything has a chunk
const fallback = function (document) {
  for (let n = 0; n < document.length; n += 1) {
    for (let t = 0; t < document[n].length; t += 1) {
      let term = document[n][t];
      if (term.chunk === undefined) {
        // conjunctions stand alone
        if (term.tags.has('Conjunction')) {
          setChunk(term, 'Pivot');
        } else if (term.tags.has('Preposition')) {
          setChunk(term, 'Pivot');
        } else if (term.tags.has('Adverb')) {
          setChunk(term, 'Verb');
        }
        // just take the chunk on the right?
        // else if (document[n][t + 1] && document[n][t + 1].chunk) {
        //   setChunk(term, document[n][t + 1].chunk)
        // }
        // // or take the chunk on the left
        // else if (document[n][t - 1] && document[n][t - 1].chunk) {
        //   setChunk(term, document[n][t - 1].chunk)
        else {
          //  Â¯\_(ãƒ„)_/Â¯
          term.chunk = 'Noun';
        }
      }
    }
  }
};

const fixUp = function (docs) {
  let byChunk = [];
  let current = null;
  docs.forEach(terms => {
    // ensure an adjective chunk is preceded by a copula
    for (let i = 0; i < terms.length; i += 1) {
      let term = terms[i];
      if (current && term.chunk === current) {
        byChunk[byChunk.length - 1].terms.push(term);
      } else {
        byChunk.push({ chunk: term.chunk, terms: [term] });
        current = term.chunk;
      }
    }
  });
  // ensure every verb-phrase actually has a verb
  byChunk.forEach(c => {
    if (c.chunk === 'Verb') {
      const hasVerb = c.terms.find(t => t.tags.has('Verb'));
      if (!hasVerb) {
        c.terms.forEach(t => t.chunk = null);
      }
    }
  });
};

/* Chunks:
    Noun
    Verb
    Adjective
    Pivot
*/

const findChunks = function (view) {
  const { document, world } = view;
  easyMode(document);
  byNeighbour(document);
  matcher(view, document, world);
  // matcher(view, document, world) //run it 2nd time
  fallback(document);
  fixUp(document);
};
var compute = { chunks: findChunks };

var chunker = {
  compute: compute,
  api: api$e,
  hooks: ['chunks'],
};

// return the nth elem of a doc
const hasPeriod = /\./g;

const api$d = function (View) {

  class Acronyms extends View {
    constructor(document, pointer, groups) {
      super(document, pointer, groups);
      this.viewType = 'Acronyms';
    }
    strip() {
      this.docs.forEach(terms => {
        terms.forEach(term => {
          term.text = term.text.replace(hasPeriod, '');
          term.normal = term.normal.replace(hasPeriod, '');
        });
      });
      return this
    }
    addPeriods() {
      this.docs.forEach(terms => {
        terms.forEach(term => {
          term.text = term.text.replace(hasPeriod, '');
          term.normal = term.normal.replace(hasPeriod, '');
          term.text = term.text.split('').join('.') + '.';
          term.normal = term.normal.split('').join('.') + '.';
        });
      });
      return this
    }
  }

  View.prototype.acronyms = function (n) {
    let m = this.match('#Acronym');
    m = m.getNth(n);
    return new Acronyms(m.document, m.pointer)
  };
};

const hasOpen$1 = /\(/;
const hasClosed$1 = /\)/;

const findEnd$1 = function (terms, i) {
  for (; i < terms.length; i += 1) {
    if (terms[i].post && hasClosed$1.test(terms[i].post)) {
      let [, index] = terms[i].index;
      index = index || 0;
      return index
    }
  }
  return null
};

const find$5 = function (doc) {
  let ptrs = [];
  doc.docs.forEach(terms => {
    for (let i = 0; i < terms.length; i += 1) {
      let term = terms[i];
      if (term.pre && hasOpen$1.test(term.pre)) {
        let end = findEnd$1(terms, i);
        if (end !== null) {
          let [n, start] = terms[i].index;
          ptrs.push([n, start, end + 1, terms[i].id]);
          i = end;
        }
      }
    }
  });
  return doc.update(ptrs)
};

const strip$2 = function (m) {
  m.docs.forEach(terms => {
    terms[0].pre = terms[0].pre.replace(hasOpen$1, '');
    let last = terms[terms.length - 1];
    last.post = last.post.replace(hasClosed$1, '');
  });
  return m
};

const api$c = function (View) {
  class Parentheses extends View {
    constructor(document, pointer, groups) {
      super(document, pointer, groups);
      this.viewType = 'Possessives';
    }
    strip() {
      return strip$2(this)
    }
  }

  View.prototype.parentheses = function (n) {
    let m = find$5(this);
    m = m.getNth(n);
    return new Parentheses(m.document, m.pointer)
  };
};

// return the nth elem of a doc
const apostropheS = /'s$/;

const find$4 = function (doc) {
  let m = doc.match('#Possessive+');
  // expand it to include 'john smith's'
  if (m.has('#Person')) {
    m = m.growLeft('#Person+');
  }
  if (m.has('#Place')) {
    m = m.growLeft('#Place+');
  }
  if (m.has('#Organization')) {
    m = m.growLeft('#Organization+');
  }
  return m
};


const api$b = function (View) {

  class Possessives extends View {
    constructor(document, pointer, groups) {
      super(document, pointer, groups);
      this.viewType = 'Possessives';
    }
    strip() {
      this.docs.forEach(terms => {
        terms.forEach(term => {
          term.text = term.text.replace(apostropheS, '');
          term.normal = term.normal.replace(apostropheS, '');
        });
      });
      return this
    }
  }

  View.prototype.possessives = function (n) {
    let m = find$4(this);
    m = m.getNth(n);
    return new Possessives(m.document, m.pointer)
  };
};

/* eslint-disable regexp/no-dupe-characters-character-class */

const pairs = {
  '\u0022': '\u0022', // 'StraightDoubleQuotes'
  '\uFF02': '\uFF02', // 'StraightDoubleQuotesWide'
  '\u0027': '\u0027', // 'StraightSingleQuotes'
  '\u201C': '\u201D', // 'CommaDoubleQuotes'
  '\u2018': '\u2019', // 'CommaSingleQuotes'
  '\u201F': '\u201D', // 'CurlyDoubleQuotesReversed'
  '\u201B': '\u2019', // 'CurlySingleQuotesReversed'
  '\u201E': '\u201D', // 'LowCurlyDoubleQuotes'
  '\u2E42': '\u201D', // 'LowCurlyDoubleQuotesReversed'
  '\u201A': '\u2019', // 'LowCurlySingleQuotes'
  '\u00AB': '\u00BB', // 'AngleDoubleQuotes' Â«, Â»
  '\u2039': '\u203A', // 'AngleSingleQuotes'
  // Prime 'non quotation'
  '\u2035': '\u2032', // 'PrimeSingleQuotes'
  '\u2036': '\u2033', // 'PrimeDoubleQuotes'
  '\u2037': '\u2034', // 'PrimeTripleQuotes'
  // Prime 'quotation' variation
  '\u301D': '\u301E', // 'PrimeDoubleQuotes'
  '\u0060': '\u00B4', // 'PrimeSingleQuotes'
  '\u301F': '\u301E', // 'LowPrimeDoubleQuotesReversed'
};

const hasOpen = RegExp('[' + Object.keys(pairs).join('') + ']');
const hasClosed = RegExp('[' + Object.values(pairs).join('') + ']');

const findEnd = function (terms, i) {
  const have = terms[i].pre.match(hasOpen)[0] || '';
  if (!have || !pairs[have]) {
    return null
  }
  const want = pairs[have];
  for (; i < terms.length; i += 1) {
    if (terms[i].post && terms[i].post.match(want)) {
      return i
    }
  }
  return null
};

const find$3 = function (doc) {
  let ptrs = [];
  doc.docs.forEach(terms => {
    for (let i = 0; i < terms.length; i += 1) {
      let term = terms[i];
      if (term.pre && hasOpen.test(term.pre)) {
        let end = findEnd(terms, i);
        if (end !== null) {
          let [n, start] = terms[i].index;
          ptrs.push([n, start, end + 1, terms[i].id]);
          i = end;
        }
      }
    }
  });
  return doc.update(ptrs)
};

const strip$1 = function (m) {
  m.docs.forEach(terms => {
    terms[0].pre = terms[0].pre.replace(hasOpen, '');
    let lastTerm = terms[terms.length - 1];
    lastTerm.post = lastTerm.post.replace(hasClosed, '');
  });
};

const api$a = function (View) {

  class Quotations extends View {
    constructor(document, pointer, groups) {
      super(document, pointer, groups);
      this.viewType = 'Possessives';
    }
    strip() {
      return strip$1(this)
    }
  }

  View.prototype.quotations = function (n) {
    let m = find$3(this);
    m = m.getNth(n);
    return new Quotations(m.document, m.pointer)
  };
};

/** return anything tagged as a phone number */
const phoneNumbers = function (n) {
  let m = this.splitAfter('@hasComma');
  m = m.match('#PhoneNumber+');
  m = m.getNth(n);
  return m
};

// setup easy helper methods
const selections = [
  ['hyphenated', '@hasHyphen .'],
  ['hashTags', '#HashTag'],
  ['emails', '#Email'],
  ['emoji', '#Emoji'],
  ['emoticons', '#Emoticon'],
  ['atMentions', '#AtMention'],
  ['urls', '#Url'],
  // ['pronouns', '#Pronoun'],
  ['conjunctions', '#Conjunction'],
  ['prepositions', '#Preposition'],
  ['abbreviations', '#Abbreviation'],
  ['honorifics', '#Honorific'],
];

// aliases
let aliases = [
  ['emojis', 'emoji'],
  ['atmentions', 'atMentions'],
];

const addMethods = function (View) {
  // add a list of new helper methods
  selections.forEach(a => {
    View.prototype[a[0]] = function (n) {
      let m = this.match(a[1]);
      return typeof n === 'number' ? m.get(n) : m
    };
  });
  View.prototype.phoneNumbers = phoneNumbers;
  // add aliases
  aliases.forEach(a => {
    View.prototype[a[0]] = View.prototype[a[1]];
  });
};

const hasSlash = /\//;

const api$9 = function (View) {

  class Slashes extends View {
    constructor(document, pointer, groups) {
      super(document, pointer, groups);
      this.viewType = 'Slashes';
    }
    split() {
      return this.map((m) => {
        let str = m.text();
        let arr = str.split(hasSlash);
        m = m.replaceWith(arr.join(' '));
        return m.growRight('(' + arr.join('|') + ')+')
      })
    }
  }

  View.prototype.slashes = function (n) {
    let m = this.match('#SlashedTerm');
    m = m.getNth(n);
    return new Slashes(m.document, m.pointer)
  };
};

var misc = {
  api: function (View) {
    api$d(View);
    api$c(View);
    api$b(View);
    api$a(View);
    addMethods(View);
    api$9(View);
  }
};

const termLoop = function (view, cb) {
  view.docs.forEach(terms => {
    terms.forEach(cb);
  });
};

var methods = {
  // remove titlecasing, uppercase
  'case': (doc) => {
    termLoop(doc, (term) => {
      term.text = term.text.toLowerCase();
    });
  },
  // visually romanize/anglicize 'BjÃ¶rk' into 'Bjork'.
  'unicode': (doc) => {
    const world = doc.world;
    const killUnicode = world.methods.one.killUnicode;
    termLoop(doc, (term) => term.text = killUnicode(term.text, world));
  },
  // remove hyphens, newlines, and force one space between words
  'whitespace': (doc) => {
    termLoop(doc, (term) => {
      // one space between words
      term.post = term.post.replace(/\s+/g, ' ');
      term.post = term.post.replace(/\s([.,?!:;])/g, '$1');//no whitespace before a period, etc
      // no whitepace before a word
      term.pre = term.pre.replace(/\s+/g, '');
    });
  },
  // remove commas, semicolons - but keep sentence-ending punctuation
  'punctuation': (doc) => {
    termLoop(doc, (term) => {
      // turn dashes to spaces
      term.post = term.post.replace(/[â€“â€”-]/g, ' ');
      // remove comma, etc 
      term.post = term.post.replace(/[,:;]/g, '');
      // remove elipses
      term.post = term.post.replace(/\.{2,}/g, '');
      // remove repeats
      term.post = term.post.replace(/\?{2,}/g, '?');
      term.post = term.post.replace(/!{2,}/g, '!');
      // replace ?!
      term.post = term.post.replace(/\?!+/g, '?');
    });
    // trim end
    let docs = doc.docs;
    let terms = docs[docs.length - 1];
    if (terms && terms.length > 0) {
      let lastTerm = terms[terms.length - 1];
      lastTerm.post = lastTerm.post.replace(/ /g, '');
    }
  },

  // ====== subsets ===

  // turn "isn't" to "is not"
  'contractions': (doc) => {
    doc.contractions().expand();
  },
  //remove periods from acronyms, like 'F.B.I.'
  'acronyms': (doc) => {
    doc.acronyms().strip();
  },
  //remove words inside brackets (like these)
  'parentheses': (doc) => {
    doc.parentheses().strip();
  },
  // turn "Google's tax return" to "Google tax return"
  'possessives': (doc) => {
    doc.possessives().strip();
  },
  // turn "tax return" to tax return
  'quotations': (doc) => {
    doc.quotations().strip();
  },

  // remove them
  'emoji': (doc) => {
    doc.emojis().remove();
  },
  //turn 'Vice Admiral John Smith' to 'John Smith'
  'honorifics': (doc) => {
    doc.match('#Honorific+ #Person').honorifics().remove();
  },
  // remove needless adverbs
  'adverbs': (doc) => {
    doc.adverbs().remove();
  },

  // turn "batmobiles" into "batmobile"
  'nouns': (doc) => {
    doc.nouns().toSingular();
  },
  // turn all verbs into Infinitive form - "I walked" â†’ "I walk"
  'verbs': (doc) => {
    doc.verbs().toInfinitive();
  },
  // turn "fifty" into "50"
  'numbers': (doc) => {
    doc.numbers().toNumber();
  },

  /** remove bullets from beginning of phrase */
  'debullet': (doc) => {
    const hasBullet = /^\s*([-â€“â€”*â€¢])\s*$/;
    doc.docs.forEach(terms => {
      //remove bullet symbols
      if (hasBullet.test(terms[0].pre)) {
        terms[0].pre = terms[0].pre.replace(hasBullet, '');
      }
    });
    return doc
  }
};

// turn presets into key-vals
const split = (str) => {
  return str.split('|').reduce((h, k) => {
    h[k] = true;
    return h
  }, {})
};

const light = 'unicode|punctuation|whitespace|acronyms';
const medium = '|case|contractions|parentheses|quotations|emoji|honorifics|debullet';
const heavy = '|possessives|adverbs|nouns|verbs';
const presets = {
  light: split(light),
  medium: split(light + medium),
  heavy: split(light + medium + heavy)
};

function api$8 (View) {
  View.prototype.normalize = function (opts = 'light') {
    if (typeof opts === 'string') {
      opts = presets[opts];
    }
    // run each method
    Object.keys(opts).forEach(fn => {
      if (methods.hasOwnProperty(fn)) {
        methods[fn](this, opts[fn]);
      }
    });
    return this
  };
}

var normalize$1 = {
  api: api$8
};

const findNouns = function (doc) {
  let m = doc.clauses().match('<Noun>');
  let commas = m.match('@hasComma');
  // allow toronto, ontario
  commas = commas.not('#Place');
  if (commas.found) {
    m = m.splitAfter(commas);
  }
  // yo there
  m = m.splitOn('#Expression');
  // these are individual nouns
  m = m.splitOn('(he|she|we|you|they|i)');
  // a client i saw
  m = m.splitOn('(#Noun|#Adjective) [(he|him|she|it)]', 0);
  // give him the best
  m = m.splitOn('[(he|him|she|it)] (#Determiner|#Value)', 0);
  // the noise the slide makes
  m = m.splitBefore('#Noun [(the|a|an)] #Adjective? #Noun', 0);
  // here spencer slept
  m = m.splitOn('[(here|there)] #Noun', 0);
  // put it there
  m = m.splitOn('[#Noun] (here|there)', 0);
  // its great purposes
  // give [parents] [our money]
  m = m.splitBefore('(our|my|their|your)');
  // tell my friend that he
  m = m.splitOn('#Noun [#Determiner]', 0);
  // his excuses
  // m = m.splitAfter('(his|hers|yours|ours|theirs)')
  // m = m.not('^#Determiner')
  //ensure there's actually a noun
  m = m.if('#Noun');
  return m
};

// https://www.trentu.ca/history/subordinate-clause-and-complex-sentence
const list$2 = [
  'after',
  'although',
  'as if',
  'as long as',
  'as',
  'because',
  'before',
  'even if',
  'even though',
  'ever since',
  'if',
  'in order that',
  'provided that',
  'since',
  'so that',
  'than',
  'that',
  'though',
  'unless',
  'until',
  'what',
  'whatever',
  'when',
  'whenever',
  'where',
  'whereas',
  'wherever',
  'whether',
  'which',
  'whichever',
  'who',
  'whoever',
  'whom',
  'whomever',
  'whose',
];

const isSubordinate = function (m) {
  // athletes from toronto, days since december
  if (m.before('#Preposition$').found) {
    return true
  }
  let leadIn = m.before();
  if (!leadIn.found) {
    return false
  }
  for (let i = 0; i < list$2.length; i += 1) {
    if (m.has(list$2[i])) {
      return true
    }
  }
  return false
};

const notPlural = '(#Pronoun|#Place|#Value|#Person|#Uncountable|#Month|#WeekDay|#Holiday|#Possessive)';

const isPlural$2 = function (m, root) {
  // const { looksPlural } = m.world.methods.two
  if (m.has('#Plural')) {
    return true
  }
  // two singular nouns are plural noun phrase
  if (m.has('#Noun and #Noun')) {
    return true
  }
  if (m.has('(we|they)')) {
    return true
  }
  // these can't be plural
  if (root.has(notPlural) === true) {
    return false
  }
  if (m.has('#Singular')) {
    return false
  }
  // word-reg fallback
  let str = root.text('normal');
  // ends with a brutal s fallback
  return str.length > 3 && str.endsWith('s') && !str.endsWith('ss')
};

const getRoot = function (m) {
  let tmp = m.clone();
  tmp = tmp.match('#Noun+');
  tmp = tmp.remove('(#Adjective|#Preposition|#Determiner|#Value)');
  tmp = tmp.not('#Possessive');
  tmp = tmp.first();
  if (!tmp.found) {
    return m
  }
  return tmp
};

const parseNoun = function (m) {
  let root = getRoot(m);
  return {
    determiner: m.match('#Determiner').eq(0),
    adjectives: m.match('#Adjective'),
    number: m.values(),
    isPlural: isPlural$2(m, root),
    isSubordinate: isSubordinate(m),
    root: root,
  }
};

const toText$2 = m => m.text();
const toArray$1 = m => m.json({ terms: false, normal: true }).map(s => s.normal);

const getNum = function (m) {
  let num = null;
  if (!m.found) {
    return num
  }
  let val = m.values(0);
  if (val.found) {
    let obj = val.parse()[0] || {};
    return obj.num
  }
  return num
};

const toJSON$1 = function (m) {
  let res = parseNoun(m);
  return {
    root: toText$2(res.root),
    number: getNum(res.number),
    determiner: toText$2(res.determiner),
    adjectives: toArray$1(res.adjectives),
    isPlural: res.isPlural,
    isSubordinate: res.isSubordinate,
  }
};

const hasPlural = function (root) {
  if (root.has('^(#Uncountable|#ProperNoun|#Place|#Pronoun|#Acronym)+$')) {
    return false
  }
  return true
};

const keep$7 = { tags: true };

const nounToPlural = function (m, parsed) {
  // already plural?
  if (parsed.isPlural === true) {
    return m
  }
  // handle "steve's"
  if (parsed.root.has('#Possessive')) {
    parsed.root = parsed.root.possessives().strip();
  }
  // is a plural appropriate?
  if (!hasPlural(parsed.root)) {
    return m
  }
  const { methods, model } = m.world;
  const { toPlural } = methods.two.transform.noun;
  // inflect the root noun
  let str = parsed.root.text({ keepPunct: false });
  let plural = toPlural(str, model);
  m.match(parsed.root).replaceWith(plural, keep$7).tag('Plural', 'toPlural');
  // should we change the determiner/article?
  if (parsed.determiner.has('(a|an)')) {
    // 'a captain' -> 'the captains'
    // m.replace(parsed.determiner, 'the', keep)
    m.remove(parsed.determiner);
  }
  // should we change the following copula?
  let copula = parsed.root.after('not? #Adverb+? [#Copula]', 0);
  if (copula.found) {
    if (copula.has('is')) {
      m.replace(copula, 'are');
    } else if (copula.has('was')) {
      m.replace(copula, 'were');
    }
  }
  return m
};

const keep$6 = { tags: true };

const nounToSingular = function (m, parsed) {
  // already singular?
  if (parsed.isPlural === false) {
    return m
  }
  const { methods, model } = m.world;
  const { toSingular } = methods.two.transform.noun;
  // inflect the root noun
  let str = parsed.root.text('normal');
  let single = toSingular(str, model);
  m.replace(parsed.root, single, keep$6).tag('Singular', 'toPlural');
  // should we change the determiner/article?
  // m.debug()
  return m
};

const api$7 = function (View) {
  class Nouns extends View {
    constructor(document, pointer, groups) {
      super(document, pointer, groups);
      this.viewType = 'Nouns';
    }

    parse(n) {
      return this.getNth(n).map(parseNoun)
    }

    json(n) {
      let opts = typeof n === 'object' ? n : {};
      return this.getNth(n).map(m => {
        let json = m.toView().json(opts)[0] || {};
        if (opts && opts.noun !== false) {
          json.noun = toJSON$1(m);
        }
        return json
      }, [])
    }
    conjugate(n) {
      const methods = this.world.methods.two.transform.noun;
      return this.getNth(n).map(m => {
        let parsed = parseNoun(m);
        let root = parsed.root.compute('root').text('root');
        let res = {
          Singular: root,
        };
        if (hasPlural(parsed.root)) {
          res.Plural = methods.toPlural(root, this.model);
        }
        // only show plural if one exists
        if (res.Singular === res.Plural) {
          delete res.Plural;
        }
        return res
      }, [])
    }
    isPlural(n) {
      let res = this.filter(m => parseNoun(m).isPlural);
      return res.getNth(n)
    }

    isSingular(n) {
      let res = this.filter(m => !parseNoun(m).isPlural);
      return res.getNth(n)
    }

    adjectives(n) {
      let res = this.update([]);
      this.forEach(m => {
        let adj = parseNoun(m).adjectives;
        if (adj.found) {
          res = res.concat(adj);
        }
      });
      return res.getNth(n)
    }

    toPlural(n) {
      return this.getNth(n).map(m => {
        return nounToPlural(m, parseNoun(m))
      })
      // return new Nouns(all.document, all.pointer)
    }

    toSingular(n) {
      return this.getNth(n).map(m => {
        let res = parseNoun(m);
        return nounToSingular(m, res)
      })
    }
    // create a new View, from this one
    update(pointer) {
      let m = new Nouns(this.document, pointer);
      m._cache = this._cache; // share this full thing
      return m
    }
  }
  View.prototype.nouns = function (n) {
    let m = findNouns(this);
    m = m.getNth(n);
    return new Nouns(this.document, m.pointer)
  };
};

var nouns = {
  api: api$7,
};

const findFractions = function (doc, n) {
  // five eighths
  let m = doc.match('#Fraction+');
  // remove 'two and five eights'
  m = m.filter(r => {
    return !r.lookBehind('#Value and$').found
  });
  // thirty seconds
  m = m.notIf('#Value seconds');
  return m
};

//support global multipliers, like 'half-million' by doing 'million' then multiplying by 0.5
const findModifiers = str => {
  const mults = [
    {
      reg: /^(minus|negative)[\s-]/i,
      mult: -1,
    },
    {
      reg: /^(a\s)?half[\s-](of\s)?/i,
      mult: 0.5,
    },
    //  {
    //   reg: /^(a\s)?quarter[\s\-]/i,
    //   mult: 0.25
    // }
  ];
  for (let i = 0; i < mults.length; i++) {
    if (mults[i].reg.test(str) === true) {
      return {
        amount: mults[i].mult,
        str: str.replace(mults[i].reg, ''),
      }
    }
  }
  return {
    amount: 1,
    str: str,
  }
};

var words = {
  ones: {
    zeroth: 0,
    first: 1,
    second: 2,
    third: 3,
    fourth: 4,
    fifth: 5,
    sixth: 6,
    seventh: 7,
    eighth: 8,
    ninth: 9,
    zero: 0,
    one: 1,
    two: 2,
    three: 3,
    four: 4,
    five: 5,
    six: 6,
    seven: 7,
    eight: 8,
    nine: 9,
  },
  teens: {
    tenth: 10,
    eleventh: 11,
    twelfth: 12,
    thirteenth: 13,
    fourteenth: 14,
    fifteenth: 15,
    sixteenth: 16,
    seventeenth: 17,
    eighteenth: 18,
    nineteenth: 19,
    ten: 10,
    eleven: 11,
    twelve: 12,
    thirteen: 13,
    fourteen: 14,
    fifteen: 15,
    sixteen: 16,
    seventeen: 17,
    eighteen: 18,
    nineteen: 19,
  },
  tens: {
    twentieth: 20,
    thirtieth: 30,
    fortieth: 40,
    fourtieth: 40,
    fiftieth: 50,
    sixtieth: 60,
    seventieth: 70,
    eightieth: 80,
    ninetieth: 90,
    twenty: 20,
    thirty: 30,
    forty: 40,
    fourty: 40,
    fifty: 50,
    sixty: 60,
    seventy: 70,
    eighty: 80,
    ninety: 90,
  },
  multiples: {
    hundredth: 100,
    thousandth: 1000,
    millionth: 1e6,
    billionth: 1e9,
    trillionth: 1e12,
    quadrillionth: 1e15,
    quintillionth: 1e18,
    sextillionth: 1e21,
    septillionth: 1e24,
    hundred: 100,
    thousand: 1000,
    million: 1e6,
    billion: 1e9,
    trillion: 1e12,
    quadrillion: 1e15,
    quintillion: 1e18,
    sextillion: 1e21,
    septillion: 1e24,
    grand: 1000,
  },
};

//prevent things like 'fifteen ten', and 'five sixty'
const isValid = (w, has) => {
  if (words.ones.hasOwnProperty(w)) {
    if (has.ones || has.teens) {
      return false
    }
  } else if (words.teens.hasOwnProperty(w)) {
    if (has.ones || has.teens || has.tens) {
      return false
    }
  } else if (words.tens.hasOwnProperty(w)) {
    if (has.ones || has.teens || has.tens) {
      return false
    }
  }
  return true
};

//concatenate into a string with leading '0.'
const parseDecimals = function (arr) {
  let str = '0.';
  for (let i = 0; i < arr.length; i++) {
    let w = arr[i];
    if (words.ones.hasOwnProperty(w) === true) {
      str += words.ones[w];
    } else if (words.teens.hasOwnProperty(w) === true) {
      str += words.teens[w];
    } else if (words.tens.hasOwnProperty(w) === true) {
      str += words.tens[w];
    } else if (/^[0-9]$/.test(w) === true) {
      str += w;
    } else {
      return 0
    }
  }
  return parseFloat(str)
};

//parse a string like "4,200.1" into Number 4200.1
const parseNumeric$1 = str => {
  //remove ordinal - 'th/rd'
  str = str.replace(/1st$/, '1');
  str = str.replace(/2nd$/, '2');
  str = str.replace(/3rd$/, '3');
  str = str.replace(/([4567890])r?th$/, '$1');
  //remove prefixes
  str = str.replace(/^[$â‚¬Â¥Â£Â¢]/, '');
  //remove suffixes
  str = str.replace(/[%$â‚¬Â¥Â£Â¢]$/, '');
  //remove commas
  str = str.replace(/,/g, '');
  //split '5kg' from '5'
  str = str.replace(/([0-9])([a-z\u00C0-\u00FF]{1,2})$/, '$1');
  return str
};

const improperFraction = /^([0-9,. ]+)\/([0-9,. ]+)$/;

//some numbers we know
const casualForms = {
  'a few': 3,
  'a couple': 2,
  'a dozen': 12,
  'two dozen': 24,
  zero: 0,
};

// a 'section' is something like 'fifty-nine thousand'
// turn a section into something we can add to - like 59000
const section_sum = obj => {
  return Object.keys(obj).reduce((sum, k) => {
    sum += obj[k];
    return sum
  }, 0)
};

//turn a string into a number
const parse$3 = function (str) {
  //convert some known-numbers
  if (casualForms.hasOwnProperty(str) === true) {
    return casualForms[str]
  }
  //'a/an' is 1
  if (str === 'a' || str === 'an') {
    return 1
  }
  const modifier = findModifiers(str);
  str = modifier.str;
  let last_mult = null;
  let has = {};
  let sum = 0;
  let isNegative = false;
  const terms = str.split(/[ -]/);
  // const isFraction = findFraction(terms)
  for (let i = 0; i < terms.length; i++) {
    let w = terms[i];
    w = parseNumeric$1(w);

    if (!w || w === 'and') {
      continue
    }
    if (w === '-' || w === 'negative') {
      isNegative = true;
      continue
    }
    if (w.charAt(0) === '-') {
      isNegative = true;
      w = w.substring(1);
    }

    //decimal mode
    if (w === 'point') {
      sum += section_sum(has);
      sum += parseDecimals(terms.slice(i + 1, terms.length));
      sum *= modifier.amount;
      return sum
    }

    //improper fraction
    const fm = w.match(improperFraction);
    if (fm) {
      const num = parseFloat(fm[1].replace(/[, ]/g, ''));
      const denom = parseFloat(fm[2].replace(/[, ]/g, ''));
      if (denom) {
        sum += num / denom || 0;
      }
      continue
    }
    // try to support 'two fifty'
    if (words.tens.hasOwnProperty(w)) {
      if (has.ones && Object.keys(has).length === 1) {
        sum = has.ones * 100;
        has = {};
      }
    }

    //prevent mismatched units, like 'seven eleven' if not a fraction
    if (isValid(w, has) === false) {
      return null
    }

    //buildOut section, collect 'has' values
    if (/^[0-9.]+$/.test(w)) {
      has.ones = parseFloat(w); //not technically right
    } else if (words.ones.hasOwnProperty(w) === true) {
      has.ones = words.ones[w];
    } else if (words.teens.hasOwnProperty(w) === true) {
      has.teens = words.teens[w];
    } else if (words.tens.hasOwnProperty(w) === true) {
      has.tens = words.tens[w];
    } else if (words.multiples.hasOwnProperty(w) === true) {
      let mult = words.multiples[w];

      //something has gone wrong : 'two hundred five hundred'
      //possibly because it's a fraction
      if (mult === last_mult) {
        return null
      }
      //support 'hundred thousand'
      //this one is tricky..
      if (mult === 100 && terms[i + 1] !== undefined) {
        const w2 = terms[i + 1];
        if (words.multiples[w2]) {
          mult *= words.multiples[w2]; //hundredThousand/hundredMillion
          i += 1;
        }
      }
      //natural order of things
      //five thousand, one hundred..
      if (last_mult === null || mult < last_mult) {
        sum += (section_sum(has) || 1) * mult;
        last_mult = mult;
        has = {};
      } else {
        //maybe hundred .. thousand
        sum += section_sum(has);
        last_mult = mult;
        sum = (sum || 1) * mult;
        has = {};
      }
    }
  }
  //dump the remaining has values
  sum += section_sum(has);
  //post-process add modifier
  sum *= modifier.amount;
  sum *= isNegative ? -1 : 1;
  //dont return 0, if it went straight-through
  if (sum === 0 && Object.keys(has).length === 0) {
    return null
  }
  return sum
};

const endS = /s$/;

// just using .toNumber() again may risk an infinite-loop
const parseNumber$1 = function (m) {
  let str = m.text('reduced');
  return parse$3(str)
};

let mapping = {
  half: 2,
  halve: 2,
  quarter: 4,
};

const slashForm = function (m) {
  let str = m.text('reduced');
  let found = str.match(/^([-+]?[0-9]+)\/([-+]?[0-9]+)(st|nd|rd|th)?s?$/);
  if (found && found[1] && found[0]) {
    return {
      numerator: Number(found[1]),
      denominator: Number(found[2]),
    }
  }
  return null
};

// parse '4 out of 4'
const nOutOfN = function (m) {
  let found = m.match('[<num>#Value+] out of every? [<den>#Value+]');
  if (found.found !== true) {
    return null
  }
  let { num, den } = found.groups();
  if (!num || !den) {
    return null
  }
  num = parseNumber$1(num);
  den = parseNumber$1(den);
  if (!num || !den) {
    return null
  }
  if (typeof num === 'number' && typeof den === 'number') {
    return {
      numerator: num,
      denominator: den,
    }
  }
  return null
};

// parse 'five thirds'
const nOrinalth = function (m) {
  let found = m.match('[<num>(#Cardinal|a)+] [<den>#Fraction+]');
  if (found.found !== true) {
    return null
  }
  let { num, den } = found.groups();
  // -- parse numerator---
  // quick-support for 'a third'
  if (num.has('a')) {
    num = 1;
  } else {
    // abuse the number-parser for 'thirty three'
    // let tmp = num.clone().unTag('Fraction')
    // num = tmp.numbers().get()[0]
    num = parseNumber$1(num);
  }
  // -- parse denominator --
  // turn 'thirds' into third
  let str = den.text('reduced');
  if (endS.test(str)) {
    str = str.replace(endS, '');
    den = den.replaceWith(str);
  }
  // support 'one half' as '1/2'
  if (mapping.hasOwnProperty(str)) {
    den = mapping[str];
  } else {
    // dem = dem.numbers().get()[0]
    den = parseNumber$1(den);
  }
  if (typeof num === 'number' && typeof den === 'number') {
    return {
      numerator: num,
      denominator: den,
    }
  }
  return null
};

// implied 1 in '100th of a', 'fifth of a'
const oneNth = function (m) {
  let found = m.match('^#Ordinal$');
  if (found.found !== true) {
    return null
  }
  // ensure it's '100th of a '
  if (m.lookAhead('^of .')) {
    // let num = found.numbers().get()[0]
    let num = parseNumber$1(found);
    return {
      numerator: 1,
      denominator: num,
    }
  }
  return null
};

// 'half'
const named = function (m) {
  let str = m.text('reduced');
  if (mapping.hasOwnProperty(str)) {
    return { numerator: 1, denominator: mapping[str] }
  }
  return null
};

const round = n => {
  let rounded = Math.round(n * 1000) / 1000;
  // don't round 1 millionth down into 0
  if (rounded === 0 && n !== 0) {
    return n
  }
  return rounded
};

const parseFraction = function (m) {
  m = m.clone();
  let res = named(m) || slashForm(m) || nOutOfN(m) || nOrinalth(m) || oneNth(m) || null;
  if (res !== null) {
    // do the math
    if (res.numerator && res.denominator) {
      res.decimal = res.numerator / res.denominator;
      res.decimal = round(res.decimal);
    }
  }
  return res
};

/**
 * turn big numbers, like 2.3e+22, into a string with a ton of trailing 0's
 * */
const numToString = function (n) {
  if (n < 1000000) {
    return String(n)
  }
  let str;
  if (typeof n === 'number') {
    str = n.toFixed(0);
  } else {
    str = n;
  }
  if (str.indexOf('e+') === -1) {
    return str
  }
  return str
    .replace('.', '')
    .split('e+')
    .reduce(function (p, b) {
      return p + Array(b - p.length + 2).join(0)
    })
};
// console.log(numToString(2.5e+22));

const tens_mapping = [
  ['ninety', 90],
  ['eighty', 80],
  ['seventy', 70],
  ['sixty', 60],
  ['fifty', 50],
  ['forty', 40],
  ['thirty', 30],
  ['twenty', 20],
];
const ones_mapping = [
  '',
  'one',
  'two',
  'three',
  'four',
  'five',
  'six',
  'seven',
  'eight',
  'nine',
  'ten',
  'eleven',
  'twelve',
  'thirteen',
  'fourteen',
  'fifteen',
  'sixteen',
  'seventeen',
  'eighteen',
  'nineteen',
];

const sequence = [
  [1e24, 'septillion'],
  [1e20, 'hundred sextillion'],
  [1e21, 'sextillion'],
  [1e20, 'hundred quintillion'],
  [1e18, 'quintillion'],
  [1e17, 'hundred quadrillion'],
  [1e15, 'quadrillion'],
  [1e14, 'hundred trillion'],
  [1e12, 'trillion'],
  [1e11, 'hundred billion'],
  [1e9, 'billion'],
  [1e8, 'hundred million'],
  [1e6, 'million'],
  [100000, 'hundred thousand'],
  [1000, 'thousand'],
  [100, 'hundred'],
  [1, 'one'],
];

/**
 * turns an integer/float into.ber, like 'fifty-five'
 */

//turn number into an array of magnitudes, like [[5, million], [2, hundred]]
const breakdown_magnitudes = function (num) {
  let working = num;
  let have = [];
  sequence.forEach(a => {
    if (num >= a[0]) {
      let howmany = Math.floor(working / a[0]);
      working -= howmany * a[0];
      if (howmany) {
        have.push({
          unit: a[1],
          count: howmany,
        });
      }
    }
  });
  return have
};

//turn numbers from 100-0 into their text
const breakdown_hundred = function (num) {
  let arr = [];
  if (num > 100) {
    return arr //something bad happened..
  }
  for (let i = 0; i < tens_mapping.length; i++) {
    if (num >= tens_mapping[i][1]) {
      num -= tens_mapping[i][1];
      arr.push(tens_mapping[i][0]);
    }
  }
  //(hopefully) we should only have 20-0 now
  if (ones_mapping[num]) {
    arr.push(ones_mapping[num]);
  }
  return arr
};

/** print-out 'point eight nine'*/
const handle_decimal = num => {
  const names = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine'];
  let arr = [];
  //parse it out like a string, because js math is such shit
  let str = numToString(num);
  let decimal = str.match(/\.([0-9]+)/);
  if (!decimal || !decimal[0]) {
    return arr
  }
  arr.push('point');
  let decimals = decimal[0].split('');
  for (let i = 0; i < decimals.length; i++) {
    arr.push(names[decimals[i]]);
  }
  return arr
};

/** turns an integer into a textual number */
const toText$1 = function (obj) {
  let num = obj.num;
  // handle zero, quickly
  if (num === 0 || num === '0') {
    return 'zero' // no?
  }
  //big numbers, north of sextillion, aren't gonna work well..
  //keep them small..
  if (num > 1e21) {
    num = numToString(num);
  }
  let arr = [];
  //handle negative numbers
  if (num < 0) {
    arr.push('minus');
    num = Math.abs(num);
  }
  //break-down into units, counts
  let units = breakdown_magnitudes(num);
  //build-up the string from its components
  for (let i = 0; i < units.length; i++) {
    let unit_name = units[i].unit;
    if (unit_name === 'one') {
      unit_name = '';
      //put an 'and' in here
      if (arr.length > 1) {
        arr.push('and');
      }
    }
    arr = arr.concat(breakdown_hundred(units[i].count));
    arr.push(unit_name);
  }
  //also support decimals - 'point eight'
  arr = arr.concat(handle_decimal(num));
  //remove empties
  arr = arr.filter(s => s);
  if (arr.length === 0) {
    arr[0] = '';
  }
  return arr.join(' ')
};

// console.log(to_text(-1000.8));

const toCardinal = function (obj) {
  if (!obj.numerator || !obj.denominator) {
    return ''
  }
  let a = toText$1({ num: obj.numerator });
  let b = toText$1({ num: obj.denominator });
  return `${a} out of ${b}`
};

const irregulars = {
  one: 'first',
  two: 'second',
  three: 'third',
  five: 'fifth',
  eight: 'eighth',
  nine: 'ninth',
  twelve: 'twelfth',
  twenty: 'twentieth',
  thirty: 'thirtieth',
  forty: 'fortieth',
  fourty: 'fourtieth',
  fifty: 'fiftieth',
  sixty: 'sixtieth',
  seventy: 'seventieth',
  eighty: 'eightieth',
  ninety: 'ninetieth',
};

/**
 * convert a javascript number to 'twentieth' format
 * */
const textOrdinal = obj => {
  let words = toText$1(obj).split(' ');
  //convert the last number to an ordinal
  let last = words[words.length - 1];
  if (irregulars.hasOwnProperty(last)) {
    words[words.length - 1] = irregulars[last];
  } else {
    words[words.length - 1] = last.replace(/y$/, 'i') + 'th';
  }
  return words.join(' ')
};

const toOrdinal = function (obj) {
  // don't divide by zero!
  if (!obj.numerator || !obj.denominator) {
    return ''
  }
  // create [two] [fifths]
  let start = toText$1({ num: obj.numerator });
  let end = textOrdinal({ num: obj.denominator });
  // 'one secondth' -> 'one half'
  if (obj.denominator === 2) {
    end = 'half';
  }
  if (start && end) {
    if (obj.numerator !== 1) {
      end += 's';
    }
    return `${start} ${end}`
  }
  return ''
};

const plugin$1 = function (View) {
  /**
   */
  class Fractions extends View {
    constructor(document, pointer, groups) {
      super(document, pointer, groups);
      this.viewType = 'Fractions';
    }
    parse(n) {
      return this.getNth(n).map(parseFraction)
    }
    get(n) {
      return this.getNth(n).map(parseFraction)
    }
    json(n) {
      return this.getNth(n).map(p => {
        let json = p.toView().json(n)[0];
        let parsed = parseFraction(p);
        json.fraction = parsed;
        return json
      }, [])
    }
    // become 0.5
    toDecimal(n) {
      this.getNth(n).forEach(m => {
        let { decimal } = parseFraction(m);
        m = m.replaceWith(String(decimal), true);
        m.tag('NumericValue');
        m.unTag('Fraction');
      });
      return this
    }
    toFraction(n) {
      this.getNth(n).forEach(m => {
        let obj = parseFraction(m);
        if (obj && typeof obj.numerator === 'number' && typeof obj.denominator === 'number') {
          let str = `${obj.numerator}/${obj.denominator}`;
          this.replace(m, str);
        }
      });
      return this
    }
    toOrdinal(n) {
      this.getNth(n).forEach(m => {
        let obj = parseFraction(m);
        let str = toOrdinal(obj);
        if (m.after('^#Noun').found) {
          str += ' of'; // three fifths of dentists
        }
        m.replaceWith(str);
      });
      return this
    }
    toCardinal(n) {
      this.getNth(n).forEach(m => {
        let obj = parseFraction(m);
        let str = toCardinal(obj);
        m.replaceWith(str);
      });
      return this
    }
    toPercentage(n) {
      this.getNth(n).forEach(m => {
        let { decimal } = parseFraction(m);
        let percent = decimal * 100;
        percent = Math.round(percent * 100) / 100; // round it
        m.replaceWith(`${percent}%`);
      });
      return this
    }
  }

  View.prototype.fractions = function (n) {
    let m = findFractions(this);
    m = m.getNth(n);
    return new Fractions(this.document, m.pointer)
  };
};

const ones = 'one|two|three|four|five|six|seven|eight|nine';
const tens = 'twenty|thirty|forty|fifty|sixty|seventy|eighty|ninety|fourty';
const teens = 'eleven|twelve|thirteen|fourteen|fifteen|sixteen|seventeen|eighteen|nineteen';

// this is a bit of a mess
// segment consecutive number-words into sensible chunks
const findNumbers = function (doc) {
  let m = doc.match('#Value+');

  //"50 83"
  if (m.has('#NumericValue #NumericValue')) {
    //a comma may mean two numbers
    if (m.has('#Value @hasComma #Value')) {
      m.splitAfter('@hasComma');
    } else if (m.has('#NumericValue #Fraction')) {
      m.splitAfter('#NumericValue #Fraction');
    } else {
      m = m.splitAfter('#NumericValue');
    }
  }

  //three-length
  if (m.has('#Value #Value #Value') && !m.has('#Multiple')) {
    //twenty-five-twenty
    if (m.has('(' + tens + ') #Cardinal #Cardinal')) {
      m = m.splitAfter('(' + tens + ') #Cardinal');
    }
  }

  //two-length ones
  if (m.has('#Value #Value')) {
    //june 21st 1992 is two seperate values
    if (m.has('#NumericValue #NumericValue')) {
      m = m.splitOn('#Year');
    }
    //sixty fifteen
    if (m.has('(' + tens + ') (' + teens + ')')) {
      m = m.splitAfter('(' + tens + ')');
    }

    //"72 82"
    let double = m.match('#Cardinal #Cardinal');
    if (double.found && !m.has('(point|decimal|#Fraction)')) {
      //not 'two hundred'
      if (!double.has('#Cardinal (#Multiple|point|decimal)')) {
        // two fifty five
        let noMultiple = m.has(`(${ones}) (${tens})`);
        // twenty one
        let tensVal = double.has('(' + tens + ') #Cardinal');
        // hundredOne
        let multVal = double.has('#Multiple #Value');
        //one proper way, 'twenty one', or 'hundred one'
        if (!noMultiple && !tensVal && !multVal) {
          // double = double.firstTerm()
          double.terms().forEach(d => {
            m = m.splitOn(d);
          });
        }
      }
    }

    //seventh fifth
    if (m.match('#Ordinal #Ordinal').match('#TextValue').found && !m.has('#Multiple')) {
      //the one proper way, 'twenty first'
      if (!m.has('(' + tens + ') #Ordinal')) {
        m = m.splitAfter('#Ordinal');
      }
    }
    //fifth five
    m = m.splitBefore('#Ordinal [#Cardinal]', 0);
    //five 2017 (support '5 hundred', and 'twenty 5'
    if (m.has('#TextValue #NumericValue') && !m.has('(' + tens + '|#Multiple)')) {
      m = m.splitBefore('#TextValue #NumericValue');
    }
  }

  //5-8
  m = m.splitAfter('#NumberRange');
  // june 5th 1999
  m = m.splitBefore('#Year');
  return m
};

const parseNumeric = function (str, m) {
  str = str.replace(/,/g, '');
  //parse a numeric-number
  let arr = str.split(/([0-9.,]*)/);
  let [prefix, num] = arr;
  let suffix = arr.slice(2).join('');
  if (num !== '' && m.length < 2) {
    num = Number(num || str);
    //ensure that num is an actual number
    if (typeof num !== 'number') {
      num = null;
    }
    // strip an ordinal off the suffix
    suffix = suffix || '';
    if (suffix === 'st' || suffix === 'nd' || suffix === 'rd' || suffix === 'th') {
      suffix = '';
    }
    // support M for million, k for thousand
    // if (suffix === 'm' || suffix === 'M') {
    //   num *= 1000000
    //   suffix = ''
    // }
    // if (suffix === 'k' || suffix === 'k') {
    //   num *= 1000
    //   suffix = ''
    // }
    return {
      prefix: prefix || '',
      num: num,
      suffix: suffix,
    }
  }
  return null
};

// get a numeric value from this phrase
const parseNumber = function (m) {
  if (typeof m === 'string') {
    return { num: parse$3(m) }
  }
  let str = m.text('reduced');
  // reach for '12 litres'
  let unit = m.growRight('#Unit').match('#Unit$').text('machine');
  // is it in '3,123' format?
  let hasComma = /[0-9],[0-9]/.test(m.text('text'));
  // parse a numeric-number like '$4.00'
  if (m.terms().length === 1 && !m.has('#Multiple')) {
    let res = parseNumeric(str, m);
    if (res !== null) {
      res.hasComma = hasComma;
      res.unit = unit;
      return res
    }
  }
  // -- parse text-formats --
  // Fractions: remove 'and a half' etc. from the end
  let frPart = m.match('#Fraction{2,}$');
  frPart = frPart.found === false ? m.match('^#Fraction$') : frPart;
  let fraction = null;
  if (frPart.found) {
    if (frPart.has('#Value and #Value #Fraction')) {
      frPart = frPart.match('and #Value #Fraction');
    }
    fraction = parseFraction(frPart);
    // remove it from our string
    m = m.not(frPart);
    m = m.not('and$');
    str = m.text('reduced');
  }
  let num = 0;
  if (str) {
    num = parse$3(str) || 0;
  }
  // apply numeric fraction
  if (fraction && fraction.decimal) {
    num += fraction.decimal;
  }


  return {
    hasComma,
    prefix: '',
    num,
    suffix: '',
    isOrdinal: m.has('#Ordinal'),
    isText: m.has('#TextValue'),
    isFraction: m.has('#Fraction'),
    isMoney: m.has('#Money'),
    unit
  }
};

/**
 * turn a number like 5 into an ordinal like 5th
 */
const numOrdinal = function (obj) {
  let num = obj.num;
  if (!num && num !== 0) {
    return null
  }
  //the teens are all 'th'
  let tens = num % 100;
  if (tens > 10 && tens < 20) {
    return String(num) + 'th'
  }
  //the rest of 'em
  const mapping = {
    0: 'th',
    1: 'st',
    2: 'nd',
    3: 'rd',
  };
  let str = numToString(num);
  let last = str.slice(str.length - 1, str.length);
  if (mapping[last]) {
    str += mapping[last];
  } else {
    str += 'th';
  }
  return str
};

const prefixes = {
  'Â¢': 'cents',
  $: 'dollars',
  'Â£': 'pounds',
  'Â¥': 'yen',
  'â‚¬': 'euros',
  'â‚¡': 'colÃ³n',
  'à¸¿': 'baht',
  'â‚­': 'kip',
  'â‚©': 'won',
  'â‚¹': 'rupees',
  'â‚½': 'ruble',
  'â‚º': 'liras',
};
const suffixes = {
  '%': 'percent',
  // s: 'seconds',
  // cm: 'centimetres',
  // km: 'kilometres',
  // ft: 'feet',
  'Â°': 'degrees'
};

const addSuffix = function (obj) {
  let res = {
    suffix: '',
    prefix: obj.prefix,
  };
  // $5 to 'five dollars'
  if (prefixes.hasOwnProperty(obj.prefix)) {
    res.suffix += ' ' + prefixes[obj.prefix];
    res.prefix = '';
  }
  // 5% to 'five percent'
  if (suffixes.hasOwnProperty(obj.suffix)) {
    res.suffix += ' ' + suffixes[obj.suffix];
  }
  if (res.suffix && obj.num === 1) {
    res.suffix = res.suffix.replace(/s$/, '');
  }
  // misc other suffixes
  if (!res.suffix && obj.suffix) {
    res.suffix += ' ' + obj.suffix;
  }
  return res
};

const format = function (obj, fmt) {
  if (fmt === 'TextOrdinal') {
    let { prefix, suffix } = addSuffix(obj);
    return prefix + textOrdinal(obj) + suffix
  }
  if (fmt === 'Ordinal') {
    return obj.prefix + numOrdinal(obj) + obj.suffix
  }
  if (fmt === 'TextCardinal') {
    let { prefix, suffix } = addSuffix(obj);
    return prefix + toText$1(obj) + suffix
  }
  // assume Cardinal
  let num = obj.num;
  if (obj.hasComma) {
    num = num.toLocaleString();
  }
  return obj.prefix + String(num) + obj.suffix
};

const isArray = arr => Object.prototype.toString.call(arr) === '[object Array]';

// turn anything into {foo:true} format
const coerceToObject = function (input) {
  if (typeof input === 'string' || typeof input === 'number') {
    let tmp = {};
    tmp[input] = true;
    return tmp
  }
  if (isArray(input)) {
    return input.reduce((h, s) => {
      h[s] = true;
      return h
    }, {})
  }
  return input || {}
};

// only return values with the given unit
const isUnit = function (doc, input = {}) {
  input = coerceToObject(input);
  return doc.filter(p => {
    let { unit } = parseNumber(p);
    if (unit && input[unit] === true) {
      return true
    }
    return false
  })
};

const addMethod$2 = function (View) {
  /**   */
  class Numbers extends View {
    constructor(document, pointer, groups) {
      super(document, pointer, groups);
      this.viewType = 'Numbers';
    }
    parse(n) {
      return this.getNth(n).map(parseNumber)
    }
    get(n) {
      return this.getNth(n)
        .map(parseNumber)
        .map(o => o.num)
    }
    json(n) {
      let opts = typeof n === 'object' ? n : {};
      return this.getNth(n).map(p => {
        let json = p.toView().json(opts)[0];
        let parsed = parseNumber(p);
        json.number = {
          prefix: parsed.prefix,
          num: parsed.num,
          suffix: parsed.suffix,
          hasComma: parsed.hasComma,
          unit: parsed.unit,
        };
        return json
      }, [])
    }
    /** any known measurement unit, for the number */
    units() {
      return this.growRight('#Unit').match('#Unit$')
    }
    /** return values that match a given unit */
    isUnit(allowed) {
      return isUnit(this, allowed)
    }
    /** return only ordinal numbers */
    isOrdinal() {
      return this.if('#Ordinal')
    }
    /** return only cardinal numbers*/
    isCardinal() {
      return this.if('#Cardinal')
    }

    /** convert to numeric form like '8' or '8th' */
    toNumber() {
      let res = this.map(val => {
        if (!this.has('#TextValue')) {
          return val
        }
        let obj = parseNumber(val);
        if (obj.num === null) {
          return val
        }
        let fmt = val.has('#Ordinal') ? 'Ordinal' : 'Cardinal';
        let str = format(obj, fmt);
        val.replaceWith(str, { tags: true });
        return val.tag('NumericValue')
      });
      return new Numbers(res.document, res.pointer)
    }
    /** add commas, or nicer formatting for numbers */
    toLocaleString() {
      let m = this;
      m.forEach(val => {
        let obj = parseNumber(val);
        if (obj.num === null) {
          return
        }
        let num = obj.num.toLocaleString();
        // support ordinal ending, too
        if (val.has('#Ordinal')) {
          let str = format(obj, 'Ordinal');
          let end = str.match(/[a-z]+$/);
          if (end) {
            num += end[0] || '';
          }
        }
        val.replaceWith(num, { tags: true });
      });
      return this
    }
    /** convert to numeric form like 'eight' or 'eighth' */
    toText() {
      let m = this;
      let res = m.map(val => {
        if (val.has('#TextValue')) {
          return val
        }
        let obj = parseNumber(val);
        if (obj.num === null) {
          return val
        }
        let fmt = val.has('#Ordinal') ? 'TextOrdinal' : 'TextCardinal';
        let str = format(obj, fmt);
        val.replaceWith(str, { tags: true });
        val.tag('TextValue');
        return val
      });
      return new Numbers(res.document, res.pointer)
    }
    /** convert ordinal to cardinal form, like 'eight', or '8' */
    toCardinal() {
      let m = this;
      let res = m.map(val => {
        if (!val.has('#Ordinal')) {
          return val
        }
        let obj = parseNumber(val);
        if (obj.num === null) {
          return val
        }
        let fmt = val.has('#TextValue') ? 'TextCardinal' : 'Cardinal';
        let str = format(obj, fmt);
        val.replaceWith(str, { tags: true });
        val.tag('Cardinal');
        return val
      });
      return new Numbers(res.document, res.pointer)
    }
    /** convert cardinal to ordinal form, like 'eighth', or '8th' */
    toOrdinal() {
      let m = this;
      let res = m.map(val => {
        if (val.has('#Ordinal')) {
          return val
        }
        let obj = parseNumber(val);
        if (obj.num === null) {
          return val
        }
        let fmt = val.has('#TextValue') ? 'TextOrdinal' : 'Ordinal';
        let str = format(obj, fmt);
        val.replaceWith(str, { tags: true });
        val.tag('Ordinal');
        return val
      });
      return new Numbers(res.document, res.pointer)
    }

    /** return only numbers that are == n */
    isEqual(n) {
      return this.filter(val => {
        let num = parseNumber(val).num;
        return num === n
      })
    }
    /** return only numbers that are > n*/
    greaterThan(n) {
      return this.filter(val => {
        let num = parseNumber(val).num;
        return num > n
      })
    }
    /** return only numbers that are < n*/
    lessThan(n) {
      return this.filter(val => {
        let num = parseNumber(val).num;
        return num < n
      })
    }
    /** return only numbers > min and < max */
    between(min, max) {
      return this.filter(val => {
        let num = parseNumber(val).num;
        return num > min && num < max
      })
    }
    /** set these number to n */
    set(n) {
      if (n === undefined) {
        return this // don't bother
      }
      if (typeof n === 'string') {
        n = parseNumber(n).num;
      }
      let m = this;
      let res = m.map(val => {
        let obj = parseNumber(val);
        obj.num = n;
        if (obj.num === null) {
          return val
        }
        let fmt = val.has('#Ordinal') ? 'Ordinal' : 'Cardinal';
        if (val.has('#TextValue')) {
          fmt = val.has('#Ordinal') ? 'TextOrdinal' : 'TextCardinal';
        }
        let str = format(obj, fmt);
        // add commas to number
        if (obj.hasComma && fmt === 'Cardinal') {
          str = Number(str).toLocaleString();
        }
        val = val.not('#Currency');
        val.replaceWith(str, { tags: true });
        // handle plural/singular unit
        // agreeUnits(agree, val, obj)
        return val
      });
      return new Numbers(res.document, res.pointer)
    }
    add(n) {
      if (!n) {
        return this // don't bother
      }
      if (typeof n === 'string') {
        n = parseNumber(n).num;
      }
      let m = this;
      let res = m.map(val => {
        let obj = parseNumber(val);
        if (obj.num === null) {
          return val
        }
        obj.num += n;
        let fmt = val.has('#Ordinal') ? 'Ordinal' : 'Cardinal';
        if (obj.isText) {
          fmt = val.has('#Ordinal') ? 'TextOrdinal' : 'TextCardinal';
        }
        let str = format(obj, fmt);
        val.replaceWith(str, { tags: true });
        // handle plural/singular unit
        // agreeUnits(agree, val, obj)
        return val
      });
      return new Numbers(res.document, res.pointer)
    }
    /** decrease each number by n*/
    subtract(n, agree) {
      return this.add(n * -1, agree)
    }
    /** increase each number by 1 */
    increment(agree) {
      return this.add(1, agree)
    }
    /** decrease each number by 1 */
    decrement(agree) {
      return this.add(-1, agree)
    }
    // overloaded - keep Numbers class
    update(pointer) {
      let m = new Numbers(this.document, pointer);
      m._cache = this._cache; // share this full thing
      return m
    }
  }
  // aliases
  Numbers.prototype.toNice = Numbers.prototype.toLocaleString;
  Numbers.prototype.isBetween = Numbers.prototype.between;
  Numbers.prototype.minus = Numbers.prototype.subtract;
  Numbers.prototype.plus = Numbers.prototype.add;
  Numbers.prototype.equals = Numbers.prototype.isEqual;

  View.prototype.numbers = function (n) {
    let m = findNumbers(this);
    m = m.getNth(n);
    return new Numbers(this.document, m.pointer)
  };
  View.prototype.percentages = function (n) {
    let m = findNumbers(this);
    m = m.filter(v => v.has('#Percent') || v.after('^percent'));
    m = m.getNth(n);
    return new Numbers(this.document, m.pointer)
  };
  View.prototype.money = function (n) {
    let m = findNumbers(this);
    m = m.filter(v => v.has('#Money') || v.after('^#Currency'));
    m = m.getNth(n);
    return new Numbers(this.document, m.pointer)
  };
  // alias
  View.prototype.values = View.prototype.numbers;
};

const api$6 = function (View) {
  plugin$1(View);
  addMethod$2(View);
};

var numbers = {
  api: api$6,

  // add @greaterThan, @lessThan
  // mutate: world => {
  //   let termMethods = world.methods.one.termMethods

  //   termMethods.lessThan = function (term) {
  //     return false //TODO: implement
  //     // return /[aeiou]/.test(term.text)
  //   }
  // },
};

const defaults = {
  people: true,
  emails: true,
  phoneNumbers: true,
  places: true,
};

const redact = function (opts = {}) {
  opts = Object.assign({}, defaults, opts);
  if (opts.people !== false) {
    this.people().replaceWith('â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ');
  }
  if (opts.emails !== false) {
    this.emails().replaceWith('â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ');
  }
  if (opts.places !== false) {
    this.places().replaceWith('â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ');
  }
  if (opts.phoneNumbers !== false) {
    this.phoneNumbers().replaceWith('â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ');
  }
  return this
};

const plugin = {
  api: function (View) {
    View.prototype.redact = redact;
  }
};

//is this sentence asking a question?
const isQuestion = function (doc) {
  let clauses = doc.clauses();

  // Has ellipsis at the end means it's probably not a question
  // e.g., Is this just fantasy...
  if (/\.\.$/.test(doc.out('text'))) {
    return false
  }

  // Starts with question word, but has a comma, so probably not a question
  // e.g., Why are we caught in a land slide, no escape from reality
  if (doc.has('^#QuestionWord') && doc.has('@hasComma')) {
    return false
  }

  // do you see it or not
  if (doc.has('or not$')) {
    return true
  }

  // Starts with a #QuestionWord
  // e.g., What open your eyes look up to the skies and see
  if (doc.has('^#QuestionWord')) {
    return true
  }

  // Second word is a #QuestionWord
  // e.g., I'm what a poor boy
  // case ts.has('^\w+\s#QuestionWord'):
  // return true;

  // is it, do you - start of sentence
  // e.g., Do I need no sympathy
  if (doc.has('^(do|does|did|is|was|can|could|will|would|may) #Noun')) {
    return true
  }

  // these are a little more loose..
  // e.g., Must I be come easy come easy go
  if (doc.has('^(have|must) you')) {
    return true
  }

  // Clause starts with a question word
  // e.g., Anyway the wind blows, what doesn't really matter to me
  // if (clauses.has('^#QuestionWord')) {
  //   return true
  // }

  //is wayne gretskzy alive
  if (clauses.has('(do|does|is|was) #Noun+ #Adverb? (#Adjective|#Infinitive)$')) {
    return true
  }

  // Probably not a question
  return false
};

const findQuestions = function (view) {
  const hasQ = /\?/;
  const { document } = view;
  return view.filter(m => {
    let terms = m.docs[0] || [];
    let lastTerm = terms[terms.length - 1];
    // is it not a full sentence?
    if (!lastTerm || document[lastTerm.index[0]].length !== terms.length) {
      return false
    }
    // does it end with a question mark?
    if (hasQ.test(lastTerm.post)) {
      return true
    }
    // try to guess a sentence without a question-mark
    return isQuestion(m)
  })
};

// if a clause starts with these, it's not a main clause
const subordinate = `(after|although|as|because|before|if|since|than|that|though|when|whenever|where|whereas|wherever|whether|while|why|unless|until|once)`;
const relative = `(that|which|whichever|who|whoever|whom|whose|whomever)`;

//try to remove secondary clauses
const mainClause = function (s) {
  let m = s;
  if (m.length === 1) {
    return m
  }
  // if there's no verb, it's dependent
  m = m.if('#Verb');
  if (m.length === 1) {
    return m
  }
  // this is a signal for subordinate-clauses
  m = m.ifNo(subordinate);
  m = m.ifNo('^even (if|though)');
  m = m.ifNo('^so that');
  m = m.ifNo('^rather than');
  m = m.ifNo('^provided that');
  if (m.length === 1) {
    return m
  }
  // relative clauses
  m = m.ifNo(relative);
  if (m.length === 1) {
    return m
  }

  // check for subordinating conjunctions -- must be at the beginning of the clause
  m = m.ifNo('(^despite|^during|^before|^through|^throughout)');
  if (m.length === 1) {
    return m
  }

  // check for clauses beginning with Gerund ("Taking ..., ...")
  m = m.ifNo('^#Gerund');
  if (m.length === 1) {
    return m
  }

  // did we go too far?
  if (m.length === 0) {
    m = s;
  }
  // choose the first one?
  return m.eq(0)
};

const grammar = function (vb) {
  let tense = null;
  if (vb.has('#PastTense')) {
    tense = 'PastTense';
  } else if (vb.has('#FutureTense')) {
    tense = 'FutureTense';
  } else if (vb.has('#PresentTense')) {
    tense = 'PresentTense';
  }
  return {
    tense
  }
};

const parse$2 = function (s) {
  let clauses = s.clauses();
  let main = mainClause(clauses);
  let chunks = main.chunks();
  let subj = s.none();
  let verb = s.none();
  let pred = s.none();
  chunks.forEach((ch, i) => {
    if (i === 0 && !ch.has('<Verb>')) {
      subj = ch;
      return
    }
    if (!verb.found && ch.has('<Verb>')) {
      verb = ch;
      return
    }
    if (verb.found) {
      pred = pred.concat(ch);
    }
  });
  // cleanup a missed parse
  if (verb.found && !subj.found) {
    subj = verb.before('<Noun>+').first();
  }
  return {
    subj,
    verb,
    pred,
    grammar: grammar(verb)
  }
};

const toPast$2 = function (s) {
  let verbs = s.verbs();
  // translate the first verb, no-stress
  let first = verbs.eq(0);
  // already past
  if (first.has('#PastTense')) {
    return s
  }
  first.toPastTense();

  // force agreement with any 2nd/3rd verbs:
  if (verbs.length > 1) {
    verbs = verbs.slice(1);
    // remove any sorta infinitive - 'to engage'
    verbs = verbs.filter((v) => !v.lookBehind('to$').found);

    // keep -ing verbs
    verbs = verbs.if('#PresentTense');
    verbs = verbs.notIf('#Gerund');

    //run-on infinitive-list - 'to walk, sit and eat'
    let list = s.match('to #Verb+ #Conjunction #Verb').terms();
    verbs = verbs.not(list);

    // otherwise, I guess so?
    if (verbs.found) {
      verbs.verbs().toPastTense();
    }
  }

  // s.compute('chunks')
  return s
};

const toPresent$1 = function (s) {
  let verbs = s.verbs();
  // translate the first verb, no-stress
  let first = verbs.eq(0);
  // already present
  // if (first.has('#PresentTense')) {
  //   return s
  // }
  first.toPresentTense();

  // force agreement with any 2nd/3rd verbs:
  if (verbs.length > 1) {
    verbs = verbs.slice(1);
    // remove any sorta infinitive - 'to engage'
    verbs = verbs.filter((v) => !v.lookBehind('to$').found);

    // keep -ing verbs
    // verbs = verbs.if('#PresentTense')
    verbs = verbs.notIf('#Gerund');

    //run-on infinitive-list - 'to walk, sit and eat'
    // let list = s.match('to #Verb+ #Conjunction #Verb').terms()
    // verbs = verbs.not(list)

    // otherwise, I guess so?
    if (verbs.found) {
      verbs.verbs().toPresentTense();
    }
  }

  // s.compute('chunks')
  return s
};

const toFuture$1 = function (s) {
  let verbs = s.verbs();
  // translate the first verb, no-stress
  let first = verbs.eq(0);
  first.toFutureTense();
  s = s.fullSentence();
  verbs = s.verbs();//re-do it
  // verbs.debug()
  // force agreement with any 2nd/3rd verbs:
  if (verbs.length > 1) {
    verbs = verbs.slice(1);
    // which following-verbs should we also change?
    let toChange = verbs.filter((vb) => {
      // remove any sorta infinitive - 'to engage'
      if (vb.lookBehind('to$').found) {
        return false
      }
      // is watching
      if (vb.has('#Copula #Gerund')) {
        return true
      }
      // keep -ing verbs
      if (vb.has('#Gerund')) {
        return false
      }
      // he is green and he is friendly
      if (vb.has('#Copula')) {
        return true
      }
      // 'he will see when he watches'
      if (vb.has('#PresentTense') && !vb.has('#Infinitive') && vb.lookBefore('(he|she|it|that|which)$').found) {
        return false
      }
      return true
    });
    // otherwise, change em too
    if (toChange.found) {
      toChange.forEach(m => {
        //extra rules for 'is'
        if (m.has('#Copula')) {
          // when he was out..
          m.match('was').replaceWith('is');
          // when he is out
          m.match('is').replaceWith('will be');
          return
        }
        // if (m.has('#PastTense')) {
        //   m.toPresentTense()
        //   return
        // }
        m.toInfinitive();
      });
    }
  }
  return s
};

const toNegative$1 = function (s) {
  s.verbs().first().toNegative().compute('chunks');
  return s
};
const toPositive = function (s) {
  s.verbs().first().toPositive().compute('chunks');
  return s
};

const toInfinitive = function (s) {
  s.verbs().toInfinitive();
  // s.compute('chunks')
  return s
};

const api$5 = function (View) {
  class Sentences extends View {
    constructor(document, pointer, groups) {
      super(document, pointer, groups);
      this.viewType = 'Sentences';
    }
    json(opts = {}) {
      return this.map(m => {
        let json = m.toView().json(opts)[0] || {};
        let { subj, verb, pred, grammar } = parse$2(m);
        json.sentence = {
          subject: subj.text('normal'),
          verb: verb.text('normal'),
          predicate: pred.text('normal'),
          grammar
        };
        return json
      }, [])
    }
    toPastTense(n) {
      return this.getNth(n).map(s => {
        parse$2(s);
        return toPast$2(s)
      })
    }
    toPresentTense(n) {
      return this.getNth(n).map(s => {
        parse$2(s);
        return toPresent$1(s)
      })
    }
    toFutureTense(n) {
      return this.getNth(n).map(s => {
        parse$2(s);
        s = toFuture$1(s);
        return s
      })
    }
    toInfinitive(n) {
      return this.getNth(n).map(s => {
        parse$2(s);
        return toInfinitive(s)
      })
    }
    toNegative(n) {
      return this.getNth(n).map(vb => {
        parse$2(vb);
        return toNegative$1(vb)
      })
    }
    toPositive(n) {
      return this.getNth(n).map(vb => {
        parse$2(vb);
        return toPositive(vb)
      })
    }
    isQuestion(n) {
      return this.questions(n)
    }
    isExclamation(n) {
      let res = this.filter(s => s.lastTerm().has('@hasExclamation'));
      return res.getNth(n)
    }
    isStatement(n) {
      let res = this.filter(s => !s.isExclamation().found && !s.isQuestion().found);
      return res.getNth(n)
    }
    // overloaded - keep Sentences class
    update(pointer) {
      let m = new Sentences(this.document, pointer);
      m._cache = this._cache; // share this full thing
      return m
    }
  }
  // aliases
  Sentences.prototype.toPresent = Sentences.prototype.toPresentTense;
  Sentences.prototype.toPast = Sentences.prototype.toPastTense;
  Sentences.prototype.toFuture = Sentences.prototype.toFutureTense;

  const methods = {
    sentences: function (n) {
      let m = this.map(s => s.fullSentence());
      m = m.getNth(n);
      return new Sentences(this.document, m.pointer)
    },
    questions: function (n) {
      let m = findQuestions(this);
      return m.getNth(n)
    },
  };

  Object.assign(View.prototype, methods);
};

var sentences = { api: api$5 };

const find$2 = function (doc) {
  let m = doc.splitAfter('@hasComma');
  m = m.match('#Honorific+? #Person+');
  // Spencer's King
  let poss = m.match('#Possessive').notIf('(his|her)'); //her majesty ...
  m = m.splitAfter(poss);
  return m
};

const parse$1 = function (m) {
  let res = {};
  res.firstName = m.match('#FirstName+');
  res.lastName = m.match('#LastName+');
  res.honorific = m.match('#Honorific+');

  let last = res.lastName;
  let first = res.firstName;
  if (!first.found || !last.found) {
    // let p = m.clone()
    // assume 'Mr Springer' is a last-name
    if (!first.found && !last.found && m.has('^#Honorific .$')) {
      res.lastName = m.match('.$');
      return res
    }
  }
  return res
};

/*
  Important notice - 
  this method makes many assumptions about gender-identity, in-order to assign grammatical gender.
  it should not be used for any other purposes, other than resolving pronouns in english
*/
const m = 'male';
const f$1 = 'female';

// known gendered honorifics
const honorifics = {
  mr: m,
  mrs: f$1,
  miss: f$1,
  madam: f$1,

  // british stuff
  king: m,
  queen: f$1,
  duke: m,
  duchess: f$1,
  baron: m,
  baroness: f$1,
  count: m,
  countess: f$1,
  prince: m,
  princess: f$1,
  sire: m,
  dame: f$1,
  lady: f$1,

  ayatullah: m, //i think?

  congressman: m,
  congresswoman: f$1,
  'first lady': f$1,

  // marked as non-binary
  mx: null,
};

const predictGender = function (parsed, person) {
  let { firstName, honorific } = parsed;
  // use first-name as signal-signal
  if (firstName.has('#FemaleName')) {
    return f$1
  }
  if (firstName.has('#MaleName')) {
    return m
  }
  // use honorics as gender-signal
  if (honorific.found) {
    let hon = honorific.text('normal');
    hon = hon.replace(/\./g, ''); //clean it up a bit
    if (honorifics.hasOwnProperty(hon)) {
      return honorifics[hon]
    }
    // her excelency
    if (/^her /.test(hon)) {
      return f$1
    }
    if (/^his /.test(hon)) {
      return m
    }
  }
  // offer used-pronouns as a signal
  let after = person.after();
  if (!after.has('#Person') && after.has('#Pronoun')) {
    let pro = after.match('#Pronoun');
    // manual use of gender-neutral
    if (pro.has('(they|their)')) {
      return null
    }
    let hasMasc = pro.has('(he|his)');
    let hasFem = pro.has('(she|her|hers)');
    if (hasMasc && !hasFem) {
      return m
    }
    if (hasFem && !hasMasc) {
      return f$1
    }
  }
  return null
};

const addMethod$1 = function (View) {
  /**
   *
   */
  class People extends View {
    constructor(document, pointer, groups) {
      super(document, pointer, groups);
      this.viewType = 'People';
    }
    parse(n) {
      return this.getNth(n).map(parse$1)
    }
    json(n) {
      let opts = typeof n === 'object' ? n : {};
      return this.getNth(n).map(p => {
        let json = p.toView().json(opts)[0];
        let parsed = parse$1(p);
        json.person = {
          firstName: parsed.firstName.text('normal'),
          lastName: parsed.lastName.text('normal'),
          honorific: parsed.honorific.text('normal'),
          presumed_gender: predictGender(parsed, p),
        };
        return json
      }, [])
    }
    // used for co-reference resolution only
    presumedMale() {
      return this.filter(m => {
        return m.has('(#MaleName|mr|mister|sr|jr|king|pope|prince|sir)')//todo configure these in .world
      })
    }
    presumedFemale() {
      return this.filter(m => {
        return m.has('(#FemaleName|mrs|miss|queen|princess|madam)')
      })
    }
    // overloaded - keep People class
    update(pointer) {
      let m = new People(this.document, pointer);
      m._cache = this._cache; // share this full thing
      return m
    }
  }

  View.prototype.people = function (n) {
    let m = find$2(this);
    m = m.getNth(n);
    return new People(this.document, m.pointer)
  };
};

const find$1 = function (doc) {
  let m = doc.match('(#Place|#Address)+');

  // split all commas except for 'paris, france'
  let splits = m.match('@hasComma');
  splits = splits.filter(c => {
    // split 'europe, china'
    if (c.has('(asia|africa|europe|america)$')) {
      return true
    }
    // don't split 'paris, france'
    if (c.has('(#City|#Region|#ProperNoun)$') && c.after('^(#Country|#Region)').found) {
      return false
    }
    return true
  });
  m = m.splitAfter(splits);
  return m
};

const addMethod = function (View) {
  View.prototype.places = function (n) {
    let m = find$1(this);
    m = m.getNth(n);
    return new View(this.document, m.pointer)
  };
};

const api$4 = function (View) {
  View.prototype.organizations = function (n) {
    let m = this.match('#Organization+');
    return m.getNth(n)
  };
};

//combine them with .topics() method
const find = function (n) {
  let r = this.clauses();
  // Find people, places, and organizations
  let m = r.people();
  m = m.concat(r.places());
  m = m.concat(r.organizations());
  m = m.not('(someone|man|woman|mother|brother|sister|father)');
  //return them to normal ordering
  m = m.sort('seq');
  // m = m.unique()
  m = m.getNth(n);
  return m
};

const api$3 = function (View) {
  View.prototype.topics = find;
};

const api$2 = function (View) {
  addMethod$1(View);
  addMethod(View);
  api$4(View);
  api$3(View);
};
var topics = { api: api$2 };

const findVerbs = function (doc) {
  let m = doc.match('<Verb>');
  // want to see
  m = m.not('#Conjunction');
  // by walking
  m = m.not('#Preposition');


  m = m.splitAfter('@hasComma');

  // the reason he will is ...
  // all i do is talk
  m = m.splitAfter('[(do|did|am|was|is|will)] (is|was)', 0);
  // m = m.splitAfter('[(do|did|am|was|is|will)] #PresentTense', 0)

  // cool

  // like being pampered
  m = m.splitBefore('(#Verb && !#Copula) [being] #Verb', 0);
  // like to be pampered
  m = m.splitBefore('#Verb [to be] #Verb', 0);

  // implicit conjugation - 'help fix'

  m = m.splitAfter('[help] #PresentTense', 0);
  // what i can sell is..
  m = m.splitBefore('(#PresentTense|#PastTense) [#Copula]$', 0);
  // what i can sell will be
  m = m.splitBefore('(#PresentTense|#PastTense) [will be]$', 0);
  // directing had
  m = m.splitBefore('(#PresentTense|#PastTense) [(had|has)]', 0);

  // 'allow yourself'
  m = m.not('#Reflexive$');
  // sitting near
  m = m.not('#Adjective');

  // pastTense-pastTense
  // Everyone he [met] [told] him
  m = m.splitAfter('[#PastTense] #PastTense', 0);
  // Everyone he [met] had [told] him
  m = m.splitAfter('[#PastTense] #Auxiliary+ #PastTense', 0);

  // fans that were blowing felt amazing
  m = m.splitAfter('#Copula [#Gerund] #PastTense', 0);

  // managed to see
  // m = m.splitOn('#PastTense [to] #Infinitive', 0)


  //ensure there's actually a verb
  m = m.if('#Verb');
  // the reason he will is ...
  // ensure it's not two verbs
  // held annually is called
  if (m.has('(#Verb && !#Auxiliary) #Adverb+? #Copula')) {
    m = m.splitBefore('#Copula');
  }
  return m
};

// find the main verb, from a verb phrase
const getMain = function (vb) {
  let root = vb;
  if (vb.wordCount() > 1) {
    root = vb.not('(#Negative|#Auxiliary|#Modal|#Adverb|#Prefix)');
  }
  // fallback to just the last word, sometimes
  if (root.length > 1 && !root.has('#Phrasal #Particle')) {
    root = root.last();
  }
  // look for more modals
  root = root.not('(want|wants|wanted) to');

  // fallback
  if (!root.found) {
    root = vb.not('#Negative');
    return root
  }
  return root
};

// split adverbs as before/after the root
const getAdverbs = function (vb, root) {
  let res = {
    pre: vb.none(),
    post: vb.none(),
  };
  if (!vb.has('#Adverb')) {
    return res
  }
  // pivot on the main verb
  let parts = vb.splitOn(root);
  if (parts.length === 3) {
    return {
      pre: parts.eq(0).adverbs(),
      post: parts.eq(2).adverbs(),
    }
  }
  // it must be the second one
  if (parts.eq(0).isDoc(root)) {
    res.post = parts.eq(1).adverbs();
    return res
  }
  res.pre = parts.eq(0).adverbs();
  return res
};

const getAuxiliary = function (vb, root) {
  let parts = vb.splitBefore(root);
  if (parts.length <= 1) {
    return vb.none()
  }
  let aux = parts.eq(0);
  aux = aux.not('(#Adverb|#Negative|#Prefix)');
  return aux
};

const getNegative = function (vb) {
  return vb.match('#Negative')
};

// pull-apart phrasal-verb into verb-particle
const getPhrasal = function (root) {
  if (!root.has('(#Particle|#PhrasalVerb)')) {
    return {
      verb: root.none(),
      particle: root.none()
    }
  }
  let particle = root.match('#Particle$');
  return {
    verb: root.not(particle),
    particle: particle,
  }
};

const parseVerb = function (view) {
  let vb = view.clone();
  vb.contractions().expand();
  const root = getMain(vb);
  let res = {
    root: root,
    prefix: vb.match('#Prefix'),
    adverbs: getAdverbs(vb, root),
    auxiliary: getAuxiliary(vb, root),
    negative: getNegative(vb),
    phrasal: getPhrasal(root),
  };
  return res
};

const present = { tense: 'PresentTense' };
const conditional = { conditional: true };
const future = { tense: 'FutureTense' };
const prog = { progressive: true };
const past = { tense: 'PastTense' };
const complete = { complete: true, progressive: false };
const passive = { passive: true };
const plural = { plural: true };
const singular = { plural: false };

const getData = function (tags) {
  let data = {};
  tags.forEach(o => {
    Object.assign(data, o);
  });
  return data
};

const verbForms = {
  // === Simple ===
  'imperative': [
    // walk!
    ['#Imperative', []],
  ],

  'want-infinitive': [
    ['^(want|wants|wanted) to #Infinitive$', [present]],
    ['^wanted to #Infinitive$', [past]],
    ['^will want to #Infinitive$', [future]],
  ],

  'gerund-phrase': [
    // started looking
    ['^#PastTense #Gerund$', [past]],
    // starts looking
    ['^#PresentTense #Gerund$', [present]],
    // start looking
    ['^#Infinitive #Gerund$', [present]],
    // will start looking
    ['^will #Infinitive #Gerund$', [future]],
    // have started looking
    ['^have #PastTense #Gerund$', [past]],
    // will have started looking
    ['^will have #PastTense #Gerund$', [past]],
  ],

  'simple-present': [
    // he walks',
    ['^#PresentTense$', [present]],
    // we walk
    ['^#Infinitive$', [present]],
  ],
  'simple-past': [
    // he walked',
    ['^#PastTense$', [past]],
  ],
  'simple-future': [
    // he will walk
    ['^will #Adverb? #Infinitive', [future]],
  ],

  // === Progressive ===
  'present-progressive': [
    // he is walking
    ['^(is|are|am) #Gerund$', [present, prog]],
  ],
  'past-progressive': [
    // he was walking
    ['^(was|were) #Gerund$', [past, prog]],
  ],
  'future-progressive': [
    // he will be
    ['^will be #Gerund$', [future, prog]],
  ],

  // === Perfect ===
  'present-perfect': [
    // he has walked
    ['^(has|have) #PastTense$', [past, complete]], //past?
  ],
  'past-perfect': [
    // he had walked
    ['^had #PastTense$', [past, complete]],
    // had been to see
    ['^had #PastTense to #Infinitive', [past, complete]],
  ],
  'future-perfect': [
    // he will have
    ['^will have #PastTense$', [future, complete]],
  ],

  // === Progressive-perfect ===
  'present-perfect-progressive': [
    // he has been walking
    ['^(has|have) been #Gerund$', [past, prog]], //present?
  ],
  'past-perfect-progressive': [
    // he had been
    ['^had been #Gerund$', [past, prog]],
  ],
  'future-perfect-progressive': [
    // will have been
    ['^will have been #Gerund$', [future, prog]],
  ],

  // ==== Passive ===
  'passive-past': [
    // got walked, was walked, were walked
    ['(got|were|was) #Passive', [past, passive]],
    // was being walked
    ['^(was|were) being #Passive', [past, passive]],
    // had been walked, have been eaten
    ['^(had|have) been #Passive', [past, passive]],
  ],
  'passive-present': [
    // is walked, are stolen
    ['^(is|are|am) #Passive', [present, passive]],
    // is being walked
    ['^(is|are|am) being #Passive', [present, passive]],
    // has been cleaned
    ['^has been #Passive', [present, passive]],
  ],
  'passive-future': [
    // will have been walked
    ['will have been #Passive', [future, passive, conditional]],
    // will be cleaned
    ['will be being? #Passive', [future, passive, conditional]],
  ],

  // === Conditional ===
  'present-conditional': [
    // would be walked
    ['would be #PastTense', [present, conditional]],
  ],
  'past-conditional': [
    // would have been walked
    ['would have been #PastTense', [past, conditional]],
  ],

  // ==== Auxiliary ===
  'auxiliary-future': [
    // going to drink
    ['(is|are|am|was) going to (#Infinitive|#PresentTense)', [future]],
  ],
  'auxiliary-past': [
    // he did walk
    ['^did #Infinitive$', [past, singular]],
    // used to walk
    ['^used to #Infinitive$', [past, complete]],
  ],
  'auxiliary-present': [
    // we do walk
    ['^(does|do) #Infinitive$', [present, complete, plural]],
  ],

  // === modals ===
  'modal-past': [
    // he could have walked
    ['^(could|must|should|shall) have #PastTense$', [past]],
  ],
  'modal-infinitive': [
    // he can walk
    ['^#Modal #Infinitive$', []],
  ],

  'infinitive': [
    // walk
    ['^#Infinitive$', []],
  ],
};

let list$1 = [];
Object.keys(verbForms).map(k => {
  verbForms[k].forEach(a => {
    list$1.push({
      name: k,
      match: a[0],
      data: getData(a[1]),
    });
  });
});

const cleanUp = function (vb, res) {
  vb = vb.clone();
  // remove adverbs
  if (res.adverbs.post && res.adverbs.post.found) {
    vb.remove(res.adverbs.post);
  }
  if (res.adverbs.pre && res.adverbs.pre.found) {
    vb.remove(res.adverbs.pre);
  }
  // remove negatives
  if (vb.has('#Negative')) {
    vb = vb.remove('#Negative');
  }
  // remove prefixes like 'anti'
  if (vb.has('#Prefix')) {
    vb = vb.remove('#Prefix');
  }
  // cut-off phrasal-verb
  if (res.root.has('#PhrasalVerb #Particle')) {
    vb.remove('#Particle$');
  }
  // did we miss any of these?
  // vb = vb.remove('#Adverb')
  vb = vb.not('#Adverb');
  return vb
};

// 'learned [to code]'
const isInfinitive = function (vb) {
  if (vb.has('#Infinitive')) {
    let m = vb.growLeft('to');
    if (m.has('^to #Infinitive')) {
      return true
    }
  }
  return false
};

const getGrammar = function (vb, res) {
  let grammar = {};
  // make it easy to classify, first
  vb = cleanUp(vb, res);
  for (let i = 0; i < list$1.length; i += 1) {
    let todo = list$1[i];
    if (vb.has(todo.match) === true) {
      grammar.form = todo.name;
      Object.assign(grammar, todo.data);
      break //only match one
    }
  }
  // did we find nothing?
  if (!grammar.form) {
    if (vb.has('^#Verb$')) {
      grammar.form = 'infinitive';
    }
  }
  // fallback to 'naiive' tense detection
  if (!grammar.tense) {
    grammar.tense = res.root.has('#PastTense') ? 'PastTense' : 'PresentTense';
  }
  grammar.copula = res.root.has('#Copula');
  // 'learn to code'
  grammar.isInfinitive = isInfinitive(vb);
  return grammar
};

const shouldSkip = function (last) {
  // is it our only choice?
  if (last.length <= 1) {
    return false
  }
  let obj = last.parse()[0] || {};
  return obj.isSubordinate
};

// try to chop-out any obvious conditional phrases
// he wore, [if it was raining], a raincoat.
const noSubClause = function (before) {
  let parts = before.clauses();
  parts = parts.filter((m, i) => {
    // if it was raining..
    if (m.has('^(if|unless|while|but|for|per|at|by|that|which|who|from)')) {
      return false
    }
    // bowed to her,
    if (i > 0 && m.has('^#Verb . #Noun+$')) {
      return false
    }
    // the fog, suddenly increasing in..
    if (i > 0 && m.has('^#Adverb')) {
      return false
    }
    return true
  });
  // don't drop the whole thing.
  if (parts.length === 0) {
    return before
  }
  return parts
};

//
const lastNoun = function (vb) {
  let before = vb.before();
  // try to drop any mid-sentence clauses
  before = noSubClause(before);
  // parse-out our preceding nouns
  let nouns = before.nouns();
  // look for any dead-ringers
  let last = nouns.last();
  // i/she/he/they are very strong
  let pronoun = last.match('(i|he|she|we|you|they)');
  if (pronoun.found) {
    return pronoun.nouns()
  }
  // these are also good hints
  let det = nouns.if('^(that|this|those)');
  if (det.found) {
    return det
  }
  if (nouns.found === false) {
    det = before.match('^(that|this|those)');
    if (det.found) {
      return det
    }
  }

  // should we skip a subbordinate clause or two?
  last = nouns.last();
  if (shouldSkip(last)) {
    nouns.remove(last);
    last = nouns.last();
  }
  // i suppose we can skip two?
  if (shouldSkip(last)) {
    nouns.remove(last);
    last = nouns.last();
  }
  return last
};

const isPlural$1 = function (subj, vb) {
  // 'we are' vs 'he is'
  if (vb.has('(are|were|does)')) {
    return true
  }
  if (subj.has('(those|they|we)')) {
    return true
  }
  if (subj.found && subj.isPlural) {
    return subj.isPlural().found
  }
  return false
};

const getSubject = function (vb) {
  let subj = lastNoun(vb);
  return {
    subject: subj,
    plural: isPlural$1(subj, vb),
  }
};

const noop = vb => vb;

const isPlural = (vb, parsed) => {
  let subj = getSubject(vb);
  let m = subj.subject;
  if (m.has('i') || m.has('we')) {
    return true
  }
  return subj.plural
};

const wasWere = (vb, parsed) => {
  let { subject, plural } = getSubject(vb);
  if (plural || subject.has('we')) {
    return 'were'
  }
  return 'was'
};

// present-tense copula
const isAreAm = function (vb, parsed) {
  // 'people were' -> 'people are'
  if (vb.has('were')) {
    return 'are'
  }
  // 'i was' -> i am
  let { subject, plural } = getSubject(vb);
  if (subject.has('i')) {
    return 'am'
  }
  if (subject.has('we') || plural) {
    return 'are'
  }
  // 'he was' -> he is
  return 'is'
};


const doDoes = function (vb, parsed) {
  let subj = getSubject(vb);
  let m = subj.subject;
  if (m.has('i') || m.has('we')) {
    return 'do'
  }
  if (subj.plural) {
    return 'do'
  }
  return 'does'
};

const getTense = function (m) {
  if (m.has('#Infinitive')) {
    return 'Infinitive'
  }
  if (m.has('#Participle')) {
    return 'Participle'
  }
  if (m.has('#PastTense')) {
    return 'PastTense'
  }
  if (m.has('#Gerund')) {
    return 'Gerund'
  }
  if (m.has('#PresentTense')) {
    return 'PresentTense'
  }
  return undefined
};

const toInf$2 = function (vb, parsed) {
  const { toInfinitive } = vb.methods.two.transform.verb;
  let str = parsed.root.text({ keepPunct: false });
  str = toInfinitive(str, vb.model, getTense(vb));
  if (str) {
    vb.replace(parsed.root, str);
  }
  return vb
};



// i will start looking -> i started looking
// i will not start looking -> i did not start looking
const noWill = (vb) => {
  if (vb.has('will not')) {
    return vb.replace('will not', 'have not')
  }
  return vb.remove('will')
};

const toArray = function (m) {
  if (!m || !m.isView) {
    return []
  }
  const opts = { normal: true, terms: false, text: false };
  return m.json(opts).map(s => s.normal)
};

const toText = function (m) {
  if (!m || !m.isView) {
    return ''
  }
  return m.text('normal')
};

const toInf$1 = function (root) {
  const { toInfinitive } = root.methods.two.transform.verb;
  let str = root.text('normal');
  return toInfinitive(str, root.model, getTense(root))
};

const toJSON = function (vb) {
  let parsed = parseVerb(vb);
  vb = vb.clone().toView();
  const info = getGrammar(vb, parsed);
  return {
    root: parsed.root.text(),
    preAdverbs: toArray(parsed.adverbs.pre),
    postAdverbs: toArray(parsed.adverbs.post),
    auxiliary: toText(parsed.auxiliary),
    negative: parsed.negative.found,
    prefix: toText(parsed.prefix),
    infinitive: toInf$1(parsed.root),
    grammar: info,
  }
};

const keep$5 = { tags: true };

// all verb forms are the same
const toInf = function (vb, parsed) {
  const { toInfinitive } = vb.methods.two.transform.verb;
  const { root, auxiliary } = parsed;
  let aux = auxiliary.terms().harden();
  let str = root.text('normal');
  str = toInfinitive(str, vb.model, getTense(root));
  if (str) {
    vb.replace(root, str, keep$5).tag('Verb').firstTerm().tag('Infinitive');
  }
  // remove any auxiliary terms
  if (aux.found) {
    vb.remove(aux);
  }
  // there is no real way to do this
  // 'i not walk'?  'i walk not'?
  if (parsed.negative.found) {
    if (!vb.has('not')) {
      vb.prepend('not');
    }
    let does = doDoes(vb);
    vb.prepend(does);
  }
  vb.fullSentence().compute(['freeze', 'lexicon', 'preTagger', 'postTagger', 'unfreeze', 'chunks']);
  return vb
};

const keep$4 = { tags: true };

const fns = {

  noAux: (vb, parsed) => {
    if (parsed.auxiliary.found) {
      vb = vb.remove(parsed.auxiliary);
    }
    return vb
  },

  // walk->walked
  simple: (vb, parsed) => {
    const { conjugate, toInfinitive } = vb.methods.two.transform.verb;
    const root = parsed.root;
    // 'i may'
    if (root.has('#Modal')) {
      return vb
    }
    let str = root.text({ keepPunct: false });
    str = toInfinitive(str, vb.model, getTense(root));
    let all = conjugate(str, vb.model);
    // 'driven' || 'drove'
    str = all.PastTense;
    // all.Participle || all.PastTense
    // but skip the 'is' participle..
    str = str === 'been' ? 'was' : str;
    if (str === 'was') {
      str = wasWere(vb);
    }
    if (str) {
      vb.replace(root, str, keep$4);
    }
    return vb
  },

  both: function (vb, parsed) {
    // 'he did not walk'
    if (parsed.negative.found) {
      vb.replace('will', 'did');
      return vb
    }
    // 'he walked'
    vb = fns.simple(vb, parsed);
    vb = fns.noAux(vb, parsed);
    return vb
  },

  hasHad: vb => {
    vb.replace('has', 'had', keep$4);
    return vb
  },

  // some verbs have this weird past-tense form
  // drive -> driven, (!drove)
  hasParticiple: (vb, parsed) => {
    const { conjugate, toInfinitive } = vb.methods.two.transform.verb;
    const root = parsed.root;
    let str = root.text('normal');
    str = toInfinitive(str, vb.model, getTense(root));
    return conjugate(str, vb.model).Participle
  },



};


const forms$4 = {
  // walk -> walked
  'infinitive': fns.simple,
  // he walks -> he walked
  'simple-present': fns.simple,
  // he walked
  'simple-past': noop,
  // he will walk -> he walked
  'simple-future': fns.both,

  // he is walking
  'present-progressive': vb => {
    vb.replace('are', 'were', keep$4);
    vb.replace('(is|are|am)', 'was', keep$4);
    return vb
  },
  // he was walking
  'past-progressive': noop,
  // he will be walking
  'future-progressive': (vb, parsed) => {
    vb.match(parsed.root).insertBefore('was');
    vb.remove('(will|be)');
    return vb
  },

  // has walked -> had walked (?)
  'present-perfect': fns.hasHad,
  // had walked
  'past-perfect': noop,
  // will have walked -> had walked
  'future-perfect': (vb, parsed) => {
    vb.match(parsed.root).insertBefore('had');
    if (vb.has('will')) {
      vb = noWill(vb);
    }
    vb.remove('have');
    return vb
  },

  // has been walking -> had been
  'present-perfect-progressive': fns.hasHad,
  // had been walking
  'past-perfect-progressive': noop,
  // will have been -> had
  'future-perfect-progressive': vb => {
    vb.remove('will');
    vb.replace('have', 'had', keep$4);
    return vb
  },

  // got walked
  'passive-past': vb => {
    // 'have been walked' -> 'had been walked'
    vb.replace('have', 'had', keep$4);
    return vb
  },
  // is being walked  -> 'was being walked'
  'passive-present': vb => {
    vb.replace('(is|are)', 'was', keep$4);
    return vb
  },
  // will be walked -> had been walked
  'passive-future': (vb, parsed) => {
    if (parsed.auxiliary.has('will be')) {
      vb.match(parsed.root).insertBefore('had been');
      vb.remove('(will|be)');
    }
    // will have been walked -> had been walked
    if (parsed.auxiliary.has('will have been')) {
      vb.replace('have', 'had', keep$4);
      vb.remove('will');
    }
    return vb
  },

  // would be walked -> 'would have been walked'
  'present-conditional': vb => {
    vb.replace('be', 'have been');
    return vb
  },
  // would have been walked
  'past-conditional': noop,

  // is going to drink -> was going to drink
  'auxiliary-future': vb => {
    vb.replace('(is|are|am)', 'was', keep$4);
    return vb
  },
  // used to walk
  'auxiliary-past': noop,
  // we do walk -> we did walk
  'auxiliary-present': vb => {
    vb.replace('(do|does)', 'did', keep$4);
    return vb
  },

  // must walk -> 'must have walked'
  'modal-infinitive': (vb, parsed) => {
    // this modal has a clear tense
    if (vb.has('can')) {
      // can drive -> could drive
      vb.replace('can', 'could', keep$4);
    } else {
      // otherwise, 
      //  walk -> have walked
      //  drive -> have driven
      fns.simple(vb, parsed);
      vb.match('#Modal').insertAfter('have').tag('Auxiliary');
    }
    return vb
  },
  // must have walked
  'modal-past': noop,
  // wanted to walk
  'want-infinitive': vb => {
    vb.replace('(want|wants)', 'wanted', keep$4);
    vb.remove('will');
    return vb
  },
  // started looking
  'gerund-phrase': (vb, parsed) => {
    parsed.root = parsed.root.not('#Gerund$');
    fns.simple(vb, parsed);
    noWill(vb);
    return vb
  },
};

const toPast$1 = function (vb, parsed, form) {
  // console.log(form)
  if (forms$4.hasOwnProperty(form)) {
    vb = forms$4[form](vb, parsed);
    vb.fullSentence().compute(['tagger', 'chunks']);
    return vb
  }
  // do nothing i guess?
  return vb
};

const haveHas = function (vb, parsed) {
  let subj = getSubject(vb);
  let m = subj.subject;
  if (m.has('(i|we|you)')) {
    return 'have'
  }
  // the dog has
  if (subj.plural === false) {
    return 'has'
  }
  // spencer has
  if (m.has('he') || m.has('she') || m.has('#Person')) {
    return 'has'
  }
  return 'have'
};

// walk-> has walked
const simple$2 = (vb, parsed) => {
  const { conjugate, toInfinitive } = vb.methods.two.transform.verb;
  const { root, auxiliary } = parsed;
  // 'i may'
  if (root.has('#Modal')) {
    return vb
  }
  let str = root.text({ keepPunct: false });
  str = toInfinitive(str, vb.model, getTense(root));
  let all = conjugate(str, vb.model);
  // 'driven' || 'drove'
  str = all.Participle || all.PastTense;

  if (str) {
    vb = vb.replace(root, str);
    // 'have/had/has eaten'
    let have = haveHas(vb);
    vb.prepend(have).match(have).tag('Auxiliary');
    vb.remove(auxiliary);
  }

  return vb
};



const forms$3 = {
  // walk -> walked
  'infinitive': simple$2,
  // he walks -> he walked
  'simple-present': simple$2,
  // he walked
  // 'simple-past': noop,
  // he will walk -> he walked
  'simple-future': (vb, parsed) => vb.replace('will', haveHas(vb)),

  // he is walking
  // 'present-progressive': noop,
  // he was walking
  // 'past-progressive': noop,
  // he will be walking
  // 'future-progressive': noop,

  // has walked -> had walked (?)
  'present-perfect': noop,
  // had walked
  'past-perfect': noop,
  // will have walked -> had walked
  'future-perfect': (vb, parsed) => vb.replace('will have', haveHas(vb)),

  // has been walking -> had been
  'present-perfect-progressive': noop,
  // had been walking
  'past-perfect-progressive': noop,
  // will have been -> had
  'future-perfect-progressive': noop,

  // got walked
  // 'passive-past': noop,
  // is being walked  -> 'was being walked'
  // 'passive-present': noop,
  // will be walked -> had been walked
  // 'passive-future': noop,

  // would be walked -> 'would have been walked'
  // 'present-conditional': noop,
  // would have been walked
  // 'past-conditional': noop,

  // is going to drink -> was going to drink
  // 'auxiliary-future': noop,
  // used to walk
  // 'auxiliary-past': noop,
  // we do walk -> we did walk
  // 'auxiliary-present': noop,

  // must walk -> 'must have walked'
  // 'modal-infinitive': noop,
  // must have walked
  // 'modal-past': noop,
  // wanted to walk
  // 'want-infinitive': noop,
  // started looking
  // 'gerund-phrase': noop,
};

const toPast = function (vb, parsed, form) {
  // console.log(form)
  if (forms$3.hasOwnProperty(form)) {
    vb = forms$3[form](vb, parsed);
    vb.fullSentence().compute(['tagger', 'chunks']);
    return vb
  }
  // do the simple form
  vb = simple$2(vb, parsed);
  vb.fullSentence().compute(['tagger', 'chunks']);
  // do nothing, then
  return vb
};

const keep$3 = { tags: true };

// walk->walked
const simple$1 = (vb, parsed) => {
  const { conjugate, toInfinitive } = vb.methods.two.transform.verb;
  const root = parsed.root;
  let str = root.text('normal');
  str = toInfinitive(str, vb.model, getTense(root));
  // 'i walk' vs 'he walks'
  if (isPlural(vb) === false) {
    str = conjugate(str, vb.model).PresentTense;
  }
  // handle copula
  if (root.has('#Copula')) {
    str = isAreAm(vb);
  }
  if (str) {
    vb = vb.replace(root, str, keep$3);
    vb.not('#Particle').tag('PresentTense');
  }
  // vb.replace('not ' + str, str + ' not')
  return vb
};

const toGerund$1 = (vb, parsed) => {
  const { conjugate, toInfinitive } = vb.methods.two.transform.verb;
  const root = parsed.root;
  let str = root.text('normal');
  str = toInfinitive(str, vb.model, getTense(root));
  // 'i walk' vs 'he walks'
  if (isPlural(vb) === false) {
    str = conjugate(str, vb.model).Gerund;
  }
  if (str) {
    vb = vb.replace(root, str, keep$3);
    vb.not('#Particle').tag('Gerund');
  }
  return vb
};

const vbToInf = (vb, parsed) => {
  const { toInfinitive } = vb.methods.two.transform.verb;
  const root = parsed.root;
  let str = parsed.root.text('normal');
  str = toInfinitive(str, vb.model, getTense(root));
  if (str) {
    vb = vb.replace(parsed.root, str, keep$3);
  }
  return vb
};



const forms$2 = {
  // walk
  'infinitive': simple$1,
  // he walks -> he walked
  'simple-present': (vb, parsed) => {
    const { conjugate } = vb.methods.two.transform.verb;
    let { root } = parsed;
    // is it *only* a infinitive? - 'we buy' etc
    if (root.has('#Infinitive')) {
      let subj = getSubject(vb);
      let m = subj.subject;
      if (isPlural(vb) || m.has('i')) {
        // keep it infinitive
        return vb
      }
      let str = root.text('normal');
      let pres = conjugate(str, vb.model).PresentTense;
      if (str !== pres) {
        vb.replace(root, pres, keep$3);
      }
    } else {
      return simple$1(vb, parsed)
    }
    return vb
  },
  // he walked
  'simple-past': simple$1,
  // he will walk -> he walked
  'simple-future': (vb, parsed) => {
    const { root, auxiliary } = parsed;
    // handle 'will be'
    if (auxiliary.has('will') && root.has('be')) {
      let str = isAreAm(vb);
      vb.replace(root, str);
      vb = vb.remove('will');
      vb.replace('not ' + str, str + ' not');
    } else {
      simple$1(vb, parsed);
      vb = vb.remove('will');
    }
    return vb
  },

  // is walking ->
  'present-progressive': noop,
  // was walking -> is walking
  'past-progressive': (vb, parsed) => {
    let str = isAreAm(vb);
    return vb.replace('(were|was)', str, keep$3)
  },
  // will be walking -> is walking
  'future-progressive': vb => {
    vb.match('will').insertBefore('is');
    vb.remove('be');
    return vb.remove('will')
  },

  // has walked ->  (?)
  'present-perfect': (vb, parsed) => {
    simple$1(vb, parsed);
    vb = vb.remove('(have|had|has)');
    return vb
  },

  // had walked -> has walked
  'past-perfect': (vb, parsed) => {
    // not 'we has walked'
    let subj = getSubject(vb);
    let m = subj.subject;
    if (isPlural(vb) || m.has('i')) {
      vb = toInf$2(vb, parsed);// we walk
      vb.remove('had');
      return vb
    }
    vb.replace('had', 'has', keep$3);
    return vb
  },
  // will have walked -> has walked
  'future-perfect': vb => {
    vb.match('will').insertBefore('has');
    return vb.remove('have').remove('will')
  },

  // has been walking
  'present-perfect-progressive': noop,
  // had been walking
  'past-perfect-progressive': vb => vb.replace('had', 'has', keep$3),
  // will have been -> has been
  'future-perfect-progressive': vb => {
    vb.match('will').insertBefore('has');
    return vb.remove('have').remove('will')
  },

  // got walked -> is walked
  // was walked -> is walked
  // had been walked -> is walked
  'passive-past': (vb, parsed) => {
    let str = isAreAm(vb);
    if (vb.has('(had|have|has)') && vb.has('been')) {
      vb.replace('(had|have|has)', str, keep$3);
      vb.replace('been', 'being');
      return vb
    }
    return vb.replace('(got|was|were)', str)
  },
  // is being walked  ->
  'passive-present': noop,
  // will be walked -> is being walked
  'passive-future': vb => {
    vb.replace('will', 'is');
    return vb.replace('be', 'being')
  },

  // would be walked ->
  'present-conditional': noop,
  // would have been walked ->
  'past-conditional': vb => {
    vb.replace('been', 'be');
    return vb.remove('have')
  },

  // is going to drink -> is drinking
  'auxiliary-future': (vb, parsed) => {
    toGerund$1(vb, parsed);
    vb.remove('(going|to)');
    return vb
  },
  // used to walk -> is walking
  // did walk -> is walking
  'auxiliary-past': (vb, parsed) => {
    // 'did provide' -> 'does provide'
    if (parsed.auxiliary.has('did')) {
      let str = doDoes(vb);
      vb.replace(parsed.auxiliary, str);
      return vb
    }
    toGerund$1(vb, parsed);
    vb.replace(parsed.auxiliary, 'is');
    return vb
  },
  // we do walk ->
  'auxiliary-present': noop,

  // must walk -> 'must have walked'
  'modal-infinitive': noop,
  // must have walked
  'modal-past': (vb, parsed) => {
    vbToInf(vb, parsed);
    return vb.remove('have')
  },
  // started looking
  'gerund-phrase': (vb, parsed) => {
    parsed.root = parsed.root.not('#Gerund$');
    simple$1(vb, parsed);
    return vb.remove('(will|have)')
  },
  // wanted to walk
  'want-infinitive': (vb, parsed) => {
    let str = 'wants';
    if (isPlural(vb)) {
      str = 'want';//we want
    }
    vb.replace('(want|wanted|wants)', str, keep$3);
    vb.remove('will');
    return vb
  },
};

const toPresent = function (vb, parsed, form) {
  // console.log(form)
  if (forms$2.hasOwnProperty(form)) {
    vb = forms$2[form](vb, parsed);
    vb.fullSentence().compute(['tagger', 'chunks']);
    return vb
  }
  return vb
};

const keep$2 = { tags: true };

const simple = (vb, parsed) => {
  const { toInfinitive } = vb.methods.two.transform.verb;
  const { root, auxiliary } = parsed;
  // 'i may'
  if (root.has('#Modal')) {
    return vb
  }
  let str = root.text('normal');
  str = toInfinitive(str, vb.model, getTense(root));
  if (str) {
    vb = vb.replace(root, str, keep$2);
    vb.not('#Particle').tag('Verb');
  }
  vb.prepend('will').match('will').tag('Auxiliary');
  vb.remove(auxiliary);
  return vb
};

// 'will be walking'
const progressive = (vb, parsed) => {
  const { conjugate, toInfinitive } = vb.methods.two.transform.verb;
  const { root, auxiliary } = parsed;
  let str = root.text('normal');
  str = toInfinitive(str, vb.model, getTense(root));
  if (str) {
    str = conjugate(str, vb.model).Gerund;
    vb.replace(root, str, keep$2);
    vb.not('#Particle').tag('PresentTense');
  }
  vb.remove(auxiliary);
  vb.prepend('will be').match('will be').tag('Auxiliary');
  return vb
};

const forms$1 = {
  // walk ->
  'infinitive': simple,
  // he walks ->
  'simple-present': simple,
  // he walked
  'simple-past': simple,
  // he will walk ->
  'simple-future': noop,

  // is walking ->
  'present-progressive': progressive,
  // was walking ->
  'past-progressive': progressive,
  // will be walking ->
  'future-progressive': noop,

  // has walked ->
  'present-perfect': (vb) => {
    vb.match('(have|has)').replaceWith('will have');
    return vb
  },
  // had walked ->
  'past-perfect': vb => vb.replace('(had|has)', 'will have'),
  // will have walked ->
  'future-perfect': noop,

  // has been walking
  'present-perfect-progressive': vb => vb.replace('has', 'will have'),
  // had been walking
  'past-perfect-progressive': vb => vb.replace('had', 'will have'),
  // will have been ->
  'future-perfect-progressive': noop,

  // got walked ->
  // was walked ->
  // was being walked ->
  // had been walked ->
  'passive-past': vb => {
    if (vb.has('got')) {
      return vb.replace('got', 'will get')
    }
    if (vb.has('(was|were)')) {
      vb.replace('(was|were)', 'will be');
      return vb.remove('being')
    }
    if (vb.has('(have|has|had) been')) {
      return vb.replace('(have|has|had) been', 'will be')
    }
    return vb
  },
  // is being walked  ->
  'passive-present': vb => {
    vb.replace('being', 'will be');
    vb.remove('(is|are|am)');
    return vb
  },
  // will be walked ->
  'passive-future': noop,
  // would be walked ->
  'present-conditional': vb => vb.replace('would', 'will'),
  // would have been walked ->
  'past-conditional': vb => vb.replace('would', 'will'),

  // is going to drink ->
  'auxiliary-future': noop,
  // used to walk -> is walking
  // did walk -> is walking
  'auxiliary-past': vb => {
    if (vb.has('used') && vb.has('to')) {
      vb.replace('used', 'will');
      return vb.remove('to')
    }
    vb.replace('did', 'will');
    return vb
  },
  // we do walk ->
  // he does walk ->
  'auxiliary-present': vb => {
    return vb.replace('(do|does)', 'will')
  },

  // must walk ->
  'modal-infinitive': noop,
  // must have walked
  'modal-past': noop,
  // started looking
  'gerund-phrase': (vb, parsed) => {
    parsed.root = parsed.root.not('#Gerund$');
    simple(vb, parsed);
    return vb.remove('(had|have)')
  },
  // wanted to walk
  'want-infinitive': vb => {
    vb.replace('(want|wants|wanted)', 'will want');
    return vb
  },
};

const toFuture = function (vb, parsed, form) {
  // console.log(form)
  // is it already future-tense?
  if (vb.has('will') || vb.has('going to')) {
    return vb
  }
  if (forms$1.hasOwnProperty(form)) {
    vb = forms$1[form](vb, parsed);
    vb.fullSentence().compute(['tagger', 'chunks']);
    return vb
  }
  return vb
};

const keep$1 = { tags: true };

// all verb forms are the same
const toGerund = function (vb, parsed) {
  // console.log(form)
  const { toInfinitive, conjugate } = vb.methods.two.transform.verb;
  const { root, auxiliary } = parsed;
  if (vb.has('#Gerund')) {
    return vb
  }

  // conjugate '-ing' verb
  let str = root.text('normal');
  str = toInfinitive(str, vb.model, getTense(root));
  let gerund = conjugate(str, vb.model).Gerund;
  // 'are walking', 'is walking'
  if (gerund) {
    let aux = isAreAm(vb);
    vb.replace(root, gerund, keep$1);
    vb.remove(auxiliary);
    vb.prepend(aux);//.match(aux)
  }
  // remove any existing auxiliary
  // if (auxiliary.found) {
  // vb.match(auxiliary).debug()
  // vb.remove(auxiliary)
  // }

  vb.replace('not is', 'is not');
  vb.replace('not are', 'are not');
  vb.fullSentence().compute(['tagger', 'chunks']);
  return vb
};

const keep = { tags: true };

// do/does not walk 
const doesNot = function (vb, parsed) {
  let does = doDoes(vb);
  vb.prepend(does + ' not');
  return vb
};

const isWas = function (vb) {
  // not be
  let m = vb.match('be');
  if (m.found) {
    m.prepend('not');
    return vb
  }
  // will not
  m = vb.match('(is|was|am|are|will|were)');
  if (m.found) {
    m.append('not');
    return vb
  }
  return vb
};

const hasCopula = (vb) => vb.has('(is|was|am|are|will|were|be)');

//vaguely, turn 'he is cool' into 'he is not cool'
const forms = {


  // he walks' -> 'he does not walk'
  'simple-present': (vb, parsed) => {
    // is/was
    if (hasCopula(vb) === true) {
      return isWas(vb)
    }
    // he walk
    vb = toInf$2(vb, parsed);
    // does not 
    vb = doesNot(vb);
    return vb
  },
  // 'he walked' -> 'he did not walk'
  'simple-past': (vb, parsed) => {
    // is/was
    if (hasCopula(vb) === true) {
      return isWas(vb)
    }
    // he walk
    vb = toInf$2(vb, parsed);
    // vb.debug()
    // did not walk
    vb.prepend('did not');
    return vb
  },

  // walk! -> 'do not walk'
  'imperative': (vb) => {
    vb.prepend('do not');
    return vb
  },
  // walk -> does not walk
  'infinitive': (vb, parsed) => {
    if (hasCopula(vb) === true) {
      return isWas(vb)
    }
    return doesNot(vb)
  },

  'passive-past': (vb) => {
    // got walked -> did not get walked
    if (vb.has('got')) {
      vb.replace('got', 'get', keep);
      vb.prepend('did not');
      return vb
    }
    // was walked, were walked
    // was being walked
    // had been walked, have been eaten
    let m = vb.match('(was|were|had|have)');
    if (m.found) {
      m.append('not');
    }
    return vb
  },
  'auxiliary-past': (vb) => {
    // used to walk
    if (vb.has('used')) {
      vb.prepend('did not');
      return vb
    }
    // he did walk
    let m = vb.match('(did|does|do)');
    if (m.found) {
      m.append('not');
    }
    return vb
  },

  // wants to walk
  'want-infinitive': (vb, parsed) => {
    // does not 
    vb = doesNot(vb);
    // want
    vb = vb.replace('wants', 'want', keep);
    return vb
  },

};

const toNegative = function (vb, parsed, form) {
  // console.log(form)
  if (vb.has('#Negative')) {
    return vb
  }
  if (forms.hasOwnProperty(form)) {
    vb = forms[form](vb, parsed);
    return vb
  }

  // 'not be'
  let m = vb.matchOne('be');
  if (m.found) {
    m.prepend('not');
    return vb
  }
  // is/was not
  if (hasCopula(vb) === true) {
    return isWas(vb)
  }

  // 'would not'
  m = vb.matchOne('(will|had|have|has|did|does|do|#Modal)');
  if (m.found) {
    m.append('not');
    return vb
  }
  // do nothing i guess?
  return vb
};

const api$1 = function (View) {
  class Verbs extends View {
    constructor(document, pointer, groups) {
      super(document, pointer, groups);
      this.viewType = 'Verbs';
    }
    parse(n) {
      return this.getNth(n).map(parseVerb)
    }
    json(opts, n) {
      let m = this.getNth(n);
      let arr = m.map(vb => {
        let json = vb.toView().json(opts)[0] || {};
        json.verb = toJSON(vb);
        return json
      }, []);
      return arr
    }
    subjects(n) {
      return this.getNth(n).map(vb => {
        parseVerb(vb);
        return getSubject(vb).subject
      })
    }
    adverbs(n) {
      return this.getNth(n).map(vb => vb.match('#Adverb'))
    }
    isSingular(n) {
      return this.getNth(n).filter(vb => {
        return getSubject(vb).plural !== true
      })
    }
    isPlural(n) {
      return this.getNth(n).filter(vb => {
        return getSubject(vb).plural === true
      })
    }
    isImperative(n) {
      return this.getNth(n).filter(vb => vb.has('#Imperative'))
    }
    toInfinitive(n) {
      return this.getNth(n).map(vb => {
        let parsed = parseVerb(vb);
        let info = getGrammar(vb, parsed);
        return toInf(vb, parsed, info.form)
      })
    }
    toPresentTense(n) {
      return this.getNth(n).map(vb => {
        let parsed = parseVerb(vb);
        let info = getGrammar(vb, parsed);
        if (info.isInfinitive) {
          return vb
        }
        return toPresent(vb, parsed, info.form)
      })
    }
    toPastTense(n) {
      return this.getNth(n).map(vb => {
        let parsed = parseVerb(vb);
        let info = getGrammar(vb, parsed);
        if (info.isInfinitive) {
          return vb
        }
        return toPast$1(vb, parsed, info.form)
      })
    }
    toFutureTense(n) {
      return this.getNth(n).map(vb => {
        let parsed = parseVerb(vb);
        let info = getGrammar(vb, parsed);
        if (info.isInfinitive) {
          return vb
        }
        return toFuture(vb, parsed, info.form)
      })
    }
    toGerund(n) {
      return this.getNth(n).map(vb => {
        let parsed = parseVerb(vb);
        let info = getGrammar(vb, parsed);
        if (info.isInfinitive) {
          return vb
        }
        return toGerund(vb, parsed, info.form)
      })
    }
    toPastParticiple(n) {
      return this.getNth(n).map(vb => {
        let parsed = parseVerb(vb);
        let info = getGrammar(vb, parsed);
        if (info.isInfinitive) {
          return vb
        }
        return toPast(vb, parsed, info.form)
      })
    }
    conjugate(n) {
      const { conjugate, toInfinitive } = this.world.methods.two.transform.verb;
      return this.getNth(n).map(vb => {
        let parsed = parseVerb(vb);
        let info = getGrammar(vb, parsed);
        // allow imperatives like 'go!' to be conjugated here (only)
        if (info.form === 'imperative') {
          info.form = 'simple-present';
        }
        let inf = parsed.root.text('normal');
        if (!parsed.root.has('#Infinitive')) {
          let tense = getTense(parsed.root);
          inf = toInfinitive(inf, vb.model, tense) || inf;
        }
        return conjugate(inf, vb.model)
      }, [])
    }

    /** return only verbs with 'not'*/
    isNegative() {
      return this.if('#Negative')
    }
    /**  return only verbs without 'not'*/
    isPositive() {
      return this.ifNo('#Negative')
    }
    /** remove 'not' from these verbs */
    toPositive() {
      let m = this.match('do not #Verb');
      if (m.found) {
        m.remove('do not');
      }
      return this.remove('#Negative')
    }
    toNegative(n) {
      return this.getNth(n).map(vb => {
        let parsed = parseVerb(vb);
        let info = getGrammar(vb, parsed);
        return toNegative(vb, parsed, info.form)
      })
    }
    // overloaded - keep Verb class
    update(pointer) {
      let m = new Verbs(this.document, pointer);
      m._cache = this._cache; // share this full thing
      return m
    }
  }
  Verbs.prototype.toPast = Verbs.prototype.toPastTense;
  Verbs.prototype.toPresent = Verbs.prototype.toPresentTense;
  Verbs.prototype.toFuture = Verbs.prototype.toFutureTense;

  View.prototype.verbs = function (n) {
    let vb = findVerbs(this);
    vb = vb.getNth(n);
    return new Verbs(this.document, vb.pointer)
  };
};

var verbs = {
  api: api$1,
};

// borrow a reference from another pronoun
// 'mike is tall, [he] climbs and [he] swims'
const findChained = function (want, s) {
  let m = s.match(want);
  if (m.found) {
    let ref = m.pronouns().refersTo();
    if (ref.found) {
      return ref
    }
  }
  return s.none()
};

const prevSentence = function (m) {
  if (!m.found) {
    return m
  }
  let [n] = m.fullPointer[0];
  if (n && n > 0) {
    return m.update([[n - 1]])
  }
  return m.none()
};

// only filter if we know a gender
// ambiguous names like 'jamie smith' will refer to either he or she
const byGender = function (ppl, gender) {
  if (gender === 'm') {
    return ppl.filter(m => !m.presumedFemale().found)
  } else if (gender === 'f') {
    return ppl.filter(m => !m.presumedMale().found)
  }
  return ppl
};


const getPerson = function (s, gender) {
  // look at current sentence
  let people = s.people();
  people = byGender(people, gender);
  if (people.found) {
    return people.last()
  }
  // non-named people, like 'the cowboy'
  people = s.nouns('#Actor');
  if (people.found) {
    return people.last()
  }
  // existing pronouns
  if (gender === 'f') {
    return findChained('(she|her|hers)', s)
  }
  if (gender === 'm') {
    return findChained('(he|him|his)', s)
  }
  return s.none()
};

// find best reference for 'they' & 'their'
const getThey = function (s) {
  let nouns = s.nouns();

  // 'the bananas'
  let things = nouns.isPlural().notIf('#Pronoun');
  if (things.found) {
    return things.last()
  }
  // re-use existing pronoun reference
  let chain = findChained('(they|their|theirs)', s);
  if (chain.found) {
    return chain
  }

  // they can also refer to a singular noun
  // "the restaurant sold their food"
  // "a choir sang their song"

  // somebody shaved their head
  things = nouns.match('(somebody|nobody|everybody|anybody|someone|noone|everyone|anyone)');
  if (things.found) {
    return things.last()
  }
  return s.none()
};

const addReference = function (pron, m) {
  if (m && m.found) {
    // add reference on the pronoun
    let term = pron.docs[0][0];//pronouns are 1 word only
    term.reference = m.ptrs[0];
  }
};

const stepBack = function (m, cb) {
  // 1st - in same sentence
  let s = m.before();
  let res = cb(s);
  if (res.found) {
    return res
  }
  // 2nd - previous sentence
  s = prevSentence(m);
  res = cb(s);
  if (res.found) {
    return res
  }
  // 3rd - two sentences back
  s = prevSentence(s);
  res = cb(s);
  if (res.found) {
    return res
  }
  return m.none()
};

const coreference$1 = function (view) {
  let pronouns = view.pronouns().if('(he|him|his|she|her|hers|they|their|theirs|it|its)');
  pronouns.forEach(pron => {
    let res = null;
    // connect pronoun to its reference
    if (pron.has('(he|him|his)')) {
      res = stepBack(pron, (m) => getPerson(m, 'm'));
    } else if (pron.has('(she|her|hers)')) {
      res = stepBack(pron, (m) => getPerson(m, 'f'));
    } else if (pron.has('(they|their|theirs)')) {
      res = stepBack(pron, getThey);
    }
    if (res && res.found) {
      addReference(pron, res);
    }
  });
};

const api = function (View) {

  class Pronouns extends View {
    constructor(document, pointer, groups) {
      super(document, pointer, groups);
      this.viewType = 'Pronouns';
    }
    hasReference() {
      this.compute('coreference');
      return this.filter(m => {
        let term = m.docs[0][0];
        return term.reference
      })
    }
    // get the noun-phrase this pronoun refers to
    refersTo() {
      //calculate links
      this.compute('coreference');
      // return them
      return this.map(m => {
        if (!m.found) {
          return m.none()
        }
        let term = m.docs[0][0];
        if (term.reference) {
          return m.update([term.reference])
        }
        return m.none()
      })
    }
    // overloaded - keep Numbers class
    update(pointer) {
      let m = new Pronouns(this.document, pointer);
      m._cache = this._cache; // share this full thing
      return m
    }
  }

  View.prototype.pronouns = function (n) {
    let m = this.match('#Pronoun');
    m = m.getNth(n);
    return new Pronouns(m.document, m.pointer)
  };
};

var coreference = {
  compute: { coreference: coreference$1 },
  api
};

nlp.plugin(adjectives); //
nlp.plugin(adverbs); //
nlp.plugin(chunker); //
nlp.plugin(coreference);
nlp.plugin(misc); //
nlp.plugin(normalize$1); //
nlp.plugin(nouns); //
nlp.plugin(numbers); //
nlp.plugin(plugin); //
nlp.plugin(sentences); //
nlp.plugin(topics); //
nlp.plugin(verbs); //

// convenience function to filter out duplicates in an array
const unique = (value, index, self) => self.indexOf(value) === index;
const strip = (text) => text.trim().replace(/\s/g, "-").replace(/[._]/g, "");
const symbols = "|;\\/:*\\p{Ps}\\p{Pe}\\p{S}";
const matchDashSymbols = /\p{Pd}/gu;
const matchIgnoreSymbols = /"/g;
const matchCleanUpSymbols = /\s\u064D/g;
const matchAlternativeSentanceEnd = /\|+/g;
const matchMultipleSpaces = /\s+/g;
const matchMultipleCommas = /,+/g;
const matchMultipleFullstops = /\.+/g;
// eslint-disable-next-line sonarjs/slow-regex
const matchSpacesBeforePunctuation = /(\s+)(?=[,.])/g;
const matchLeadingSymbols = new RegExp(`^[${symbols}\\p{Zs}]+`, "gu");
const matchTrailingSymbols = new RegExp(`[${symbols}\\p{Zs}]+$`, "gu");
const matchSymbols = new RegExp(`[${symbols}]`, "gu");
const matchApostropheNotContraction = /'(?!t|s|ve)/g;
const matchMarkdownUri = /(?<=])\(.*\)/g;
const matchCodeBlock = /`[^`]+`/g;
const preStrip = (text) => text
    .trim()
    .replace(matchMarkdownUri, "")
    .replace(matchCodeBlock, "")
    .replace(matchCleanUpSymbols, "")
    .replace(matchIgnoreSymbols, "")
    .replace(matchApostropheNotContraction, "")
    .replace(matchDashSymbols, " ")
    .replace(matchLeadingSymbols, "")
    .replace(matchAlternativeSentanceEnd, ". ")
    .replace(matchTrailingSymbols, ".")
    .replace(matchSymbols, ", ")
    .replace(matchSpacesBeforePunctuation, "")
    .replace(matchMultipleCommas, ",")
    .replace(matchMultipleFullstops, ".")
    .replace(matchMultipleSpaces, " ");
const postStrip = /,|'s/g;
const allowedLinks = (name) => name.length > 1;
function naturalProcess(content, excludes = []) {
    const document = nlp(preStrip(content));
    const enhancedExcludes = [...excludes, "", ",", "s", "ing"];
    const links = document.not("#Pronoun")
        .nouns()
        .toLowerCase()
        .json()
        .map((term) => {
        const rawRoot = strip(term.noun.root);
        const root = rawRoot.replace(postStrip, "");
        if (term.noun.adjectives.length === 0) {
            return root;
        }
        return [
            root,
            ...term.noun.adjectives.map((adjective) => strip(adjective)),
            ...term.noun.adjectives.map((adjective) => [strip(adjective), root].join("-")),
        ];
    })
        .flat()
        .filter(allowedLinks)
        .filter((name) => !enhancedExcludes.includes(name))
        .filter(unique)
        .map((name) => name);
    return { links };
}

/**
 * @typedef {import('mdast').Nodes} Nodes
 *
 * @typedef Options
 *   Configuration (optional).
 * @property {boolean | null | undefined} [includeImageAlt=true]
 *   Whether to use `alt` for `image`s (default: `true`).
 * @property {boolean | null | undefined} [includeHtml=true]
 *   Whether to use `value` of HTML (default: `true`).
 */

/** @type {Options} */
const emptyOptions = {};

/**
 * Get the text content of a node or list of nodes.
 *
 * Prefers the nodeâ€™s plain-text fields, otherwise serializes its children,
 * and if the given value is an array, serialize the nodes in it.
 *
 * @param {unknown} [value]
 *   Thing to serialize, typically `Node`.
 * @param {Options | null | undefined} [options]
 *   Configuration (optional).
 * @returns {string}
 *   Serialized `value`.
 */
function toString(value, options) {
  const settings = emptyOptions;
  const includeImageAlt =
    typeof settings.includeImageAlt === 'boolean'
      ? settings.includeImageAlt
      : true;
  const includeHtml =
    typeof settings.includeHtml === 'boolean' ? settings.includeHtml : true;

  return one(value, includeImageAlt, includeHtml)
}

/**
 * One node or several nodes.
 *
 * @param {unknown} value
 *   Thing to serialize.
 * @param {boolean} includeImageAlt
 *   Include image `alt`s.
 * @param {boolean} includeHtml
 *   Include HTML.
 * @returns {string}
 *   Serialized node.
 */
function one(value, includeImageAlt, includeHtml) {
  if (node(value)) {
    if ('value' in value) {
      return value.type === 'html' && !includeHtml ? '' : value.value
    }

    if (includeImageAlt && 'alt' in value && value.alt) {
      return value.alt
    }

    if ('children' in value) {
      return all(value.children, includeImageAlt, includeHtml)
    }
  }

  if (Array.isArray(value)) {
    return all(value, includeImageAlt, includeHtml)
  }

  return ''
}

/**
 * Serialize a list of nodes.
 *
 * @param {Array<unknown>} values
 *   Thing to serialize.
 * @param {boolean} includeImageAlt
 *   Include image `alt`s.
 * @param {boolean} includeHtml
 *   Include HTML.
 * @returns {string}
 *   Serialized nodes.
 */
function all(values, includeImageAlt, includeHtml) {
  /** @type {Array<string>} */
  const result = [];
  let index = -1;

  while (++index < values.length) {
    result[index] = one(values[index], includeImageAlt, includeHtml);
  }

  return result.join('')
}

/**
 * Check if `value` looks like a node.
 *
 * @param {unknown} value
 *   Thing.
 * @returns {value is Nodes}
 *   Whether `value` is a node.
 */
function node(value) {
  return Boolean(value && typeof value === 'object')
}

/**
 * Map of named character references.
 *
 * @type {Record<string, string>}
 */
const characterEntities = {
  AElig: 'Ã†',
  AMP: '&',
  Aacute: 'Ã',
  Abreve: 'Ä‚',
  Acirc: 'Ã‚',
  Acy: 'Ð',
  Afr: 'ð”„',
  Agrave: 'Ã€',
  Alpha: 'Î‘',
  Amacr: 'Ä€',
  And: 'â©“',
  Aogon: 'Ä„',
  Aopf: 'ð”¸',
  ApplyFunction: 'â¡',
  Aring: 'Ã…',
  Ascr: 'ð’œ',
  Assign: 'â‰”',
  Atilde: 'Ãƒ',
  Auml: 'Ã„',
  Backslash: 'âˆ–',
  Barv: 'â«§',
  Barwed: 'âŒ†',
  Bcy: 'Ð‘',
  Because: 'âˆµ',
  Bernoullis: 'â„¬',
  Beta: 'Î’',
  Bfr: 'ð”…',
  Bopf: 'ð”¹',
  Breve: 'Ë˜',
  Bscr: 'â„¬',
  Bumpeq: 'â‰Ž',
  CHcy: 'Ð§',
  COPY: 'Â©',
  Cacute: 'Ä†',
  Cap: 'â‹’',
  CapitalDifferentialD: 'â……',
  Cayleys: 'â„­',
  Ccaron: 'ÄŒ',
  Ccedil: 'Ã‡',
  Ccirc: 'Äˆ',
  Cconint: 'âˆ°',
  Cdot: 'ÄŠ',
  Cedilla: 'Â¸',
  CenterDot: 'Â·',
  Cfr: 'â„­',
  Chi: 'Î§',
  CircleDot: 'âŠ™',
  CircleMinus: 'âŠ–',
  CirclePlus: 'âŠ•',
  CircleTimes: 'âŠ—',
  ClockwiseContourIntegral: 'âˆ²',
  CloseCurlyDoubleQuote: 'â€',
  CloseCurlyQuote: 'â€™',
  Colon: 'âˆ·',
  Colone: 'â©´',
  Congruent: 'â‰¡',
  Conint: 'âˆ¯',
  ContourIntegral: 'âˆ®',
  Copf: 'â„‚',
  Coproduct: 'âˆ',
  CounterClockwiseContourIntegral: 'âˆ³',
  Cross: 'â¨¯',
  Cscr: 'ð’ž',
  Cup: 'â‹“',
  CupCap: 'â‰',
  DD: 'â……',
  DDotrahd: 'â¤‘',
  DJcy: 'Ð‚',
  DScy: 'Ð…',
  DZcy: 'Ð',
  Dagger: 'â€¡',
  Darr: 'â†¡',
  Dashv: 'â«¤',
  Dcaron: 'ÄŽ',
  Dcy: 'Ð”',
  Del: 'âˆ‡',
  Delta: 'Î”',
  Dfr: 'ð”‡',
  DiacriticalAcute: 'Â´',
  DiacriticalDot: 'Ë™',
  DiacriticalDoubleAcute: 'Ë',
  DiacriticalGrave: '`',
  DiacriticalTilde: 'Ëœ',
  Diamond: 'â‹„',
  DifferentialD: 'â…†',
  Dopf: 'ð”»',
  Dot: 'Â¨',
  DotDot: 'âƒœ',
  DotEqual: 'â‰',
  DoubleContourIntegral: 'âˆ¯',
  DoubleDot: 'Â¨',
  DoubleDownArrow: 'â‡“',
  DoubleLeftArrow: 'â‡',
  DoubleLeftRightArrow: 'â‡”',
  DoubleLeftTee: 'â«¤',
  DoubleLongLeftArrow: 'âŸ¸',
  DoubleLongLeftRightArrow: 'âŸº',
  DoubleLongRightArrow: 'âŸ¹',
  DoubleRightArrow: 'â‡’',
  DoubleRightTee: 'âŠ¨',
  DoubleUpArrow: 'â‡‘',
  DoubleUpDownArrow: 'â‡•',
  DoubleVerticalBar: 'âˆ¥',
  DownArrow: 'â†“',
  DownArrowBar: 'â¤“',
  DownArrowUpArrow: 'â‡µ',
  DownBreve: 'Ì‘',
  DownLeftRightVector: 'â¥',
  DownLeftTeeVector: 'â¥ž',
  DownLeftVector: 'â†½',
  DownLeftVectorBar: 'â¥–',
  DownRightTeeVector: 'â¥Ÿ',
  DownRightVector: 'â‡',
  DownRightVectorBar: 'â¥—',
  DownTee: 'âŠ¤',
  DownTeeArrow: 'â†§',
  Downarrow: 'â‡“',
  Dscr: 'ð’Ÿ',
  Dstrok: 'Ä',
  ENG: 'ÅŠ',
  ETH: 'Ã',
  Eacute: 'Ã‰',
  Ecaron: 'Äš',
  Ecirc: 'ÃŠ',
  Ecy: 'Ð­',
  Edot: 'Ä–',
  Efr: 'ð”ˆ',
  Egrave: 'Ãˆ',
  Element: 'âˆˆ',
  Emacr: 'Ä’',
  EmptySmallSquare: 'â—»',
  EmptyVerySmallSquare: 'â–«',
  Eogon: 'Ä˜',
  Eopf: 'ð”¼',
  Epsilon: 'Î•',
  Equal: 'â©µ',
  EqualTilde: 'â‰‚',
  Equilibrium: 'â‡Œ',
  Escr: 'â„°',
  Esim: 'â©³',
  Eta: 'Î—',
  Euml: 'Ã‹',
  Exists: 'âˆƒ',
  ExponentialE: 'â…‡',
  Fcy: 'Ð¤',
  Ffr: 'ð”‰',
  FilledSmallSquare: 'â—¼',
  FilledVerySmallSquare: 'â–ª',
  Fopf: 'ð”½',
  ForAll: 'âˆ€',
  Fouriertrf: 'â„±',
  Fscr: 'â„±',
  GJcy: 'Ðƒ',
  GT: '>',
  Gamma: 'Î“',
  Gammad: 'Ïœ',
  Gbreve: 'Äž',
  Gcedil: 'Ä¢',
  Gcirc: 'Äœ',
  Gcy: 'Ð“',
  Gdot: 'Ä ',
  Gfr: 'ð”Š',
  Gg: 'â‹™',
  Gopf: 'ð”¾',
  GreaterEqual: 'â‰¥',
  GreaterEqualLess: 'â‹›',
  GreaterFullEqual: 'â‰§',
  GreaterGreater: 'âª¢',
  GreaterLess: 'â‰·',
  GreaterSlantEqual: 'â©¾',
  GreaterTilde: 'â‰³',
  Gscr: 'ð’¢',
  Gt: 'â‰«',
  HARDcy: 'Ðª',
  Hacek: 'Ë‡',
  Hat: '^',
  Hcirc: 'Ä¤',
  Hfr: 'â„Œ',
  HilbertSpace: 'â„‹',
  Hopf: 'â„',
  HorizontalLine: 'â”€',
  Hscr: 'â„‹',
  Hstrok: 'Ä¦',
  HumpDownHump: 'â‰Ž',
  HumpEqual: 'â‰',
  IEcy: 'Ð•',
  IJlig: 'Ä²',
  IOcy: 'Ð',
  Iacute: 'Ã',
  Icirc: 'ÃŽ',
  Icy: 'Ð˜',
  Idot: 'Ä°',
  Ifr: 'â„‘',
  Igrave: 'ÃŒ',
  Im: 'â„‘',
  Imacr: 'Äª',
  ImaginaryI: 'â…ˆ',
  Implies: 'â‡’',
  Int: 'âˆ¬',
  Integral: 'âˆ«',
  Intersection: 'â‹‚',
  InvisibleComma: 'â£',
  InvisibleTimes: 'â¢',
  Iogon: 'Ä®',
  Iopf: 'ð•€',
  Iota: 'Î™',
  Iscr: 'â„',
  Itilde: 'Ä¨',
  Iukcy: 'Ð†',
  Iuml: 'Ã',
  Jcirc: 'Ä´',
  Jcy: 'Ð™',
  Jfr: 'ð”',
  Jopf: 'ð•',
  Jscr: 'ð’¥',
  Jsercy: 'Ðˆ',
  Jukcy: 'Ð„',
  KHcy: 'Ð¥',
  KJcy: 'ÐŒ',
  Kappa: 'Îš',
  Kcedil: 'Ä¶',
  Kcy: 'Ðš',
  Kfr: 'ð”Ž',
  Kopf: 'ð•‚',
  Kscr: 'ð’¦',
  LJcy: 'Ð‰',
  LT: '<',
  Lacute: 'Ä¹',
  Lambda: 'Î›',
  Lang: 'âŸª',
  Laplacetrf: 'â„’',
  Larr: 'â†ž',
  Lcaron: 'Ä½',
  Lcedil: 'Ä»',
  Lcy: 'Ð›',
  LeftAngleBracket: 'âŸ¨',
  LeftArrow: 'â†',
  LeftArrowBar: 'â‡¤',
  LeftArrowRightArrow: 'â‡†',
  LeftCeiling: 'âŒˆ',
  LeftDoubleBracket: 'âŸ¦',
  LeftDownTeeVector: 'â¥¡',
  LeftDownVector: 'â‡ƒ',
  LeftDownVectorBar: 'â¥™',
  LeftFloor: 'âŒŠ',
  LeftRightArrow: 'â†”',
  LeftRightVector: 'â¥Ž',
  LeftTee: 'âŠ£',
  LeftTeeArrow: 'â†¤',
  LeftTeeVector: 'â¥š',
  LeftTriangle: 'âŠ²',
  LeftTriangleBar: 'â§',
  LeftTriangleEqual: 'âŠ´',
  LeftUpDownVector: 'â¥‘',
  LeftUpTeeVector: 'â¥ ',
  LeftUpVector: 'â†¿',
  LeftUpVectorBar: 'â¥˜',
  LeftVector: 'â†¼',
  LeftVectorBar: 'â¥’',
  Leftarrow: 'â‡',
  Leftrightarrow: 'â‡”',
  LessEqualGreater: 'â‹š',
  LessFullEqual: 'â‰¦',
  LessGreater: 'â‰¶',
  LessLess: 'âª¡',
  LessSlantEqual: 'â©½',
  LessTilde: 'â‰²',
  Lfr: 'ð”',
  Ll: 'â‹˜',
  Lleftarrow: 'â‡š',
  Lmidot: 'Ä¿',
  LongLeftArrow: 'âŸµ',
  LongLeftRightArrow: 'âŸ·',
  LongRightArrow: 'âŸ¶',
  Longleftarrow: 'âŸ¸',
  Longleftrightarrow: 'âŸº',
  Longrightarrow: 'âŸ¹',
  Lopf: 'ð•ƒ',
  LowerLeftArrow: 'â†™',
  LowerRightArrow: 'â†˜',
  Lscr: 'â„’',
  Lsh: 'â†°',
  Lstrok: 'Å',
  Lt: 'â‰ª',
  Map: 'â¤…',
  Mcy: 'Ðœ',
  MediumSpace: 'âŸ',
  Mellintrf: 'â„³',
  Mfr: 'ð”',
  MinusPlus: 'âˆ“',
  Mopf: 'ð•„',
  Mscr: 'â„³',
  Mu: 'Îœ',
  NJcy: 'ÐŠ',
  Nacute: 'Åƒ',
  Ncaron: 'Å‡',
  Ncedil: 'Å…',
  Ncy: 'Ð',
  NegativeMediumSpace: 'â€‹',
  NegativeThickSpace: 'â€‹',
  NegativeThinSpace: 'â€‹',
  NegativeVeryThinSpace: 'â€‹',
  NestedGreaterGreater: 'â‰«',
  NestedLessLess: 'â‰ª',
  NewLine: '\n',
  Nfr: 'ð”‘',
  NoBreak: 'â ',
  NonBreakingSpace: 'Â ',
  Nopf: 'â„•',
  Not: 'â«¬',
  NotCongruent: 'â‰¢',
  NotCupCap: 'â‰­',
  NotDoubleVerticalBar: 'âˆ¦',
  NotElement: 'âˆ‰',
  NotEqual: 'â‰ ',
  NotEqualTilde: 'â‰‚Ì¸',
  NotExists: 'âˆ„',
  NotGreater: 'â‰¯',
  NotGreaterEqual: 'â‰±',
  NotGreaterFullEqual: 'â‰§Ì¸',
  NotGreaterGreater: 'â‰«Ì¸',
  NotGreaterLess: 'â‰¹',
  NotGreaterSlantEqual: 'â©¾Ì¸',
  NotGreaterTilde: 'â‰µ',
  NotHumpDownHump: 'â‰ŽÌ¸',
  NotHumpEqual: 'â‰Ì¸',
  NotLeftTriangle: 'â‹ª',
  NotLeftTriangleBar: 'â§Ì¸',
  NotLeftTriangleEqual: 'â‹¬',
  NotLess: 'â‰®',
  NotLessEqual: 'â‰°',
  NotLessGreater: 'â‰¸',
  NotLessLess: 'â‰ªÌ¸',
  NotLessSlantEqual: 'â©½Ì¸',
  NotLessTilde: 'â‰´',
  NotNestedGreaterGreater: 'âª¢Ì¸',
  NotNestedLessLess: 'âª¡Ì¸',
  NotPrecedes: 'âŠ€',
  NotPrecedesEqual: 'âª¯Ì¸',
  NotPrecedesSlantEqual: 'â‹ ',
  NotReverseElement: 'âˆŒ',
  NotRightTriangle: 'â‹«',
  NotRightTriangleBar: 'â§Ì¸',
  NotRightTriangleEqual: 'â‹­',
  NotSquareSubset: 'âŠÌ¸',
  NotSquareSubsetEqual: 'â‹¢',
  NotSquareSuperset: 'âŠÌ¸',
  NotSquareSupersetEqual: 'â‹£',
  NotSubset: 'âŠ‚âƒ’',
  NotSubsetEqual: 'âŠˆ',
  NotSucceeds: 'âŠ',
  NotSucceedsEqual: 'âª°Ì¸',
  NotSucceedsSlantEqual: 'â‹¡',
  NotSucceedsTilde: 'â‰¿Ì¸',
  NotSuperset: 'âŠƒâƒ’',
  NotSupersetEqual: 'âŠ‰',
  NotTilde: 'â‰',
  NotTildeEqual: 'â‰„',
  NotTildeFullEqual: 'â‰‡',
  NotTildeTilde: 'â‰‰',
  NotVerticalBar: 'âˆ¤',
  Nscr: 'ð’©',
  Ntilde: 'Ã‘',
  Nu: 'Î',
  OElig: 'Å’',
  Oacute: 'Ã“',
  Ocirc: 'Ã”',
  Ocy: 'Ðž',
  Odblac: 'Å',
  Ofr: 'ð”’',
  Ograve: 'Ã’',
  Omacr: 'ÅŒ',
  Omega: 'Î©',
  Omicron: 'ÎŸ',
  Oopf: 'ð•†',
  OpenCurlyDoubleQuote: 'â€œ',
  OpenCurlyQuote: 'â€˜',
  Or: 'â©”',
  Oscr: 'ð’ª',
  Oslash: 'Ã˜',
  Otilde: 'Ã•',
  Otimes: 'â¨·',
  Ouml: 'Ã–',
  OverBar: 'â€¾',
  OverBrace: 'âž',
  OverBracket: 'âŽ´',
  OverParenthesis: 'âœ',
  PartialD: 'âˆ‚',
  Pcy: 'ÐŸ',
  Pfr: 'ð”“',
  Phi: 'Î¦',
  Pi: 'Î ',
  PlusMinus: 'Â±',
  Poincareplane: 'â„Œ',
  Popf: 'â„™',
  Pr: 'âª»',
  Precedes: 'â‰º',
  PrecedesEqual: 'âª¯',
  PrecedesSlantEqual: 'â‰¼',
  PrecedesTilde: 'â‰¾',
  Prime: 'â€³',
  Product: 'âˆ',
  Proportion: 'âˆ·',
  Proportional: 'âˆ',
  Pscr: 'ð’«',
  Psi: 'Î¨',
  QUOT: '"',
  Qfr: 'ð””',
  Qopf: 'â„š',
  Qscr: 'ð’¬',
  RBarr: 'â¤',
  REG: 'Â®',
  Racute: 'Å”',
  Rang: 'âŸ«',
  Rarr: 'â† ',
  Rarrtl: 'â¤–',
  Rcaron: 'Å˜',
  Rcedil: 'Å–',
  Rcy: 'Ð ',
  Re: 'â„œ',
  ReverseElement: 'âˆ‹',
  ReverseEquilibrium: 'â‡‹',
  ReverseUpEquilibrium: 'â¥¯',
  Rfr: 'â„œ',
  Rho: 'Î¡',
  RightAngleBracket: 'âŸ©',
  RightArrow: 'â†’',
  RightArrowBar: 'â‡¥',
  RightArrowLeftArrow: 'â‡„',
  RightCeiling: 'âŒ‰',
  RightDoubleBracket: 'âŸ§',
  RightDownTeeVector: 'â¥',
  RightDownVector: 'â‡‚',
  RightDownVectorBar: 'â¥•',
  RightFloor: 'âŒ‹',
  RightTee: 'âŠ¢',
  RightTeeArrow: 'â†¦',
  RightTeeVector: 'â¥›',
  RightTriangle: 'âŠ³',
  RightTriangleBar: 'â§',
  RightTriangleEqual: 'âŠµ',
  RightUpDownVector: 'â¥',
  RightUpTeeVector: 'â¥œ',
  RightUpVector: 'â†¾',
  RightUpVectorBar: 'â¥”',
  RightVector: 'â‡€',
  RightVectorBar: 'â¥“',
  Rightarrow: 'â‡’',
  Ropf: 'â„',
  RoundImplies: 'â¥°',
  Rrightarrow: 'â‡›',
  Rscr: 'â„›',
  Rsh: 'â†±',
  RuleDelayed: 'â§´',
  SHCHcy: 'Ð©',
  SHcy: 'Ð¨',
  SOFTcy: 'Ð¬',
  Sacute: 'Åš',
  Sc: 'âª¼',
  Scaron: 'Å ',
  Scedil: 'Åž',
  Scirc: 'Åœ',
  Scy: 'Ð¡',
  Sfr: 'ð”–',
  ShortDownArrow: 'â†“',
  ShortLeftArrow: 'â†',
  ShortRightArrow: 'â†’',
  ShortUpArrow: 'â†‘',
  Sigma: 'Î£',
  SmallCircle: 'âˆ˜',
  Sopf: 'ð•Š',
  Sqrt: 'âˆš',
  Square: 'â–¡',
  SquareIntersection: 'âŠ“',
  SquareSubset: 'âŠ',
  SquareSubsetEqual: 'âŠ‘',
  SquareSuperset: 'âŠ',
  SquareSupersetEqual: 'âŠ’',
  SquareUnion: 'âŠ”',
  Sscr: 'ð’®',
  Star: 'â‹†',
  Sub: 'â‹',
  Subset: 'â‹',
  SubsetEqual: 'âŠ†',
  Succeeds: 'â‰»',
  SucceedsEqual: 'âª°',
  SucceedsSlantEqual: 'â‰½',
  SucceedsTilde: 'â‰¿',
  SuchThat: 'âˆ‹',
  Sum: 'âˆ‘',
  Sup: 'â‹‘',
  Superset: 'âŠƒ',
  SupersetEqual: 'âŠ‡',
  Supset: 'â‹‘',
  THORN: 'Ãž',
  TRADE: 'â„¢',
  TSHcy: 'Ð‹',
  TScy: 'Ð¦',
  Tab: '\t',
  Tau: 'Î¤',
  Tcaron: 'Å¤',
  Tcedil: 'Å¢',
  Tcy: 'Ð¢',
  Tfr: 'ð”—',
  Therefore: 'âˆ´',
  Theta: 'Î˜',
  ThickSpace: 'âŸâ€Š',
  ThinSpace: 'â€‰',
  Tilde: 'âˆ¼',
  TildeEqual: 'â‰ƒ',
  TildeFullEqual: 'â‰…',
  TildeTilde: 'â‰ˆ',
  Topf: 'ð•‹',
  TripleDot: 'âƒ›',
  Tscr: 'ð’¯',
  Tstrok: 'Å¦',
  Uacute: 'Ãš',
  Uarr: 'â†Ÿ',
  Uarrocir: 'â¥‰',
  Ubrcy: 'ÐŽ',
  Ubreve: 'Å¬',
  Ucirc: 'Ã›',
  Ucy: 'Ð£',
  Udblac: 'Å°',
  Ufr: 'ð”˜',
  Ugrave: 'Ã™',
  Umacr: 'Åª',
  UnderBar: '_',
  UnderBrace: 'âŸ',
  UnderBracket: 'âŽµ',
  UnderParenthesis: 'â',
  Union: 'â‹ƒ',
  UnionPlus: 'âŠŽ',
  Uogon: 'Å²',
  Uopf: 'ð•Œ',
  UpArrow: 'â†‘',
  UpArrowBar: 'â¤’',
  UpArrowDownArrow: 'â‡…',
  UpDownArrow: 'â†•',
  UpEquilibrium: 'â¥®',
  UpTee: 'âŠ¥',
  UpTeeArrow: 'â†¥',
  Uparrow: 'â‡‘',
  Updownarrow: 'â‡•',
  UpperLeftArrow: 'â†–',
  UpperRightArrow: 'â†—',
  Upsi: 'Ï’',
  Upsilon: 'Î¥',
  Uring: 'Å®',
  Uscr: 'ð’°',
  Utilde: 'Å¨',
  Uuml: 'Ãœ',
  VDash: 'âŠ«',
  Vbar: 'â««',
  Vcy: 'Ð’',
  Vdash: 'âŠ©',
  Vdashl: 'â«¦',
  Vee: 'â‹',
  Verbar: 'â€–',
  Vert: 'â€–',
  VerticalBar: 'âˆ£',
  VerticalLine: '|',
  VerticalSeparator: 'â˜',
  VerticalTilde: 'â‰€',
  VeryThinSpace: 'â€Š',
  Vfr: 'ð”™',
  Vopf: 'ð•',
  Vscr: 'ð’±',
  Vvdash: 'âŠª',
  Wcirc: 'Å´',
  Wedge: 'â‹€',
  Wfr: 'ð”š',
  Wopf: 'ð•Ž',
  Wscr: 'ð’²',
  Xfr: 'ð”›',
  Xi: 'Îž',
  Xopf: 'ð•',
  Xscr: 'ð’³',
  YAcy: 'Ð¯',
  YIcy: 'Ð‡',
  YUcy: 'Ð®',
  Yacute: 'Ã',
  Ycirc: 'Å¶',
  Ycy: 'Ð«',
  Yfr: 'ð”œ',
  Yopf: 'ð•',
  Yscr: 'ð’´',
  Yuml: 'Å¸',
  ZHcy: 'Ð–',
  Zacute: 'Å¹',
  Zcaron: 'Å½',
  Zcy: 'Ð—',
  Zdot: 'Å»',
  ZeroWidthSpace: 'â€‹',
  Zeta: 'Î–',
  Zfr: 'â„¨',
  Zopf: 'â„¤',
  Zscr: 'ð’µ',
  aacute: 'Ã¡',
  abreve: 'Äƒ',
  ac: 'âˆ¾',
  acE: 'âˆ¾Ì³',
  acd: 'âˆ¿',
  acirc: 'Ã¢',
  acute: 'Â´',
  acy: 'Ð°',
  aelig: 'Ã¦',
  af: 'â¡',
  afr: 'ð”ž',
  agrave: 'Ã ',
  alefsym: 'â„µ',
  aleph: 'â„µ',
  alpha: 'Î±',
  amacr: 'Ä',
  amalg: 'â¨¿',
  amp: '&',
  and: 'âˆ§',
  andand: 'â©•',
  andd: 'â©œ',
  andslope: 'â©˜',
  andv: 'â©š',
  ang: 'âˆ ',
  ange: 'â¦¤',
  angle: 'âˆ ',
  angmsd: 'âˆ¡',
  angmsdaa: 'â¦¨',
  angmsdab: 'â¦©',
  angmsdac: 'â¦ª',
  angmsdad: 'â¦«',
  angmsdae: 'â¦¬',
  angmsdaf: 'â¦­',
  angmsdag: 'â¦®',
  angmsdah: 'â¦¯',
  angrt: 'âˆŸ',
  angrtvb: 'âŠ¾',
  angrtvbd: 'â¦',
  angsph: 'âˆ¢',
  angst: 'Ã…',
  angzarr: 'â¼',
  aogon: 'Ä…',
  aopf: 'ð•’',
  ap: 'â‰ˆ',
  apE: 'â©°',
  apacir: 'â©¯',
  ape: 'â‰Š',
  apid: 'â‰‹',
  apos: "'",
  approx: 'â‰ˆ',
  approxeq: 'â‰Š',
  aring: 'Ã¥',
  ascr: 'ð’¶',
  ast: '*',
  asymp: 'â‰ˆ',
  asympeq: 'â‰',
  atilde: 'Ã£',
  auml: 'Ã¤',
  awconint: 'âˆ³',
  awint: 'â¨‘',
  bNot: 'â«­',
  backcong: 'â‰Œ',
  backepsilon: 'Ï¶',
  backprime: 'â€µ',
  backsim: 'âˆ½',
  backsimeq: 'â‹',
  barvee: 'âŠ½',
  barwed: 'âŒ…',
  barwedge: 'âŒ…',
  bbrk: 'âŽµ',
  bbrktbrk: 'âŽ¶',
  bcong: 'â‰Œ',
  bcy: 'Ð±',
  bdquo: 'â€ž',
  becaus: 'âˆµ',
  because: 'âˆµ',
  bemptyv: 'â¦°',
  bepsi: 'Ï¶',
  bernou: 'â„¬',
  beta: 'Î²',
  beth: 'â„¶',
  between: 'â‰¬',
  bfr: 'ð”Ÿ',
  bigcap: 'â‹‚',
  bigcirc: 'â—¯',
  bigcup: 'â‹ƒ',
  bigodot: 'â¨€',
  bigoplus: 'â¨',
  bigotimes: 'â¨‚',
  bigsqcup: 'â¨†',
  bigstar: 'â˜…',
  bigtriangledown: 'â–½',
  bigtriangleup: 'â–³',
  biguplus: 'â¨„',
  bigvee: 'â‹',
  bigwedge: 'â‹€',
  bkarow: 'â¤',
  blacklozenge: 'â§«',
  blacksquare: 'â–ª',
  blacktriangle: 'â–´',
  blacktriangledown: 'â–¾',
  blacktriangleleft: 'â—‚',
  blacktriangleright: 'â–¸',
  blank: 'â£',
  blk12: 'â–’',
  blk14: 'â–‘',
  blk34: 'â–“',
  block: 'â–ˆ',
  bne: '=âƒ¥',
  bnequiv: 'â‰¡âƒ¥',
  bnot: 'âŒ',
  bopf: 'ð•“',
  bot: 'âŠ¥',
  bottom: 'âŠ¥',
  bowtie: 'â‹ˆ',
  boxDL: 'â•—',
  boxDR: 'â•”',
  boxDl: 'â•–',
  boxDr: 'â•“',
  boxH: 'â•',
  boxHD: 'â•¦',
  boxHU: 'â•©',
  boxHd: 'â•¤',
  boxHu: 'â•§',
  boxUL: 'â•',
  boxUR: 'â•š',
  boxUl: 'â•œ',
  boxUr: 'â•™',
  boxV: 'â•‘',
  boxVH: 'â•¬',
  boxVL: 'â•£',
  boxVR: 'â• ',
  boxVh: 'â•«',
  boxVl: 'â•¢',
  boxVr: 'â•Ÿ',
  boxbox: 'â§‰',
  boxdL: 'â••',
  boxdR: 'â•’',
  boxdl: 'â”',
  boxdr: 'â”Œ',
  boxh: 'â”€',
  boxhD: 'â•¥',
  boxhU: 'â•¨',
  boxhd: 'â”¬',
  boxhu: 'â”´',
  boxminus: 'âŠŸ',
  boxplus: 'âŠž',
  boxtimes: 'âŠ ',
  boxuL: 'â•›',
  boxuR: 'â•˜',
  boxul: 'â”˜',
  boxur: 'â””',
  boxv: 'â”‚',
  boxvH: 'â•ª',
  boxvL: 'â•¡',
  boxvR: 'â•ž',
  boxvh: 'â”¼',
  boxvl: 'â”¤',
  boxvr: 'â”œ',
  bprime: 'â€µ',
  breve: 'Ë˜',
  brvbar: 'Â¦',
  bscr: 'ð’·',
  bsemi: 'â',
  bsim: 'âˆ½',
  bsime: 'â‹',
  bsol: '\\',
  bsolb: 'â§…',
  bsolhsub: 'âŸˆ',
  bull: 'â€¢',
  bullet: 'â€¢',
  bump: 'â‰Ž',
  bumpE: 'âª®',
  bumpe: 'â‰',
  bumpeq: 'â‰',
  cacute: 'Ä‡',
  cap: 'âˆ©',
  capand: 'â©„',
  capbrcup: 'â©‰',
  capcap: 'â©‹',
  capcup: 'â©‡',
  capdot: 'â©€',
  caps: 'âˆ©ï¸€',
  caret: 'â',
  caron: 'Ë‡',
  ccaps: 'â©',
  ccaron: 'Ä',
  ccedil: 'Ã§',
  ccirc: 'Ä‰',
  ccups: 'â©Œ',
  ccupssm: 'â©',
  cdot: 'Ä‹',
  cedil: 'Â¸',
  cemptyv: 'â¦²',
  cent: 'Â¢',
  centerdot: 'Â·',
  cfr: 'ð” ',
  chcy: 'Ñ‡',
  check: 'âœ“',
  checkmark: 'âœ“',
  chi: 'Ï‡',
  cir: 'â—‹',
  cirE: 'â§ƒ',
  circ: 'Ë†',
  circeq: 'â‰—',
  circlearrowleft: 'â†º',
  circlearrowright: 'â†»',
  circledR: 'Â®',
  circledS: 'â“ˆ',
  circledast: 'âŠ›',
  circledcirc: 'âŠš',
  circleddash: 'âŠ',
  cire: 'â‰—',
  cirfnint: 'â¨',
  cirmid: 'â«¯',
  cirscir: 'â§‚',
  clubs: 'â™£',
  clubsuit: 'â™£',
  colon: ':',
  colone: 'â‰”',
  coloneq: 'â‰”',
  comma: ',',
  commat: '@',
  comp: 'âˆ',
  compfn: 'âˆ˜',
  complement: 'âˆ',
  complexes: 'â„‚',
  cong: 'â‰…',
  congdot: 'â©­',
  conint: 'âˆ®',
  copf: 'ð•”',
  coprod: 'âˆ',
  copy: 'Â©',
  copysr: 'â„—',
  crarr: 'â†µ',
  cross: 'âœ—',
  cscr: 'ð’¸',
  csub: 'â«',
  csube: 'â«‘',
  csup: 'â«',
  csupe: 'â«’',
  ctdot: 'â‹¯',
  cudarrl: 'â¤¸',
  cudarrr: 'â¤µ',
  cuepr: 'â‹ž',
  cuesc: 'â‹Ÿ',
  cularr: 'â†¶',
  cularrp: 'â¤½',
  cup: 'âˆª',
  cupbrcap: 'â©ˆ',
  cupcap: 'â©†',
  cupcup: 'â©Š',
  cupdot: 'âŠ',
  cupor: 'â©…',
  cups: 'âˆªï¸€',
  curarr: 'â†·',
  curarrm: 'â¤¼',
  curlyeqprec: 'â‹ž',
  curlyeqsucc: 'â‹Ÿ',
  curlyvee: 'â‹Ž',
  curlywedge: 'â‹',
  curren: 'Â¤',
  curvearrowleft: 'â†¶',
  curvearrowright: 'â†·',
  cuvee: 'â‹Ž',
  cuwed: 'â‹',
  cwconint: 'âˆ²',
  cwint: 'âˆ±',
  cylcty: 'âŒ­',
  dArr: 'â‡“',
  dHar: 'â¥¥',
  dagger: 'â€ ',
  daleth: 'â„¸',
  darr: 'â†“',
  dash: 'â€',
  dashv: 'âŠ£',
  dbkarow: 'â¤',
  dblac: 'Ë',
  dcaron: 'Ä',
  dcy: 'Ð´',
  dd: 'â…†',
  ddagger: 'â€¡',
  ddarr: 'â‡Š',
  ddotseq: 'â©·',
  deg: 'Â°',
  delta: 'Î´',
  demptyv: 'â¦±',
  dfisht: 'â¥¿',
  dfr: 'ð”¡',
  dharl: 'â‡ƒ',
  dharr: 'â‡‚',
  diam: 'â‹„',
  diamond: 'â‹„',
  diamondsuit: 'â™¦',
  diams: 'â™¦',
  die: 'Â¨',
  digamma: 'Ï',
  disin: 'â‹²',
  div: 'Ã·',
  divide: 'Ã·',
  divideontimes: 'â‹‡',
  divonx: 'â‹‡',
  djcy: 'Ñ’',
  dlcorn: 'âŒž',
  dlcrop: 'âŒ',
  dollar: '$',
  dopf: 'ð••',
  dot: 'Ë™',
  doteq: 'â‰',
  doteqdot: 'â‰‘',
  dotminus: 'âˆ¸',
  dotplus: 'âˆ”',
  dotsquare: 'âŠ¡',
  doublebarwedge: 'âŒ†',
  downarrow: 'â†“',
  downdownarrows: 'â‡Š',
  downharpoonleft: 'â‡ƒ',
  downharpoonright: 'â‡‚',
  drbkarow: 'â¤',
  drcorn: 'âŒŸ',
  drcrop: 'âŒŒ',
  dscr: 'ð’¹',
  dscy: 'Ñ•',
  dsol: 'â§¶',
  dstrok: 'Ä‘',
  dtdot: 'â‹±',
  dtri: 'â–¿',
  dtrif: 'â–¾',
  duarr: 'â‡µ',
  duhar: 'â¥¯',
  dwangle: 'â¦¦',
  dzcy: 'ÑŸ',
  dzigrarr: 'âŸ¿',
  eDDot: 'â©·',
  eDot: 'â‰‘',
  eacute: 'Ã©',
  easter: 'â©®',
  ecaron: 'Ä›',
  ecir: 'â‰–',
  ecirc: 'Ãª',
  ecolon: 'â‰•',
  ecy: 'Ñ',
  edot: 'Ä—',
  ee: 'â…‡',
  efDot: 'â‰’',
  efr: 'ð”¢',
  eg: 'âªš',
  egrave: 'Ã¨',
  egs: 'âª–',
  egsdot: 'âª˜',
  el: 'âª™',
  elinters: 'â§',
  ell: 'â„“',
  els: 'âª•',
  elsdot: 'âª—',
  emacr: 'Ä“',
  empty: 'âˆ…',
  emptyset: 'âˆ…',
  emptyv: 'âˆ…',
  emsp13: 'â€„',
  emsp14: 'â€…',
  emsp: 'â€ƒ',
  eng: 'Å‹',
  ensp: 'â€‚',
  eogon: 'Ä™',
  eopf: 'ð•–',
  epar: 'â‹•',
  eparsl: 'â§£',
  eplus: 'â©±',
  epsi: 'Îµ',
  epsilon: 'Îµ',
  epsiv: 'Ïµ',
  eqcirc: 'â‰–',
  eqcolon: 'â‰•',
  eqsim: 'â‰‚',
  eqslantgtr: 'âª–',
  eqslantless: 'âª•',
  equals: '=',
  equest: 'â‰Ÿ',
  equiv: 'â‰¡',
  equivDD: 'â©¸',
  eqvparsl: 'â§¥',
  erDot: 'â‰“',
  erarr: 'â¥±',
  escr: 'â„¯',
  esdot: 'â‰',
  esim: 'â‰‚',
  eta: 'Î·',
  eth: 'Ã°',
  euml: 'Ã«',
  euro: 'â‚¬',
  excl: '!',
  exist: 'âˆƒ',
  expectation: 'â„°',
  exponentiale: 'â…‡',
  fallingdotseq: 'â‰’',
  fcy: 'Ñ„',
  female: 'â™€',
  ffilig: 'ï¬ƒ',
  fflig: 'ï¬€',
  ffllig: 'ï¬„',
  ffr: 'ð”£',
  filig: 'ï¬',
  fjlig: 'fj',
  flat: 'â™­',
  fllig: 'ï¬‚',
  fltns: 'â–±',
  fnof: 'Æ’',
  fopf: 'ð•—',
  forall: 'âˆ€',
  fork: 'â‹”',
  forkv: 'â«™',
  fpartint: 'â¨',
  frac12: 'Â½',
  frac13: 'â…“',
  frac14: 'Â¼',
  frac15: 'â…•',
  frac16: 'â…™',
  frac18: 'â…›',
  frac23: 'â…”',
  frac25: 'â…–',
  frac34: 'Â¾',
  frac35: 'â…—',
  frac38: 'â…œ',
  frac45: 'â…˜',
  frac56: 'â…š',
  frac58: 'â…',
  frac78: 'â…ž',
  frasl: 'â„',
  frown: 'âŒ¢',
  fscr: 'ð’»',
  gE: 'â‰§',
  gEl: 'âªŒ',
  gacute: 'Çµ',
  gamma: 'Î³',
  gammad: 'Ï',
  gap: 'âª†',
  gbreve: 'ÄŸ',
  gcirc: 'Ä',
  gcy: 'Ð³',
  gdot: 'Ä¡',
  ge: 'â‰¥',
  gel: 'â‹›',
  geq: 'â‰¥',
  geqq: 'â‰§',
  geqslant: 'â©¾',
  ges: 'â©¾',
  gescc: 'âª©',
  gesdot: 'âª€',
  gesdoto: 'âª‚',
  gesdotol: 'âª„',
  gesl: 'â‹›ï¸€',
  gesles: 'âª”',
  gfr: 'ð”¤',
  gg: 'â‰«',
  ggg: 'â‹™',
  gimel: 'â„·',
  gjcy: 'Ñ“',
  gl: 'â‰·',
  glE: 'âª’',
  gla: 'âª¥',
  glj: 'âª¤',
  gnE: 'â‰©',
  gnap: 'âªŠ',
  gnapprox: 'âªŠ',
  gne: 'âªˆ',
  gneq: 'âªˆ',
  gneqq: 'â‰©',
  gnsim: 'â‹§',
  gopf: 'ð•˜',
  grave: '`',
  gscr: 'â„Š',
  gsim: 'â‰³',
  gsime: 'âªŽ',
  gsiml: 'âª',
  gt: '>',
  gtcc: 'âª§',
  gtcir: 'â©º',
  gtdot: 'â‹—',
  gtlPar: 'â¦•',
  gtquest: 'â©¼',
  gtrapprox: 'âª†',
  gtrarr: 'â¥¸',
  gtrdot: 'â‹—',
  gtreqless: 'â‹›',
  gtreqqless: 'âªŒ',
  gtrless: 'â‰·',
  gtrsim: 'â‰³',
  gvertneqq: 'â‰©ï¸€',
  gvnE: 'â‰©ï¸€',
  hArr: 'â‡”',
  hairsp: 'â€Š',
  half: 'Â½',
  hamilt: 'â„‹',
  hardcy: 'ÑŠ',
  harr: 'â†”',
  harrcir: 'â¥ˆ',
  harrw: 'â†­',
  hbar: 'â„',
  hcirc: 'Ä¥',
  hearts: 'â™¥',
  heartsuit: 'â™¥',
  hellip: 'â€¦',
  hercon: 'âŠ¹',
  hfr: 'ð”¥',
  hksearow: 'â¤¥',
  hkswarow: 'â¤¦',
  hoarr: 'â‡¿',
  homtht: 'âˆ»',
  hookleftarrow: 'â†©',
  hookrightarrow: 'â†ª',
  hopf: 'ð•™',
  horbar: 'â€•',
  hscr: 'ð’½',
  hslash: 'â„',
  hstrok: 'Ä§',
  hybull: 'âƒ',
  hyphen: 'â€',
  iacute: 'Ã­',
  ic: 'â£',
  icirc: 'Ã®',
  icy: 'Ð¸',
  iecy: 'Ðµ',
  iexcl: 'Â¡',
  iff: 'â‡”',
  ifr: 'ð”¦',
  igrave: 'Ã¬',
  ii: 'â…ˆ',
  iiiint: 'â¨Œ',
  iiint: 'âˆ­',
  iinfin: 'â§œ',
  iiota: 'â„©',
  ijlig: 'Ä³',
  imacr: 'Ä«',
  image: 'â„‘',
  imagline: 'â„',
  imagpart: 'â„‘',
  imath: 'Ä±',
  imof: 'âŠ·',
  imped: 'Æµ',
  in: 'âˆˆ',
  incare: 'â„…',
  infin: 'âˆž',
  infintie: 'â§',
  inodot: 'Ä±',
  int: 'âˆ«',
  intcal: 'âŠº',
  integers: 'â„¤',
  intercal: 'âŠº',
  intlarhk: 'â¨—',
  intprod: 'â¨¼',
  iocy: 'Ñ‘',
  iogon: 'Ä¯',
  iopf: 'ð•š',
  iota: 'Î¹',
  iprod: 'â¨¼',
  iquest: 'Â¿',
  iscr: 'ð’¾',
  isin: 'âˆˆ',
  isinE: 'â‹¹',
  isindot: 'â‹µ',
  isins: 'â‹´',
  isinsv: 'â‹³',
  isinv: 'âˆˆ',
  it: 'â¢',
  itilde: 'Ä©',
  iukcy: 'Ñ–',
  iuml: 'Ã¯',
  jcirc: 'Äµ',
  jcy: 'Ð¹',
  jfr: 'ð”§',
  jmath: 'È·',
  jopf: 'ð•›',
  jscr: 'ð’¿',
  jsercy: 'Ñ˜',
  jukcy: 'Ñ”',
  kappa: 'Îº',
  kappav: 'Ï°',
  kcedil: 'Ä·',
  kcy: 'Ðº',
  kfr: 'ð”¨',
  kgreen: 'Ä¸',
  khcy: 'Ñ…',
  kjcy: 'Ñœ',
  kopf: 'ð•œ',
  kscr: 'ð“€',
  lAarr: 'â‡š',
  lArr: 'â‡',
  lAtail: 'â¤›',
  lBarr: 'â¤Ž',
  lE: 'â‰¦',
  lEg: 'âª‹',
  lHar: 'â¥¢',
  lacute: 'Äº',
  laemptyv: 'â¦´',
  lagran: 'â„’',
  lambda: 'Î»',
  lang: 'âŸ¨',
  langd: 'â¦‘',
  langle: 'âŸ¨',
  lap: 'âª…',
  laquo: 'Â«',
  larr: 'â†',
  larrb: 'â‡¤',
  larrbfs: 'â¤Ÿ',
  larrfs: 'â¤',
  larrhk: 'â†©',
  larrlp: 'â†«',
  larrpl: 'â¤¹',
  larrsim: 'â¥³',
  larrtl: 'â†¢',
  lat: 'âª«',
  latail: 'â¤™',
  late: 'âª­',
  lates: 'âª­ï¸€',
  lbarr: 'â¤Œ',
  lbbrk: 'â²',
  lbrace: '{',
  lbrack: '[',
  lbrke: 'â¦‹',
  lbrksld: 'â¦',
  lbrkslu: 'â¦',
  lcaron: 'Ä¾',
  lcedil: 'Ä¼',
  lceil: 'âŒˆ',
  lcub: '{',
  lcy: 'Ð»',
  ldca: 'â¤¶',
  ldquo: 'â€œ',
  ldquor: 'â€ž',
  ldrdhar: 'â¥§',
  ldrushar: 'â¥‹',
  ldsh: 'â†²',
  le: 'â‰¤',
  leftarrow: 'â†',
  leftarrowtail: 'â†¢',
  leftharpoondown: 'â†½',
  leftharpoonup: 'â†¼',
  leftleftarrows: 'â‡‡',
  leftrightarrow: 'â†”',
  leftrightarrows: 'â‡†',
  leftrightharpoons: 'â‡‹',
  leftrightsquigarrow: 'â†­',
  leftthreetimes: 'â‹‹',
  leg: 'â‹š',
  leq: 'â‰¤',
  leqq: 'â‰¦',
  leqslant: 'â©½',
  les: 'â©½',
  lescc: 'âª¨',
  lesdot: 'â©¿',
  lesdoto: 'âª',
  lesdotor: 'âªƒ',
  lesg: 'â‹šï¸€',
  lesges: 'âª“',
  lessapprox: 'âª…',
  lessdot: 'â‹–',
  lesseqgtr: 'â‹š',
  lesseqqgtr: 'âª‹',
  lessgtr: 'â‰¶',
  lesssim: 'â‰²',
  lfisht: 'â¥¼',
  lfloor: 'âŒŠ',
  lfr: 'ð”©',
  lg: 'â‰¶',
  lgE: 'âª‘',
  lhard: 'â†½',
  lharu: 'â†¼',
  lharul: 'â¥ª',
  lhblk: 'â–„',
  ljcy: 'Ñ™',
  ll: 'â‰ª',
  llarr: 'â‡‡',
  llcorner: 'âŒž',
  llhard: 'â¥«',
  lltri: 'â—º',
  lmidot: 'Å€',
  lmoust: 'âŽ°',
  lmoustache: 'âŽ°',
  lnE: 'â‰¨',
  lnap: 'âª‰',
  lnapprox: 'âª‰',
  lne: 'âª‡',
  lneq: 'âª‡',
  lneqq: 'â‰¨',
  lnsim: 'â‹¦',
  loang: 'âŸ¬',
  loarr: 'â‡½',
  lobrk: 'âŸ¦',
  longleftarrow: 'âŸµ',
  longleftrightarrow: 'âŸ·',
  longmapsto: 'âŸ¼',
  longrightarrow: 'âŸ¶',
  looparrowleft: 'â†«',
  looparrowright: 'â†¬',
  lopar: 'â¦…',
  lopf: 'ð•',
  loplus: 'â¨­',
  lotimes: 'â¨´',
  lowast: 'âˆ—',
  lowbar: '_',
  loz: 'â—Š',
  lozenge: 'â—Š',
  lozf: 'â§«',
  lpar: '(',
  lparlt: 'â¦“',
  lrarr: 'â‡†',
  lrcorner: 'âŒŸ',
  lrhar: 'â‡‹',
  lrhard: 'â¥­',
  lrm: 'â€Ž',
  lrtri: 'âŠ¿',
  lsaquo: 'â€¹',
  lscr: 'ð“',
  lsh: 'â†°',
  lsim: 'â‰²',
  lsime: 'âª',
  lsimg: 'âª',
  lsqb: '[',
  lsquo: 'â€˜',
  lsquor: 'â€š',
  lstrok: 'Å‚',
  lt: '<',
  ltcc: 'âª¦',
  ltcir: 'â©¹',
  ltdot: 'â‹–',
  lthree: 'â‹‹',
  ltimes: 'â‹‰',
  ltlarr: 'â¥¶',
  ltquest: 'â©»',
  ltrPar: 'â¦–',
  ltri: 'â—ƒ',
  ltrie: 'âŠ´',
  ltrif: 'â—‚',
  lurdshar: 'â¥Š',
  luruhar: 'â¥¦',
  lvertneqq: 'â‰¨ï¸€',
  lvnE: 'â‰¨ï¸€',
  mDDot: 'âˆº',
  macr: 'Â¯',
  male: 'â™‚',
  malt: 'âœ ',
  maltese: 'âœ ',
  map: 'â†¦',
  mapsto: 'â†¦',
  mapstodown: 'â†§',
  mapstoleft: 'â†¤',
  mapstoup: 'â†¥',
  marker: 'â–®',
  mcomma: 'â¨©',
  mcy: 'Ð¼',
  mdash: 'â€”',
  measuredangle: 'âˆ¡',
  mfr: 'ð”ª',
  mho: 'â„§',
  micro: 'Âµ',
  mid: 'âˆ£',
  midast: '*',
  midcir: 'â«°',
  middot: 'Â·',
  minus: 'âˆ’',
  minusb: 'âŠŸ',
  minusd: 'âˆ¸',
  minusdu: 'â¨ª',
  mlcp: 'â«›',
  mldr: 'â€¦',
  mnplus: 'âˆ“',
  models: 'âŠ§',
  mopf: 'ð•ž',
  mp: 'âˆ“',
  mscr: 'ð“‚',
  mstpos: 'âˆ¾',
  mu: 'Î¼',
  multimap: 'âŠ¸',
  mumap: 'âŠ¸',
  nGg: 'â‹™Ì¸',
  nGt: 'â‰«âƒ’',
  nGtv: 'â‰«Ì¸',
  nLeftarrow: 'â‡',
  nLeftrightarrow: 'â‡Ž',
  nLl: 'â‹˜Ì¸',
  nLt: 'â‰ªâƒ’',
  nLtv: 'â‰ªÌ¸',
  nRightarrow: 'â‡',
  nVDash: 'âŠ¯',
  nVdash: 'âŠ®',
  nabla: 'âˆ‡',
  nacute: 'Å„',
  nang: 'âˆ âƒ’',
  nap: 'â‰‰',
  napE: 'â©°Ì¸',
  napid: 'â‰‹Ì¸',
  napos: 'Å‰',
  napprox: 'â‰‰',
  natur: 'â™®',
  natural: 'â™®',
  naturals: 'â„•',
  nbsp: 'Â ',
  nbump: 'â‰ŽÌ¸',
  nbumpe: 'â‰Ì¸',
  ncap: 'â©ƒ',
  ncaron: 'Åˆ',
  ncedil: 'Å†',
  ncong: 'â‰‡',
  ncongdot: 'â©­Ì¸',
  ncup: 'â©‚',
  ncy: 'Ð½',
  ndash: 'â€“',
  ne: 'â‰ ',
  neArr: 'â‡—',
  nearhk: 'â¤¤',
  nearr: 'â†—',
  nearrow: 'â†—',
  nedot: 'â‰Ì¸',
  nequiv: 'â‰¢',
  nesear: 'â¤¨',
  nesim: 'â‰‚Ì¸',
  nexist: 'âˆ„',
  nexists: 'âˆ„',
  nfr: 'ð”«',
  ngE: 'â‰§Ì¸',
  nge: 'â‰±',
  ngeq: 'â‰±',
  ngeqq: 'â‰§Ì¸',
  ngeqslant: 'â©¾Ì¸',
  nges: 'â©¾Ì¸',
  ngsim: 'â‰µ',
  ngt: 'â‰¯',
  ngtr: 'â‰¯',
  nhArr: 'â‡Ž',
  nharr: 'â†®',
  nhpar: 'â«²',
  ni: 'âˆ‹',
  nis: 'â‹¼',
  nisd: 'â‹º',
  niv: 'âˆ‹',
  njcy: 'Ñš',
  nlArr: 'â‡',
  nlE: 'â‰¦Ì¸',
  nlarr: 'â†š',
  nldr: 'â€¥',
  nle: 'â‰°',
  nleftarrow: 'â†š',
  nleftrightarrow: 'â†®',
  nleq: 'â‰°',
  nleqq: 'â‰¦Ì¸',
  nleqslant: 'â©½Ì¸',
  nles: 'â©½Ì¸',
  nless: 'â‰®',
  nlsim: 'â‰´',
  nlt: 'â‰®',
  nltri: 'â‹ª',
  nltrie: 'â‹¬',
  nmid: 'âˆ¤',
  nopf: 'ð•Ÿ',
  not: 'Â¬',
  notin: 'âˆ‰',
  notinE: 'â‹¹Ì¸',
  notindot: 'â‹µÌ¸',
  notinva: 'âˆ‰',
  notinvb: 'â‹·',
  notinvc: 'â‹¶',
  notni: 'âˆŒ',
  notniva: 'âˆŒ',
  notnivb: 'â‹¾',
  notnivc: 'â‹½',
  npar: 'âˆ¦',
  nparallel: 'âˆ¦',
  nparsl: 'â«½âƒ¥',
  npart: 'âˆ‚Ì¸',
  npolint: 'â¨”',
  npr: 'âŠ€',
  nprcue: 'â‹ ',
  npre: 'âª¯Ì¸',
  nprec: 'âŠ€',
  npreceq: 'âª¯Ì¸',
  nrArr: 'â‡',
  nrarr: 'â†›',
  nrarrc: 'â¤³Ì¸',
  nrarrw: 'â†Ì¸',
  nrightarrow: 'â†›',
  nrtri: 'â‹«',
  nrtrie: 'â‹­',
  nsc: 'âŠ',
  nsccue: 'â‹¡',
  nsce: 'âª°Ì¸',
  nscr: 'ð“ƒ',
  nshortmid: 'âˆ¤',
  nshortparallel: 'âˆ¦',
  nsim: 'â‰',
  nsime: 'â‰„',
  nsimeq: 'â‰„',
  nsmid: 'âˆ¤',
  nspar: 'âˆ¦',
  nsqsube: 'â‹¢',
  nsqsupe: 'â‹£',
  nsub: 'âŠ„',
  nsubE: 'â«…Ì¸',
  nsube: 'âŠˆ',
  nsubset: 'âŠ‚âƒ’',
  nsubseteq: 'âŠˆ',
  nsubseteqq: 'â«…Ì¸',
  nsucc: 'âŠ',
  nsucceq: 'âª°Ì¸',
  nsup: 'âŠ…',
  nsupE: 'â«†Ì¸',
  nsupe: 'âŠ‰',
  nsupset: 'âŠƒâƒ’',
  nsupseteq: 'âŠ‰',
  nsupseteqq: 'â«†Ì¸',
  ntgl: 'â‰¹',
  ntilde: 'Ã±',
  ntlg: 'â‰¸',
  ntriangleleft: 'â‹ª',
  ntrianglelefteq: 'â‹¬',
  ntriangleright: 'â‹«',
  ntrianglerighteq: 'â‹­',
  nu: 'Î½',
  num: '#',
  numero: 'â„–',
  numsp: 'â€‡',
  nvDash: 'âŠ­',
  nvHarr: 'â¤„',
  nvap: 'â‰âƒ’',
  nvdash: 'âŠ¬',
  nvge: 'â‰¥âƒ’',
  nvgt: '>âƒ’',
  nvinfin: 'â§ž',
  nvlArr: 'â¤‚',
  nvle: 'â‰¤âƒ’',
  nvlt: '<âƒ’',
  nvltrie: 'âŠ´âƒ’',
  nvrArr: 'â¤ƒ',
  nvrtrie: 'âŠµâƒ’',
  nvsim: 'âˆ¼âƒ’',
  nwArr: 'â‡–',
  nwarhk: 'â¤£',
  nwarr: 'â†–',
  nwarrow: 'â†–',
  nwnear: 'â¤§',
  oS: 'â“ˆ',
  oacute: 'Ã³',
  oast: 'âŠ›',
  ocir: 'âŠš',
  ocirc: 'Ã´',
  ocy: 'Ð¾',
  odash: 'âŠ',
  odblac: 'Å‘',
  odiv: 'â¨¸',
  odot: 'âŠ™',
  odsold: 'â¦¼',
  oelig: 'Å“',
  ofcir: 'â¦¿',
  ofr: 'ð”¬',
  ogon: 'Ë›',
  ograve: 'Ã²',
  ogt: 'â§',
  ohbar: 'â¦µ',
  ohm: 'Î©',
  oint: 'âˆ®',
  olarr: 'â†º',
  olcir: 'â¦¾',
  olcross: 'â¦»',
  oline: 'â€¾',
  olt: 'â§€',
  omacr: 'Å',
  omega: 'Ï‰',
  omicron: 'Î¿',
  omid: 'â¦¶',
  ominus: 'âŠ–',
  oopf: 'ð• ',
  opar: 'â¦·',
  operp: 'â¦¹',
  oplus: 'âŠ•',
  or: 'âˆ¨',
  orarr: 'â†»',
  ord: 'â©',
  order: 'â„´',
  orderof: 'â„´',
  ordf: 'Âª',
  ordm: 'Âº',
  origof: 'âŠ¶',
  oror: 'â©–',
  orslope: 'â©—',
  orv: 'â©›',
  oscr: 'â„´',
  oslash: 'Ã¸',
  osol: 'âŠ˜',
  otilde: 'Ãµ',
  otimes: 'âŠ—',
  otimesas: 'â¨¶',
  ouml: 'Ã¶',
  ovbar: 'âŒ½',
  par: 'âˆ¥',
  para: 'Â¶',
  parallel: 'âˆ¥',
  parsim: 'â«³',
  parsl: 'â«½',
  part: 'âˆ‚',
  pcy: 'Ð¿',
  percnt: '%',
  period: '.',
  permil: 'â€°',
  perp: 'âŠ¥',
  pertenk: 'â€±',
  pfr: 'ð”­',
  phi: 'Ï†',
  phiv: 'Ï•',
  phmmat: 'â„³',
  phone: 'â˜Ž',
  pi: 'Ï€',
  pitchfork: 'â‹”',
  piv: 'Ï–',
  planck: 'â„',
  planckh: 'â„Ž',
  plankv: 'â„',
  plus: '+',
  plusacir: 'â¨£',
  plusb: 'âŠž',
  pluscir: 'â¨¢',
  plusdo: 'âˆ”',
  plusdu: 'â¨¥',
  pluse: 'â©²',
  plusmn: 'Â±',
  plussim: 'â¨¦',
  plustwo: 'â¨§',
  pm: 'Â±',
  pointint: 'â¨•',
  popf: 'ð•¡',
  pound: 'Â£',
  pr: 'â‰º',
  prE: 'âª³',
  prap: 'âª·',
  prcue: 'â‰¼',
  pre: 'âª¯',
  prec: 'â‰º',
  precapprox: 'âª·',
  preccurlyeq: 'â‰¼',
  preceq: 'âª¯',
  precnapprox: 'âª¹',
  precneqq: 'âªµ',
  precnsim: 'â‹¨',
  precsim: 'â‰¾',
  prime: 'â€²',
  primes: 'â„™',
  prnE: 'âªµ',
  prnap: 'âª¹',
  prnsim: 'â‹¨',
  prod: 'âˆ',
  profalar: 'âŒ®',
  profline: 'âŒ’',
  profsurf: 'âŒ“',
  prop: 'âˆ',
  propto: 'âˆ',
  prsim: 'â‰¾',
  prurel: 'âŠ°',
  pscr: 'ð“…',
  psi: 'Ïˆ',
  puncsp: 'â€ˆ',
  qfr: 'ð”®',
  qint: 'â¨Œ',
  qopf: 'ð•¢',
  qprime: 'â—',
  qscr: 'ð“†',
  quaternions: 'â„',
  quatint: 'â¨–',
  quest: '?',
  questeq: 'â‰Ÿ',
  quot: '"',
  rAarr: 'â‡›',
  rArr: 'â‡’',
  rAtail: 'â¤œ',
  rBarr: 'â¤',
  rHar: 'â¥¤',
  race: 'âˆ½Ì±',
  racute: 'Å•',
  radic: 'âˆš',
  raemptyv: 'â¦³',
  rang: 'âŸ©',
  rangd: 'â¦’',
  range: 'â¦¥',
  rangle: 'âŸ©',
  raquo: 'Â»',
  rarr: 'â†’',
  rarrap: 'â¥µ',
  rarrb: 'â‡¥',
  rarrbfs: 'â¤ ',
  rarrc: 'â¤³',
  rarrfs: 'â¤ž',
  rarrhk: 'â†ª',
  rarrlp: 'â†¬',
  rarrpl: 'â¥…',
  rarrsim: 'â¥´',
  rarrtl: 'â†£',
  rarrw: 'â†',
  ratail: 'â¤š',
  ratio: 'âˆ¶',
  rationals: 'â„š',
  rbarr: 'â¤',
  rbbrk: 'â³',
  rbrace: '}',
  rbrack: ']',
  rbrke: 'â¦Œ',
  rbrksld: 'â¦Ž',
  rbrkslu: 'â¦',
  rcaron: 'Å™',
  rcedil: 'Å—',
  rceil: 'âŒ‰',
  rcub: '}',
  rcy: 'Ñ€',
  rdca: 'â¤·',
  rdldhar: 'â¥©',
  rdquo: 'â€',
  rdquor: 'â€',
  rdsh: 'â†³',
  real: 'â„œ',
  realine: 'â„›',
  realpart: 'â„œ',
  reals: 'â„',
  rect: 'â–­',
  reg: 'Â®',
  rfisht: 'â¥½',
  rfloor: 'âŒ‹',
  rfr: 'ð”¯',
  rhard: 'â‡',
  rharu: 'â‡€',
  rharul: 'â¥¬',
  rho: 'Ï',
  rhov: 'Ï±',
  rightarrow: 'â†’',
  rightarrowtail: 'â†£',
  rightharpoondown: 'â‡',
  rightharpoonup: 'â‡€',
  rightleftarrows: 'â‡„',
  rightleftharpoons: 'â‡Œ',
  rightrightarrows: 'â‡‰',
  rightsquigarrow: 'â†',
  rightthreetimes: 'â‹Œ',
  ring: 'Ëš',
  risingdotseq: 'â‰“',
  rlarr: 'â‡„',
  rlhar: 'â‡Œ',
  rlm: 'â€',
  rmoust: 'âŽ±',
  rmoustache: 'âŽ±',
  rnmid: 'â«®',
  roang: 'âŸ­',
  roarr: 'â‡¾',
  robrk: 'âŸ§',
  ropar: 'â¦†',
  ropf: 'ð•£',
  roplus: 'â¨®',
  rotimes: 'â¨µ',
  rpar: ')',
  rpargt: 'â¦”',
  rppolint: 'â¨’',
  rrarr: 'â‡‰',
  rsaquo: 'â€º',
  rscr: 'ð“‡',
  rsh: 'â†±',
  rsqb: ']',
  rsquo: 'â€™',
  rsquor: 'â€™',
  rthree: 'â‹Œ',
  rtimes: 'â‹Š',
  rtri: 'â–¹',
  rtrie: 'âŠµ',
  rtrif: 'â–¸',
  rtriltri: 'â§Ž',
  ruluhar: 'â¥¨',
  rx: 'â„ž',
  sacute: 'Å›',
  sbquo: 'â€š',
  sc: 'â‰»',
  scE: 'âª´',
  scap: 'âª¸',
  scaron: 'Å¡',
  sccue: 'â‰½',
  sce: 'âª°',
  scedil: 'ÅŸ',
  scirc: 'Å',
  scnE: 'âª¶',
  scnap: 'âªº',
  scnsim: 'â‹©',
  scpolint: 'â¨“',
  scsim: 'â‰¿',
  scy: 'Ñ',
  sdot: 'â‹…',
  sdotb: 'âŠ¡',
  sdote: 'â©¦',
  seArr: 'â‡˜',
  searhk: 'â¤¥',
  searr: 'â†˜',
  searrow: 'â†˜',
  sect: 'Â§',
  semi: ';',
  seswar: 'â¤©',
  setminus: 'âˆ–',
  setmn: 'âˆ–',
  sext: 'âœ¶',
  sfr: 'ð”°',
  sfrown: 'âŒ¢',
  sharp: 'â™¯',
  shchcy: 'Ñ‰',
  shcy: 'Ñˆ',
  shortmid: 'âˆ£',
  shortparallel: 'âˆ¥',
  shy: 'Â­',
  sigma: 'Ïƒ',
  sigmaf: 'Ï‚',
  sigmav: 'Ï‚',
  sim: 'âˆ¼',
  simdot: 'â©ª',
  sime: 'â‰ƒ',
  simeq: 'â‰ƒ',
  simg: 'âªž',
  simgE: 'âª ',
  siml: 'âª',
  simlE: 'âªŸ',
  simne: 'â‰†',
  simplus: 'â¨¤',
  simrarr: 'â¥²',
  slarr: 'â†',
  smallsetminus: 'âˆ–',
  smashp: 'â¨³',
  smeparsl: 'â§¤',
  smid: 'âˆ£',
  smile: 'âŒ£',
  smt: 'âªª',
  smte: 'âª¬',
  smtes: 'âª¬ï¸€',
  softcy: 'ÑŒ',
  sol: '/',
  solb: 'â§„',
  solbar: 'âŒ¿',
  sopf: 'ð•¤',
  spades: 'â™ ',
  spadesuit: 'â™ ',
  spar: 'âˆ¥',
  sqcap: 'âŠ“',
  sqcaps: 'âŠ“ï¸€',
  sqcup: 'âŠ”',
  sqcups: 'âŠ”ï¸€',
  sqsub: 'âŠ',
  sqsube: 'âŠ‘',
  sqsubset: 'âŠ',
  sqsubseteq: 'âŠ‘',
  sqsup: 'âŠ',
  sqsupe: 'âŠ’',
  sqsupset: 'âŠ',
  sqsupseteq: 'âŠ’',
  squ: 'â–¡',
  square: 'â–¡',
  squarf: 'â–ª',
  squf: 'â–ª',
  srarr: 'â†’',
  sscr: 'ð“ˆ',
  ssetmn: 'âˆ–',
  ssmile: 'âŒ£',
  sstarf: 'â‹†',
  star: 'â˜†',
  starf: 'â˜…',
  straightepsilon: 'Ïµ',
  straightphi: 'Ï•',
  strns: 'Â¯',
  sub: 'âŠ‚',
  subE: 'â«…',
  subdot: 'âª½',
  sube: 'âŠ†',
  subedot: 'â«ƒ',
  submult: 'â«',
  subnE: 'â«‹',
  subne: 'âŠŠ',
  subplus: 'âª¿',
  subrarr: 'â¥¹',
  subset: 'âŠ‚',
  subseteq: 'âŠ†',
  subseteqq: 'â«…',
  subsetneq: 'âŠŠ',
  subsetneqq: 'â«‹',
  subsim: 'â«‡',
  subsub: 'â«•',
  subsup: 'â«“',
  succ: 'â‰»',
  succapprox: 'âª¸',
  succcurlyeq: 'â‰½',
  succeq: 'âª°',
  succnapprox: 'âªº',
  succneqq: 'âª¶',
  succnsim: 'â‹©',
  succsim: 'â‰¿',
  sum: 'âˆ‘',
  sung: 'â™ª',
  sup1: 'Â¹',
  sup2: 'Â²',
  sup3: 'Â³',
  sup: 'âŠƒ',
  supE: 'â«†',
  supdot: 'âª¾',
  supdsub: 'â«˜',
  supe: 'âŠ‡',
  supedot: 'â«„',
  suphsol: 'âŸ‰',
  suphsub: 'â«—',
  suplarr: 'â¥»',
  supmult: 'â«‚',
  supnE: 'â«Œ',
  supne: 'âŠ‹',
  supplus: 'â«€',
  supset: 'âŠƒ',
  supseteq: 'âŠ‡',
  supseteqq: 'â«†',
  supsetneq: 'âŠ‹',
  supsetneqq: 'â«Œ',
  supsim: 'â«ˆ',
  supsub: 'â«”',
  supsup: 'â«–',
  swArr: 'â‡™',
  swarhk: 'â¤¦',
  swarr: 'â†™',
  swarrow: 'â†™',
  swnwar: 'â¤ª',
  szlig: 'ÃŸ',
  target: 'âŒ–',
  tau: 'Ï„',
  tbrk: 'âŽ´',
  tcaron: 'Å¥',
  tcedil: 'Å£',
  tcy: 'Ñ‚',
  tdot: 'âƒ›',
  telrec: 'âŒ•',
  tfr: 'ð”±',
  there4: 'âˆ´',
  therefore: 'âˆ´',
  theta: 'Î¸',
  thetasym: 'Ï‘',
  thetav: 'Ï‘',
  thickapprox: 'â‰ˆ',
  thicksim: 'âˆ¼',
  thinsp: 'â€‰',
  thkap: 'â‰ˆ',
  thksim: 'âˆ¼',
  thorn: 'Ã¾',
  tilde: 'Ëœ',
  times: 'Ã—',
  timesb: 'âŠ ',
  timesbar: 'â¨±',
  timesd: 'â¨°',
  tint: 'âˆ­',
  toea: 'â¤¨',
  top: 'âŠ¤',
  topbot: 'âŒ¶',
  topcir: 'â«±',
  topf: 'ð•¥',
  topfork: 'â«š',
  tosa: 'â¤©',
  tprime: 'â€´',
  trade: 'â„¢',
  triangle: 'â–µ',
  triangledown: 'â–¿',
  triangleleft: 'â—ƒ',
  trianglelefteq: 'âŠ´',
  triangleq: 'â‰œ',
  triangleright: 'â–¹',
  trianglerighteq: 'âŠµ',
  tridot: 'â—¬',
  trie: 'â‰œ',
  triminus: 'â¨º',
  triplus: 'â¨¹',
  trisb: 'â§',
  tritime: 'â¨»',
  trpezium: 'â¢',
  tscr: 'ð“‰',
  tscy: 'Ñ†',
  tshcy: 'Ñ›',
  tstrok: 'Å§',
  twixt: 'â‰¬',
  twoheadleftarrow: 'â†ž',
  twoheadrightarrow: 'â† ',
  uArr: 'â‡‘',
  uHar: 'â¥£',
  uacute: 'Ãº',
  uarr: 'â†‘',
  ubrcy: 'Ñž',
  ubreve: 'Å­',
  ucirc: 'Ã»',
  ucy: 'Ñƒ',
  udarr: 'â‡…',
  udblac: 'Å±',
  udhar: 'â¥®',
  ufisht: 'â¥¾',
  ufr: 'ð”²',
  ugrave: 'Ã¹',
  uharl: 'â†¿',
  uharr: 'â†¾',
  uhblk: 'â–€',
  ulcorn: 'âŒœ',
  ulcorner: 'âŒœ',
  ulcrop: 'âŒ',
  ultri: 'â—¸',
  umacr: 'Å«',
  uml: 'Â¨',
  uogon: 'Å³',
  uopf: 'ð•¦',
  uparrow: 'â†‘',
  updownarrow: 'â†•',
  upharpoonleft: 'â†¿',
  upharpoonright: 'â†¾',
  uplus: 'âŠŽ',
  upsi: 'Ï…',
  upsih: 'Ï’',
  upsilon: 'Ï…',
  upuparrows: 'â‡ˆ',
  urcorn: 'âŒ',
  urcorner: 'âŒ',
  urcrop: 'âŒŽ',
  uring: 'Å¯',
  urtri: 'â—¹',
  uscr: 'ð“Š',
  utdot: 'â‹°',
  utilde: 'Å©',
  utri: 'â–µ',
  utrif: 'â–´',
  uuarr: 'â‡ˆ',
  uuml: 'Ã¼',
  uwangle: 'â¦§',
  vArr: 'â‡•',
  vBar: 'â«¨',
  vBarv: 'â«©',
  vDash: 'âŠ¨',
  vangrt: 'â¦œ',
  varepsilon: 'Ïµ',
  varkappa: 'Ï°',
  varnothing: 'âˆ…',
  varphi: 'Ï•',
  varpi: 'Ï–',
  varpropto: 'âˆ',
  varr: 'â†•',
  varrho: 'Ï±',
  varsigma: 'Ï‚',
  varsubsetneq: 'âŠŠï¸€',
  varsubsetneqq: 'â«‹ï¸€',
  varsupsetneq: 'âŠ‹ï¸€',
  varsupsetneqq: 'â«Œï¸€',
  vartheta: 'Ï‘',
  vartriangleleft: 'âŠ²',
  vartriangleright: 'âŠ³',
  vcy: 'Ð²',
  vdash: 'âŠ¢',
  vee: 'âˆ¨',
  veebar: 'âŠ»',
  veeeq: 'â‰š',
  vellip: 'â‹®',
  verbar: '|',
  vert: '|',
  vfr: 'ð”³',
  vltri: 'âŠ²',
  vnsub: 'âŠ‚âƒ’',
  vnsup: 'âŠƒâƒ’',
  vopf: 'ð•§',
  vprop: 'âˆ',
  vrtri: 'âŠ³',
  vscr: 'ð“‹',
  vsubnE: 'â«‹ï¸€',
  vsubne: 'âŠŠï¸€',
  vsupnE: 'â«Œï¸€',
  vsupne: 'âŠ‹ï¸€',
  vzigzag: 'â¦š',
  wcirc: 'Åµ',
  wedbar: 'â©Ÿ',
  wedge: 'âˆ§',
  wedgeq: 'â‰™',
  weierp: 'â„˜',
  wfr: 'ð”´',
  wopf: 'ð•¨',
  wp: 'â„˜',
  wr: 'â‰€',
  wreath: 'â‰€',
  wscr: 'ð“Œ',
  xcap: 'â‹‚',
  xcirc: 'â—¯',
  xcup: 'â‹ƒ',
  xdtri: 'â–½',
  xfr: 'ð”µ',
  xhArr: 'âŸº',
  xharr: 'âŸ·',
  xi: 'Î¾',
  xlArr: 'âŸ¸',
  xlarr: 'âŸµ',
  xmap: 'âŸ¼',
  xnis: 'â‹»',
  xodot: 'â¨€',
  xopf: 'ð•©',
  xoplus: 'â¨',
  xotime: 'â¨‚',
  xrArr: 'âŸ¹',
  xrarr: 'âŸ¶',
  xscr: 'ð“',
  xsqcup: 'â¨†',
  xuplus: 'â¨„',
  xutri: 'â–³',
  xvee: 'â‹',
  xwedge: 'â‹€',
  yacute: 'Ã½',
  yacy: 'Ñ',
  ycirc: 'Å·',
  ycy: 'Ñ‹',
  yen: 'Â¥',
  yfr: 'ð”¶',
  yicy: 'Ñ—',
  yopf: 'ð•ª',
  yscr: 'ð“Ž',
  yucy: 'ÑŽ',
  yuml: 'Ã¿',
  zacute: 'Åº',
  zcaron: 'Å¾',
  zcy: 'Ð·',
  zdot: 'Å¼',
  zeetrf: 'â„¨',
  zeta: 'Î¶',
  zfr: 'ð”·',
  zhcy: 'Ð¶',
  zigrarr: 'â‡',
  zopf: 'ð•«',
  zscr: 'ð“',
  zwj: 'â€',
  zwnj: 'â€Œ'
};

// To do: next major: use `Object.hasOwn`.
const own$2 = {}.hasOwnProperty;

/**
 * Decode a single character reference (without the `&` or `;`).
 * You probably only need this when youâ€™re building parsers yourself that follow
 * different rules compared to HTML.
 * This is optimized to be tiny in browsers.
 *
 * @param {string} value
 *   `notin` (named), `#123` (deci), `#x123` (hexa).
 * @returns {string|false}
 *   Decoded reference.
 */
function decodeNamedCharacterReference(value) {
  return own$2.call(characterEntities, value) ? characterEntities[value] : false
}

/**
 * Like `Array#splice`, but smarter for giant arrays.
 *
 * `Array#splice` takes all items to be inserted as individual argument which
 * causes a stack overflow in V8 when trying to insert 100k items for instance.
 *
 * Otherwise, this does not return the removed items, and takes `items` as an
 * array instead of rest parameters.
 *
 * @template {unknown} T
 *   Item type.
 * @param {Array<T>} list
 *   List to operate on.
 * @param {number} start
 *   Index to remove/insert at (can be negative).
 * @param {number} remove
 *   Number of items to remove.
 * @param {Array<T>} items
 *   Items to inject into `list`.
 * @returns {undefined}
 *   Nothing.
 */
function splice(list, start, remove, items) {
  const end = list.length;
  let chunkStart = 0;
  /** @type {Array<unknown>} */
  let parameters;

  // Make start between zero and `end` (included).
  if (start < 0) {
    start = -start > end ? 0 : end + start;
  } else {
    start = start > end ? end : start;
  }
  remove = remove > 0 ? remove : 0;

  // No need to chunk the items if thereâ€™s only a couple (10k) items.
  if (items.length < 10000) {
    parameters = Array.from(items);
    parameters.unshift(start, remove);
    // @ts-expect-error Hush, itâ€™s fine.
    list.splice(...parameters);
  } else {
    // Delete `remove` items starting from `start`
    if (remove) list.splice(start, remove);

    // Insert the items in chunks to not cause stack overflows.
    while (chunkStart < items.length) {
      parameters = items.slice(chunkStart, chunkStart + 10000);
      parameters.unshift(start, 0);
      // @ts-expect-error Hush, itâ€™s fine.
      list.splice(...parameters);
      chunkStart += 10000;
      start += 10000;
    }
  }
}

/**
 * Append `items` (an array) at the end of `list` (another array).
 * When `list` was empty, returns `items` instead.
 *
 * This prevents a potentially expensive operation when `list` is empty,
 * and adds items in batches to prevent V8 from hanging.
 *
 * @template {unknown} T
 *   Item type.
 * @param {Array<T>} list
 *   List to operate on.
 * @param {Array<T>} items
 *   Items to add to `list`.
 * @returns {Array<T>}
 *   Either `list` or `items`.
 */
function push(list, items) {
  if (list.length > 0) {
    splice(list, list.length, 0, items);
    return list;
  }
  return items;
}

/**
 * @import {
 *   Extension,
 *   Handles,
 *   HtmlExtension,
 *   NormalizedExtension
 * } from 'micromark-util-types'
 */


const hasOwnProperty = {}.hasOwnProperty;

/**
 * Combine multiple syntax extensions into one.
 *
 * @param {ReadonlyArray<Extension>} extensions
 *   List of syntax extensions.
 * @returns {NormalizedExtension}
 *   A single combined extension.
 */
function combineExtensions(extensions) {
  /** @type {NormalizedExtension} */
  const all = {};
  let index = -1;

  while (++index < extensions.length) {
    syntaxExtension(all, extensions[index]);
  }

  return all
}

/**
 * Merge `extension` into `all`.
 *
 * @param {NormalizedExtension} all
 *   Extension to merge into.
 * @param {Extension} extension
 *   Extension to merge.
 * @returns {undefined}
 *   Nothing.
 */
function syntaxExtension(all, extension) {
  /** @type {keyof Extension} */
  let hook;

  for (hook in extension) {
    const maybe = hasOwnProperty.call(all, hook) ? all[hook] : undefined;
    /** @type {Record<string, unknown>} */
    const left = maybe || (all[hook] = {});
    /** @type {Record<string, unknown> | undefined} */
    const right = extension[hook];
    /** @type {string} */
    let code;

    if (right) {
      for (code in right) {
        if (!hasOwnProperty.call(left, code)) left[code] = [];
        const value = right[code];
        constructs(
          // @ts-expect-error Looks like a list.
          left[code],
          Array.isArray(value) ? value : value ? [value] : []
        );
      }
    }
  }
}

/**
 * Merge `list` into `existing` (both lists of constructs).
 * Mutates `existing`.
 *
 * @param {Array<unknown>} existing
 *   List of constructs to merge into.
 * @param {Array<unknown>} list
 *   List of constructs to merge.
 * @returns {undefined}
 *   Nothing.
 */
function constructs(existing, list) {
  let index = -1;
  /** @type {Array<unknown>} */
  const before = [];

  while (++index < list.length) {
(list[index].add === 'after' ? existing : before).push(list[index]);
  }

  splice(existing, 0, 0, before);
}

/**
 * Turn the number (in string form as either hexa- or plain decimal) coming from
 * a numeric character reference into a character.
 *
 * Sort of like `String.fromCodePoint(Number.parseInt(value, base))`, but makes
 * non-characters and control characters safe.
 *
 * @param {string} value
 *   Value to decode.
 * @param {number} base
 *   Numeric base.
 * @returns {string}
 *   Character.
 */
function decodeNumericCharacterReference(value, base) {
  const code = Number.parseInt(value, base);
  if (
  // C0 except for HT, LF, FF, CR, space.
  code < 9 || code === 11 || code > 13 && code < 32 ||
  // Control character (DEL) of C0, and C1 controls.
  code > 126 && code < 160 ||
  // Lone high surrogates and low surrogates.
  code > 55_295 && code < 57_344 ||
  // Noncharacters.
  code > 64_975 && code < 65_008 || /* eslint-disable no-bitwise */
  (code & 65_535) === 65_535 || (code & 65_535) === 65_534 || /* eslint-enable no-bitwise */
  // Out of range
  code > 1_114_111) {
    return "\uFFFD";
  }
  return String.fromCodePoint(code);
}

/**
 * Normalize an identifier (as found in references, definitions).
 *
 * Collapses markdown whitespace, trim, and then lower- and uppercase.
 *
 * Some characters are considered â€œuppercaseâ€, such as U+03F4 (`Ï´`), but if their
 * lowercase counterpart (U+03B8 (`Î¸`)) is uppercased will result in a different
 * uppercase character (U+0398 (`Î˜`)).
 * So, to get a canonical form, we perform both lower- and uppercase.
 *
 * Using uppercase last makes sure keys will never interact with default
 * prototypal values (such as `constructor`): nothing in the prototype of
 * `Object` is uppercase.
 *
 * @param {string} value
 *   Identifier to normalize.
 * @returns {string}
 *   Normalized identifier.
 */
function normalizeIdentifier(value) {
  return value
  // Collapse markdown whitespace.
  .replace(/[\t\n\r ]+/g, " ")
  // Trim.
  .replace(/^ | $/g, '')
  // Some characters are considered â€œuppercaseâ€, but if their lowercase
  // counterpart is uppercased will result in a different uppercase
  // character.
  // Hence, to get that form, we perform both lower- and uppercase.
  // Upper case makes sure keys will not interact with default prototypal
  // methods: no method is uppercase.
  .toLowerCase().toUpperCase();
}

/**
 * @import {Code} from 'micromark-util-types'
 */

/**
 * Check whether the character code represents an ASCII alpha (`a` through `z`,
 * case insensitive).
 *
 * An **ASCII alpha** is an ASCII upper alpha or ASCII lower alpha.
 *
 * An **ASCII upper alpha** is a character in the inclusive range U+0041 (`A`)
 * to U+005A (`Z`).
 *
 * An **ASCII lower alpha** is a character in the inclusive range U+0061 (`a`)
 * to U+007A (`z`).
 *
 * @param code
 *   Code.
 * @returns {boolean}
 *   Whether it matches.
 */
const asciiAlpha = regexCheck(/[A-Za-z]/);

/**
 * Check whether the character code represents an ASCII alphanumeric (`a`
 * through `z`, case insensitive, or `0` through `9`).
 *
 * An **ASCII alphanumeric** is an ASCII digit (see `asciiDigit`) or ASCII alpha
 * (see `asciiAlpha`).
 *
 * @param code
 *   Code.
 * @returns {boolean}
 *   Whether it matches.
 */
const asciiAlphanumeric = regexCheck(/[\dA-Za-z]/);

/**
 * Check whether the character code represents an ASCII atext.
 *
 * atext is an ASCII alphanumeric (see `asciiAlphanumeric`), or a character in
 * the inclusive ranges U+0023 NUMBER SIGN (`#`) to U+0027 APOSTROPHE (`'`),
 * U+002A ASTERISK (`*`), U+002B PLUS SIGN (`+`), U+002D DASH (`-`), U+002F
 * SLASH (`/`), U+003D EQUALS TO (`=`), U+003F QUESTION MARK (`?`), U+005E
 * CARET (`^`) to U+0060 GRAVE ACCENT (`` ` ``), or U+007B LEFT CURLY BRACE
 * (`{`) to U+007E TILDE (`~`).
 *
 * See:
 * **\[RFC5322]**:
 * [Internet Message Format](https://tools.ietf.org/html/rfc5322).
 * P. Resnick.
 * IETF.
 *
 * @param code
 *   Code.
 * @returns {boolean}
 *   Whether it matches.
 */
const asciiAtext = regexCheck(/[#-'*+\--9=?A-Z^-~]/);

/**
 * Check whether a character code is an ASCII control character.
 *
 * An **ASCII control** is a character in the inclusive range U+0000 NULL (NUL)
 * to U+001F (US), or U+007F (DEL).
 *
 * @param {Code} code
 *   Code.
 * @returns {boolean}
 *   Whether it matches.
 */
function asciiControl(code) {
  return (
    // Special whitespace codes (which have negative values), C0 and Control
    // character DEL
    code !== null && (code < 32 || code === 127)
  );
}

/**
 * Check whether the character code represents an ASCII digit (`0` through `9`).
 *
 * An **ASCII digit** is a character in the inclusive range U+0030 (`0`) to
 * U+0039 (`9`).
 *
 * @param code
 *   Code.
 * @returns {boolean}
 *   Whether it matches.
 */
const asciiDigit = regexCheck(/\d/);

/**
 * Check whether the character code represents an ASCII hex digit (`a` through
 * `f`, case insensitive, or `0` through `9`).
 *
 * An **ASCII hex digit** is an ASCII digit (see `asciiDigit`), ASCII upper hex
 * digit, or an ASCII lower hex digit.
 *
 * An **ASCII upper hex digit** is a character in the inclusive range U+0041
 * (`A`) to U+0046 (`F`).
 *
 * An **ASCII lower hex digit** is a character in the inclusive range U+0061
 * (`a`) to U+0066 (`f`).
 *
 * @param code
 *   Code.
 * @returns {boolean}
 *   Whether it matches.
 */
const asciiHexDigit = regexCheck(/[\dA-Fa-f]/);

/**
 * Check whether the character code represents ASCII punctuation.
 *
 * An **ASCII punctuation** is a character in the inclusive ranges U+0021
 * EXCLAMATION MARK (`!`) to U+002F SLASH (`/`), U+003A COLON (`:`) to U+0040 AT
 * SIGN (`@`), U+005B LEFT SQUARE BRACKET (`[`) to U+0060 GRAVE ACCENT
 * (`` ` ``), or U+007B LEFT CURLY BRACE (`{`) to U+007E TILDE (`~`).
 *
 * @param code
 *   Code.
 * @returns {boolean}
 *   Whether it matches.
 */
const asciiPunctuation = regexCheck(/[!-/:-@[-`{-~]/);

/**
 * Check whether a character code is a markdown line ending.
 *
 * A **markdown line ending** is the virtual characters M-0003 CARRIAGE RETURN
 * LINE FEED (CRLF), M-0004 LINE FEED (LF) and M-0005 CARRIAGE RETURN (CR).
 *
 * In micromark, the actual character U+000A LINE FEED (LF) and U+000D CARRIAGE
 * RETURN (CR) are replaced by these virtual characters depending on whether
 * they occurred together.
 *
 * @param {Code} code
 *   Code.
 * @returns {boolean}
 *   Whether it matches.
 */
function markdownLineEnding(code) {
  return code !== null && code < -2;
}

/**
 * Check whether a character code is a markdown line ending (see
 * `markdownLineEnding`) or markdown space (see `markdownSpace`).
 *
 * @param {Code} code
 *   Code.
 * @returns {boolean}
 *   Whether it matches.
 */
function markdownLineEndingOrSpace(code) {
  return code !== null && (code < 0 || code === 32);
}

/**
 * Check whether a character code is a markdown space.
 *
 * A **markdown space** is the concrete character U+0020 SPACE (SP) and the
 * virtual characters M-0001 VIRTUAL SPACE (VS) and M-0002 HORIZONTAL TAB (HT).
 *
 * In micromark, the actual character U+0009 CHARACTER TABULATION (HT) is
 * replaced by one M-0002 HORIZONTAL TAB (HT) and between 0 and 3 M-0001 VIRTUAL
 * SPACE (VS) characters, depending on the column at which the tab occurred.
 *
 * @param {Code} code
 *   Code.
 * @returns {boolean}
 *   Whether it matches.
 */
function markdownSpace(code) {
  return code === -2 || code === -1 || code === 32;
}

// Size note: removing ASCII from the regex and using `asciiPunctuation` here
// In fact adds to the bundle size.
/**
 * Check whether the character code represents Unicode punctuation.
 *
 * A **Unicode punctuation** is a character in the Unicode `Pc` (Punctuation,
 * Connector), `Pd` (Punctuation, Dash), `Pe` (Punctuation, Close), `Pf`
 * (Punctuation, Final quote), `Pi` (Punctuation, Initial quote), `Po`
 * (Punctuation, Other), or `Ps` (Punctuation, Open) categories, or an ASCII
 * punctuation (see `asciiPunctuation`).
 *
 * See:
 * **\[UNICODE]**:
 * [The Unicode Standard](https://www.unicode.org/versions/).
 * Unicode Consortium.
 *
 * @param code
 *   Code.
 * @returns
 *   Whether it matches.
 */
const unicodePunctuation = regexCheck(/\p{P}|\p{S}/u);

/**
 * Check whether the character code represents Unicode whitespace.
 *
 * Note that this does handle micromark specific markdown whitespace characters.
 * See `markdownLineEndingOrSpace` to check that.
 *
 * A **Unicode whitespace** is a character in the Unicode `Zs` (Separator,
 * Space) category, or U+0009 CHARACTER TABULATION (HT), U+000A LINE FEED (LF),
 * U+000C (FF), or U+000D CARRIAGE RETURN (CR) (**\[UNICODE]**).
 *
 * See:
 * **\[UNICODE]**:
 * [The Unicode Standard](https://www.unicode.org/versions/).
 * Unicode Consortium.
 *
 * @param code
 *   Code.
 * @returns
 *   Whether it matches.
 */
const unicodeWhitespace = regexCheck(/\s/);

/**
 * Create a code check from a regex.
 *
 * @param {RegExp} regex
 *   Expression.
 * @returns {(code: Code) => boolean}
 *   Check.
 */
function regexCheck(regex) {
  return check;

  /**
   * Check whether a code matches the bound regex.
   *
   * @param {Code} code
   *   Character code.
   * @returns {boolean}
   *   Whether the character code matches the bound regex.
   */
  function check(code) {
    return code !== null && code > -1 && regex.test(String.fromCharCode(code));
  }
}

/**
 * @import {Effects, State, TokenType} from 'micromark-util-types'
 */


// To do: implement `spaceOrTab`, `spaceOrTabMinMax`, `spaceOrTabWithOptions`.

/**
 * Parse spaces and tabs.
 *
 * There is no `nok` parameter:
 *
 * *   spaces in markdown are often optional, in which case this factory can be
 *     used and `ok` will be switched to whether spaces were found or not
 * *   one line ending or space can be detected with `markdownSpace(code)` right
 *     before using `factorySpace`
 *
 * ###### Examples
 *
 * Where `â‰` represents a tab (plus how much it expands) and `â ` represents a
 * single space.
 *
 * ```markdown
 * â‰
 * â â â â 
 * â‰â 
 * ```
 *
 * @param {Effects} effects
 *   Context.
 * @param {State} ok
 *   State switched to when successful.
 * @param {TokenType} type
 *   Type (`' \t'`).
 * @param {number | undefined} [max=Infinity]
 *   Max (exclusive).
 * @returns {State}
 *   Start state.
 */
function factorySpace(effects, ok, type, max) {
  const limit = max ? max - 1 : Number.POSITIVE_INFINITY;
  let size = 0;
  return start;

  /** @type {State} */
  function start(code) {
    if (markdownSpace(code)) {
      effects.enter(type);
      return prefix(code);
    }
    return ok(code);
  }

  /** @type {State} */
  function prefix(code) {
    if (markdownSpace(code) && size++ < limit) {
      effects.consume(code);
      return prefix;
    }
    effects.exit(type);
    return ok(code);
  }
}

/**
 * @import {
 *   InitialConstruct,
 *   Initializer,
 *   State,
 *   TokenizeContext,
 *   Token
 * } from 'micromark-util-types'
 */

/** @type {InitialConstruct} */
const content$1 = {
  tokenize: initializeContent
};

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Initializer}
 *   Content.
 */
function initializeContent(effects) {
  const contentStart = effects.attempt(this.parser.constructs.contentInitial, afterContentStartConstruct, paragraphInitial);
  /** @type {Token} */
  let previous;
  return contentStart;

  /** @type {State} */
  function afterContentStartConstruct(code) {
    if (code === null) {
      effects.consume(code);
      return;
    }
    effects.enter("lineEnding");
    effects.consume(code);
    effects.exit("lineEnding");
    return factorySpace(effects, contentStart, "linePrefix");
  }

  /** @type {State} */
  function paragraphInitial(code) {
    effects.enter("paragraph");
    return lineStart(code);
  }

  /** @type {State} */
  function lineStart(code) {
    const token = effects.enter("chunkText", {
      contentType: "text",
      previous
    });
    if (previous) {
      previous.next = token;
    }
    previous = token;
    return data(code);
  }

  /** @type {State} */
  function data(code) {
    if (code === null) {
      effects.exit("chunkText");
      effects.exit("paragraph");
      effects.consume(code);
      return;
    }
    if (markdownLineEnding(code)) {
      effects.consume(code);
      effects.exit("chunkText");
      return lineStart;
    }

    // Data.
    effects.consume(code);
    return data;
  }
}

/**
 * @import {
 *   Construct,
 *   ContainerState,
 *   InitialConstruct,
 *   Initializer,
 *   Point,
 *   State,
 *   TokenizeContext,
 *   Tokenizer,
 *   Token
 * } from 'micromark-util-types'
 */

/** @type {InitialConstruct} */
const document$1 = {
  tokenize: initializeDocument
};

/** @type {Construct} */
const containerConstruct = {
  tokenize: tokenizeContainer
};

/**
 * @this {TokenizeContext}
 *   Self.
 * @type {Initializer}
 *   Initializer.
 */
function initializeDocument(effects) {
  const self = this;
  /** @type {Array<StackItem>} */
  const stack = [];
  let continued = 0;
  /** @type {TokenizeContext | undefined} */
  let childFlow;
  /** @type {Token | undefined} */
  let childToken;
  /** @type {number} */
  let lineStartOffset;
  return start;

  /** @type {State} */
  function start(code) {
    // First we iterate through the open blocks, starting with the root
    // document, and descending through last children down to the last open
    // block.
    // Each block imposes a condition that the line must satisfy if the block is
    // to remain open.
    // For example, a block quote requires a `>` character.
    // A paragraph requires a non-blank line.
    // In this phase we may match all or just some of the open blocks.
    // But we cannot close unmatched blocks yet, because we may have a lazy
    // continuation line.
    if (continued < stack.length) {
      const item = stack[continued];
      self.containerState = item[1];
      return effects.attempt(item[0].continuation, documentContinue, checkNewContainers)(code);
    }

    // Done.
    return checkNewContainers(code);
  }

  /** @type {State} */
  function documentContinue(code) {
    continued++;

    // Note: this field is called `_closeFlow` but it also closes containers.
    // Perhaps a good idea to rename it but itâ€™s already used in the wild by
    // extensions.
    if (self.containerState._closeFlow) {
      self.containerState._closeFlow = undefined;
      if (childFlow) {
        closeFlow();
      }

      // Note: this algorithm for moving events around is similar to the
      // algorithm when dealing with lazy lines in `writeToChild`.
      const indexBeforeExits = self.events.length;
      let indexBeforeFlow = indexBeforeExits;
      /** @type {Point | undefined} */
      let point;

      // Find the flow chunk.
      while (indexBeforeFlow--) {
        if (self.events[indexBeforeFlow][0] === 'exit' && self.events[indexBeforeFlow][1].type === "chunkFlow") {
          point = self.events[indexBeforeFlow][1].end;
          break;
        }
      }
      exitContainers(continued);

      // Fix positions.
      let index = indexBeforeExits;
      while (index < self.events.length) {
        self.events[index][1].end = {
          ...point
        };
        index++;
      }

      // Inject the exits earlier (theyâ€™re still also at the end).
      splice(self.events, indexBeforeFlow + 1, 0, self.events.slice(indexBeforeExits));

      // Discard the duplicate exits.
      self.events.length = index;
      return checkNewContainers(code);
    }
    return start(code);
  }

  /** @type {State} */
  function checkNewContainers(code) {
    // Next, after consuming the continuation markers for existing blocks, we
    // look for new block starts (e.g. `>` for a block quote).
    // If we encounter a new block start, we close any blocks unmatched in
    // step 1 before creating the new block as a child of the last matched
    // block.
    if (continued === stack.length) {
      // No need to `check` whether thereâ€™s a container, of `exitContainers`
      // would be moot.
      // We can instead immediately `attempt` to parse one.
      if (!childFlow) {
        return documentContinued(code);
      }

      // If we have concrete content, such as block HTML or fenced code,
      // we canâ€™t have containers â€œpierceâ€ into them, so we can immediately
      // start.
      if (childFlow.currentConstruct && childFlow.currentConstruct.concrete) {
        return flowStart(code);
      }

      // If we do have flow, it could still be a blank line,
      // but weâ€™d be interrupting it w/ a new container if thereâ€™s a current
      // construct.
      // To do: next major: remove `_gfmTableDynamicInterruptHack` (no longer
      // needed in micromark-extension-gfm-table@1.0.6).
      self.interrupt = Boolean(childFlow.currentConstruct && !childFlow._gfmTableDynamicInterruptHack);
    }

    // Check if there is a new container.
    self.containerState = {};
    return effects.check(containerConstruct, thereIsANewContainer, thereIsNoNewContainer)(code);
  }

  /** @type {State} */
  function thereIsANewContainer(code) {
    if (childFlow) closeFlow();
    exitContainers(continued);
    return documentContinued(code);
  }

  /** @type {State} */
  function thereIsNoNewContainer(code) {
    self.parser.lazy[self.now().line] = continued !== stack.length;
    lineStartOffset = self.now().offset;
    return flowStart(code);
  }

  /** @type {State} */
  function documentContinued(code) {
    // Try new containers.
    self.containerState = {};
    return effects.attempt(containerConstruct, containerContinue, flowStart)(code);
  }

  /** @type {State} */
  function containerContinue(code) {
    continued++;
    stack.push([self.currentConstruct, self.containerState]);
    // Try another.
    return documentContinued(code);
  }

  /** @type {State} */
  function flowStart(code) {
    if (code === null) {
      if (childFlow) closeFlow();
      exitContainers(0);
      effects.consume(code);
      return;
    }
    childFlow = childFlow || self.parser.flow(self.now());
    effects.enter("chunkFlow", {
      _tokenizer: childFlow,
      contentType: "flow",
      previous: childToken
    });
    return flowContinue(code);
  }

  /** @type {State} */
  function flowContinue(code) {
    if (code === null) {
      writeToChild(effects.exit("chunkFlow"), true);
      exitContainers(0);
      effects.consume(code);
      return;
    }
    if (markdownLineEnding(code)) {
      effects.consume(code);
      writeToChild(effects.exit("chunkFlow"));
      // Get ready for the next line.
      continued = 0;
      self.interrupt = undefined;
      return start;
    }
    effects.consume(code);
    return flowContinue;
  }

  /**
   * @param {Token} token
   *   Token.
   * @param {boolean | undefined} [endOfFile]
   *   Whether the token is at the end of the file (default: `false`).
   * @returns {undefined}
   *   Nothing.
   */
  function writeToChild(token, endOfFile) {
    const stream = self.sliceStream(token);
    if (endOfFile) stream.push(null);
    token.previous = childToken;
    if (childToken) childToken.next = token;
    childToken = token;
    childFlow.defineSkip(token.start);
    childFlow.write(stream);

    // Alright, so we just added a lazy line:
    //
    // ```markdown
    // > a
    // b.
    //
    // Or:
    //
    // > ~~~c
    // d
    //
    // Or:
    //
    // > | e |
    // f
    // ```
    //
    // The construct in the second example (fenced code) does not accept lazy
    // lines, so it marked itself as done at the end of its first line, and
    // then the content construct parses `d`.
    // Most constructs in markdown match on the first line: if the first line
    // forms a construct, a non-lazy line canâ€™t â€œunmakeâ€ it.
    //
    // The construct in the third example is potentially a GFM table, and
    // those are *weird*.
    // It *could* be a table, from the first line, if the following line
    // matches a condition.
    // In this case, that second line is lazy, which â€œunmakesâ€ the first line
    // and turns the whole into one content block.
    //
    // Weâ€™ve now parsed the non-lazy and the lazy line, and can figure out
    // whether the lazy line started a new flow block.
    // If it did, we exit the current containers between the two flow blocks.
    if (self.parser.lazy[token.start.line]) {
      let index = childFlow.events.length;
      while (index--) {
        if (
        // The token starts before the line endingâ€¦
        childFlow.events[index][1].start.offset < lineStartOffset && (
        // â€¦and either is not ended yetâ€¦
        !childFlow.events[index][1].end ||
        // â€¦or ends after it.
        childFlow.events[index][1].end.offset > lineStartOffset)) {
          // Exit: thereâ€™s still something open, which means itâ€™s a lazy line
          // part of something.
          return;
        }
      }

      // Note: this algorithm for moving events around is similar to the
      // algorithm when closing flow in `documentContinue`.
      const indexBeforeExits = self.events.length;
      let indexBeforeFlow = indexBeforeExits;
      /** @type {boolean | undefined} */
      let seen;
      /** @type {Point | undefined} */
      let point;

      // Find the previous chunk (the one before the lazy line).
      while (indexBeforeFlow--) {
        if (self.events[indexBeforeFlow][0] === 'exit' && self.events[indexBeforeFlow][1].type === "chunkFlow") {
          if (seen) {
            point = self.events[indexBeforeFlow][1].end;
            break;
          }
          seen = true;
        }
      }
      exitContainers(continued);

      // Fix positions.
      index = indexBeforeExits;
      while (index < self.events.length) {
        self.events[index][1].end = {
          ...point
        };
        index++;
      }

      // Inject the exits earlier (theyâ€™re still also at the end).
      splice(self.events, indexBeforeFlow + 1, 0, self.events.slice(indexBeforeExits));

      // Discard the duplicate exits.
      self.events.length = index;
    }
  }

  /**
   * @param {number} size
   *   Size.
   * @returns {undefined}
   *   Nothing.
   */
  function exitContainers(size) {
    let index = stack.length;

    // Exit open containers.
    while (index-- > size) {
      const entry = stack[index];
      self.containerState = entry[1];
      entry[0].exit.call(self, effects);
    }
    stack.length = size;
  }
  function closeFlow() {
    childFlow.write([null]);
    childToken = undefined;
    childFlow = undefined;
    self.containerState._closeFlow = undefined;
  }
}

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 *   Tokenizer.
 */
function tokenizeContainer(effects, ok, nok) {
  // Always populated by defaults.

  return factorySpace(effects, effects.attempt(this.parser.constructs.document, ok, nok), "linePrefix", this.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4);
}

/**
 * @import {Code} from 'micromark-util-types'
 */

/**
 * Classify whether a code represents whitespace, punctuation, or something
 * else.
 *
 * Used for attention (emphasis, strong), whose sequences can open or close
 * based on the class of surrounding characters.
 *
 * > ðŸ‘‰ **Note**: eof (`null`) is seen as whitespace.
 *
 * @param {Code} code
 *   Code.
 * @returns {typeof constants.characterGroupWhitespace | typeof constants.characterGroupPunctuation | undefined}
 *   Group.
 */
function classifyCharacter(code) {
  if (code === null || markdownLineEndingOrSpace(code) || unicodeWhitespace(code)) {
    return 1;
  }
  if (unicodePunctuation(code)) {
    return 2;
  }
}

/**
 * @import {Event, Resolver, TokenizeContext} from 'micromark-util-types'
 */

/**
 * Call all `resolveAll`s.
 *
 * @param {ReadonlyArray<{resolveAll?: Resolver | undefined}>} constructs
 *   List of constructs, optionally with `resolveAll`s.
 * @param {Array<Event>} events
 *   List of events.
 * @param {TokenizeContext} context
 *   Context used by `tokenize`.
 * @returns {Array<Event>}
 *   Changed events.
 */
function resolveAll(constructs, events, context) {
  /** @type {Array<Resolver>} */
  const called = [];
  let index = -1;

  while (++index < constructs.length) {
    const resolve = constructs[index].resolveAll;

    if (resolve && !called.includes(resolve)) {
      events = resolve(events, context);
      called.push(resolve);
    }
  }

  return events
}

/**
 * @import {
 *   Code,
 *   Construct,
 *   Event,
 *   Point,
 *   Resolver,
 *   State,
 *   TokenizeContext,
 *   Tokenizer,
 *   Token
 * } from 'micromark-util-types'
 */

/** @type {Construct} */
const attention = {
  name: 'attention',
  resolveAll: resolveAllAttention,
  tokenize: tokenizeAttention
};

/**
 * Take all events and resolve attention to emphasis or strong.
 *
 * @type {Resolver}
 */
// eslint-disable-next-line complexity
function resolveAllAttention(events, context) {
  let index = -1;
  /** @type {number} */
  let open;
  /** @type {Token} */
  let group;
  /** @type {Token} */
  let text;
  /** @type {Token} */
  let openingSequence;
  /** @type {Token} */
  let closingSequence;
  /** @type {number} */
  let use;
  /** @type {Array<Event>} */
  let nextEvents;
  /** @type {number} */
  let offset;

  // Walk through all events.
  //
  // Note: performance of this is fine on an mb of normal markdown, but itâ€™s
  // a bottleneck for malicious stuff.
  while (++index < events.length) {
    // Find a token that can close.
    if (events[index][0] === 'enter' && events[index][1].type === 'attentionSequence' && events[index][1]._close) {
      open = index;

      // Now walk back to find an opener.
      while (open--) {
        // Find a token that can open the closer.
        if (events[open][0] === 'exit' && events[open][1].type === 'attentionSequence' && events[open][1]._open &&
        // If the markers are the same:
        context.sliceSerialize(events[open][1]).charCodeAt(0) === context.sliceSerialize(events[index][1]).charCodeAt(0)) {
          // If the opening can close or the closing can open,
          // and the close size *is not* a multiple of three,
          // but the sum of the opening and closing size *is* multiple of three,
          // then donâ€™t match.
          if ((events[open][1]._close || events[index][1]._open) && (events[index][1].end.offset - events[index][1].start.offset) % 3 && !((events[open][1].end.offset - events[open][1].start.offset + events[index][1].end.offset - events[index][1].start.offset) % 3)) {
            continue;
          }

          // Number of markers to use from the sequence.
          use = events[open][1].end.offset - events[open][1].start.offset > 1 && events[index][1].end.offset - events[index][1].start.offset > 1 ? 2 : 1;
          const start = {
            ...events[open][1].end
          };
          const end = {
            ...events[index][1].start
          };
          movePoint(start, -use);
          movePoint(end, use);
          openingSequence = {
            type: use > 1 ? "strongSequence" : "emphasisSequence",
            start,
            end: {
              ...events[open][1].end
            }
          };
          closingSequence = {
            type: use > 1 ? "strongSequence" : "emphasisSequence",
            start: {
              ...events[index][1].start
            },
            end
          };
          text = {
            type: use > 1 ? "strongText" : "emphasisText",
            start: {
              ...events[open][1].end
            },
            end: {
              ...events[index][1].start
            }
          };
          group = {
            type: use > 1 ? "strong" : "emphasis",
            start: {
              ...openingSequence.start
            },
            end: {
              ...closingSequence.end
            }
          };
          events[open][1].end = {
            ...openingSequence.start
          };
          events[index][1].start = {
            ...closingSequence.end
          };
          nextEvents = [];

          // If there are more markers in the opening, add them before.
          if (events[open][1].end.offset - events[open][1].start.offset) {
            nextEvents = push(nextEvents, [['enter', events[open][1], context], ['exit', events[open][1], context]]);
          }

          // Opening.
          nextEvents = push(nextEvents, [['enter', group, context], ['enter', openingSequence, context], ['exit', openingSequence, context], ['enter', text, context]]);

          // Always populated by defaults.

          // Between.
          nextEvents = push(nextEvents, resolveAll(context.parser.constructs.insideSpan.null, events.slice(open + 1, index), context));

          // Closing.
          nextEvents = push(nextEvents, [['exit', text, context], ['enter', closingSequence, context], ['exit', closingSequence, context], ['exit', group, context]]);

          // If there are more markers in the closing, add them after.
          if (events[index][1].end.offset - events[index][1].start.offset) {
            offset = 2;
            nextEvents = push(nextEvents, [['enter', events[index][1], context], ['exit', events[index][1], context]]);
          } else {
            offset = 0;
          }
          splice(events, open - 1, index - open + 3, nextEvents);
          index = open + nextEvents.length - offset - 2;
          break;
        }
      }
    }
  }

  // Remove remaining sequences.
  index = -1;
  while (++index < events.length) {
    if (events[index][1].type === 'attentionSequence') {
      events[index][1].type = 'data';
    }
  }
  return events;
}

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeAttention(effects, ok) {
  const attentionMarkers = this.parser.constructs.attentionMarkers.null;
  const previous = this.previous;
  const before = classifyCharacter(previous);

  /** @type {NonNullable<Code>} */
  let marker;
  return start;

  /**
   * Before a sequence.
   *
   * ```markdown
   * > | **
   *     ^
   * ```
   *
   * @type {State}
   */
  function start(code) {
    marker = code;
    effects.enter('attentionSequence');
    return inside(code);
  }

  /**
   * In a sequence.
   *
   * ```markdown
   * > | **
   *     ^^
   * ```
   *
   * @type {State}
   */
  function inside(code) {
    if (code === marker) {
      effects.consume(code);
      return inside;
    }
    const token = effects.exit('attentionSequence');

    // To do: next major: move this to resolver, just like `markdown-rs`.
    const after = classifyCharacter(code);

    // Always populated by defaults.

    const open = !after || after === 2 && before || attentionMarkers.includes(code);
    const close = !before || before === 2 && after || attentionMarkers.includes(previous);
    token._open = Boolean(marker === 42 ? open : open && (before || !close));
    token._close = Boolean(marker === 42 ? close : close && (after || !open));
    return ok(code);
  }
}

/**
 * Move a point a bit.
 *
 * Note: `move` only works inside lines! Itâ€™s not possible to move past other
 * chunks (replacement characters, tabs, or line endings).
 *
 * @param {Point} point
 *   Point.
 * @param {number} offset
 *   Amount to move.
 * @returns {undefined}
 *   Nothing.
 */
function movePoint(point, offset) {
  point.column += offset;
  point.offset += offset;
  point._bufferIndex += offset;
}

/**
 * @import {
 *   Construct,
 *   State,
 *   TokenizeContext,
 *   Tokenizer
 * } from 'micromark-util-types'
 */

/** @type {Construct} */
const autolink = {
  name: 'autolink',
  tokenize: tokenizeAutolink
};

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeAutolink(effects, ok, nok) {
  let size = 0;
  return start;

  /**
   * Start of an autolink.
   *
   * ```markdown
   * > | a<https://example.com>b
   *      ^
   * > | a<user@example.com>b
   *      ^
   * ```
   *
   * @type {State}
   */
  function start(code) {
    effects.enter("autolink");
    effects.enter("autolinkMarker");
    effects.consume(code);
    effects.exit("autolinkMarker");
    effects.enter("autolinkProtocol");
    return open;
  }

  /**
   * After `<`, at protocol or atext.
   *
   * ```markdown
   * > | a<https://example.com>b
   *       ^
   * > | a<user@example.com>b
   *       ^
   * ```
   *
   * @type {State}
   */
  function open(code) {
    if (asciiAlpha(code)) {
      effects.consume(code);
      return schemeOrEmailAtext;
    }
    if (code === 64) {
      return nok(code);
    }
    return emailAtext(code);
  }

  /**
   * At second byte of protocol or atext.
   *
   * ```markdown
   * > | a<https://example.com>b
   *        ^
   * > | a<user@example.com>b
   *        ^
   * ```
   *
   * @type {State}
   */
  function schemeOrEmailAtext(code) {
    // ASCII alphanumeric and `+`, `-`, and `.`.
    if (code === 43 || code === 45 || code === 46 || asciiAlphanumeric(code)) {
      // Count the previous alphabetical from `open` too.
      size = 1;
      return schemeInsideOrEmailAtext(code);
    }
    return emailAtext(code);
  }

  /**
   * In ambiguous protocol or atext.
   *
   * ```markdown
   * > | a<https://example.com>b
   *        ^
   * > | a<user@example.com>b
   *        ^
   * ```
   *
   * @type {State}
   */
  function schemeInsideOrEmailAtext(code) {
    if (code === 58) {
      effects.consume(code);
      size = 0;
      return urlInside;
    }

    // ASCII alphanumeric and `+`, `-`, and `.`.
    if ((code === 43 || code === 45 || code === 46 || asciiAlphanumeric(code)) && size++ < 32) {
      effects.consume(code);
      return schemeInsideOrEmailAtext;
    }
    size = 0;
    return emailAtext(code);
  }

  /**
   * After protocol, in URL.
   *
   * ```markdown
   * > | a<https://example.com>b
   *             ^
   * ```
   *
   * @type {State}
   */
  function urlInside(code) {
    if (code === 62) {
      effects.exit("autolinkProtocol");
      effects.enter("autolinkMarker");
      effects.consume(code);
      effects.exit("autolinkMarker");
      effects.exit("autolink");
      return ok;
    }

    // ASCII control, space, or `<`.
    if (code === null || code === 32 || code === 60 || asciiControl(code)) {
      return nok(code);
    }
    effects.consume(code);
    return urlInside;
  }

  /**
   * In email atext.
   *
   * ```markdown
   * > | a<user.name@example.com>b
   *              ^
   * ```
   *
   * @type {State}
   */
  function emailAtext(code) {
    if (code === 64) {
      effects.consume(code);
      return emailAtSignOrDot;
    }
    if (asciiAtext(code)) {
      effects.consume(code);
      return emailAtext;
    }
    return nok(code);
  }

  /**
   * In label, after at-sign or dot.
   *
   * ```markdown
   * > | a<user.name@example.com>b
   *                 ^       ^
   * ```
   *
   * @type {State}
   */
  function emailAtSignOrDot(code) {
    return asciiAlphanumeric(code) ? emailLabel(code) : nok(code);
  }

  /**
   * In label, where `.` and `>` are allowed.
   *
   * ```markdown
   * > | a<user.name@example.com>b
   *                   ^
   * ```
   *
   * @type {State}
   */
  function emailLabel(code) {
    if (code === 46) {
      effects.consume(code);
      size = 0;
      return emailAtSignOrDot;
    }
    if (code === 62) {
      // Exit, then change the token type.
      effects.exit("autolinkProtocol").type = "autolinkEmail";
      effects.enter("autolinkMarker");
      effects.consume(code);
      effects.exit("autolinkMarker");
      effects.exit("autolink");
      return ok;
    }
    return emailValue(code);
  }

  /**
   * In label, where `.` and `>` are *not* allowed.
   *
   * Though, this is also used in `emailLabel` to parse other values.
   *
   * ```markdown
   * > | a<user.name@ex-ample.com>b
   *                    ^
   * ```
   *
   * @type {State}
   */
  function emailValue(code) {
    // ASCII alphanumeric or `-`.
    if ((code === 45 || asciiAlphanumeric(code)) && size++ < 63) {
      const next = code === 45 ? emailValue : emailLabel;
      effects.consume(code);
      return next;
    }
    return nok(code);
  }
}

/**
 * @import {
 *   Construct,
 *   State,
 *   TokenizeContext,
 *   Tokenizer
 * } from 'micromark-util-types'
 */

/** @type {Construct} */
const blankLine = {
  partial: true,
  tokenize: tokenizeBlankLine
};

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeBlankLine(effects, ok, nok) {
  return start;

  /**
   * Start of blank line.
   *
   * > ðŸ‘‰ **Note**: `â ` represents a space character.
   *
   * ```markdown
   * > | â â âŠ
   *     ^
   * > | âŠ
   *     ^
   * ```
   *
   * @type {State}
   */
  function start(code) {
    return markdownSpace(code) ? factorySpace(effects, after, "linePrefix")(code) : after(code);
  }

  /**
   * At eof/eol, after optional whitespace.
   *
   * > ðŸ‘‰ **Note**: `â ` represents a space character.
   *
   * ```markdown
   * > | â â âŠ
   *       ^
   * > | âŠ
   *     ^
   * ```
   *
   * @type {State}
   */
  function after(code) {
    return code === null || markdownLineEnding(code) ? ok(code) : nok(code);
  }
}

/**
 * @import {
 *   Construct,
 *   Exiter,
 *   State,
 *   TokenizeContext,
 *   Tokenizer
 * } from 'micromark-util-types'
 */

/** @type {Construct} */
const blockQuote = {
  continuation: {
    tokenize: tokenizeBlockQuoteContinuation
  },
  exit,
  name: 'blockQuote',
  tokenize: tokenizeBlockQuoteStart
};

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeBlockQuoteStart(effects, ok, nok) {
  const self = this;
  return start;

  /**
   * Start of block quote.
   *
   * ```markdown
   * > | > a
   *     ^
   * ```
   *
   * @type {State}
   */
  function start(code) {
    if (code === 62) {
      const state = self.containerState;
      if (!state.open) {
        effects.enter("blockQuote", {
          _container: true
        });
        state.open = true;
      }
      effects.enter("blockQuotePrefix");
      effects.enter("blockQuoteMarker");
      effects.consume(code);
      effects.exit("blockQuoteMarker");
      return after;
    }
    return nok(code);
  }

  /**
   * After `>`, before optional whitespace.
   *
   * ```markdown
   * > | > a
   *      ^
   * ```
   *
   * @type {State}
   */
  function after(code) {
    if (markdownSpace(code)) {
      effects.enter("blockQuotePrefixWhitespace");
      effects.consume(code);
      effects.exit("blockQuotePrefixWhitespace");
      effects.exit("blockQuotePrefix");
      return ok;
    }
    effects.exit("blockQuotePrefix");
    return ok(code);
  }
}

/**
 * Start of block quote continuation.
 *
 * ```markdown
 *   | > a
 * > | > b
 *     ^
 * ```
 *
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeBlockQuoteContinuation(effects, ok, nok) {
  const self = this;
  return contStart;

  /**
   * Start of block quote continuation.
   *
   * Also used to parse the first block quote opening.
   *
   * ```markdown
   *   | > a
   * > | > b
   *     ^
   * ```
   *
   * @type {State}
   */
  function contStart(code) {
    if (markdownSpace(code)) {
      // Always populated by defaults.

      return factorySpace(effects, contBefore, "linePrefix", self.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4)(code);
    }
    return contBefore(code);
  }

  /**
   * At `>`, after optional whitespace.
   *
   * Also used to parse the first block quote opening.
   *
   * ```markdown
   *   | > a
   * > | > b
   *     ^
   * ```
   *
   * @type {State}
   */
  function contBefore(code) {
    return effects.attempt(blockQuote, ok, nok)(code);
  }
}

/** @type {Exiter} */
function exit(effects) {
  effects.exit("blockQuote");
}

/**
 * @import {
 *   Construct,
 *   State,
 *   TokenizeContext,
 *   Tokenizer
 * } from 'micromark-util-types'
 */

/** @type {Construct} */
const characterEscape = {
  name: 'characterEscape',
  tokenize: tokenizeCharacterEscape
};

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeCharacterEscape(effects, ok, nok) {
  return start;

  /**
   * Start of character escape.
   *
   * ```markdown
   * > | a\*b
   *      ^
   * ```
   *
   * @type {State}
   */
  function start(code) {
    effects.enter("characterEscape");
    effects.enter("escapeMarker");
    effects.consume(code);
    effects.exit("escapeMarker");
    return inside;
  }

  /**
   * After `\`, at punctuation.
   *
   * ```markdown
   * > | a\*b
   *       ^
   * ```
   *
   * @type {State}
   */
  function inside(code) {
    // ASCII punctuation.
    if (asciiPunctuation(code)) {
      effects.enter("characterEscapeValue");
      effects.consume(code);
      effects.exit("characterEscapeValue");
      effects.exit("characterEscape");
      return ok;
    }
    return nok(code);
  }
}

/**
 * @import {
 *   Code,
 *   Construct,
 *   State,
 *   TokenizeContext,
 *   Tokenizer
 * } from 'micromark-util-types'
 */

/** @type {Construct} */
const characterReference = {
  name: 'characterReference',
  tokenize: tokenizeCharacterReference
};

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeCharacterReference(effects, ok, nok) {
  const self = this;
  let size = 0;
  /** @type {number} */
  let max;
  /** @type {(code: Code) => boolean} */
  let test;
  return start;

  /**
   * Start of character reference.
   *
   * ```markdown
   * > | a&amp;b
   *      ^
   * > | a&#123;b
   *      ^
   * > | a&#x9;b
   *      ^
   * ```
   *
   * @type {State}
   */
  function start(code) {
    effects.enter("characterReference");
    effects.enter("characterReferenceMarker");
    effects.consume(code);
    effects.exit("characterReferenceMarker");
    return open;
  }

  /**
   * After `&`, at `#` for numeric references or alphanumeric for named
   * references.
   *
   * ```markdown
   * > | a&amp;b
   *       ^
   * > | a&#123;b
   *       ^
   * > | a&#x9;b
   *       ^
   * ```
   *
   * @type {State}
   */
  function open(code) {
    if (code === 35) {
      effects.enter("characterReferenceMarkerNumeric");
      effects.consume(code);
      effects.exit("characterReferenceMarkerNumeric");
      return numeric;
    }
    effects.enter("characterReferenceValue");
    max = 31;
    test = asciiAlphanumeric;
    return value(code);
  }

  /**
   * After `#`, at `x` for hexadecimals or digit for decimals.
   *
   * ```markdown
   * > | a&#123;b
   *        ^
   * > | a&#x9;b
   *        ^
   * ```
   *
   * @type {State}
   */
  function numeric(code) {
    if (code === 88 || code === 120) {
      effects.enter("characterReferenceMarkerHexadecimal");
      effects.consume(code);
      effects.exit("characterReferenceMarkerHexadecimal");
      effects.enter("characterReferenceValue");
      max = 6;
      test = asciiHexDigit;
      return value;
    }
    effects.enter("characterReferenceValue");
    max = 7;
    test = asciiDigit;
    return value(code);
  }

  /**
   * After markers (`&#x`, `&#`, or `&`), in value, before `;`.
   *
   * The character reference kind defines what and how many characters are
   * allowed.
   *
   * ```markdown
   * > | a&amp;b
   *       ^^^
   * > | a&#123;b
   *        ^^^
   * > | a&#x9;b
   *         ^
   * ```
   *
   * @type {State}
   */
  function value(code) {
    if (code === 59 && size) {
      const token = effects.exit("characterReferenceValue");
      if (test === asciiAlphanumeric && !decodeNamedCharacterReference(self.sliceSerialize(token))) {
        return nok(code);
      }

      // To do: `markdown-rs` uses a different name:
      // `CharacterReferenceMarkerSemi`.
      effects.enter("characterReferenceMarker");
      effects.consume(code);
      effects.exit("characterReferenceMarker");
      effects.exit("characterReference");
      return ok;
    }
    if (test(code) && size++ < max) {
      effects.consume(code);
      return value;
    }
    return nok(code);
  }
}

/**
 * @import {
 *   Code,
 *   Construct,
 *   State,
 *   TokenizeContext,
 *   Tokenizer
 * } from 'micromark-util-types'
 */

/** @type {Construct} */
const nonLazyContinuation = {
  partial: true,
  tokenize: tokenizeNonLazyContinuation
};

/** @type {Construct} */
const codeFenced = {
  concrete: true,
  name: 'codeFenced',
  tokenize: tokenizeCodeFenced
};

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeCodeFenced(effects, ok, nok) {
  const self = this;
  /** @type {Construct} */
  const closeStart = {
    partial: true,
    tokenize: tokenizeCloseStart
  };
  let initialPrefix = 0;
  let sizeOpen = 0;
  /** @type {NonNullable<Code>} */
  let marker;
  return start;

  /**
   * Start of code.
   *
   * ```markdown
   * > | ~~~js
   *     ^
   *   | alert(1)
   *   | ~~~
   * ```
   *
   * @type {State}
   */
  function start(code) {
    // To do: parse whitespace like `markdown-rs`.
    return beforeSequenceOpen(code);
  }

  /**
   * In opening fence, after prefix, at sequence.
   *
   * ```markdown
   * > | ~~~js
   *     ^
   *   | alert(1)
   *   | ~~~
   * ```
   *
   * @type {State}
   */
  function beforeSequenceOpen(code) {
    const tail = self.events[self.events.length - 1];
    initialPrefix = tail && tail[1].type === "linePrefix" ? tail[2].sliceSerialize(tail[1], true).length : 0;
    marker = code;
    effects.enter("codeFenced");
    effects.enter("codeFencedFence");
    effects.enter("codeFencedFenceSequence");
    return sequenceOpen(code);
  }

  /**
   * In opening fence sequence.
   *
   * ```markdown
   * > | ~~~js
   *      ^
   *   | alert(1)
   *   | ~~~
   * ```
   *
   * @type {State}
   */
  function sequenceOpen(code) {
    if (code === marker) {
      sizeOpen++;
      effects.consume(code);
      return sequenceOpen;
    }
    if (sizeOpen < 3) {
      return nok(code);
    }
    effects.exit("codeFencedFenceSequence");
    return markdownSpace(code) ? factorySpace(effects, infoBefore, "whitespace")(code) : infoBefore(code);
  }

  /**
   * In opening fence, after the sequence (and optional whitespace), before info.
   *
   * ```markdown
   * > | ~~~js
   *        ^
   *   | alert(1)
   *   | ~~~
   * ```
   *
   * @type {State}
   */
  function infoBefore(code) {
    if (code === null || markdownLineEnding(code)) {
      effects.exit("codeFencedFence");
      return self.interrupt ? ok(code) : effects.check(nonLazyContinuation, atNonLazyBreak, after)(code);
    }
    effects.enter("codeFencedFenceInfo");
    effects.enter("chunkString", {
      contentType: "string"
    });
    return info(code);
  }

  /**
   * In info.
   *
   * ```markdown
   * > | ~~~js
   *        ^
   *   | alert(1)
   *   | ~~~
   * ```
   *
   * @type {State}
   */
  function info(code) {
    if (code === null || markdownLineEnding(code)) {
      effects.exit("chunkString");
      effects.exit("codeFencedFenceInfo");
      return infoBefore(code);
    }
    if (markdownSpace(code)) {
      effects.exit("chunkString");
      effects.exit("codeFencedFenceInfo");
      return factorySpace(effects, metaBefore, "whitespace")(code);
    }
    if (code === 96 && code === marker) {
      return nok(code);
    }
    effects.consume(code);
    return info;
  }

  /**
   * In opening fence, after info and whitespace, before meta.
   *
   * ```markdown
   * > | ~~~js eval
   *           ^
   *   | alert(1)
   *   | ~~~
   * ```
   *
   * @type {State}
   */
  function metaBefore(code) {
    if (code === null || markdownLineEnding(code)) {
      return infoBefore(code);
    }
    effects.enter("codeFencedFenceMeta");
    effects.enter("chunkString", {
      contentType: "string"
    });
    return meta(code);
  }

  /**
   * In meta.
   *
   * ```markdown
   * > | ~~~js eval
   *           ^
   *   | alert(1)
   *   | ~~~
   * ```
   *
   * @type {State}
   */
  function meta(code) {
    if (code === null || markdownLineEnding(code)) {
      effects.exit("chunkString");
      effects.exit("codeFencedFenceMeta");
      return infoBefore(code);
    }
    if (code === 96 && code === marker) {
      return nok(code);
    }
    effects.consume(code);
    return meta;
  }

  /**
   * At eol/eof in code, before a non-lazy closing fence or content.
   *
   * ```markdown
   * > | ~~~js
   *          ^
   * > | alert(1)
   *             ^
   *   | ~~~
   * ```
   *
   * @type {State}
   */
  function atNonLazyBreak(code) {
    return effects.attempt(closeStart, after, contentBefore)(code);
  }

  /**
   * Before code content, not a closing fence, at eol.
   *
   * ```markdown
   *   | ~~~js
   * > | alert(1)
   *             ^
   *   | ~~~
   * ```
   *
   * @type {State}
   */
  function contentBefore(code) {
    effects.enter("lineEnding");
    effects.consume(code);
    effects.exit("lineEnding");
    return contentStart;
  }

  /**
   * Before code content, not a closing fence.
   *
   * ```markdown
   *   | ~~~js
   * > | alert(1)
   *     ^
   *   | ~~~
   * ```
   *
   * @type {State}
   */
  function contentStart(code) {
    return initialPrefix > 0 && markdownSpace(code) ? factorySpace(effects, beforeContentChunk, "linePrefix", initialPrefix + 1)(code) : beforeContentChunk(code);
  }

  /**
   * Before code content, after optional prefix.
   *
   * ```markdown
   *   | ~~~js
   * > | alert(1)
   *     ^
   *   | ~~~
   * ```
   *
   * @type {State}
   */
  function beforeContentChunk(code) {
    if (code === null || markdownLineEnding(code)) {
      return effects.check(nonLazyContinuation, atNonLazyBreak, after)(code);
    }
    effects.enter("codeFlowValue");
    return contentChunk(code);
  }

  /**
   * In code content.
   *
   * ```markdown
   *   | ~~~js
   * > | alert(1)
   *     ^^^^^^^^
   *   | ~~~
   * ```
   *
   * @type {State}
   */
  function contentChunk(code) {
    if (code === null || markdownLineEnding(code)) {
      effects.exit("codeFlowValue");
      return beforeContentChunk(code);
    }
    effects.consume(code);
    return contentChunk;
  }

  /**
   * After code.
   *
   * ```markdown
   *   | ~~~js
   *   | alert(1)
   * > | ~~~
   *        ^
   * ```
   *
   * @type {State}
   */
  function after(code) {
    effects.exit("codeFenced");
    return ok(code);
  }

  /**
   * @this {TokenizeContext}
   *   Context.
   * @type {Tokenizer}
   */
  function tokenizeCloseStart(effects, ok, nok) {
    let size = 0;
    return startBefore;

    /**
     *
     *
     * @type {State}
     */
    function startBefore(code) {
      effects.enter("lineEnding");
      effects.consume(code);
      effects.exit("lineEnding");
      return start;
    }

    /**
     * Before closing fence, at optional whitespace.
     *
     * ```markdown
     *   | ~~~js
     *   | alert(1)
     * > | ~~~
     *     ^
     * ```
     *
     * @type {State}
     */
    function start(code) {
      // Always populated by defaults.

      // To do: `enter` here or in next state?
      effects.enter("codeFencedFence");
      return markdownSpace(code) ? factorySpace(effects, beforeSequenceClose, "linePrefix", self.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4)(code) : beforeSequenceClose(code);
    }

    /**
     * In closing fence, after optional whitespace, at sequence.
     *
     * ```markdown
     *   | ~~~js
     *   | alert(1)
     * > | ~~~
     *     ^
     * ```
     *
     * @type {State}
     */
    function beforeSequenceClose(code) {
      if (code === marker) {
        effects.enter("codeFencedFenceSequence");
        return sequenceClose(code);
      }
      return nok(code);
    }

    /**
     * In closing fence sequence.
     *
     * ```markdown
     *   | ~~~js
     *   | alert(1)
     * > | ~~~
     *     ^
     * ```
     *
     * @type {State}
     */
    function sequenceClose(code) {
      if (code === marker) {
        size++;
        effects.consume(code);
        return sequenceClose;
      }
      if (size >= sizeOpen) {
        effects.exit("codeFencedFenceSequence");
        return markdownSpace(code) ? factorySpace(effects, sequenceCloseAfter, "whitespace")(code) : sequenceCloseAfter(code);
      }
      return nok(code);
    }

    /**
     * After closing fence sequence, after optional whitespace.
     *
     * ```markdown
     *   | ~~~js
     *   | alert(1)
     * > | ~~~
     *        ^
     * ```
     *
     * @type {State}
     */
    function sequenceCloseAfter(code) {
      if (code === null || markdownLineEnding(code)) {
        effects.exit("codeFencedFence");
        return ok(code);
      }
      return nok(code);
    }
  }
}

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeNonLazyContinuation(effects, ok, nok) {
  const self = this;
  return start;

  /**
   *
   *
   * @type {State}
   */
  function start(code) {
    if (code === null) {
      return nok(code);
    }
    effects.enter("lineEnding");
    effects.consume(code);
    effects.exit("lineEnding");
    return lineStart;
  }

  /**
   *
   *
   * @type {State}
   */
  function lineStart(code) {
    return self.parser.lazy[self.now().line] ? nok(code) : ok(code);
  }
}

/**
 * @import {
 *   Construct,
 *   State,
 *   TokenizeContext,
 *   Tokenizer
 * } from 'micromark-util-types'
 */

/** @type {Construct} */
const codeIndented = {
  name: 'codeIndented',
  tokenize: tokenizeCodeIndented
};

/** @type {Construct} */
const furtherStart = {
  partial: true,
  tokenize: tokenizeFurtherStart
};

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeCodeIndented(effects, ok, nok) {
  const self = this;
  return start;

  /**
   * Start of code (indented).
   *
   * > **Parsing note**: it is not needed to check if this first line is a
   * > filled line (that it has a non-whitespace character), because blank lines
   * > are parsed already, so we never run into that.
   *
   * ```markdown
   * > |     aaa
   *     ^
   * ```
   *
   * @type {State}
   */
  function start(code) {
    // To do: manually check if interrupting like `markdown-rs`.

    effects.enter("codeIndented");
    // To do: use an improved `space_or_tab` function like `markdown-rs`,
    // so that we can drop the next state.
    return factorySpace(effects, afterPrefix, "linePrefix", 4 + 1)(code);
  }

  /**
   * At start, after 1 or 4 spaces.
   *
   * ```markdown
   * > |     aaa
   *         ^
   * ```
   *
   * @type {State}
   */
  function afterPrefix(code) {
    const tail = self.events[self.events.length - 1];
    return tail && tail[1].type === "linePrefix" && tail[2].sliceSerialize(tail[1], true).length >= 4 ? atBreak(code) : nok(code);
  }

  /**
   * At a break.
   *
   * ```markdown
   * > |     aaa
   *         ^  ^
   * ```
   *
   * @type {State}
   */
  function atBreak(code) {
    if (code === null) {
      return after(code);
    }
    if (markdownLineEnding(code)) {
      return effects.attempt(furtherStart, atBreak, after)(code);
    }
    effects.enter("codeFlowValue");
    return inside(code);
  }

  /**
   * In code content.
   *
   * ```markdown
   * > |     aaa
   *         ^^^^
   * ```
   *
   * @type {State}
   */
  function inside(code) {
    if (code === null || markdownLineEnding(code)) {
      effects.exit("codeFlowValue");
      return atBreak(code);
    }
    effects.consume(code);
    return inside;
  }

  /** @type {State} */
  function after(code) {
    effects.exit("codeIndented");
    // To do: allow interrupting like `markdown-rs`.
    // Feel free to interrupt.
    // tokenizer.interrupt = false
    return ok(code);
  }
}

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeFurtherStart(effects, ok, nok) {
  const self = this;
  return furtherStart;

  /**
   * At eol, trying to parse another indent.
   *
   * ```markdown
   * > |     aaa
   *            ^
   *   |     bbb
   * ```
   *
   * @type {State}
   */
  function furtherStart(code) {
    // To do: improve `lazy` / `pierce` handling.
    // If this is a lazy line, it canâ€™t be code.
    if (self.parser.lazy[self.now().line]) {
      return nok(code);
    }
    if (markdownLineEnding(code)) {
      effects.enter("lineEnding");
      effects.consume(code);
      effects.exit("lineEnding");
      return furtherStart;
    }

    // To do: the code here in `micromark-js` is a bit different from
    // `markdown-rs` because there it can attempt spaces.
    // We canâ€™t yet.
    //
    // To do: use an improved `space_or_tab` function like `markdown-rs`,
    // so that we can drop the next state.
    return factorySpace(effects, afterPrefix, "linePrefix", 4 + 1)(code);
  }

  /**
   * At start, after 1 or 4 spaces.
   *
   * ```markdown
   * > |     aaa
   *         ^
   * ```
   *
   * @type {State}
   */
  function afterPrefix(code) {
    const tail = self.events[self.events.length - 1];
    return tail && tail[1].type === "linePrefix" && tail[2].sliceSerialize(tail[1], true).length >= 4 ? ok(code) : markdownLineEnding(code) ? furtherStart(code) : nok(code);
  }
}

/**
 * @import {
 *   Construct,
 *   Previous,
 *   Resolver,
 *   State,
 *   TokenizeContext,
 *   Tokenizer,
 *   Token
 * } from 'micromark-util-types'
 */

/** @type {Construct} */
const codeText = {
  name: 'codeText',
  previous,
  resolve: resolveCodeText,
  tokenize: tokenizeCodeText
};

// To do: next major: donâ€™t resolve, like `markdown-rs`.
/** @type {Resolver} */
function resolveCodeText(events) {
  let tailExitIndex = events.length - 4;
  let headEnterIndex = 3;
  /** @type {number} */
  let index;
  /** @type {number | undefined} */
  let enter;

  // If we start and end with an EOL or a space.
  if ((events[headEnterIndex][1].type === "lineEnding" || events[headEnterIndex][1].type === 'space') && (events[tailExitIndex][1].type === "lineEnding" || events[tailExitIndex][1].type === 'space')) {
    index = headEnterIndex;

    // And we have data.
    while (++index < tailExitIndex) {
      if (events[index][1].type === "codeTextData") {
        // Then we have padding.
        events[headEnterIndex][1].type = "codeTextPadding";
        events[tailExitIndex][1].type = "codeTextPadding";
        headEnterIndex += 2;
        tailExitIndex -= 2;
        break;
      }
    }
  }

  // Merge adjacent spaces and data.
  index = headEnterIndex - 1;
  tailExitIndex++;
  while (++index <= tailExitIndex) {
    if (enter === undefined) {
      if (index !== tailExitIndex && events[index][1].type !== "lineEnding") {
        enter = index;
      }
    } else if (index === tailExitIndex || events[index][1].type === "lineEnding") {
      events[enter][1].type = "codeTextData";
      if (index !== enter + 2) {
        events[enter][1].end = events[index - 1][1].end;
        events.splice(enter + 2, index - enter - 2);
        tailExitIndex -= index - enter - 2;
        index = enter + 2;
      }
      enter = undefined;
    }
  }
  return events;
}

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Previous}
 */
function previous(code) {
  // If there is a previous code, there will always be a tail.
  return code !== 96 || this.events[this.events.length - 1][1].type === "characterEscape";
}

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeCodeText(effects, ok, nok) {
  let sizeOpen = 0;
  /** @type {number} */
  let size;
  /** @type {Token} */
  let token;
  return start;

  /**
   * Start of code (text).
   *
   * ```markdown
   * > | `a`
   *     ^
   * > | \`a`
   *      ^
   * ```
   *
   * @type {State}
   */
  function start(code) {
    effects.enter("codeText");
    effects.enter("codeTextSequence");
    return sequenceOpen(code);
  }

  /**
   * In opening sequence.
   *
   * ```markdown
   * > | `a`
   *     ^
   * ```
   *
   * @type {State}
   */
  function sequenceOpen(code) {
    if (code === 96) {
      effects.consume(code);
      sizeOpen++;
      return sequenceOpen;
    }
    effects.exit("codeTextSequence");
    return between(code);
  }

  /**
   * Between something and something else.
   *
   * ```markdown
   * > | `a`
   *      ^^
   * ```
   *
   * @type {State}
   */
  function between(code) {
    // EOF.
    if (code === null) {
      return nok(code);
    }

    // To do: next major: donâ€™t do spaces in resolve, but when compiling,
    // like `markdown-rs`.
    // Tabs donâ€™t work, and virtual spaces donâ€™t make sense.
    if (code === 32) {
      effects.enter('space');
      effects.consume(code);
      effects.exit('space');
      return between;
    }

    // Closing fence? Could also be data.
    if (code === 96) {
      token = effects.enter("codeTextSequence");
      size = 0;
      return sequenceClose(code);
    }
    if (markdownLineEnding(code)) {
      effects.enter("lineEnding");
      effects.consume(code);
      effects.exit("lineEnding");
      return between;
    }

    // Data.
    effects.enter("codeTextData");
    return data(code);
  }

  /**
   * In data.
   *
   * ```markdown
   * > | `a`
   *      ^
   * ```
   *
   * @type {State}
   */
  function data(code) {
    if (code === null || code === 32 || code === 96 || markdownLineEnding(code)) {
      effects.exit("codeTextData");
      return between(code);
    }
    effects.consume(code);
    return data;
  }

  /**
   * In closing sequence.
   *
   * ```markdown
   * > | `a`
   *       ^
   * ```
   *
   * @type {State}
   */
  function sequenceClose(code) {
    // More.
    if (code === 96) {
      effects.consume(code);
      size++;
      return sequenceClose;
    }

    // Done!
    if (size === sizeOpen) {
      effects.exit("codeTextSequence");
      effects.exit("codeText");
      return ok(code);
    }

    // More or less accents: mark as data.
    token.type = "codeTextData";
    return data(code);
  }
}

/**
 * Some of the internal operations of micromark do lots of editing
 * operations on very large arrays. This runs into problems with two
 * properties of most circa-2020 JavaScript interpreters:
 *
 *  - Array-length modifications at the high end of an array (push/pop) are
 *    expected to be common and are implemented in (amortized) time
 *    proportional to the number of elements added or removed, whereas
 *    other operations (shift/unshift and splice) are much less efficient.
 *  - Function arguments are passed on the stack, so adding tens of thousands
 *    of elements to an array with `arr.push(...newElements)` will frequently
 *    cause stack overflows. (see <https://stackoverflow.com/questions/22123769/rangeerror-maximum-call-stack-size-exceeded-why>)
 *
 * SpliceBuffers are an implementation of gap buffers, which are a
 * generalization of the "queue made of two stacks" idea. The splice buffer
 * maintains a cursor, and moving the cursor has cost proportional to the
 * distance the cursor moves, but inserting, deleting, or splicing in
 * new information at the cursor is as efficient as the push/pop operation.
 * This allows for an efficient sequence of splices (or pushes, pops, shifts,
 * or unshifts) as long such edits happen at the same part of the array or
 * generally sweep through the array from the beginning to the end.
 *
 * The interface for splice buffers also supports large numbers of inputs by
 * passing a single array argument rather passing multiple arguments on the
 * function call stack.
 *
 * @template T
 *   Item type.
 */
class SpliceBuffer {
  /**
   * @param {ReadonlyArray<T> | null | undefined} [initial]
   *   Initial items (optional).
   * @returns
   *   Splice buffer.
   */
  constructor(initial) {
    /** @type {Array<T>} */
    this.left = initial ? [...initial] : [];
    /** @type {Array<T>} */
    this.right = [];
  }

  /**
   * Array access;
   * does not move the cursor.
   *
   * @param {number} index
   *   Index.
   * @return {T}
   *   Item.
   */
  get(index) {
    if (index < 0 || index >= this.left.length + this.right.length) {
      throw new RangeError('Cannot access index `' + index + '` in a splice buffer of size `' + (this.left.length + this.right.length) + '`');
    }
    if (index < this.left.length) return this.left[index];
    return this.right[this.right.length - index + this.left.length - 1];
  }

  /**
   * The length of the splice buffer, one greater than the largest index in the
   * array.
   */
  get length() {
    return this.left.length + this.right.length;
  }

  /**
   * Remove and return `list[0]`;
   * moves the cursor to `0`.
   *
   * @returns {T | undefined}
   *   Item, optional.
   */
  shift() {
    this.setCursor(0);
    return this.right.pop();
  }

  /**
   * Slice the buffer to get an array;
   * does not move the cursor.
   *
   * @param {number} start
   *   Start.
   * @param {number | null | undefined} [end]
   *   End (optional).
   * @returns {Array<T>}
   *   Array of items.
   */
  slice(start, end) {
    /** @type {number} */
    const stop = end === null || end === undefined ? Number.POSITIVE_INFINITY : end;
    if (stop < this.left.length) {
      return this.left.slice(start, stop);
    }
    if (start > this.left.length) {
      return this.right.slice(this.right.length - stop + this.left.length, this.right.length - start + this.left.length).reverse();
    }
    return this.left.slice(start).concat(this.right.slice(this.right.length - stop + this.left.length).reverse());
  }

  /**
   * Mimics the behavior of Array.prototype.splice() except for the change of
   * interface necessary to avoid segfaults when patching in very large arrays.
   *
   * This operation moves cursor is moved to `start` and results in the cursor
   * placed after any inserted items.
   *
   * @param {number} start
   *   Start;
   *   zero-based index at which to start changing the array;
   *   negative numbers count backwards from the end of the array and values
   *   that are out-of bounds are clamped to the appropriate end of the array.
   * @param {number | null | undefined} [deleteCount=0]
   *   Delete count (default: `0`);
   *   maximum number of elements to delete, starting from start.
   * @param {Array<T> | null | undefined} [items=[]]
   *   Items to include in place of the deleted items (default: `[]`).
   * @return {Array<T>}
   *   Any removed items.
   */
  splice(start, deleteCount, items) {
    /** @type {number} */
    const count = deleteCount || 0;
    this.setCursor(Math.trunc(start));
    const removed = this.right.splice(this.right.length - count, Number.POSITIVE_INFINITY);
    if (items) chunkedPush(this.left, items);
    return removed.reverse();
  }

  /**
   * Remove and return the highest-numbered item in the array, so
   * `list[list.length - 1]`;
   * Moves the cursor to `length`.
   *
   * @returns {T | undefined}
   *   Item, optional.
   */
  pop() {
    this.setCursor(Number.POSITIVE_INFINITY);
    return this.left.pop();
  }

  /**
   * Inserts a single item to the high-numbered side of the array;
   * moves the cursor to `length`.
   *
   * @param {T} item
   *   Item.
   * @returns {undefined}
   *   Nothing.
   */
  push(item) {
    this.setCursor(Number.POSITIVE_INFINITY);
    this.left.push(item);
  }

  /**
   * Inserts many items to the high-numbered side of the array.
   * Moves the cursor to `length`.
   *
   * @param {Array<T>} items
   *   Items.
   * @returns {undefined}
   *   Nothing.
   */
  pushMany(items) {
    this.setCursor(Number.POSITIVE_INFINITY);
    chunkedPush(this.left, items);
  }

  /**
   * Inserts a single item to the low-numbered side of the array;
   * Moves the cursor to `0`.
   *
   * @param {T} item
   *   Item.
   * @returns {undefined}
   *   Nothing.
   */
  unshift(item) {
    this.setCursor(0);
    this.right.push(item);
  }

  /**
   * Inserts many items to the low-numbered side of the array;
   * moves the cursor to `0`.
   *
   * @param {Array<T>} items
   *   Items.
   * @returns {undefined}
   *   Nothing.
   */
  unshiftMany(items) {
    this.setCursor(0);
    chunkedPush(this.right, items.reverse());
  }

  /**
   * Move the cursor to a specific position in the array. Requires
   * time proportional to the distance moved.
   *
   * If `n < 0`, the cursor will end up at the beginning.
   * If `n > length`, the cursor will end up at the end.
   *
   * @param {number} n
   *   Position.
   * @return {undefined}
   *   Nothing.
   */
  setCursor(n) {
    if (n === this.left.length || n > this.left.length && this.right.length === 0 || n < 0 && this.left.length === 0) return;
    if (n < this.left.length) {
      // Move cursor to the this.left
      const removed = this.left.splice(n, Number.POSITIVE_INFINITY);
      chunkedPush(this.right, removed.reverse());
    } else {
      // Move cursor to the this.right
      const removed = this.right.splice(this.left.length + this.right.length - n, Number.POSITIVE_INFINITY);
      chunkedPush(this.left, removed.reverse());
    }
  }
}

/**
 * Avoid stack overflow by pushing items onto the stack in segments
 *
 * @template T
 *   Item type.
 * @param {Array<T>} list
 *   List to inject into.
 * @param {ReadonlyArray<T>} right
 *   Items to inject.
 * @return {undefined}
 *   Nothing.
 */
function chunkedPush(list, right) {
  /** @type {number} */
  let chunkStart = 0;
  if (right.length < 10000) {
    list.push(...right);
  } else {
    while (chunkStart < right.length) {
      list.push(...right.slice(chunkStart, chunkStart + 10000));
      chunkStart += 10000;
    }
  }
}

/**
 * @import {Chunk, Event, Token} from 'micromark-util-types'
 */


/**
 * Tokenize subcontent.
 *
 * @param {Array<Event>} eventsArray
 *   List of events.
 * @returns {boolean}
 *   Whether subtokens were found.
 */
// eslint-disable-next-line complexity
function subtokenize(eventsArray) {
  /** @type {Record<string, number>} */
  const jumps = {};
  let index = -1;
  /** @type {Event} */
  let event;
  /** @type {number | undefined} */
  let lineIndex;
  /** @type {number} */
  let otherIndex;
  /** @type {Event} */
  let otherEvent;
  /** @type {Array<Event>} */
  let parameters;
  /** @type {Array<Event>} */
  let subevents;
  /** @type {boolean | undefined} */
  let more;
  const events = new SpliceBuffer(eventsArray);
  while (++index < events.length) {
    while (index in jumps) {
      index = jumps[index];
    }
    event = events.get(index);

    // Add a hook for the GFM tasklist extension, which needs to know if text
    // is in the first content of a list item.
    if (index && event[1].type === "chunkFlow" && events.get(index - 1)[1].type === "listItemPrefix") {
      subevents = event[1]._tokenizer.events;
      otherIndex = 0;
      if (otherIndex < subevents.length && subevents[otherIndex][1].type === "lineEndingBlank") {
        otherIndex += 2;
      }
      if (otherIndex < subevents.length && subevents[otherIndex][1].type === "content") {
        while (++otherIndex < subevents.length) {
          if (subevents[otherIndex][1].type === "content") {
            break;
          }
          if (subevents[otherIndex][1].type === "chunkText") {
            subevents[otherIndex][1]._isInFirstContentOfListItem = true;
            otherIndex++;
          }
        }
      }
    }

    // Enter.
    if (event[0] === 'enter') {
      if (event[1].contentType) {
        Object.assign(jumps, subcontent(events, index));
        index = jumps[index];
        more = true;
      }
    }
    // Exit.
    else if (event[1]._container) {
      otherIndex = index;
      lineIndex = undefined;
      while (otherIndex--) {
        otherEvent = events.get(otherIndex);
        if (otherEvent[1].type === "lineEnding" || otherEvent[1].type === "lineEndingBlank") {
          if (otherEvent[0] === 'enter') {
            if (lineIndex) {
              events.get(lineIndex)[1].type = "lineEndingBlank";
            }
            otherEvent[1].type = "lineEnding";
            lineIndex = otherIndex;
          }
        } else if (otherEvent[1].type === "linePrefix" || otherEvent[1].type === "listItemIndent") ; else {
          break;
        }
      }
      if (lineIndex) {
        // Fix position.
        event[1].end = {
          ...events.get(lineIndex)[1].start
        };

        // Switch container exit w/ line endings.
        parameters = events.slice(lineIndex, index);
        parameters.unshift(event);
        events.splice(lineIndex, index - lineIndex + 1, parameters);
      }
    }
  }

  // The changes to the `events` buffer must be copied back into the eventsArray
  splice(eventsArray, 0, Number.POSITIVE_INFINITY, events.slice(0));
  return !more;
}

/**
 * Tokenize embedded tokens.
 *
 * @param {SpliceBuffer<Event>} events
 *   Events.
 * @param {number} eventIndex
 *   Index.
 * @returns {Record<string, number>}
 *   Gaps.
 */
function subcontent(events, eventIndex) {
  const token = events.get(eventIndex)[1];
  const context = events.get(eventIndex)[2];
  let startPosition = eventIndex - 1;
  /** @type {Array<number>} */
  const startPositions = [];
  let tokenizer = token._tokenizer;
  if (!tokenizer) {
    tokenizer = context.parser[token.contentType](token.start);
    if (token._contentTypeTextTrailing) {
      tokenizer._contentTypeTextTrailing = true;
    }
  }
  const childEvents = tokenizer.events;
  /** @type {Array<[number, number]>} */
  const jumps = [];
  /** @type {Record<string, number>} */
  const gaps = {};
  /** @type {Array<Chunk>} */
  let stream;
  /** @type {Token | undefined} */
  let previous;
  let index = -1;
  /** @type {Token | undefined} */
  let current = token;
  let adjust = 0;
  let start = 0;
  const breaks = [start];

  // Loop forward through the linked tokens to pass them in order to the
  // subtokenizer.
  while (current) {
    // Find the position of the event for this token.
    while (events.get(++startPosition)[1] !== current) {
      // Empty.
    }
    startPositions.push(startPosition);
    if (!current._tokenizer) {
      stream = context.sliceStream(current);
      if (!current.next) {
        stream.push(null);
      }
      if (previous) {
        tokenizer.defineSkip(current.start);
      }
      if (current._isInFirstContentOfListItem) {
        tokenizer._gfmTasklistFirstContentOfListItem = true;
      }
      tokenizer.write(stream);
      if (current._isInFirstContentOfListItem) {
        tokenizer._gfmTasklistFirstContentOfListItem = undefined;
      }
    }

    // Unravel the next token.
    previous = current;
    current = current.next;
  }

  // Now, loop back through all events (and linked tokens), to figure out which
  // parts belong where.
  current = token;
  while (++index < childEvents.length) {
    if (
    // Find a void token that includes a break.
    childEvents[index][0] === 'exit' && childEvents[index - 1][0] === 'enter' && childEvents[index][1].type === childEvents[index - 1][1].type && childEvents[index][1].start.line !== childEvents[index][1].end.line) {
      start = index + 1;
      breaks.push(start);
      // Help GC.
      current._tokenizer = undefined;
      current.previous = undefined;
      current = current.next;
    }
  }

  // Help GC.
  tokenizer.events = [];

  // If thereâ€™s one more token (which is the cases for lines that end in an
  // EOF), thatâ€™s perfect: the last point we found starts it.
  // If there isnâ€™t then make sure any remaining content is added to it.
  if (current) {
    // Help GC.
    current._tokenizer = undefined;
    current.previous = undefined;
  } else {
    breaks.pop();
  }

  // Now splice the events from the subtokenizer into the current events,
  // moving back to front so that splice indices arenâ€™t affected.
  index = breaks.length;
  while (index--) {
    const slice = childEvents.slice(breaks[index], breaks[index + 1]);
    const start = startPositions.pop();
    jumps.push([start, start + slice.length - 1]);
    events.splice(start, 2, slice);
  }
  jumps.reverse();
  index = -1;
  while (++index < jumps.length) {
    gaps[adjust + jumps[index][0]] = adjust + jumps[index][1];
    adjust += jumps[index][1] - jumps[index][0] - 1;
  }
  return gaps;
}

/**
 * @import {
 *   Construct,
 *   Resolver,
 *   State,
 *   TokenizeContext,
 *   Tokenizer,
 *   Token
 * } from 'micromark-util-types'
 */

/**
 * No name because it must not be turned off.
 * @type {Construct}
 */
const content = {
  resolve: resolveContent,
  tokenize: tokenizeContent
};

/** @type {Construct} */
const continuationConstruct = {
  partial: true,
  tokenize: tokenizeContinuation
};

/**
 * Content is transparent: itâ€™s parsed right now. That way, definitions are also
 * parsed right now: before text in paragraphs (specifically, media) are parsed.
 *
 * @type {Resolver}
 */
function resolveContent(events) {
  subtokenize(events);
  return events;
}

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeContent(effects, ok) {
  /** @type {Token | undefined} */
  let previous;
  return chunkStart;

  /**
   * Before a content chunk.
   *
   * ```markdown
   * > | abc
   *     ^
   * ```
   *
   * @type {State}
   */
  function chunkStart(code) {
    effects.enter("content");
    previous = effects.enter("chunkContent", {
      contentType: "content"
    });
    return chunkInside(code);
  }

  /**
   * In a content chunk.
   *
   * ```markdown
   * > | abc
   *     ^^^
   * ```
   *
   * @type {State}
   */
  function chunkInside(code) {
    if (code === null) {
      return contentEnd(code);
    }

    // To do: in `markdown-rs`, each line is parsed on its own, and everything
    // is stitched together resolving.
    if (markdownLineEnding(code)) {
      return effects.check(continuationConstruct, contentContinue, contentEnd)(code);
    }

    // Data.
    effects.consume(code);
    return chunkInside;
  }

  /**
   *
   *
   * @type {State}
   */
  function contentEnd(code) {
    effects.exit("chunkContent");
    effects.exit("content");
    return ok(code);
  }

  /**
   *
   *
   * @type {State}
   */
  function contentContinue(code) {
    effects.consume(code);
    effects.exit("chunkContent");
    previous.next = effects.enter("chunkContent", {
      contentType: "content",
      previous
    });
    previous = previous.next;
    return chunkInside;
  }
}

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeContinuation(effects, ok, nok) {
  const self = this;
  return startLookahead;

  /**
   *
   *
   * @type {State}
   */
  function startLookahead(code) {
    effects.exit("chunkContent");
    effects.enter("lineEnding");
    effects.consume(code);
    effects.exit("lineEnding");
    return factorySpace(effects, prefixed, "linePrefix");
  }

  /**
   *
   *
   * @type {State}
   */
  function prefixed(code) {
    if (code === null || markdownLineEnding(code)) {
      return nok(code);
    }

    // Always populated by defaults.

    const tail = self.events[self.events.length - 1];
    if (!self.parser.constructs.disable.null.includes('codeIndented') && tail && tail[1].type === "linePrefix" && tail[2].sliceSerialize(tail[1], true).length >= 4) {
      return ok(code);
    }
    return effects.interrupt(self.parser.constructs.flow, nok, ok)(code);
  }
}

/**
 * @import {Effects, State, TokenType} from 'micromark-util-types'
 */

/**
 * Parse destinations.
 *
 * ###### Examples
 *
 * ```markdown
 * <a>
 * <a\>b>
 * <a b>
 * <a)>
 * a
 * a\)b
 * a(b)c
 * a(b)
 * ```
 *
 * @param {Effects} effects
 *   Context.
 * @param {State} ok
 *   State switched to when successful.
 * @param {State} nok
 *   State switched to when unsuccessful.
 * @param {TokenType} type
 *   Type for whole (`<a>` or `b`).
 * @param {TokenType} literalType
 *   Type when enclosed (`<a>`).
 * @param {TokenType} literalMarkerType
 *   Type for enclosing (`<` and `>`).
 * @param {TokenType} rawType
 *   Type when not enclosed (`b`).
 * @param {TokenType} stringType
 *   Type for the value (`a` or `b`).
 * @param {number | undefined} [max=Infinity]
 *   Depth of nested parens (inclusive).
 * @returns {State}
 *   Start state.
 */
function factoryDestination(effects, ok, nok, type, literalType, literalMarkerType, rawType, stringType, max) {
  const limit = max || Number.POSITIVE_INFINITY;
  let balance = 0;
  return start;

  /**
   * Start of destination.
   *
   * ```markdown
   * > | <aa>
   *     ^
   * > | aa
   *     ^
   * ```
   *
   * @type {State}
   */
  function start(code) {
    if (code === 60) {
      effects.enter(type);
      effects.enter(literalType);
      effects.enter(literalMarkerType);
      effects.consume(code);
      effects.exit(literalMarkerType);
      return enclosedBefore;
    }

    // ASCII control, space, closing paren.
    if (code === null || code === 32 || code === 41 || asciiControl(code)) {
      return nok(code);
    }
    effects.enter(type);
    effects.enter(rawType);
    effects.enter(stringType);
    effects.enter("chunkString", {
      contentType: "string"
    });
    return raw(code);
  }

  /**
   * After `<`, at an enclosed destination.
   *
   * ```markdown
   * > | <aa>
   *      ^
   * ```
   *
   * @type {State}
   */
  function enclosedBefore(code) {
    if (code === 62) {
      effects.enter(literalMarkerType);
      effects.consume(code);
      effects.exit(literalMarkerType);
      effects.exit(literalType);
      effects.exit(type);
      return ok;
    }
    effects.enter(stringType);
    effects.enter("chunkString", {
      contentType: "string"
    });
    return enclosed(code);
  }

  /**
   * In enclosed destination.
   *
   * ```markdown
   * > | <aa>
   *      ^
   * ```
   *
   * @type {State}
   */
  function enclosed(code) {
    if (code === 62) {
      effects.exit("chunkString");
      effects.exit(stringType);
      return enclosedBefore(code);
    }
    if (code === null || code === 60 || markdownLineEnding(code)) {
      return nok(code);
    }
    effects.consume(code);
    return code === 92 ? enclosedEscape : enclosed;
  }

  /**
   * After `\`, at a special character.
   *
   * ```markdown
   * > | <a\*a>
   *        ^
   * ```
   *
   * @type {State}
   */
  function enclosedEscape(code) {
    if (code === 60 || code === 62 || code === 92) {
      effects.consume(code);
      return enclosed;
    }
    return enclosed(code);
  }

  /**
   * In raw destination.
   *
   * ```markdown
   * > | aa
   *     ^
   * ```
   *
   * @type {State}
   */
  function raw(code) {
    if (!balance && (code === null || code === 41 || markdownLineEndingOrSpace(code))) {
      effects.exit("chunkString");
      effects.exit(stringType);
      effects.exit(rawType);
      effects.exit(type);
      return ok(code);
    }
    if (balance < limit && code === 40) {
      effects.consume(code);
      balance++;
      return raw;
    }
    if (code === 41) {
      effects.consume(code);
      balance--;
      return raw;
    }

    // ASCII control (but *not* `\0`) and space and `(`.
    // Note: in `markdown-rs`, `\0` exists in codes, in `micromark-js` it
    // doesnâ€™t.
    if (code === null || code === 32 || code === 40 || asciiControl(code)) {
      return nok(code);
    }
    effects.consume(code);
    return code === 92 ? rawEscape : raw;
  }

  /**
   * After `\`, at special character.
   *
   * ```markdown
   * > | a\*a
   *       ^
   * ```
   *
   * @type {State}
   */
  function rawEscape(code) {
    if (code === 40 || code === 41 || code === 92) {
      effects.consume(code);
      return raw;
    }
    return raw(code);
  }
}

/**
 * @import {
 *   Effects,
 *   State,
 *   TokenizeContext,
 *   TokenType
 * } from 'micromark-util-types'
 */

/**
 * Parse labels.
 *
 * > ðŸ‘‰ **Note**: labels in markdown are capped at 999 characters in the string.
 *
 * ###### Examples
 *
 * ```markdown
 * [a]
 * [a
 * b]
 * [a\]b]
 * ```
 *
 * @this {TokenizeContext}
 *   Tokenize context.
 * @param {Effects} effects
 *   Context.
 * @param {State} ok
 *   State switched to when successful.
 * @param {State} nok
 *   State switched to when unsuccessful.
 * @param {TokenType} type
 *   Type of the whole label (`[a]`).
 * @param {TokenType} markerType
 *   Type for the markers (`[` and `]`).
 * @param {TokenType} stringType
 *   Type for the identifier (`a`).
 * @returns {State}
 *   Start state.
 */
function factoryLabel(effects, ok, nok, type, markerType, stringType) {
  const self = this;
  let size = 0;
  /** @type {boolean} */
  let seen;
  return start;

  /**
   * Start of label.
   *
   * ```markdown
   * > | [a]
   *     ^
   * ```
   *
   * @type {State}
   */
  function start(code) {
    effects.enter(type);
    effects.enter(markerType);
    effects.consume(code);
    effects.exit(markerType);
    effects.enter(stringType);
    return atBreak;
  }

  /**
   * In label, at something, before something else.
   *
   * ```markdown
   * > | [a]
   *      ^
   * ```
   *
   * @type {State}
   */
  function atBreak(code) {
    if (size > 999 || code === null || code === 91 || code === 93 && !seen ||
    // To do: remove in the future once weâ€™ve switched from
    // `micromark-extension-footnote` to `micromark-extension-gfm-footnote`,
    // which doesnâ€™t need this.
    // Hidden footnotes hook.
    /* c8 ignore next 3 */
    code === 94 && !size && '_hiddenFootnoteSupport' in self.parser.constructs) {
      return nok(code);
    }
    if (code === 93) {
      effects.exit(stringType);
      effects.enter(markerType);
      effects.consume(code);
      effects.exit(markerType);
      effects.exit(type);
      return ok;
    }

    // To do: indent? Link chunks and EOLs together?
    if (markdownLineEnding(code)) {
      effects.enter("lineEnding");
      effects.consume(code);
      effects.exit("lineEnding");
      return atBreak;
    }
    effects.enter("chunkString", {
      contentType: "string"
    });
    return labelInside(code);
  }

  /**
   * In label, in text.
   *
   * ```markdown
   * > | [a]
   *      ^
   * ```
   *
   * @type {State}
   */
  function labelInside(code) {
    if (code === null || code === 91 || code === 93 || markdownLineEnding(code) || size++ > 999) {
      effects.exit("chunkString");
      return atBreak(code);
    }
    effects.consume(code);
    if (!seen) seen = !markdownSpace(code);
    return code === 92 ? labelEscape : labelInside;
  }

  /**
   * After `\`, at a special character.
   *
   * ```markdown
   * > | [a\*a]
   *        ^
   * ```
   *
   * @type {State}
   */
  function labelEscape(code) {
    if (code === 91 || code === 92 || code === 93) {
      effects.consume(code);
      size++;
      return labelInside;
    }
    return labelInside(code);
  }
}

/**
 * @import {
 *   Code,
 *   Effects,
 *   State,
 *   TokenType
 * } from 'micromark-util-types'
 */

/**
 * Parse titles.
 *
 * ###### Examples
 *
 * ```markdown
 * "a"
 * 'b'
 * (c)
 * "a
 * b"
 * 'a
 *     b'
 * (a\)b)
 * ```
 *
 * @param {Effects} effects
 *   Context.
 * @param {State} ok
 *   State switched to when successful.
 * @param {State} nok
 *   State switched to when unsuccessful.
 * @param {TokenType} type
 *   Type of the whole title (`"a"`, `'b'`, `(c)`).
 * @param {TokenType} markerType
 *   Type for the markers (`"`, `'`, `(`, and `)`).
 * @param {TokenType} stringType
 *   Type for the value (`a`).
 * @returns {State}
 *   Start state.
 */
function factoryTitle(effects, ok, nok, type, markerType, stringType) {
  /** @type {NonNullable<Code>} */
  let marker;
  return start;

  /**
   * Start of title.
   *
   * ```markdown
   * > | "a"
   *     ^
   * ```
   *
   * @type {State}
   */
  function start(code) {
    if (code === 34 || code === 39 || code === 40) {
      effects.enter(type);
      effects.enter(markerType);
      effects.consume(code);
      effects.exit(markerType);
      marker = code === 40 ? 41 : code;
      return begin;
    }
    return nok(code);
  }

  /**
   * After opening marker.
   *
   * This is also used at the closing marker.
   *
   * ```markdown
   * > | "a"
   *      ^
   * ```
   *
   * @type {State}
   */
  function begin(code) {
    if (code === marker) {
      effects.enter(markerType);
      effects.consume(code);
      effects.exit(markerType);
      effects.exit(type);
      return ok;
    }
    effects.enter(stringType);
    return atBreak(code);
  }

  /**
   * At something, before something else.
   *
   * ```markdown
   * > | "a"
   *      ^
   * ```
   *
   * @type {State}
   */
  function atBreak(code) {
    if (code === marker) {
      effects.exit(stringType);
      return begin(marker);
    }
    if (code === null) {
      return nok(code);
    }

    // Note: blank lines canâ€™t exist in content.
    if (markdownLineEnding(code)) {
      // To do: use `space_or_tab_eol_with_options`, connect.
      effects.enter("lineEnding");
      effects.consume(code);
      effects.exit("lineEnding");
      return factorySpace(effects, atBreak, "linePrefix");
    }
    effects.enter("chunkString", {
      contentType: "string"
    });
    return inside(code);
  }

  /**
   *
   *
   * @type {State}
   */
  function inside(code) {
    if (code === marker || code === null || markdownLineEnding(code)) {
      effects.exit("chunkString");
      return atBreak(code);
    }
    effects.consume(code);
    return code === 92 ? escape : inside;
  }

  /**
   * After `\`, at a special character.
   *
   * ```markdown
   * > | "a\*b"
   *      ^
   * ```
   *
   * @type {State}
   */
  function escape(code) {
    if (code === marker || code === 92) {
      effects.consume(code);
      return inside;
    }
    return inside(code);
  }
}

/**
 * @import {Effects, State} from 'micromark-util-types'
 */

/**
 * Parse spaces and tabs.
 *
 * There is no `nok` parameter:
 *
 * *   line endings or spaces in markdown are often optional, in which case this
 *     factory can be used and `ok` will be switched to whether spaces were found
 *     or not
 * *   one line ending or space can be detected with
 *     `markdownLineEndingOrSpace(code)` right before using `factoryWhitespace`
 *
 * @param {Effects} effects
 *   Context.
 * @param {State} ok
 *   State switched to when successful.
 * @returns {State}
 *   Start state.
 */
function factoryWhitespace(effects, ok) {
  /** @type {boolean} */
  let seen;
  return start;

  /** @type {State} */
  function start(code) {
    if (markdownLineEnding(code)) {
      effects.enter("lineEnding");
      effects.consume(code);
      effects.exit("lineEnding");
      seen = true;
      return start;
    }
    if (markdownSpace(code)) {
      return factorySpace(effects, start, seen ? "linePrefix" : "lineSuffix")(code);
    }
    return ok(code);
  }
}

/**
 * @import {
 *   Construct,
 *   State,
 *   TokenizeContext,
 *   Tokenizer
 * } from 'micromark-util-types'
 */

/** @type {Construct} */
const definition = {
  name: 'definition',
  tokenize: tokenizeDefinition
};

/** @type {Construct} */
const titleBefore = {
  partial: true,
  tokenize: tokenizeTitleBefore
};

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeDefinition(effects, ok, nok) {
  const self = this;
  /** @type {string} */
  let identifier;
  return start;

  /**
   * At start of a definition.
   *
   * ```markdown
   * > | [a]: b "c"
   *     ^
   * ```
   *
   * @type {State}
   */
  function start(code) {
    // Do not interrupt paragraphs (but do follow definitions).
    // To do: do `interrupt` the way `markdown-rs` does.
    // To do: parse whitespace the way `markdown-rs` does.
    effects.enter("definition");
    return before(code);
  }

  /**
   * After optional whitespace, at `[`.
   *
   * ```markdown
   * > | [a]: b "c"
   *     ^
   * ```
   *
   * @type {State}
   */
  function before(code) {
    // To do: parse whitespace the way `markdown-rs` does.

    return factoryLabel.call(self, effects, labelAfter,
    // Note: we donâ€™t need to reset the way `markdown-rs` does.
    nok, "definitionLabel", "definitionLabelMarker", "definitionLabelString")(code);
  }

  /**
   * After label.
   *
   * ```markdown
   * > | [a]: b "c"
   *        ^
   * ```
   *
   * @type {State}
   */
  function labelAfter(code) {
    identifier = normalizeIdentifier(self.sliceSerialize(self.events[self.events.length - 1][1]).slice(1, -1));
    if (code === 58) {
      effects.enter("definitionMarker");
      effects.consume(code);
      effects.exit("definitionMarker");
      return markerAfter;
    }
    return nok(code);
  }

  /**
   * After marker.
   *
   * ```markdown
   * > | [a]: b "c"
   *         ^
   * ```
   *
   * @type {State}
   */
  function markerAfter(code) {
    // Note: whitespace is optional.
    return markdownLineEndingOrSpace(code) ? factoryWhitespace(effects, destinationBefore)(code) : destinationBefore(code);
  }

  /**
   * Before destination.
   *
   * ```markdown
   * > | [a]: b "c"
   *          ^
   * ```
   *
   * @type {State}
   */
  function destinationBefore(code) {
    return factoryDestination(effects, destinationAfter,
    // Note: we donâ€™t need to reset the way `markdown-rs` does.
    nok, "definitionDestination", "definitionDestinationLiteral", "definitionDestinationLiteralMarker", "definitionDestinationRaw", "definitionDestinationString")(code);
  }

  /**
   * After destination.
   *
   * ```markdown
   * > | [a]: b "c"
   *           ^
   * ```
   *
   * @type {State}
   */
  function destinationAfter(code) {
    return effects.attempt(titleBefore, after, after)(code);
  }

  /**
   * After definition.
   *
   * ```markdown
   * > | [a]: b
   *           ^
   * > | [a]: b "c"
   *               ^
   * ```
   *
   * @type {State}
   */
  function after(code) {
    return markdownSpace(code) ? factorySpace(effects, afterWhitespace, "whitespace")(code) : afterWhitespace(code);
  }

  /**
   * After definition, after optional whitespace.
   *
   * ```markdown
   * > | [a]: b
   *           ^
   * > | [a]: b "c"
   *               ^
   * ```
   *
   * @type {State}
   */
  function afterWhitespace(code) {
    if (code === null || markdownLineEnding(code)) {
      effects.exit("definition");

      // Note: we donâ€™t care about uniqueness.
      // Itâ€™s likely that that doesnâ€™t happen very frequently.
      // It is more likely that it wastes precious time.
      self.parser.defined.push(identifier);

      // To do: `markdown-rs` interrupt.
      // // Youâ€™d be interrupting.
      // tokenizer.interrupt = true
      return ok(code);
    }
    return nok(code);
  }
}

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeTitleBefore(effects, ok, nok) {
  return titleBefore;

  /**
   * After destination, at whitespace.
   *
   * ```markdown
   * > | [a]: b
   *           ^
   * > | [a]: b "c"
   *           ^
   * ```
   *
   * @type {State}
   */
  function titleBefore(code) {
    return markdownLineEndingOrSpace(code) ? factoryWhitespace(effects, beforeMarker)(code) : nok(code);
  }

  /**
   * At title.
   *
   * ```markdown
   *   | [a]: b
   * > | "c"
   *     ^
   * ```
   *
   * @type {State}
   */
  function beforeMarker(code) {
    return factoryTitle(effects, titleAfter, nok, "definitionTitle", "definitionTitleMarker", "definitionTitleString")(code);
  }

  /**
   * After title.
   *
   * ```markdown
   * > | [a]: b "c"
   *               ^
   * ```
   *
   * @type {State}
   */
  function titleAfter(code) {
    return markdownSpace(code) ? factorySpace(effects, titleAfterOptionalWhitespace, "whitespace")(code) : titleAfterOptionalWhitespace(code);
  }

  /**
   * After title, after optional whitespace.
   *
   * ```markdown
   * > | [a]: b "c"
   *               ^
   * ```
   *
   * @type {State}
   */
  function titleAfterOptionalWhitespace(code) {
    return code === null || markdownLineEnding(code) ? ok(code) : nok(code);
  }
}

/**
 * @import {
 *   Construct,
 *   State,
 *   TokenizeContext,
 *   Tokenizer
 * } from 'micromark-util-types'
 */

/** @type {Construct} */
const hardBreakEscape = {
  name: 'hardBreakEscape',
  tokenize: tokenizeHardBreakEscape
};

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeHardBreakEscape(effects, ok, nok) {
  return start;

  /**
   * Start of a hard break (escape).
   *
   * ```markdown
   * > | a\
   *      ^
   *   | b
   * ```
   *
   * @type {State}
   */
  function start(code) {
    effects.enter("hardBreakEscape");
    effects.consume(code);
    return after;
  }

  /**
   * After `\`, at eol.
   *
   * ```markdown
   * > | a\
   *       ^
   *   | b
   * ```
   *
   *  @type {State}
   */
  function after(code) {
    if (markdownLineEnding(code)) {
      effects.exit("hardBreakEscape");
      return ok(code);
    }
    return nok(code);
  }
}

/**
 * @import {
 *   Construct,
 *   Resolver,
 *   State,
 *   TokenizeContext,
 *   Tokenizer,
 *   Token
 * } from 'micromark-util-types'
 */

/** @type {Construct} */
const headingAtx = {
  name: 'headingAtx',
  resolve: resolveHeadingAtx,
  tokenize: tokenizeHeadingAtx
};

/** @type {Resolver} */
function resolveHeadingAtx(events, context) {
  let contentEnd = events.length - 2;
  let contentStart = 3;
  /** @type {Token} */
  let content;
  /** @type {Token} */
  let text;

  // Prefix whitespace, part of the opening.
  if (events[contentStart][1].type === "whitespace") {
    contentStart += 2;
  }

  // Suffix whitespace, part of the closing.
  if (contentEnd - 2 > contentStart && events[contentEnd][1].type === "whitespace") {
    contentEnd -= 2;
  }
  if (events[contentEnd][1].type === "atxHeadingSequence" && (contentStart === contentEnd - 1 || contentEnd - 4 > contentStart && events[contentEnd - 2][1].type === "whitespace")) {
    contentEnd -= contentStart + 1 === contentEnd ? 2 : 4;
  }
  if (contentEnd > contentStart) {
    content = {
      type: "atxHeadingText",
      start: events[contentStart][1].start,
      end: events[contentEnd][1].end
    };
    text = {
      type: "chunkText",
      start: events[contentStart][1].start,
      end: events[contentEnd][1].end,
      contentType: "text"
    };
    splice(events, contentStart, contentEnd - contentStart + 1, [['enter', content, context], ['enter', text, context], ['exit', text, context], ['exit', content, context]]);
  }
  return events;
}

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeHeadingAtx(effects, ok, nok) {
  let size = 0;
  return start;

  /**
   * Start of a heading (atx).
   *
   * ```markdown
   * > | ## aa
   *     ^
   * ```
   *
   * @type {State}
   */
  function start(code) {
    // To do: parse indent like `markdown-rs`.
    effects.enter("atxHeading");
    return before(code);
  }

  /**
   * After optional whitespace, at `#`.
   *
   * ```markdown
   * > | ## aa
   *     ^
   * ```
   *
   * @type {State}
   */
  function before(code) {
    effects.enter("atxHeadingSequence");
    return sequenceOpen(code);
  }

  /**
   * In opening sequence.
   *
   * ```markdown
   * > | ## aa
   *     ^
   * ```
   *
   * @type {State}
   */
  function sequenceOpen(code) {
    if (code === 35 && size++ < 6) {
      effects.consume(code);
      return sequenceOpen;
    }

    // Always at least one `#`.
    if (code === null || markdownLineEndingOrSpace(code)) {
      effects.exit("atxHeadingSequence");
      return atBreak(code);
    }
    return nok(code);
  }

  /**
   * After something, before something else.
   *
   * ```markdown
   * > | ## aa
   *       ^
   * ```
   *
   * @type {State}
   */
  function atBreak(code) {
    if (code === 35) {
      effects.enter("atxHeadingSequence");
      return sequenceFurther(code);
    }
    if (code === null || markdownLineEnding(code)) {
      effects.exit("atxHeading");
      // To do: interrupt like `markdown-rs`.
      // // Feel free to interrupt.
      // tokenizer.interrupt = false
      return ok(code);
    }
    if (markdownSpace(code)) {
      return factorySpace(effects, atBreak, "whitespace")(code);
    }

    // To do: generate `data` tokens, add the `text` token later.
    // Needs edit map, see: `markdown.rs`.
    effects.enter("atxHeadingText");
    return data(code);
  }

  /**
   * In further sequence (after whitespace).
   *
   * Could be normal â€œvisibleâ€ hashes in the heading or a final sequence.
   *
   * ```markdown
   * > | ## aa ##
   *           ^
   * ```
   *
   * @type {State}
   */
  function sequenceFurther(code) {
    if (code === 35) {
      effects.consume(code);
      return sequenceFurther;
    }
    effects.exit("atxHeadingSequence");
    return atBreak(code);
  }

  /**
   * In text.
   *
   * ```markdown
   * > | ## aa
   *        ^
   * ```
   *
   * @type {State}
   */
  function data(code) {
    if (code === null || code === 35 || markdownLineEndingOrSpace(code)) {
      effects.exit("atxHeadingText");
      return atBreak(code);
    }
    effects.consume(code);
    return data;
  }
}

/**
 * List of lowercase HTML â€œblockâ€ tag names.
 *
 * The list, when parsing HTML (flow), results in more relaxed rules (condition
 * 6).
 * Because they are known blocks, the HTML-like syntax doesnâ€™t have to be
 * strictly parsed.
 * For tag names not in this list, a more strict algorithm (condition 7) is used
 * to detect whether the HTML-like syntax is seen as HTML (flow) or not.
 *
 * This is copied from:
 * <https://spec.commonmark.org/0.30/#html-blocks>.
 *
 * > ðŸ‘‰ **Note**: `search` was added in `CommonMark@0.31`.
 */
const htmlBlockNames = [
  'address',
  'article',
  'aside',
  'base',
  'basefont',
  'blockquote',
  'body',
  'caption',
  'center',
  'col',
  'colgroup',
  'dd',
  'details',
  'dialog',
  'dir',
  'div',
  'dl',
  'dt',
  'fieldset',
  'figcaption',
  'figure',
  'footer',
  'form',
  'frame',
  'frameset',
  'h1',
  'h2',
  'h3',
  'h4',
  'h5',
  'h6',
  'head',
  'header',
  'hr',
  'html',
  'iframe',
  'legend',
  'li',
  'link',
  'main',
  'menu',
  'menuitem',
  'nav',
  'noframes',
  'ol',
  'optgroup',
  'option',
  'p',
  'param',
  'search',
  'section',
  'summary',
  'table',
  'tbody',
  'td',
  'tfoot',
  'th',
  'thead',
  'title',
  'tr',
  'track',
  'ul'
];

/**
 * List of lowercase HTML â€œrawâ€ tag names.
 *
 * The list, when parsing HTML (flow), results in HTML that can include lines
 * without exiting, until a closing tag also in this list is found (condition
 * 1).
 *
 * This module is copied from:
 * <https://spec.commonmark.org/0.30/#html-blocks>.
 *
 * > ðŸ‘‰ **Note**: `textarea` was added in `CommonMark@0.30`.
 */
const htmlRawNames = ['pre', 'script', 'style', 'textarea'];

/**
 * @import {
 *   Code,
 *   Construct,
 *   Resolver,
 *   State,
 *   TokenizeContext,
 *   Tokenizer
 * } from 'micromark-util-types'
 */


/** @type {Construct} */
const htmlFlow = {
  concrete: true,
  name: 'htmlFlow',
  resolveTo: resolveToHtmlFlow,
  tokenize: tokenizeHtmlFlow
};

/** @type {Construct} */
const blankLineBefore = {
  partial: true,
  tokenize: tokenizeBlankLineBefore
};
const nonLazyContinuationStart = {
  partial: true,
  tokenize: tokenizeNonLazyContinuationStart
};

/** @type {Resolver} */
function resolveToHtmlFlow(events) {
  let index = events.length;
  while (index--) {
    if (events[index][0] === 'enter' && events[index][1].type === "htmlFlow") {
      break;
    }
  }
  if (index > 1 && events[index - 2][1].type === "linePrefix") {
    // Add the prefix start to the HTML token.
    events[index][1].start = events[index - 2][1].start;
    // Add the prefix start to the HTML line token.
    events[index + 1][1].start = events[index - 2][1].start;
    // Remove the line prefix.
    events.splice(index - 2, 2);
  }
  return events;
}

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeHtmlFlow(effects, ok, nok) {
  const self = this;
  /** @type {number} */
  let marker;
  /** @type {boolean} */
  let closingTag;
  /** @type {string} */
  let buffer;
  /** @type {number} */
  let index;
  /** @type {Code} */
  let markerB;
  return start;

  /**
   * Start of HTML (flow).
   *
   * ```markdown
   * > | <x />
   *     ^
   * ```
   *
   * @type {State}
   */
  function start(code) {
    // To do: parse indent like `markdown-rs`.
    return before(code);
  }

  /**
   * At `<`, after optional whitespace.
   *
   * ```markdown
   * > | <x />
   *     ^
   * ```
   *
   * @type {State}
   */
  function before(code) {
    effects.enter("htmlFlow");
    effects.enter("htmlFlowData");
    effects.consume(code);
    return open;
  }

  /**
   * After `<`, at tag name or other stuff.
   *
   * ```markdown
   * > | <x />
   *      ^
   * > | <!doctype>
   *      ^
   * > | <!--xxx-->
   *      ^
   * ```
   *
   * @type {State}
   */
  function open(code) {
    if (code === 33) {
      effects.consume(code);
      return declarationOpen;
    }
    if (code === 47) {
      effects.consume(code);
      closingTag = true;
      return tagCloseStart;
    }
    if (code === 63) {
      effects.consume(code);
      marker = 3;
      // To do:
      // tokenizer.concrete = true
      // To do: use `markdown-rs` style interrupt.
      // While weâ€™re in an instruction instead of a declaration, weâ€™re on a `?`
      // right now, so we do need to search for `>`, similar to declarations.
      return self.interrupt ? ok : continuationDeclarationInside;
    }

    // ASCII alphabetical.
    if (asciiAlpha(code)) {
      // Always the case.
      effects.consume(code);
      buffer = String.fromCharCode(code);
      return tagName;
    }
    return nok(code);
  }

  /**
   * After `<!`, at declaration, comment, or CDATA.
   *
   * ```markdown
   * > | <!doctype>
   *       ^
   * > | <!--xxx-->
   *       ^
   * > | <![CDATA[>&<]]>
   *       ^
   * ```
   *
   * @type {State}
   */
  function declarationOpen(code) {
    if (code === 45) {
      effects.consume(code);
      marker = 2;
      return commentOpenInside;
    }
    if (code === 91) {
      effects.consume(code);
      marker = 5;
      index = 0;
      return cdataOpenInside;
    }

    // ASCII alphabetical.
    if (asciiAlpha(code)) {
      effects.consume(code);
      marker = 4;
      // // Do not form containers.
      // tokenizer.concrete = true
      return self.interrupt ? ok : continuationDeclarationInside;
    }
    return nok(code);
  }

  /**
   * After `<!-`, inside a comment, at another `-`.
   *
   * ```markdown
   * > | <!--xxx-->
   *        ^
   * ```
   *
   * @type {State}
   */
  function commentOpenInside(code) {
    if (code === 45) {
      effects.consume(code);
      // // Do not form containers.
      // tokenizer.concrete = true
      return self.interrupt ? ok : continuationDeclarationInside;
    }
    return nok(code);
  }

  /**
   * After `<![`, inside CDATA, expecting `CDATA[`.
   *
   * ```markdown
   * > | <![CDATA[>&<]]>
   *        ^^^^^^
   * ```
   *
   * @type {State}
   */
  function cdataOpenInside(code) {
    const value = "CDATA[";
    if (code === value.charCodeAt(index++)) {
      effects.consume(code);
      if (index === value.length) {
        // // Do not form containers.
        // tokenizer.concrete = true
        return self.interrupt ? ok : continuation;
      }
      return cdataOpenInside;
    }
    return nok(code);
  }

  /**
   * After `</`, in closing tag, at tag name.
   *
   * ```markdown
   * > | </x>
   *       ^
   * ```
   *
   * @type {State}
   */
  function tagCloseStart(code) {
    if (asciiAlpha(code)) {
      // Always the case.
      effects.consume(code);
      buffer = String.fromCharCode(code);
      return tagName;
    }
    return nok(code);
  }

  /**
   * In tag name.
   *
   * ```markdown
   * > | <ab>
   *      ^^
   * > | </ab>
   *       ^^
   * ```
   *
   * @type {State}
   */
  function tagName(code) {
    if (code === null || code === 47 || code === 62 || markdownLineEndingOrSpace(code)) {
      const slash = code === 47;
      const name = buffer.toLowerCase();
      if (!slash && !closingTag && htmlRawNames.includes(name)) {
        marker = 1;
        // // Do not form containers.
        // tokenizer.concrete = true
        return self.interrupt ? ok(code) : continuation(code);
      }
      if (htmlBlockNames.includes(buffer.toLowerCase())) {
        marker = 6;
        if (slash) {
          effects.consume(code);
          return basicSelfClosing;
        }

        // // Do not form containers.
        // tokenizer.concrete = true
        return self.interrupt ? ok(code) : continuation(code);
      }
      marker = 7;
      // Do not support complete HTML when interrupting.
      return self.interrupt && !self.parser.lazy[self.now().line] ? nok(code) : closingTag ? completeClosingTagAfter(code) : completeAttributeNameBefore(code);
    }

    // ASCII alphanumerical and `-`.
    if (code === 45 || asciiAlphanumeric(code)) {
      effects.consume(code);
      buffer += String.fromCharCode(code);
      return tagName;
    }
    return nok(code);
  }

  /**
   * After closing slash of a basic tag name.
   *
   * ```markdown
   * > | <div/>
   *          ^
   * ```
   *
   * @type {State}
   */
  function basicSelfClosing(code) {
    if (code === 62) {
      effects.consume(code);
      // // Do not form containers.
      // tokenizer.concrete = true
      return self.interrupt ? ok : continuation;
    }
    return nok(code);
  }

  /**
   * After closing slash of a complete tag name.
   *
   * ```markdown
   * > | <x/>
   *        ^
   * ```
   *
   * @type {State}
   */
  function completeClosingTagAfter(code) {
    if (markdownSpace(code)) {
      effects.consume(code);
      return completeClosingTagAfter;
    }
    return completeEnd(code);
  }

  /**
   * At an attribute name.
   *
   * At first, this state is used after a complete tag name, after whitespace,
   * where it expects optional attributes or the end of the tag.
   * It is also reused after attributes, when expecting more optional
   * attributes.
   *
   * ```markdown
   * > | <a />
   *        ^
   * > | <a :b>
   *        ^
   * > | <a _b>
   *        ^
   * > | <a b>
   *        ^
   * > | <a >
   *        ^
   * ```
   *
   * @type {State}
   */
  function completeAttributeNameBefore(code) {
    if (code === 47) {
      effects.consume(code);
      return completeEnd;
    }

    // ASCII alphanumerical and `:` and `_`.
    if (code === 58 || code === 95 || asciiAlpha(code)) {
      effects.consume(code);
      return completeAttributeName;
    }
    if (markdownSpace(code)) {
      effects.consume(code);
      return completeAttributeNameBefore;
    }
    return completeEnd(code);
  }

  /**
   * In attribute name.
   *
   * ```markdown
   * > | <a :b>
   *         ^
   * > | <a _b>
   *         ^
   * > | <a b>
   *         ^
   * ```
   *
   * @type {State}
   */
  function completeAttributeName(code) {
    // ASCII alphanumerical and `-`, `.`, `:`, and `_`.
    if (code === 45 || code === 46 || code === 58 || code === 95 || asciiAlphanumeric(code)) {
      effects.consume(code);
      return completeAttributeName;
    }
    return completeAttributeNameAfter(code);
  }

  /**
   * After attribute name, at an optional initializer, the end of the tag, or
   * whitespace.
   *
   * ```markdown
   * > | <a b>
   *         ^
   * > | <a b=c>
   *         ^
   * ```
   *
   * @type {State}
   */
  function completeAttributeNameAfter(code) {
    if (code === 61) {
      effects.consume(code);
      return completeAttributeValueBefore;
    }
    if (markdownSpace(code)) {
      effects.consume(code);
      return completeAttributeNameAfter;
    }
    return completeAttributeNameBefore(code);
  }

  /**
   * Before unquoted, double quoted, or single quoted attribute value, allowing
   * whitespace.
   *
   * ```markdown
   * > | <a b=c>
   *          ^
   * > | <a b="c">
   *          ^
   * ```
   *
   * @type {State}
   */
  function completeAttributeValueBefore(code) {
    if (code === null || code === 60 || code === 61 || code === 62 || code === 96) {
      return nok(code);
    }
    if (code === 34 || code === 39) {
      effects.consume(code);
      markerB = code;
      return completeAttributeValueQuoted;
    }
    if (markdownSpace(code)) {
      effects.consume(code);
      return completeAttributeValueBefore;
    }
    return completeAttributeValueUnquoted(code);
  }

  /**
   * In double or single quoted attribute value.
   *
   * ```markdown
   * > | <a b="c">
   *           ^
   * > | <a b='c'>
   *           ^
   * ```
   *
   * @type {State}
   */
  function completeAttributeValueQuoted(code) {
    if (code === markerB) {
      effects.consume(code);
      markerB = null;
      return completeAttributeValueQuotedAfter;
    }
    if (code === null || markdownLineEnding(code)) {
      return nok(code);
    }
    effects.consume(code);
    return completeAttributeValueQuoted;
  }

  /**
   * In unquoted attribute value.
   *
   * ```markdown
   * > | <a b=c>
   *          ^
   * ```
   *
   * @type {State}
   */
  function completeAttributeValueUnquoted(code) {
    if (code === null || code === 34 || code === 39 || code === 47 || code === 60 || code === 61 || code === 62 || code === 96 || markdownLineEndingOrSpace(code)) {
      return completeAttributeNameAfter(code);
    }
    effects.consume(code);
    return completeAttributeValueUnquoted;
  }

  /**
   * After double or single quoted attribute value, before whitespace or the
   * end of the tag.
   *
   * ```markdown
   * > | <a b="c">
   *            ^
   * ```
   *
   * @type {State}
   */
  function completeAttributeValueQuotedAfter(code) {
    if (code === 47 || code === 62 || markdownSpace(code)) {
      return completeAttributeNameBefore(code);
    }
    return nok(code);
  }

  /**
   * In certain circumstances of a complete tag where only an `>` is allowed.
   *
   * ```markdown
   * > | <a b="c">
   *             ^
   * ```
   *
   * @type {State}
   */
  function completeEnd(code) {
    if (code === 62) {
      effects.consume(code);
      return completeAfter;
    }
    return nok(code);
  }

  /**
   * After `>` in a complete tag.
   *
   * ```markdown
   * > | <x>
   *        ^
   * ```
   *
   * @type {State}
   */
  function completeAfter(code) {
    if (code === null || markdownLineEnding(code)) {
      // // Do not form containers.
      // tokenizer.concrete = true
      return continuation(code);
    }
    if (markdownSpace(code)) {
      effects.consume(code);
      return completeAfter;
    }
    return nok(code);
  }

  /**
   * In continuation of any HTML kind.
   *
   * ```markdown
   * > | <!--xxx-->
   *          ^
   * ```
   *
   * @type {State}
   */
  function continuation(code) {
    if (code === 45 && marker === 2) {
      effects.consume(code);
      return continuationCommentInside;
    }
    if (code === 60 && marker === 1) {
      effects.consume(code);
      return continuationRawTagOpen;
    }
    if (code === 62 && marker === 4) {
      effects.consume(code);
      return continuationClose;
    }
    if (code === 63 && marker === 3) {
      effects.consume(code);
      return continuationDeclarationInside;
    }
    if (code === 93 && marker === 5) {
      effects.consume(code);
      return continuationCdataInside;
    }
    if (markdownLineEnding(code) && (marker === 6 || marker === 7)) {
      effects.exit("htmlFlowData");
      return effects.check(blankLineBefore, continuationAfter, continuationStart)(code);
    }
    if (code === null || markdownLineEnding(code)) {
      effects.exit("htmlFlowData");
      return continuationStart(code);
    }
    effects.consume(code);
    return continuation;
  }

  /**
   * In continuation, at eol.
   *
   * ```markdown
   * > | <x>
   *        ^
   *   | asd
   * ```
   *
   * @type {State}
   */
  function continuationStart(code) {
    return effects.check(nonLazyContinuationStart, continuationStartNonLazy, continuationAfter)(code);
  }

  /**
   * In continuation, at eol, before non-lazy content.
   *
   * ```markdown
   * > | <x>
   *        ^
   *   | asd
   * ```
   *
   * @type {State}
   */
  function continuationStartNonLazy(code) {
    effects.enter("lineEnding");
    effects.consume(code);
    effects.exit("lineEnding");
    return continuationBefore;
  }

  /**
   * In continuation, before non-lazy content.
   *
   * ```markdown
   *   | <x>
   * > | asd
   *     ^
   * ```
   *
   * @type {State}
   */
  function continuationBefore(code) {
    if (code === null || markdownLineEnding(code)) {
      return continuationStart(code);
    }
    effects.enter("htmlFlowData");
    return continuation(code);
  }

  /**
   * In comment continuation, after one `-`, expecting another.
   *
   * ```markdown
   * > | <!--xxx-->
   *             ^
   * ```
   *
   * @type {State}
   */
  function continuationCommentInside(code) {
    if (code === 45) {
      effects.consume(code);
      return continuationDeclarationInside;
    }
    return continuation(code);
  }

  /**
   * In raw continuation, after `<`, at `/`.
   *
   * ```markdown
   * > | <script>console.log(1)</script>
   *                            ^
   * ```
   *
   * @type {State}
   */
  function continuationRawTagOpen(code) {
    if (code === 47) {
      effects.consume(code);
      buffer = '';
      return continuationRawEndTag;
    }
    return continuation(code);
  }

  /**
   * In raw continuation, after `</`, in a raw tag name.
   *
   * ```markdown
   * > | <script>console.log(1)</script>
   *                             ^^^^^^
   * ```
   *
   * @type {State}
   */
  function continuationRawEndTag(code) {
    if (code === 62) {
      const name = buffer.toLowerCase();
      if (htmlRawNames.includes(name)) {
        effects.consume(code);
        return continuationClose;
      }
      return continuation(code);
    }
    if (asciiAlpha(code) && buffer.length < 8) {
      // Always the case.
      effects.consume(code);
      buffer += String.fromCharCode(code);
      return continuationRawEndTag;
    }
    return continuation(code);
  }

  /**
   * In cdata continuation, after `]`, expecting `]>`.
   *
   * ```markdown
   * > | <![CDATA[>&<]]>
   *                  ^
   * ```
   *
   * @type {State}
   */
  function continuationCdataInside(code) {
    if (code === 93) {
      effects.consume(code);
      return continuationDeclarationInside;
    }
    return continuation(code);
  }

  /**
   * In declaration or instruction continuation, at `>`.
   *
   * ```markdown
   * > | <!-->
   *         ^
   * > | <?>
   *       ^
   * > | <!q>
   *        ^
   * > | <!--ab-->
   *             ^
   * > | <![CDATA[>&<]]>
   *                   ^
   * ```
   *
   * @type {State}
   */
  function continuationDeclarationInside(code) {
    if (code === 62) {
      effects.consume(code);
      return continuationClose;
    }

    // More dashes.
    if (code === 45 && marker === 2) {
      effects.consume(code);
      return continuationDeclarationInside;
    }
    return continuation(code);
  }

  /**
   * In closed continuation: everything we get until the eol/eof is part of it.
   *
   * ```markdown
   * > | <!doctype>
   *               ^
   * ```
   *
   * @type {State}
   */
  function continuationClose(code) {
    if (code === null || markdownLineEnding(code)) {
      effects.exit("htmlFlowData");
      return continuationAfter(code);
    }
    effects.consume(code);
    return continuationClose;
  }

  /**
   * Done.
   *
   * ```markdown
   * > | <!doctype>
   *               ^
   * ```
   *
   * @type {State}
   */
  function continuationAfter(code) {
    effects.exit("htmlFlow");
    // // Feel free to interrupt.
    // tokenizer.interrupt = false
    // // No longer concrete.
    // tokenizer.concrete = false
    return ok(code);
  }
}

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeNonLazyContinuationStart(effects, ok, nok) {
  const self = this;
  return start;

  /**
   * At eol, before continuation.
   *
   * ```markdown
   * > | * ```js
   *            ^
   *   | b
   * ```
   *
   * @type {State}
   */
  function start(code) {
    if (markdownLineEnding(code)) {
      effects.enter("lineEnding");
      effects.consume(code);
      effects.exit("lineEnding");
      return after;
    }
    return nok(code);
  }

  /**
   * A continuation.
   *
   * ```markdown
   *   | * ```js
   * > | b
   *     ^
   * ```
   *
   * @type {State}
   */
  function after(code) {
    return self.parser.lazy[self.now().line] ? nok(code) : ok(code);
  }
}

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeBlankLineBefore(effects, ok, nok) {
  return start;

  /**
   * Before eol, expecting blank line.
   *
   * ```markdown
   * > | <div>
   *          ^
   *   |
   * ```
   *
   * @type {State}
   */
  function start(code) {
    effects.enter("lineEnding");
    effects.consume(code);
    effects.exit("lineEnding");
    return effects.attempt(blankLine, ok, nok);
  }
}

/**
 * @import {
 *   Code,
 *   Construct,
 *   State,
 *   TokenizeContext,
 *   Tokenizer
 * } from 'micromark-util-types'
 */

/** @type {Construct} */
const htmlText = {
  name: 'htmlText',
  tokenize: tokenizeHtmlText
};

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeHtmlText(effects, ok, nok) {
  const self = this;
  /** @type {NonNullable<Code> | undefined} */
  let marker;
  /** @type {number} */
  let index;
  /** @type {State} */
  let returnState;
  return start;

  /**
   * Start of HTML (text).
   *
   * ```markdown
   * > | a <b> c
   *       ^
   * ```
   *
   * @type {State}
   */
  function start(code) {
    effects.enter("htmlText");
    effects.enter("htmlTextData");
    effects.consume(code);
    return open;
  }

  /**
   * After `<`, at tag name or other stuff.
   *
   * ```markdown
   * > | a <b> c
   *        ^
   * > | a <!doctype> c
   *        ^
   * > | a <!--b--> c
   *        ^
   * ```
   *
   * @type {State}
   */
  function open(code) {
    if (code === 33) {
      effects.consume(code);
      return declarationOpen;
    }
    if (code === 47) {
      effects.consume(code);
      return tagCloseStart;
    }
    if (code === 63) {
      effects.consume(code);
      return instruction;
    }

    // ASCII alphabetical.
    if (asciiAlpha(code)) {
      effects.consume(code);
      return tagOpen;
    }
    return nok(code);
  }

  /**
   * After `<!`, at declaration, comment, or CDATA.
   *
   * ```markdown
   * > | a <!doctype> c
   *         ^
   * > | a <!--b--> c
   *         ^
   * > | a <![CDATA[>&<]]> c
   *         ^
   * ```
   *
   * @type {State}
   */
  function declarationOpen(code) {
    if (code === 45) {
      effects.consume(code);
      return commentOpenInside;
    }
    if (code === 91) {
      effects.consume(code);
      index = 0;
      return cdataOpenInside;
    }
    if (asciiAlpha(code)) {
      effects.consume(code);
      return declaration;
    }
    return nok(code);
  }

  /**
   * In a comment, after `<!-`, at another `-`.
   *
   * ```markdown
   * > | a <!--b--> c
   *          ^
   * ```
   *
   * @type {State}
   */
  function commentOpenInside(code) {
    if (code === 45) {
      effects.consume(code);
      return commentEnd;
    }
    return nok(code);
  }

  /**
   * In comment.
   *
   * ```markdown
   * > | a <!--b--> c
   *           ^
   * ```
   *
   * @type {State}
   */
  function comment(code) {
    if (code === null) {
      return nok(code);
    }
    if (code === 45) {
      effects.consume(code);
      return commentClose;
    }
    if (markdownLineEnding(code)) {
      returnState = comment;
      return lineEndingBefore(code);
    }
    effects.consume(code);
    return comment;
  }

  /**
   * In comment, after `-`.
   *
   * ```markdown
   * > | a <!--b--> c
   *             ^
   * ```
   *
   * @type {State}
   */
  function commentClose(code) {
    if (code === 45) {
      effects.consume(code);
      return commentEnd;
    }
    return comment(code);
  }

  /**
   * In comment, after `--`.
   *
   * ```markdown
   * > | a <!--b--> c
   *              ^
   * ```
   *
   * @type {State}
   */
  function commentEnd(code) {
    return code === 62 ? end(code) : code === 45 ? commentClose(code) : comment(code);
  }

  /**
   * After `<![`, in CDATA, expecting `CDATA[`.
   *
   * ```markdown
   * > | a <![CDATA[>&<]]> b
   *          ^^^^^^
   * ```
   *
   * @type {State}
   */
  function cdataOpenInside(code) {
    const value = "CDATA[";
    if (code === value.charCodeAt(index++)) {
      effects.consume(code);
      return index === value.length ? cdata : cdataOpenInside;
    }
    return nok(code);
  }

  /**
   * In CDATA.
   *
   * ```markdown
   * > | a <![CDATA[>&<]]> b
   *                ^^^
   * ```
   *
   * @type {State}
   */
  function cdata(code) {
    if (code === null) {
      return nok(code);
    }
    if (code === 93) {
      effects.consume(code);
      return cdataClose;
    }
    if (markdownLineEnding(code)) {
      returnState = cdata;
      return lineEndingBefore(code);
    }
    effects.consume(code);
    return cdata;
  }

  /**
   * In CDATA, after `]`, at another `]`.
   *
   * ```markdown
   * > | a <![CDATA[>&<]]> b
   *                    ^
   * ```
   *
   * @type {State}
   */
  function cdataClose(code) {
    if (code === 93) {
      effects.consume(code);
      return cdataEnd;
    }
    return cdata(code);
  }

  /**
   * In CDATA, after `]]`, at `>`.
   *
   * ```markdown
   * > | a <![CDATA[>&<]]> b
   *                     ^
   * ```
   *
   * @type {State}
   */
  function cdataEnd(code) {
    if (code === 62) {
      return end(code);
    }
    if (code === 93) {
      effects.consume(code);
      return cdataEnd;
    }
    return cdata(code);
  }

  /**
   * In declaration.
   *
   * ```markdown
   * > | a <!b> c
   *          ^
   * ```
   *
   * @type {State}
   */
  function declaration(code) {
    if (code === null || code === 62) {
      return end(code);
    }
    if (markdownLineEnding(code)) {
      returnState = declaration;
      return lineEndingBefore(code);
    }
    effects.consume(code);
    return declaration;
  }

  /**
   * In instruction.
   *
   * ```markdown
   * > | a <?b?> c
   *         ^
   * ```
   *
   * @type {State}
   */
  function instruction(code) {
    if (code === null) {
      return nok(code);
    }
    if (code === 63) {
      effects.consume(code);
      return instructionClose;
    }
    if (markdownLineEnding(code)) {
      returnState = instruction;
      return lineEndingBefore(code);
    }
    effects.consume(code);
    return instruction;
  }

  /**
   * In instruction, after `?`, at `>`.
   *
   * ```markdown
   * > | a <?b?> c
   *           ^
   * ```
   *
   * @type {State}
   */
  function instructionClose(code) {
    return code === 62 ? end(code) : instruction(code);
  }

  /**
   * After `</`, in closing tag, at tag name.
   *
   * ```markdown
   * > | a </b> c
   *         ^
   * ```
   *
   * @type {State}
   */
  function tagCloseStart(code) {
    // ASCII alphabetical.
    if (asciiAlpha(code)) {
      effects.consume(code);
      return tagClose;
    }
    return nok(code);
  }

  /**
   * After `</x`, in a tag name.
   *
   * ```markdown
   * > | a </b> c
   *          ^
   * ```
   *
   * @type {State}
   */
  function tagClose(code) {
    // ASCII alphanumerical and `-`.
    if (code === 45 || asciiAlphanumeric(code)) {
      effects.consume(code);
      return tagClose;
    }
    return tagCloseBetween(code);
  }

  /**
   * In closing tag, after tag name.
   *
   * ```markdown
   * > | a </b> c
   *          ^
   * ```
   *
   * @type {State}
   */
  function tagCloseBetween(code) {
    if (markdownLineEnding(code)) {
      returnState = tagCloseBetween;
      return lineEndingBefore(code);
    }
    if (markdownSpace(code)) {
      effects.consume(code);
      return tagCloseBetween;
    }
    return end(code);
  }

  /**
   * After `<x`, in opening tag name.
   *
   * ```markdown
   * > | a <b> c
   *         ^
   * ```
   *
   * @type {State}
   */
  function tagOpen(code) {
    // ASCII alphanumerical and `-`.
    if (code === 45 || asciiAlphanumeric(code)) {
      effects.consume(code);
      return tagOpen;
    }
    if (code === 47 || code === 62 || markdownLineEndingOrSpace(code)) {
      return tagOpenBetween(code);
    }
    return nok(code);
  }

  /**
   * In opening tag, after tag name.
   *
   * ```markdown
   * > | a <b> c
   *         ^
   * ```
   *
   * @type {State}
   */
  function tagOpenBetween(code) {
    if (code === 47) {
      effects.consume(code);
      return end;
    }

    // ASCII alphabetical and `:` and `_`.
    if (code === 58 || code === 95 || asciiAlpha(code)) {
      effects.consume(code);
      return tagOpenAttributeName;
    }
    if (markdownLineEnding(code)) {
      returnState = tagOpenBetween;
      return lineEndingBefore(code);
    }
    if (markdownSpace(code)) {
      effects.consume(code);
      return tagOpenBetween;
    }
    return end(code);
  }

  /**
   * In attribute name.
   *
   * ```markdown
   * > | a <b c> d
   *          ^
   * ```
   *
   * @type {State}
   */
  function tagOpenAttributeName(code) {
    // ASCII alphabetical and `-`, `.`, `:`, and `_`.
    if (code === 45 || code === 46 || code === 58 || code === 95 || asciiAlphanumeric(code)) {
      effects.consume(code);
      return tagOpenAttributeName;
    }
    return tagOpenAttributeNameAfter(code);
  }

  /**
   * After attribute name, before initializer, the end of the tag, or
   * whitespace.
   *
   * ```markdown
   * > | a <b c> d
   *           ^
   * ```
   *
   * @type {State}
   */
  function tagOpenAttributeNameAfter(code) {
    if (code === 61) {
      effects.consume(code);
      return tagOpenAttributeValueBefore;
    }
    if (markdownLineEnding(code)) {
      returnState = tagOpenAttributeNameAfter;
      return lineEndingBefore(code);
    }
    if (markdownSpace(code)) {
      effects.consume(code);
      return tagOpenAttributeNameAfter;
    }
    return tagOpenBetween(code);
  }

  /**
   * Before unquoted, double quoted, or single quoted attribute value, allowing
   * whitespace.
   *
   * ```markdown
   * > | a <b c=d> e
   *            ^
   * ```
   *
   * @type {State}
   */
  function tagOpenAttributeValueBefore(code) {
    if (code === null || code === 60 || code === 61 || code === 62 || code === 96) {
      return nok(code);
    }
    if (code === 34 || code === 39) {
      effects.consume(code);
      marker = code;
      return tagOpenAttributeValueQuoted;
    }
    if (markdownLineEnding(code)) {
      returnState = tagOpenAttributeValueBefore;
      return lineEndingBefore(code);
    }
    if (markdownSpace(code)) {
      effects.consume(code);
      return tagOpenAttributeValueBefore;
    }
    effects.consume(code);
    return tagOpenAttributeValueUnquoted;
  }

  /**
   * In double or single quoted attribute value.
   *
   * ```markdown
   * > | a <b c="d"> e
   *             ^
   * ```
   *
   * @type {State}
   */
  function tagOpenAttributeValueQuoted(code) {
    if (code === marker) {
      effects.consume(code);
      marker = undefined;
      return tagOpenAttributeValueQuotedAfter;
    }
    if (code === null) {
      return nok(code);
    }
    if (markdownLineEnding(code)) {
      returnState = tagOpenAttributeValueQuoted;
      return lineEndingBefore(code);
    }
    effects.consume(code);
    return tagOpenAttributeValueQuoted;
  }

  /**
   * In unquoted attribute value.
   *
   * ```markdown
   * > | a <b c=d> e
   *            ^
   * ```
   *
   * @type {State}
   */
  function tagOpenAttributeValueUnquoted(code) {
    if (code === null || code === 34 || code === 39 || code === 60 || code === 61 || code === 96) {
      return nok(code);
    }
    if (code === 47 || code === 62 || markdownLineEndingOrSpace(code)) {
      return tagOpenBetween(code);
    }
    effects.consume(code);
    return tagOpenAttributeValueUnquoted;
  }

  /**
   * After double or single quoted attribute value, before whitespace or the end
   * of the tag.
   *
   * ```markdown
   * > | a <b c="d"> e
   *               ^
   * ```
   *
   * @type {State}
   */
  function tagOpenAttributeValueQuotedAfter(code) {
    if (code === 47 || code === 62 || markdownLineEndingOrSpace(code)) {
      return tagOpenBetween(code);
    }
    return nok(code);
  }

  /**
   * In certain circumstances of a tag where only an `>` is allowed.
   *
   * ```markdown
   * > | a <b c="d"> e
   *               ^
   * ```
   *
   * @type {State}
   */
  function end(code) {
    if (code === 62) {
      effects.consume(code);
      effects.exit("htmlTextData");
      effects.exit("htmlText");
      return ok;
    }
    return nok(code);
  }

  /**
   * At eol.
   *
   * > ðŸ‘‰ **Note**: we canâ€™t have blank lines in text, so no need to worry about
   * > empty tokens.
   *
   * ```markdown
   * > | a <!--a
   *            ^
   *   | b-->
   * ```
   *
   * @type {State}
   */
  function lineEndingBefore(code) {
    effects.exit("htmlTextData");
    effects.enter("lineEnding");
    effects.consume(code);
    effects.exit("lineEnding");
    return lineEndingAfter;
  }

  /**
   * After eol, at optional whitespace.
   *
   * > ðŸ‘‰ **Note**: we canâ€™t have blank lines in text, so no need to worry about
   * > empty tokens.
   *
   * ```markdown
   *   | a <!--a
   * > | b-->
   *     ^
   * ```
   *
   * @type {State}
   */
  function lineEndingAfter(code) {
    // Always populated by defaults.

    return markdownSpace(code) ? factorySpace(effects, lineEndingAfterPrefix, "linePrefix", self.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4)(code) : lineEndingAfterPrefix(code);
  }

  /**
   * After eol, after optional whitespace.
   *
   * > ðŸ‘‰ **Note**: we canâ€™t have blank lines in text, so no need to worry about
   * > empty tokens.
   *
   * ```markdown
   *   | a <!--a
   * > | b-->
   *     ^
   * ```
   *
   * @type {State}
   */
  function lineEndingAfterPrefix(code) {
    effects.enter("htmlTextData");
    return returnState(code);
  }
}

/**
 * @import {
 *   Construct,
 *   Event,
 *   Resolver,
 *   State,
 *   TokenizeContext,
 *   Tokenizer,
 *   Token
 * } from 'micromark-util-types'
 */

/** @type {Construct} */
const labelEnd = {
  name: 'labelEnd',
  resolveAll: resolveAllLabelEnd,
  resolveTo: resolveToLabelEnd,
  tokenize: tokenizeLabelEnd
};

/** @type {Construct} */
const resourceConstruct = {
  tokenize: tokenizeResource
};
/** @type {Construct} */
const referenceFullConstruct = {
  tokenize: tokenizeReferenceFull
};
/** @type {Construct} */
const referenceCollapsedConstruct = {
  tokenize: tokenizeReferenceCollapsed
};

/** @type {Resolver} */
function resolveAllLabelEnd(events) {
  let index = -1;
  /** @type {Array<Event>} */
  const newEvents = [];
  while (++index < events.length) {
    const token = events[index][1];
    newEvents.push(events[index]);
    if (token.type === "labelImage" || token.type === "labelLink" || token.type === "labelEnd") {
      // Remove the marker.
      const offset = token.type === "labelImage" ? 4 : 2;
      token.type = "data";
      index += offset;
    }
  }

  // If the events are equal, we don't have to copy newEvents to events
  if (events.length !== newEvents.length) {
    splice(events, 0, events.length, newEvents);
  }
  return events;
}

/** @type {Resolver} */
function resolveToLabelEnd(events, context) {
  let index = events.length;
  let offset = 0;
  /** @type {Token} */
  let token;
  /** @type {number | undefined} */
  let open;
  /** @type {number | undefined} */
  let close;
  /** @type {Array<Event>} */
  let media;

  // Find an opening.
  while (index--) {
    token = events[index][1];
    if (open) {
      // If we see another link, or inactive link label, weâ€™ve been here before.
      if (token.type === "link" || token.type === "labelLink" && token._inactive) {
        break;
      }

      // Mark other link openings as inactive, as we canâ€™t have links in
      // links.
      if (events[index][0] === 'enter' && token.type === "labelLink") {
        token._inactive = true;
      }
    } else if (close) {
      if (events[index][0] === 'enter' && (token.type === "labelImage" || token.type === "labelLink") && !token._balanced) {
        open = index;
        if (token.type !== "labelLink") {
          offset = 2;
          break;
        }
      }
    } else if (token.type === "labelEnd") {
      close = index;
    }
  }
  const group = {
    type: events[open][1].type === "labelLink" ? "link" : "image",
    start: {
      ...events[open][1].start
    },
    end: {
      ...events[events.length - 1][1].end
    }
  };
  const label = {
    type: "label",
    start: {
      ...events[open][1].start
    },
    end: {
      ...events[close][1].end
    }
  };
  const text = {
    type: "labelText",
    start: {
      ...events[open + offset + 2][1].end
    },
    end: {
      ...events[close - 2][1].start
    }
  };
  media = [['enter', group, context], ['enter', label, context]];

  // Opening marker.
  media = push(media, events.slice(open + 1, open + offset + 3));

  // Text open.
  media = push(media, [['enter', text, context]]);

  // Always populated by defaults.

  // Between.
  media = push(media, resolveAll(context.parser.constructs.insideSpan.null, events.slice(open + offset + 4, close - 3), context));

  // Text close, marker close, label close.
  media = push(media, [['exit', text, context], events[close - 2], events[close - 1], ['exit', label, context]]);

  // Reference, resource, or so.
  media = push(media, events.slice(close + 1));

  // Media close.
  media = push(media, [['exit', group, context]]);
  splice(events, open, events.length, media);
  return events;
}

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeLabelEnd(effects, ok, nok) {
  const self = this;
  let index = self.events.length;
  /** @type {Token} */
  let labelStart;
  /** @type {boolean} */
  let defined;

  // Find an opening.
  while (index--) {
    if ((self.events[index][1].type === "labelImage" || self.events[index][1].type === "labelLink") && !self.events[index][1]._balanced) {
      labelStart = self.events[index][1];
      break;
    }
  }
  return start;

  /**
   * Start of label end.
   *
   * ```markdown
   * > | [a](b) c
   *       ^
   * > | [a][b] c
   *       ^
   * > | [a][] b
   *       ^
   * > | [a] b
   * ```
   *
   * @type {State}
   */
  function start(code) {
    // If there is not an okay opening.
    if (!labelStart) {
      return nok(code);
    }

    // If the corresponding label (link) start is marked as inactive,
    // it means weâ€™d be wrapping a link, like this:
    //
    // ```markdown
    // > | a [b [c](d) e](f) g.
    //                  ^
    // ```
    //
    // We canâ€™t have that, so itâ€™s just balanced brackets.
    if (labelStart._inactive) {
      return labelEndNok(code);
    }
    defined = self.parser.defined.includes(normalizeIdentifier(self.sliceSerialize({
      start: labelStart.end,
      end: self.now()
    })));
    effects.enter("labelEnd");
    effects.enter("labelMarker");
    effects.consume(code);
    effects.exit("labelMarker");
    effects.exit("labelEnd");
    return after;
  }

  /**
   * After `]`.
   *
   * ```markdown
   * > | [a](b) c
   *       ^
   * > | [a][b] c
   *       ^
   * > | [a][] b
   *       ^
   * > | [a] b
   *       ^
   * ```
   *
   * @type {State}
   */
  function after(code) {
    // Note: `markdown-rs` also parses GFM footnotes here, which for us is in
    // an extension.

    // Resource (`[asd](fgh)`)?
    if (code === 40) {
      return effects.attempt(resourceConstruct, labelEndOk, defined ? labelEndOk : labelEndNok)(code);
    }

    // Full (`[asd][fgh]`) or collapsed (`[asd][]`) reference?
    if (code === 91) {
      return effects.attempt(referenceFullConstruct, labelEndOk, defined ? referenceNotFull : labelEndNok)(code);
    }

    // Shortcut (`[asd]`) reference?
    return defined ? labelEndOk(code) : labelEndNok(code);
  }

  /**
   * After `]`, at `[`, but not at a full reference.
   *
   * > ðŸ‘‰ **Note**: we only get here if the label is defined.
   *
   * ```markdown
   * > | [a][] b
   *        ^
   * > | [a] b
   *        ^
   * ```
   *
   * @type {State}
   */
  function referenceNotFull(code) {
    return effects.attempt(referenceCollapsedConstruct, labelEndOk, labelEndNok)(code);
  }

  /**
   * Done, we found something.
   *
   * ```markdown
   * > | [a](b) c
   *           ^
   * > | [a][b] c
   *           ^
   * > | [a][] b
   *          ^
   * > | [a] b
   *        ^
   * ```
   *
   * @type {State}
   */
  function labelEndOk(code) {
    // Note: `markdown-rs` does a bunch of stuff here.
    return ok(code);
  }

  /**
   * Done, itâ€™s nothing.
   *
   * There was an okay opening, but we didnâ€™t match anything.
   *
   * ```markdown
   * > | [a](b c
   *        ^
   * > | [a][b c
   *        ^
   * > | [a] b
   *        ^
   * ```
   *
   * @type {State}
   */
  function labelEndNok(code) {
    labelStart._balanced = true;
    return nok(code);
  }
}

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeResource(effects, ok, nok) {
  return resourceStart;

  /**
   * At a resource.
   *
   * ```markdown
   * > | [a](b) c
   *        ^
   * ```
   *
   * @type {State}
   */
  function resourceStart(code) {
    effects.enter("resource");
    effects.enter("resourceMarker");
    effects.consume(code);
    effects.exit("resourceMarker");
    return resourceBefore;
  }

  /**
   * In resource, after `(`, at optional whitespace.
   *
   * ```markdown
   * > | [a](b) c
   *         ^
   * ```
   *
   * @type {State}
   */
  function resourceBefore(code) {
    return markdownLineEndingOrSpace(code) ? factoryWhitespace(effects, resourceOpen)(code) : resourceOpen(code);
  }

  /**
   * In resource, after optional whitespace, at `)` or a destination.
   *
   * ```markdown
   * > | [a](b) c
   *         ^
   * ```
   *
   * @type {State}
   */
  function resourceOpen(code) {
    if (code === 41) {
      return resourceEnd(code);
    }
    return factoryDestination(effects, resourceDestinationAfter, resourceDestinationMissing, "resourceDestination", "resourceDestinationLiteral", "resourceDestinationLiteralMarker", "resourceDestinationRaw", "resourceDestinationString", 32)(code);
  }

  /**
   * In resource, after destination, at optional whitespace.
   *
   * ```markdown
   * > | [a](b) c
   *          ^
   * ```
   *
   * @type {State}
   */
  function resourceDestinationAfter(code) {
    return markdownLineEndingOrSpace(code) ? factoryWhitespace(effects, resourceBetween)(code) : resourceEnd(code);
  }

  /**
   * At invalid destination.
   *
   * ```markdown
   * > | [a](<<) b
   *         ^
   * ```
   *
   * @type {State}
   */
  function resourceDestinationMissing(code) {
    return nok(code);
  }

  /**
   * In resource, after destination and whitespace, at `(` or title.
   *
   * ```markdown
   * > | [a](b ) c
   *           ^
   * ```
   *
   * @type {State}
   */
  function resourceBetween(code) {
    if (code === 34 || code === 39 || code === 40) {
      return factoryTitle(effects, resourceTitleAfter, nok, "resourceTitle", "resourceTitleMarker", "resourceTitleString")(code);
    }
    return resourceEnd(code);
  }

  /**
   * In resource, after title, at optional whitespace.
   *
   * ```markdown
   * > | [a](b "c") d
   *              ^
   * ```
   *
   * @type {State}
   */
  function resourceTitleAfter(code) {
    return markdownLineEndingOrSpace(code) ? factoryWhitespace(effects, resourceEnd)(code) : resourceEnd(code);
  }

  /**
   * In resource, at `)`.
   *
   * ```markdown
   * > | [a](b) d
   *          ^
   * ```
   *
   * @type {State}
   */
  function resourceEnd(code) {
    if (code === 41) {
      effects.enter("resourceMarker");
      effects.consume(code);
      effects.exit("resourceMarker");
      effects.exit("resource");
      return ok;
    }
    return nok(code);
  }
}

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeReferenceFull(effects, ok, nok) {
  const self = this;
  return referenceFull;

  /**
   * In a reference (full), at the `[`.
   *
   * ```markdown
   * > | [a][b] d
   *        ^
   * ```
   *
   * @type {State}
   */
  function referenceFull(code) {
    return factoryLabel.call(self, effects, referenceFullAfter, referenceFullMissing, "reference", "referenceMarker", "referenceString")(code);
  }

  /**
   * In a reference (full), after `]`.
   *
   * ```markdown
   * > | [a][b] d
   *          ^
   * ```
   *
   * @type {State}
   */
  function referenceFullAfter(code) {
    return self.parser.defined.includes(normalizeIdentifier(self.sliceSerialize(self.events[self.events.length - 1][1]).slice(1, -1))) ? ok(code) : nok(code);
  }

  /**
   * In reference (full) that was missing.
   *
   * ```markdown
   * > | [a][b d
   *        ^
   * ```
   *
   * @type {State}
   */
  function referenceFullMissing(code) {
    return nok(code);
  }
}

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeReferenceCollapsed(effects, ok, nok) {
  return referenceCollapsedStart;

  /**
   * In reference (collapsed), at `[`.
   *
   * > ðŸ‘‰ **Note**: we only get here if the label is defined.
   *
   * ```markdown
   * > | [a][] d
   *        ^
   * ```
   *
   * @type {State}
   */
  function referenceCollapsedStart(code) {
    // We only attempt a collapsed label if thereâ€™s a `[`.

    effects.enter("reference");
    effects.enter("referenceMarker");
    effects.consume(code);
    effects.exit("referenceMarker");
    return referenceCollapsedOpen;
  }

  /**
   * In reference (collapsed), at `]`.
   *
   * > ðŸ‘‰ **Note**: we only get here if the label is defined.
   *
   * ```markdown
   * > | [a][] d
   *         ^
   * ```
   *
   *  @type {State}
   */
  function referenceCollapsedOpen(code) {
    if (code === 93) {
      effects.enter("referenceMarker");
      effects.consume(code);
      effects.exit("referenceMarker");
      effects.exit("reference");
      return ok;
    }
    return nok(code);
  }
}

/**
 * @import {
 *   Construct,
 *   State,
 *   TokenizeContext,
 *   Tokenizer
 * } from 'micromark-util-types'
 */


/** @type {Construct} */
const labelStartImage = {
  name: 'labelStartImage',
  resolveAll: labelEnd.resolveAll,
  tokenize: tokenizeLabelStartImage
};

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeLabelStartImage(effects, ok, nok) {
  const self = this;
  return start;

  /**
   * Start of label (image) start.
   *
   * ```markdown
   * > | a ![b] c
   *       ^
   * ```
   *
   * @type {State}
   */
  function start(code) {
    effects.enter("labelImage");
    effects.enter("labelImageMarker");
    effects.consume(code);
    effects.exit("labelImageMarker");
    return open;
  }

  /**
   * After `!`, at `[`.
   *
   * ```markdown
   * > | a ![b] c
   *        ^
   * ```
   *
   * @type {State}
   */
  function open(code) {
    if (code === 91) {
      effects.enter("labelMarker");
      effects.consume(code);
      effects.exit("labelMarker");
      effects.exit("labelImage");
      return after;
    }
    return nok(code);
  }

  /**
   * After `![`.
   *
   * ```markdown
   * > | a ![b] c
   *         ^
   * ```
   *
   * This is needed in because, when GFM footnotes are enabled, images never
   * form when started with a `^`.
   * Instead, links form:
   *
   * ```markdown
   * ![^a](b)
   *
   * ![^a][b]
   *
   * [b]: c
   * ```
   *
   * ```html
   * <p>!<a href=\"b\">^a</a></p>
   * <p>!<a href=\"c\">^a</a></p>
   * ```
   *
   * @type {State}
   */
  function after(code) {
    // To do: use a new field to do this, this is still needed for
    // `micromark-extension-gfm-footnote`, but the `label-start-link`
    // behavior isnâ€™t.
    // Hidden footnotes hook.
    /* c8 ignore next 3 */
    return code === 94 && '_hiddenFootnoteSupport' in self.parser.constructs ? nok(code) : ok(code);
  }
}

/**
 * @import {
 *   Construct,
 *   State,
 *   TokenizeContext,
 *   Tokenizer
 * } from 'micromark-util-types'
 */


/** @type {Construct} */
const labelStartLink = {
  name: 'labelStartLink',
  resolveAll: labelEnd.resolveAll,
  tokenize: tokenizeLabelStartLink
};

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeLabelStartLink(effects, ok, nok) {
  const self = this;
  return start;

  /**
   * Start of label (link) start.
   *
   * ```markdown
   * > | a [b] c
   *       ^
   * ```
   *
   * @type {State}
   */
  function start(code) {
    effects.enter("labelLink");
    effects.enter("labelMarker");
    effects.consume(code);
    effects.exit("labelMarker");
    effects.exit("labelLink");
    return after;
  }

  /** @type {State} */
  function after(code) {
    // To do: this isnâ€™t needed in `micromark-extension-gfm-footnote`,
    // remove.
    // Hidden footnotes hook.
    /* c8 ignore next 3 */
    return code === 94 && '_hiddenFootnoteSupport' in self.parser.constructs ? nok(code) : ok(code);
  }
}

/**
 * @import {
 *   Construct,
 *   State,
 *   TokenizeContext,
 *   Tokenizer
 * } from 'micromark-util-types'
 */

/** @type {Construct} */
const lineEnding = {
  name: 'lineEnding',
  tokenize: tokenizeLineEnding
};

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeLineEnding(effects, ok) {
  return start;

  /** @type {State} */
  function start(code) {
    effects.enter("lineEnding");
    effects.consume(code);
    effects.exit("lineEnding");
    return factorySpace(effects, ok, "linePrefix");
  }
}

/**
 * @import {
 *   Code,
 *   Construct,
 *   State,
 *   TokenizeContext,
 *   Tokenizer
 * } from 'micromark-util-types'
 */

/** @type {Construct} */
const thematicBreak = {
  name: 'thematicBreak',
  tokenize: tokenizeThematicBreak
};

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeThematicBreak(effects, ok, nok) {
  let size = 0;
  /** @type {NonNullable<Code>} */
  let marker;
  return start;

  /**
   * Start of thematic break.
   *
   * ```markdown
   * > | ***
   *     ^
   * ```
   *
   * @type {State}
   */
  function start(code) {
    effects.enter("thematicBreak");
    // To do: parse indent like `markdown-rs`.
    return before(code);
  }

  /**
   * After optional whitespace, at marker.
   *
   * ```markdown
   * > | ***
   *     ^
   * ```
   *
   * @type {State}
   */
  function before(code) {
    marker = code;
    return atBreak(code);
  }

  /**
   * After something, before something else.
   *
   * ```markdown
   * > | ***
   *     ^
   * ```
   *
   * @type {State}
   */
  function atBreak(code) {
    if (code === marker) {
      effects.enter("thematicBreakSequence");
      return sequence(code);
    }
    if (size >= 3 && (code === null || markdownLineEnding(code))) {
      effects.exit("thematicBreak");
      return ok(code);
    }
    return nok(code);
  }

  /**
   * In sequence.
   *
   * ```markdown
   * > | ***
   *     ^
   * ```
   *
   * @type {State}
   */
  function sequence(code) {
    if (code === marker) {
      effects.consume(code);
      size++;
      return sequence;
    }
    effects.exit("thematicBreakSequence");
    return markdownSpace(code) ? factorySpace(effects, atBreak, "whitespace")(code) : atBreak(code);
  }
}

/**
 * @import {
 *   Code,
 *   Construct,
 *   Exiter,
 *   State,
 *   TokenizeContext,
 *   Tokenizer
 * } from 'micromark-util-types'
 */


/** @type {Construct} */
const list = {
  continuation: {
    tokenize: tokenizeListContinuation
  },
  exit: tokenizeListEnd,
  name: 'list',
  tokenize: tokenizeListStart
};

/** @type {Construct} */
const listItemPrefixWhitespaceConstruct = {
  partial: true,
  tokenize: tokenizeListItemPrefixWhitespace
};

/** @type {Construct} */
const indentConstruct = {
  partial: true,
  tokenize: tokenizeIndent
};

// To do: `markdown-rs` parses list items on their own and later stitches them
// together.

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeListStart(effects, ok, nok) {
  const self = this;
  const tail = self.events[self.events.length - 1];
  let initialSize = tail && tail[1].type === "linePrefix" ? tail[2].sliceSerialize(tail[1], true).length : 0;
  let size = 0;
  return start;

  /** @type {State} */
  function start(code) {
    const kind = self.containerState.type || (code === 42 || code === 43 || code === 45 ? "listUnordered" : "listOrdered");
    if (kind === "listUnordered" ? !self.containerState.marker || code === self.containerState.marker : asciiDigit(code)) {
      if (!self.containerState.type) {
        self.containerState.type = kind;
        effects.enter(kind, {
          _container: true
        });
      }
      if (kind === "listUnordered") {
        effects.enter("listItemPrefix");
        return code === 42 || code === 45 ? effects.check(thematicBreak, nok, atMarker)(code) : atMarker(code);
      }
      if (!self.interrupt || code === 49) {
        effects.enter("listItemPrefix");
        effects.enter("listItemValue");
        return inside(code);
      }
    }
    return nok(code);
  }

  /** @type {State} */
  function inside(code) {
    if (asciiDigit(code) && ++size < 10) {
      effects.consume(code);
      return inside;
    }
    if ((!self.interrupt || size < 2) && (self.containerState.marker ? code === self.containerState.marker : code === 41 || code === 46)) {
      effects.exit("listItemValue");
      return atMarker(code);
    }
    return nok(code);
  }

  /**
   * @type {State}
   **/
  function atMarker(code) {
    effects.enter("listItemMarker");
    effects.consume(code);
    effects.exit("listItemMarker");
    self.containerState.marker = self.containerState.marker || code;
    return effects.check(blankLine,
    // Canâ€™t be empty when interrupting.
    self.interrupt ? nok : onBlank, effects.attempt(listItemPrefixWhitespaceConstruct, endOfPrefix, otherPrefix));
  }

  /** @type {State} */
  function onBlank(code) {
    self.containerState.initialBlankLine = true;
    initialSize++;
    return endOfPrefix(code);
  }

  /** @type {State} */
  function otherPrefix(code) {
    if (markdownSpace(code)) {
      effects.enter("listItemPrefixWhitespace");
      effects.consume(code);
      effects.exit("listItemPrefixWhitespace");
      return endOfPrefix;
    }
    return nok(code);
  }

  /** @type {State} */
  function endOfPrefix(code) {
    self.containerState.size = initialSize + self.sliceSerialize(effects.exit("listItemPrefix"), true).length;
    return ok(code);
  }
}

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeListContinuation(effects, ok, nok) {
  const self = this;
  self.containerState._closeFlow = undefined;
  return effects.check(blankLine, onBlank, notBlank);

  /** @type {State} */
  function onBlank(code) {
    self.containerState.furtherBlankLines = self.containerState.furtherBlankLines || self.containerState.initialBlankLine;

    // We have a blank line.
    // Still, try to consume at most the items size.
    return factorySpace(effects, ok, "listItemIndent", self.containerState.size + 1)(code);
  }

  /** @type {State} */
  function notBlank(code) {
    if (self.containerState.furtherBlankLines || !markdownSpace(code)) {
      self.containerState.furtherBlankLines = undefined;
      self.containerState.initialBlankLine = undefined;
      return notInCurrentItem(code);
    }
    self.containerState.furtherBlankLines = undefined;
    self.containerState.initialBlankLine = undefined;
    return effects.attempt(indentConstruct, ok, notInCurrentItem)(code);
  }

  /** @type {State} */
  function notInCurrentItem(code) {
    // While we do continue, we signal that the flow should be closed.
    self.containerState._closeFlow = true;
    // As weâ€™re closing flow, weâ€™re no longer interrupting.
    self.interrupt = undefined;
    // Always populated by defaults.

    return factorySpace(effects, effects.attempt(list, ok, nok), "linePrefix", self.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4)(code);
  }
}

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeIndent(effects, ok, nok) {
  const self = this;
  return factorySpace(effects, afterPrefix, "listItemIndent", self.containerState.size + 1);

  /** @type {State} */
  function afterPrefix(code) {
    const tail = self.events[self.events.length - 1];
    return tail && tail[1].type === "listItemIndent" && tail[2].sliceSerialize(tail[1], true).length === self.containerState.size ? ok(code) : nok(code);
  }
}

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Exiter}
 */
function tokenizeListEnd(effects) {
  effects.exit(this.containerState.type);
}

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeListItemPrefixWhitespace(effects, ok, nok) {
  const self = this;

  // Always populated by defaults.

  return factorySpace(effects, afterPrefix, "listItemPrefixWhitespace", self.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4 + 1);

  /** @type {State} */
  function afterPrefix(code) {
    const tail = self.events[self.events.length - 1];
    return !markdownSpace(code) && tail && tail[1].type === "listItemPrefixWhitespace" ? ok(code) : nok(code);
  }
}

/**
 * @import {
 *   Code,
 *   Construct,
 *   Resolver,
 *   State,
 *   TokenizeContext,
 *   Tokenizer
 * } from 'micromark-util-types'
 */

/** @type {Construct} */
const setextUnderline = {
  name: 'setextUnderline',
  resolveTo: resolveToSetextUnderline,
  tokenize: tokenizeSetextUnderline
};

/** @type {Resolver} */
function resolveToSetextUnderline(events, context) {
  // To do: resolve like `markdown-rs`.
  let index = events.length;
  /** @type {number | undefined} */
  let content;
  /** @type {number | undefined} */
  let text;
  /** @type {number | undefined} */
  let definition;

  // Find the opening of the content.
  // Itâ€™ll always exist: we donâ€™t tokenize if it isnâ€™t there.
  while (index--) {
    if (events[index][0] === 'enter') {
      if (events[index][1].type === "content") {
        content = index;
        break;
      }
      if (events[index][1].type === "paragraph") {
        text = index;
      }
    }
    // Exit
    else {
      if (events[index][1].type === "content") {
        // Remove the content end (if needed weâ€™ll add it later)
        events.splice(index, 1);
      }
      if (!definition && events[index][1].type === "definition") {
        definition = index;
      }
    }
  }
  const heading = {
    type: "setextHeading",
    start: {
      ...events[content][1].start
    },
    end: {
      ...events[events.length - 1][1].end
    }
  };

  // Change the paragraph to setext heading text.
  events[text][1].type = "setextHeadingText";

  // If we have definitions in the content, weâ€™ll keep on having content,
  // but we need move it.
  if (definition) {
    events.splice(text, 0, ['enter', heading, context]);
    events.splice(definition + 1, 0, ['exit', events[content][1], context]);
    events[content][1].end = {
      ...events[definition][1].end
    };
  } else {
    events[content][1] = heading;
  }

  // Add the heading exit at the end.
  events.push(['exit', heading, context]);
  return events;
}

/**
 * @this {TokenizeContext}
 *   Context.
 * @type {Tokenizer}
 */
function tokenizeSetextUnderline(effects, ok, nok) {
  const self = this;
  /** @type {NonNullable<Code>} */
  let marker;
  return start;

  /**
   * At start of heading (setext) underline.
   *
   * ```markdown
   *   | aa
   * > | ==
   *     ^
   * ```
   *
   * @type {State}
   */
  function start(code) {
    let index = self.events.length;
    /** @type {boolean | undefined} */
    let paragraph;
    // Find an opening.
    while (index--) {
      // Skip enter/exit of line ending, line prefix, and content.
      // We can now either have a definition or a paragraph.
      if (self.events[index][1].type !== "lineEnding" && self.events[index][1].type !== "linePrefix" && self.events[index][1].type !== "content") {
        paragraph = self.events[index][1].type === "paragraph";
        break;
      }
    }

    // To do: handle lazy/pierce like `markdown-rs`.
    // To do: parse indent like `markdown-rs`.
    if (!self.parser.lazy[self.now().line] && (self.interrupt || paragraph)) {
      effects.enter("setextHeadingLine");
      marker = code;
      return before(code);
    }
    return nok(code);
  }

  /**
   * After optional whitespace, at `-` or `=`.
   *
   * ```markdown
   *   | aa
   * > | ==
   *     ^
   * ```
   *
   * @type {State}
   */
  function before(code) {
    effects.enter("setextHeadingLineSequence");
    return inside(code);
  }

  /**
   * In sequence.
   *
   * ```markdown
   *   | aa
   * > | ==
   *     ^
   * ```
   *
   * @type {State}
   */
  function inside(code) {
    if (code === marker) {
      effects.consume(code);
      return inside;
    }
    effects.exit("setextHeadingLineSequence");
    return markdownSpace(code) ? factorySpace(effects, after, "lineSuffix")(code) : after(code);
  }

  /**
   * After sequence, after optional whitespace.
   *
   * ```markdown
   *   | aa
   * > | ==
   *       ^
   * ```
   *
   * @type {State}
   */
  function after(code) {
    if (code === null || markdownLineEnding(code)) {
      effects.exit("setextHeadingLine");
      return ok(code);
    }
    return nok(code);
  }
}

/**
 * @import {
 *   InitialConstruct,
 *   Initializer,
 *   State,
 *   TokenizeContext
 * } from 'micromark-util-types'
 */

/** @type {InitialConstruct} */
const flow$1 = {
  tokenize: initializeFlow
};

/**
 * @this {TokenizeContext}
 *   Self.
 * @type {Initializer}
 *   Initializer.
 */
function initializeFlow(effects) {
  const self = this;
  const initial = effects.attempt(
  // Try to parse a blank line.
  blankLine, atBlankEnding,
  // Try to parse initial flow (essentially, only code).
  effects.attempt(this.parser.constructs.flowInitial, afterConstruct, factorySpace(effects, effects.attempt(this.parser.constructs.flow, afterConstruct, effects.attempt(content, afterConstruct)), "linePrefix")));
  return initial;

  /** @type {State} */
  function atBlankEnding(code) {
    if (code === null) {
      effects.consume(code);
      return;
    }
    effects.enter("lineEndingBlank");
    effects.consume(code);
    effects.exit("lineEndingBlank");
    self.currentConstruct = undefined;
    return initial;
  }

  /** @type {State} */
  function afterConstruct(code) {
    if (code === null) {
      effects.consume(code);
      return;
    }
    effects.enter("lineEnding");
    effects.consume(code);
    effects.exit("lineEnding");
    self.currentConstruct = undefined;
    return initial;
  }
}

/**
 * @import {
 *   Code,
 *   InitialConstruct,
 *   Initializer,
 *   Resolver,
 *   State,
 *   TokenizeContext
 * } from 'micromark-util-types'
 */

const resolver = {
  resolveAll: createResolver()
};
const string$1 = initializeFactory('string');
const text$1 = initializeFactory('text');

/**
 * @param {'string' | 'text'} field
 *   Field.
 * @returns {InitialConstruct}
 *   Construct.
 */
function initializeFactory(field) {
  return {
    resolveAll: createResolver(field === 'text' ? resolveAllLineSuffixes : undefined),
    tokenize: initializeText
  };

  /**
   * @this {TokenizeContext}
   *   Context.
   * @type {Initializer}
   */
  function initializeText(effects) {
    const self = this;
    const constructs = this.parser.constructs[field];
    const text = effects.attempt(constructs, start, notText);
    return start;

    /** @type {State} */
    function start(code) {
      return atBreak(code) ? text(code) : notText(code);
    }

    /** @type {State} */
    function notText(code) {
      if (code === null) {
        effects.consume(code);
        return;
      }
      effects.enter("data");
      effects.consume(code);
      return data;
    }

    /** @type {State} */
    function data(code) {
      if (atBreak(code)) {
        effects.exit("data");
        return text(code);
      }

      // Data.
      effects.consume(code);
      return data;
    }

    /**
     * @param {Code} code
     *   Code.
     * @returns {boolean}
     *   Whether the code is a break.
     */
    function atBreak(code) {
      if (code === null) {
        return true;
      }
      const list = constructs[code];
      let index = -1;
      if (list) {
        // Always populated by defaults.

        while (++index < list.length) {
          const item = list[index];
          if (!item.previous || item.previous.call(self, self.previous)) {
            return true;
          }
        }
      }
      return false;
    }
  }
}

/**
 * @param {Resolver | undefined} [extraResolver]
 *   Resolver.
 * @returns {Resolver}
 *   Resolver.
 */
function createResolver(extraResolver) {
  return resolveAllText;

  /** @type {Resolver} */
  function resolveAllText(events, context) {
    let index = -1;
    /** @type {number | undefined} */
    let enter;

    // A rather boring computation (to merge adjacent `data` events) which
    // improves mm performance by 29%.
    while (++index <= events.length) {
      if (enter === undefined) {
        if (events[index] && events[index][1].type === "data") {
          enter = index;
          index++;
        }
      } else if (!events[index] || events[index][1].type !== "data") {
        // Donâ€™t do anything if there is one data token.
        if (index !== enter + 2) {
          events[enter][1].end = events[index - 1][1].end;
          events.splice(enter + 2, index - enter - 2);
          index = enter + 2;
        }
        enter = undefined;
      }
    }
    return extraResolver ? extraResolver(events, context) : events;
  }
}

/**
 * A rather ugly set of instructions which again looks at chunks in the input
 * stream.
 * The reason to do this here is that it is *much* faster to parse in reverse.
 * And that we canâ€™t hook into `null` to split the line suffix before an EOF.
 * To do: figure out if we can make this into a clean utility, or even in core.
 * As it will be useful for GFMs literal autolink extension (and maybe even
 * tables?)
 *
 * @type {Resolver}
 */
function resolveAllLineSuffixes(events, context) {
  let eventIndex = 0; // Skip first.

  while (++eventIndex <= events.length) {
    if ((eventIndex === events.length || events[eventIndex][1].type === "lineEnding") && events[eventIndex - 1][1].type === "data") {
      const data = events[eventIndex - 1][1];
      const chunks = context.sliceStream(data);
      let index = chunks.length;
      let bufferIndex = -1;
      let size = 0;
      /** @type {boolean | undefined} */
      let tabs;
      while (index--) {
        const chunk = chunks[index];
        if (typeof chunk === 'string') {
          bufferIndex = chunk.length;
          while (chunk.charCodeAt(bufferIndex - 1) === 32) {
            size++;
            bufferIndex--;
          }
          if (bufferIndex) break;
          bufferIndex = -1;
        }
        // Number
        else if (chunk === -2) {
          tabs = true;
          size++;
        } else if (chunk === -1) ; else {
          // Replacement character, exit.
          index++;
          break;
        }
      }

      // Allow final trailing whitespace.
      if (context._contentTypeTextTrailing && eventIndex === events.length) {
        size = 0;
      }
      if (size) {
        const token = {
          type: eventIndex === events.length || tabs || size < 2 ? "lineSuffix" : "hardBreakTrailing",
          start: {
            _bufferIndex: index ? bufferIndex : data.start._bufferIndex + bufferIndex,
            _index: data.start._index + index,
            line: data.end.line,
            column: data.end.column - size,
            offset: data.end.offset - size
          },
          end: {
            ...data.end
          }
        };
        data.end = {
          ...token.start
        };
        if (data.start.offset === data.end.offset) {
          Object.assign(data, token);
        } else {
          events.splice(eventIndex, 0, ['enter', token, context], ['exit', token, context]);
          eventIndex += 2;
        }
      }
      eventIndex++;
    }
  }
  return events;
}

/**
 * @import {Extension} from 'micromark-util-types'
 */


/** @satisfies {Extension['document']} */
const document = {
  [42]: list,
  [43]: list,
  [45]: list,
  [48]: list,
  [49]: list,
  [50]: list,
  [51]: list,
  [52]: list,
  [53]: list,
  [54]: list,
  [55]: list,
  [56]: list,
  [57]: list,
  [62]: blockQuote
};

/** @satisfies {Extension['contentInitial']} */
const contentInitial = {
  [91]: definition
};

/** @satisfies {Extension['flowInitial']} */
const flowInitial = {
  [-2]: codeIndented,
  [-1]: codeIndented,
  [32]: codeIndented
};

/** @satisfies {Extension['flow']} */
const flow = {
  [35]: headingAtx,
  [42]: thematicBreak,
  [45]: [setextUnderline, thematicBreak],
  [60]: htmlFlow,
  [61]: setextUnderline,
  [95]: thematicBreak,
  [96]: codeFenced,
  [126]: codeFenced
};

/** @satisfies {Extension['string']} */
const string = {
  [38]: characterReference,
  [92]: characterEscape
};

/** @satisfies {Extension['text']} */
const text = {
  [-5]: lineEnding,
  [-4]: lineEnding,
  [-3]: lineEnding,
  [33]: labelStartImage,
  [38]: characterReference,
  [42]: attention,
  [60]: [autolink, htmlText],
  [91]: labelStartLink,
  [92]: [hardBreakEscape, characterEscape],
  [93]: labelEnd,
  [95]: attention,
  [96]: codeText
};

/** @satisfies {Extension['insideSpan']} */
const insideSpan = {
  null: [attention, resolver]
};

/** @satisfies {Extension['attentionMarkers']} */
const attentionMarkers = {
  null: [42, 95]
};

/** @satisfies {Extension['disable']} */
const disable = {
  null: []
};

var defaultConstructs = /*#__PURE__*/Object.freeze({
    __proto__: null,
    attentionMarkers: attentionMarkers,
    contentInitial: contentInitial,
    disable: disable,
    document: document,
    flow: flow,
    flowInitial: flowInitial,
    insideSpan: insideSpan,
    string: string,
    text: text
});

/**
 * @import {
 *   Chunk,
 *   Code,
 *   ConstructRecord,
 *   Construct,
 *   Effects,
 *   InitialConstruct,
 *   ParseContext,
 *   Point,
 *   State,
 *   TokenizeContext,
 *   Token
 * } from 'micromark-util-types'
 */

/**
 * Create a tokenizer.
 * Tokenizers deal with one type of data (e.g., containers, flow, text).
 * The parser is the object dealing with it all.
 * `initialize` works like other constructs, except that only its `tokenize`
 * function is used, in which case it doesnâ€™t receive an `ok` or `nok`.
 * `from` can be given to set the point before the first character, although
 * when further lines are indented, they must be set with `defineSkip`.
 *
 * @param {ParseContext} parser
 *   Parser.
 * @param {InitialConstruct} initialize
 *   Construct.
 * @param {Omit<Point, '_bufferIndex' | '_index'> | undefined} [from]
 *   Point (optional).
 * @returns {TokenizeContext}
 *   Context.
 */
function createTokenizer(parser, initialize, from) {
  /** @type {Point} */
  let point = {
    _bufferIndex: -1,
    _index: 0,
    line: from && from.line || 1,
    column: from && from.column || 1,
    offset: from && from.offset || 0
  };
  /** @type {Record<string, number>} */
  const columnStart = {};
  /** @type {Array<Construct>} */
  const resolveAllConstructs = [];
  /** @type {Array<Chunk>} */
  let chunks = [];
  /** @type {Array<Token>} */
  let stack = [];

  /**
   * Tools used for tokenizing.
   *
   * @type {Effects}
   */
  const effects = {
    attempt: constructFactory(onsuccessfulconstruct),
    check: constructFactory(onsuccessfulcheck),
    consume,
    enter,
    exit,
    interrupt: constructFactory(onsuccessfulcheck, {
      interrupt: true
    })
  };

  /**
   * State and tools for resolving and serializing.
   *
   * @type {TokenizeContext}
   */
  const context = {
    code: null,
    containerState: {},
    defineSkip,
    events: [],
    now,
    parser,
    previous: null,
    sliceSerialize,
    sliceStream,
    write
  };

  /**
   * The state function.
   *
   * @type {State | undefined}
   */
  let state = initialize.tokenize.call(context, effects);
  if (initialize.resolveAll) {
    resolveAllConstructs.push(initialize);
  }
  return context;

  /** @type {TokenizeContext['write']} */
  function write(slice) {
    chunks = push(chunks, slice);
    main();

    // Exit if weâ€™re not done, resolve might change stuff.
    if (chunks[chunks.length - 1] !== null) {
      return [];
    }
    addResult(initialize, 0);

    // Otherwise, resolve, and exit.
    context.events = resolveAll(resolveAllConstructs, context.events, context);
    return context.events;
  }

  //
  // Tools.
  //

  /** @type {TokenizeContext['sliceSerialize']} */
  function sliceSerialize(token, expandTabs) {
    return serializeChunks(sliceStream(token), expandTabs);
  }

  /** @type {TokenizeContext['sliceStream']} */
  function sliceStream(token) {
    return sliceChunks(chunks, token);
  }

  /** @type {TokenizeContext['now']} */
  function now() {
    // This is a hot path, so we clone manually instead of `Object.assign({}, point)`
    const {
      _bufferIndex,
      _index,
      line,
      column,
      offset
    } = point;
    return {
      _bufferIndex,
      _index,
      line,
      column,
      offset
    };
  }

  /** @type {TokenizeContext['defineSkip']} */
  function defineSkip(value) {
    columnStart[value.line] = value.column;
    accountForPotentialSkip();
  }

  //
  // State management.
  //

  /**
   * Main loop (note that `_index` and `_bufferIndex` in `point` are modified by
   * `consume`).
   * Here is where we walk through the chunks, which either include strings of
   * several characters, or numerical character codes.
   * The reason to do this in a loop instead of a call is so the stack can
   * drain.
   *
   * @returns {undefined}
   *   Nothing.
   */
  function main() {
    /** @type {number} */
    let chunkIndex;
    while (point._index < chunks.length) {
      const chunk = chunks[point._index];

      // If weâ€™re in a buffer chunk, loop through it.
      if (typeof chunk === 'string') {
        chunkIndex = point._index;
        if (point._bufferIndex < 0) {
          point._bufferIndex = 0;
        }
        while (point._index === chunkIndex && point._bufferIndex < chunk.length) {
          go(chunk.charCodeAt(point._bufferIndex));
        }
      } else {
        go(chunk);
      }
    }
  }

  /**
   * Deal with one code.
   *
   * @param {Code} code
   *   Code.
   * @returns {undefined}
   *   Nothing.
   */
  function go(code) {
    state = state(code);
  }

  /** @type {Effects['consume']} */
  function consume(code) {
    if (markdownLineEnding(code)) {
      point.line++;
      point.column = 1;
      point.offset += code === -3 ? 2 : 1;
      accountForPotentialSkip();
    } else if (code !== -1) {
      point.column++;
      point.offset++;
    }

    // Not in a string chunk.
    if (point._bufferIndex < 0) {
      point._index++;
    } else {
      point._bufferIndex++;

      // At end of string chunk.
      if (point._bufferIndex ===
      // Points w/ non-negative `_bufferIndex` reference
      // strings.
      /** @type {string} */
      chunks[point._index].length) {
        point._bufferIndex = -1;
        point._index++;
      }
    }

    // Expose the previous character.
    context.previous = code;
  }

  /** @type {Effects['enter']} */
  function enter(type, fields) {
    /** @type {Token} */
    // @ts-expect-error Patch instead of assign required fields to help GC.
    const token = fields || {};
    token.type = type;
    token.start = now();
    context.events.push(['enter', token, context]);
    stack.push(token);
    return token;
  }

  /** @type {Effects['exit']} */
  function exit(type) {
    const token = stack.pop();
    token.end = now();
    context.events.push(['exit', token, context]);
    return token;
  }

  /**
   * Use results.
   *
   * @type {ReturnHandle}
   */
  function onsuccessfulconstruct(construct, info) {
    addResult(construct, info.from);
  }

  /**
   * Discard results.
   *
   * @type {ReturnHandle}
   */
  function onsuccessfulcheck(_, info) {
    info.restore();
  }

  /**
   * Factory to attempt/check/interrupt.
   *
   * @param {ReturnHandle} onreturn
   *   Callback.
   * @param {{interrupt?: boolean | undefined} | undefined} [fields]
   *   Fields.
   */
  function constructFactory(onreturn, fields) {
    return hook;

    /**
     * Handle either an object mapping codes to constructs, a list of
     * constructs, or a single construct.
     *
     * @param {Array<Construct> | ConstructRecord | Construct} constructs
     *   Constructs.
     * @param {State} returnState
     *   State.
     * @param {State | undefined} [bogusState]
     *   State.
     * @returns {State}
     *   State.
     */
    function hook(constructs, returnState, bogusState) {
      /** @type {ReadonlyArray<Construct>} */
      let listOfConstructs;
      /** @type {number} */
      let constructIndex;
      /** @type {Construct} */
      let currentConstruct;
      /** @type {Info} */
      let info;
      return Array.isArray(constructs) ? /* c8 ignore next 1 */
      handleListOfConstructs(constructs) : 'tokenize' in constructs ?
      // Looks like a construct.
      handleListOfConstructs([(/** @type {Construct} */constructs)]) : handleMapOfConstructs(constructs);

      /**
       * Handle a list of construct.
       *
       * @param {ConstructRecord} map
       *   Constructs.
       * @returns {State}
       *   State.
       */
      function handleMapOfConstructs(map) {
        return start;

        /** @type {State} */
        function start(code) {
          const left = code !== null && map[code];
          const all = code !== null && map.null;
          const list = [
          // To do: add more extension tests.
          /* c8 ignore next 2 */
          ...(Array.isArray(left) ? left : left ? [left] : []), ...(Array.isArray(all) ? all : all ? [all] : [])];
          return handleListOfConstructs(list)(code);
        }
      }

      /**
       * Handle a list of construct.
       *
       * @param {ReadonlyArray<Construct>} list
       *   Constructs.
       * @returns {State}
       *   State.
       */
      function handleListOfConstructs(list) {
        listOfConstructs = list;
        constructIndex = 0;
        if (list.length === 0) {
          return bogusState;
        }
        return handleConstruct(list[constructIndex]);
      }

      /**
       * Handle a single construct.
       *
       * @param {Construct} construct
       *   Construct.
       * @returns {State}
       *   State.
       */
      function handleConstruct(construct) {
        return start;

        /** @type {State} */
        function start(code) {
          // To do: not needed to store if there is no bogus state, probably?
          // Currently doesnâ€™t work because `inspect` in document does a check
          // w/o a bogus, which doesnâ€™t make sense. But it does seem to help perf
          // by not storing.
          info = store();
          currentConstruct = construct;
          if (!construct.partial) {
            context.currentConstruct = construct;
          }

          // Always populated by defaults.

          if (construct.name && context.parser.constructs.disable.null.includes(construct.name)) {
            return nok();
          }
          return construct.tokenize.call(
          // If we do have fields, create an object w/ `context` as its
          // prototype.
          // This allows a â€œlive bindingâ€, which is needed for `interrupt`.
          fields ? Object.assign(Object.create(context), fields) : context, effects, ok, nok)(code);
        }
      }

      /** @type {State} */
      function ok(code) {
        onreturn(currentConstruct, info);
        return returnState;
      }

      /** @type {State} */
      function nok(code) {
        info.restore();
        if (++constructIndex < listOfConstructs.length) {
          return handleConstruct(listOfConstructs[constructIndex]);
        }
        return bogusState;
      }
    }
  }

  /**
   * @param {Construct} construct
   *   Construct.
   * @param {number} from
   *   From.
   * @returns {undefined}
   *   Nothing.
   */
  function addResult(construct, from) {
    if (construct.resolveAll && !resolveAllConstructs.includes(construct)) {
      resolveAllConstructs.push(construct);
    }
    if (construct.resolve) {
      splice(context.events, from, context.events.length - from, construct.resolve(context.events.slice(from), context));
    }
    if (construct.resolveTo) {
      context.events = construct.resolveTo(context.events, context);
    }
  }

  /**
   * Store state.
   *
   * @returns {Info}
   *   Info.
   */
  function store() {
    const startPoint = now();
    const startPrevious = context.previous;
    const startCurrentConstruct = context.currentConstruct;
    const startEventsIndex = context.events.length;
    const startStack = Array.from(stack);
    return {
      from: startEventsIndex,
      restore
    };

    /**
     * Restore state.
     *
     * @returns {undefined}
     *   Nothing.
     */
    function restore() {
      point = startPoint;
      context.previous = startPrevious;
      context.currentConstruct = startCurrentConstruct;
      context.events.length = startEventsIndex;
      stack = startStack;
      accountForPotentialSkip();
    }
  }

  /**
   * Move the current point a bit forward in the line when itâ€™s on a column
   * skip.
   *
   * @returns {undefined}
   *   Nothing.
   */
  function accountForPotentialSkip() {
    if (point.line in columnStart && point.column < 2) {
      point.column = columnStart[point.line];
      point.offset += columnStart[point.line] - 1;
    }
  }
}

/**
 * Get the chunks from a slice of chunks in the range of a token.
 *
 * @param {ReadonlyArray<Chunk>} chunks
 *   Chunks.
 * @param {Pick<Token, 'end' | 'start'>} token
 *   Token.
 * @returns {Array<Chunk>}
 *   Chunks.
 */
function sliceChunks(chunks, token) {
  const startIndex = token.start._index;
  const startBufferIndex = token.start._bufferIndex;
  const endIndex = token.end._index;
  const endBufferIndex = token.end._bufferIndex;
  /** @type {Array<Chunk>} */
  let view;
  if (startIndex === endIndex) {
    // @ts-expect-error `_bufferIndex` is used on string chunks.
    view = [chunks[startIndex].slice(startBufferIndex, endBufferIndex)];
  } else {
    view = chunks.slice(startIndex, endIndex);
    if (startBufferIndex > -1) {
      const head = view[0];
      if (typeof head === 'string') {
        view[0] = head.slice(startBufferIndex);
        /* c8 ignore next 4 -- used to be used, no longer */
      } else {
        view.shift();
      }
    }
    if (endBufferIndex > 0) {
      // @ts-expect-error `_bufferIndex` is used on string chunks.
      view.push(chunks[endIndex].slice(0, endBufferIndex));
    }
  }
  return view;
}

/**
 * Get the string value of a slice of chunks.
 *
 * @param {ReadonlyArray<Chunk>} chunks
 *   Chunks.
 * @param {boolean | undefined} [expandTabs=false]
 *   Whether to expand tabs (default: `false`).
 * @returns {string}
 *   Result.
 */
function serializeChunks(chunks, expandTabs) {
  let index = -1;
  /** @type {Array<string>} */
  const result = [];
  /** @type {boolean | undefined} */
  let atTab;
  while (++index < chunks.length) {
    const chunk = chunks[index];
    /** @type {string} */
    let value;
    if (typeof chunk === 'string') {
      value = chunk;
    } else switch (chunk) {
      case -5:
        {
          value = "\r";
          break;
        }
      case -4:
        {
          value = "\n";
          break;
        }
      case -3:
        {
          value = "\r" + "\n";
          break;
        }
      case -2:
        {
          value = expandTabs ? " " : "\t";
          break;
        }
      case -1:
        {
          if (!expandTabs && atTab) continue;
          value = " ";
          break;
        }
      default:
        {
          // Currently only replacement character.
          value = String.fromCharCode(chunk);
        }
    }
    atTab = chunk === -2;
    result.push(value);
  }
  return result.join('');
}

/**
 * @import {
 *   Create,
 *   FullNormalizedExtension,
 *   InitialConstruct,
 *   ParseContext,
 *   ParseOptions
 * } from 'micromark-util-types'
 */


/**
 * @param {ParseOptions | null | undefined} [options]
 *   Configuration (optional).
 * @returns {ParseContext}
 *   Parser.
 */
function parse(options) {
  const settings = options || {};
  const constructs = /** @type {FullNormalizedExtension} */
  combineExtensions([defaultConstructs, ...(settings.extensions || [])]);

  /** @type {ParseContext} */
  const parser = {
    constructs,
    content: create(content$1),
    defined: [],
    document: create(document$1),
    flow: create(flow$1),
    lazy: {},
    string: create(string$1),
    text: create(text$1)
  };
  return parser;

  /**
   * @param {InitialConstruct} initial
   *   Construct to start with.
   * @returns {Create}
   *   Create a tokenizer.
   */
  function create(initial) {
    return creator;
    /** @type {Create} */
    function creator(from) {
      return createTokenizer(parser, initial, from);
    }
  }
}

/**
 * @import {Event} from 'micromark-util-types'
 */


/**
 * @param {Array<Event>} events
 *   Events.
 * @returns {Array<Event>}
 *   Events.
 */
function postprocess(events) {
  while (!subtokenize(events)) {
    // Empty
  }
  return events;
}

/**
 * @import {Chunk, Code, Encoding, Value} from 'micromark-util-types'
 */

/**
 * @callback Preprocessor
 *   Preprocess a value.
 * @param {Value} value
 *   Value.
 * @param {Encoding | null | undefined} [encoding]
 *   Encoding when `value` is a typed array (optional).
 * @param {boolean | null | undefined} [end=false]
 *   Whether this is the last chunk (default: `false`).
 * @returns {Array<Chunk>}
 *   Chunks.
 */

const search = /[\0\t\n\r]/g;

/**
 * @returns {Preprocessor}
 *   Preprocess a value.
 */
function preprocess() {
  let column = 1;
  let buffer = '';
  /** @type {boolean | undefined} */
  let start = true;
  /** @type {boolean | undefined} */
  let atCarriageReturn;
  return preprocessor;

  /** @type {Preprocessor} */
  // eslint-disable-next-line complexity
  function preprocessor(value, encoding, end) {
    /** @type {Array<Chunk>} */
    const chunks = [];
    /** @type {RegExpMatchArray | null} */
    let match;
    /** @type {number} */
    let next;
    /** @type {number} */
    let startPosition;
    /** @type {number} */
    let endPosition;
    /** @type {Code} */
    let code;
    value = buffer + (typeof value === 'string' ? value.toString() : new TextDecoder(encoding || undefined).decode(value));
    startPosition = 0;
    buffer = '';
    if (start) {
      // To do: `markdown-rs` actually parses BOMs (byte order mark).
      if (value.charCodeAt(0) === 65279) {
        startPosition++;
      }
      start = undefined;
    }
    while (startPosition < value.length) {
      search.lastIndex = startPosition;
      match = search.exec(value);
      endPosition = match && match.index !== undefined ? match.index : value.length;
      code = value.charCodeAt(endPosition);
      if (!match) {
        buffer = value.slice(startPosition);
        break;
      }
      if (code === 10 && startPosition === endPosition && atCarriageReturn) {
        chunks.push(-3);
        atCarriageReturn = undefined;
      } else {
        if (atCarriageReturn) {
          chunks.push(-5);
          atCarriageReturn = undefined;
        }
        if (startPosition < endPosition) {
          chunks.push(value.slice(startPosition, endPosition));
          column += endPosition - startPosition;
        }
        switch (code) {
          case 0:
            {
              chunks.push(65533);
              column++;
              break;
            }
          case 9:
            {
              next = Math.ceil(column / 4) * 4;
              chunks.push(-2);
              while (column++ < next) chunks.push(-1);
              break;
            }
          case 10:
            {
              chunks.push(-4);
              column = 1;
              break;
            }
          default:
            {
              atCarriageReturn = true;
              column = 1;
            }
        }
      }
      startPosition = endPosition + 1;
    }
    if (end) {
      if (atCarriageReturn) chunks.push(-5);
      if (buffer) chunks.push(buffer);
      chunks.push(null);
    }
    return chunks;
  }
}

const characterEscapeOrReference = /\\([!-/:-@[-`{-~])|&(#(?:\d{1,7}|x[\da-f]{1,6})|[\da-z]{1,31});/gi;

/**
 * Decode markdown strings (which occur in places such as fenced code info
 * strings, destinations, labels, and titles).
 *
 * The â€œstringâ€ content type allows character escapes and -references.
 * This decodes those.
 *
 * @param {string} value
 *   Value to decode.
 * @returns {string}
 *   Decoded value.
 */
function decodeString(value) {
  return value.replace(characterEscapeOrReference, decode);
}

/**
 * @param {string} $0
 *   Match.
 * @param {string} $1
 *   Character escape.
 * @param {string} $2
 *   Character reference.
 * @returns {string}
 *   Decoded value
 */
function decode($0, $1, $2) {
  if ($1) {
    // Escape.
    return $1;
  }

  // Reference.
  const head = $2.charCodeAt(0);
  if (head === 35) {
    const head = $2.charCodeAt(1);
    const hex = head === 120 || head === 88;
    return decodeNumericCharacterReference($2.slice(hex ? 2 : 1), hex ? 16 : 10);
  }
  return decodeNamedCharacterReference($2) || $0;
}

/**
 * @typedef {import('unist').Node} Node
 * @typedef {import('unist').Point} Point
 * @typedef {import('unist').Position} Position
 */

/**
 * @typedef NodeLike
 * @property {string} type
 * @property {PositionLike | null | undefined} [position]
 *
 * @typedef PointLike
 * @property {number | null | undefined} [line]
 * @property {number | null | undefined} [column]
 * @property {number | null | undefined} [offset]
 *
 * @typedef PositionLike
 * @property {PointLike | null | undefined} [start]
 * @property {PointLike | null | undefined} [end]
 */

/**
 * Serialize the positional info of a point, position (start and end points),
 * or node.
 *
 * @param {Node | NodeLike | Point | PointLike | Position | PositionLike | null | undefined} [value]
 *   Node, position, or point.
 * @returns {string}
 *   Pretty printed positional info of a node (`string`).
 *
 *   In the format of a range `ls:cs-le:ce` (when given `node` or `position`)
 *   or a point `l:c` (when given `point`), where `l` stands for line, `c` for
 *   column, `s` for `start`, and `e` for end.
 *   An empty string (`''`) is returned if the given value is neither `node`,
 *   `position`, nor `point`.
 */
function stringifyPosition(value) {
  // Nothing.
  if (!value || typeof value !== 'object') {
    return ''
  }

  // Node.
  if ('position' in value || 'type' in value) {
    return position(value.position)
  }

  // Position.
  if ('start' in value || 'end' in value) {
    return position(value)
  }

  // Point.
  if ('line' in value || 'column' in value) {
    return point$1(value)
  }

  // ?
  return ''
}

/**
 * @param {Point | PointLike | null | undefined} point
 * @returns {string}
 */
function point$1(point) {
  return index(point && point.line) + ':' + index(point && point.column)
}

/**
 * @param {Position | PositionLike | null | undefined} pos
 * @returns {string}
 */
function position(pos) {
  return point$1(pos && pos.start) + '-' + point$1(pos && pos.end)
}

/**
 * @param {number | null | undefined} value
 * @returns {number}
 */
function index(value) {
  return value && typeof value === 'number' ? value : 1
}

/**
 * @import {
 *   Break,
 *   Blockquote,
 *   Code,
 *   Definition,
 *   Emphasis,
 *   Heading,
 *   Html,
 *   Image,
 *   InlineCode,
 *   Link,
 *   ListItem,
 *   List,
 *   Nodes,
 *   Paragraph,
 *   PhrasingContent,
 *   ReferenceType,
 *   Root,
 *   Strong,
 *   Text,
 *   ThematicBreak
 * } from 'mdast'
 * @import {
 *   Encoding,
 *   Event,
 *   Token,
 *   Value
 * } from 'micromark-util-types'
 * @import {Point} from 'unist'
 * @import {
 *   CompileContext,
 *   CompileData,
 *   Config,
 *   Extension,
 *   Handle,
 *   OnEnterError,
 *   Options
 * } from './types.js'
 */

const own$1 = {}.hasOwnProperty;

/**
 * Turn markdown into a syntax tree.
 *
 * @overload
 * @param {Value} value
 * @param {Encoding | null | undefined} [encoding]
 * @param {Options | null | undefined} [options]
 * @returns {Root}
 *
 * @overload
 * @param {Value} value
 * @param {Options | null | undefined} [options]
 * @returns {Root}
 *
 * @param {Value} value
 *   Markdown to parse.
 * @param {Encoding | Options | null | undefined} [encoding]
 *   Character encoding for when `value` is `Buffer`.
 * @param {Options | null | undefined} [options]
 *   Configuration.
 * @returns {Root}
 *   mdast tree.
 */
function fromMarkdown(value, encoding, options) {
  if (typeof encoding !== 'string') {
    options = encoding;
    encoding = undefined;
  }
  return compiler(options)(postprocess(parse(options).document().write(preprocess()(value, encoding, true))));
}

/**
 * Note this compiler only understand complete buffering, not streaming.
 *
 * @param {Options | null | undefined} [options]
 */
function compiler(options) {
  /** @type {Config} */
  const config = {
    transforms: [],
    canContainEols: ['emphasis', 'fragment', 'heading', 'paragraph', 'strong'],
    enter: {
      autolink: opener(link),
      autolinkProtocol: onenterdata,
      autolinkEmail: onenterdata,
      atxHeading: opener(heading),
      blockQuote: opener(blockQuote),
      characterEscape: onenterdata,
      characterReference: onenterdata,
      codeFenced: opener(codeFlow),
      codeFencedFenceInfo: buffer,
      codeFencedFenceMeta: buffer,
      codeIndented: opener(codeFlow, buffer),
      codeText: opener(codeText, buffer),
      codeTextData: onenterdata,
      data: onenterdata,
      codeFlowValue: onenterdata,
      definition: opener(definition),
      definitionDestinationString: buffer,
      definitionLabelString: buffer,
      definitionTitleString: buffer,
      emphasis: opener(emphasis),
      hardBreakEscape: opener(hardBreak),
      hardBreakTrailing: opener(hardBreak),
      htmlFlow: opener(html, buffer),
      htmlFlowData: onenterdata,
      htmlText: opener(html, buffer),
      htmlTextData: onenterdata,
      image: opener(image),
      label: buffer,
      link: opener(link),
      listItem: opener(listItem),
      listItemValue: onenterlistitemvalue,
      listOrdered: opener(list, onenterlistordered),
      listUnordered: opener(list),
      paragraph: opener(paragraph),
      reference: onenterreference,
      referenceString: buffer,
      resourceDestinationString: buffer,
      resourceTitleString: buffer,
      setextHeading: opener(heading),
      strong: opener(strong),
      thematicBreak: opener(thematicBreak)
    },
    exit: {
      atxHeading: closer(),
      atxHeadingSequence: onexitatxheadingsequence,
      autolink: closer(),
      autolinkEmail: onexitautolinkemail,
      autolinkProtocol: onexitautolinkprotocol,
      blockQuote: closer(),
      characterEscapeValue: onexitdata,
      characterReferenceMarkerHexadecimal: onexitcharacterreferencemarker,
      characterReferenceMarkerNumeric: onexitcharacterreferencemarker,
      characterReferenceValue: onexitcharacterreferencevalue,
      characterReference: onexitcharacterreference,
      codeFenced: closer(onexitcodefenced),
      codeFencedFence: onexitcodefencedfence,
      codeFencedFenceInfo: onexitcodefencedfenceinfo,
      codeFencedFenceMeta: onexitcodefencedfencemeta,
      codeFlowValue: onexitdata,
      codeIndented: closer(onexitcodeindented),
      codeText: closer(onexitcodetext),
      codeTextData: onexitdata,
      data: onexitdata,
      definition: closer(),
      definitionDestinationString: onexitdefinitiondestinationstring,
      definitionLabelString: onexitdefinitionlabelstring,
      definitionTitleString: onexitdefinitiontitlestring,
      emphasis: closer(),
      hardBreakEscape: closer(onexithardbreak),
      hardBreakTrailing: closer(onexithardbreak),
      htmlFlow: closer(onexithtmlflow),
      htmlFlowData: onexitdata,
      htmlText: closer(onexithtmltext),
      htmlTextData: onexitdata,
      image: closer(onexitimage),
      label: onexitlabel,
      labelText: onexitlabeltext,
      lineEnding: onexitlineending,
      link: closer(onexitlink),
      listItem: closer(),
      listOrdered: closer(),
      listUnordered: closer(),
      paragraph: closer(),
      referenceString: onexitreferencestring,
      resourceDestinationString: onexitresourcedestinationstring,
      resourceTitleString: onexitresourcetitlestring,
      resource: onexitresource,
      setextHeading: closer(onexitsetextheading),
      setextHeadingLineSequence: onexitsetextheadinglinesequence,
      setextHeadingText: onexitsetextheadingtext,
      strong: closer(),
      thematicBreak: closer()
    }
  };
  configure(config, (options || {}).mdastExtensions || []);

  /** @type {CompileData} */
  const data = {};
  return compile;

  /**
   * Turn micromark events into an mdast tree.
   *
   * @param {Array<Event>} events
   *   Events.
   * @returns {Root}
   *   mdast tree.
   */
  function compile(events) {
    /** @type {Root} */
    let tree = {
      type: 'root',
      children: []
    };
    /** @type {Omit<CompileContext, 'sliceSerialize'>} */
    const context = {
      stack: [tree],
      tokenStack: [],
      config,
      enter,
      exit,
      buffer,
      resume,
      data
    };
    /** @type {Array<number>} */
    const listStack = [];
    let index = -1;
    while (++index < events.length) {
      // We preprocess lists to add `listItem` tokens, and to infer whether
      // items the list itself are spread out.
      if (events[index][1].type === "listOrdered" || events[index][1].type === "listUnordered") {
        if (events[index][0] === 'enter') {
          listStack.push(index);
        } else {
          const tail = listStack.pop();
          index = prepareList(events, tail, index);
        }
      }
    }
    index = -1;
    while (++index < events.length) {
      const handler = config[events[index][0]];
      if (own$1.call(handler, events[index][1].type)) {
        handler[events[index][1].type].call(Object.assign({
          sliceSerialize: events[index][2].sliceSerialize
        }, context), events[index][1]);
      }
    }

    // Handle tokens still being open.
    if (context.tokenStack.length > 0) {
      const tail = context.tokenStack[context.tokenStack.length - 1];
      const handler = tail[1] || defaultOnError;
      handler.call(context, undefined, tail[0]);
    }

    // Figure out `root` position.
    tree.position = {
      start: point(events.length > 0 ? events[0][1].start : {
        line: 1,
        column: 1,
        offset: 0
      }),
      end: point(events.length > 0 ? events[events.length - 2][1].end : {
        line: 1,
        column: 1,
        offset: 0
      })
    };

    // Call transforms.
    index = -1;
    while (++index < config.transforms.length) {
      tree = config.transforms[index](tree) || tree;
    }
    return tree;
  }

  /**
   * @param {Array<Event>} events
   * @param {number} start
   * @param {number} length
   * @returns {number}
   */
  function prepareList(events, start, length) {
    let index = start - 1;
    let containerBalance = -1;
    let listSpread = false;
    /** @type {Token | undefined} */
    let listItem;
    /** @type {number | undefined} */
    let lineIndex;
    /** @type {number | undefined} */
    let firstBlankLineIndex;
    /** @type {boolean | undefined} */
    let atMarker;
    while (++index <= length) {
      const event = events[index];
      switch (event[1].type) {
        case "listUnordered":
        case "listOrdered":
        case "blockQuote":
          {
            if (event[0] === 'enter') {
              containerBalance++;
            } else {
              containerBalance--;
            }
            atMarker = undefined;
            break;
          }
        case "lineEndingBlank":
          {
            if (event[0] === 'enter') {
              if (listItem && !atMarker && !containerBalance && !firstBlankLineIndex) {
                firstBlankLineIndex = index;
              }
              atMarker = undefined;
            }
            break;
          }
        case "linePrefix":
        case "listItemValue":
        case "listItemMarker":
        case "listItemPrefix":
        case "listItemPrefixWhitespace":
          {
            // Empty.

            break;
          }
        default:
          {
            atMarker = undefined;
          }
      }
      if (!containerBalance && event[0] === 'enter' && event[1].type === "listItemPrefix" || containerBalance === -1 && event[0] === 'exit' && (event[1].type === "listUnordered" || event[1].type === "listOrdered")) {
        if (listItem) {
          let tailIndex = index;
          lineIndex = undefined;
          while (tailIndex--) {
            const tailEvent = events[tailIndex];
            if (tailEvent[1].type === "lineEnding" || tailEvent[1].type === "lineEndingBlank") {
              if (tailEvent[0] === 'exit') continue;
              if (lineIndex) {
                events[lineIndex][1].type = "lineEndingBlank";
                listSpread = true;
              }
              tailEvent[1].type = "lineEnding";
              lineIndex = tailIndex;
            } else if (tailEvent[1].type === "linePrefix" || tailEvent[1].type === "blockQuotePrefix" || tailEvent[1].type === "blockQuotePrefixWhitespace" || tailEvent[1].type === "blockQuoteMarker" || tailEvent[1].type === "listItemIndent") ; else {
              break;
            }
          }
          if (firstBlankLineIndex && (!lineIndex || firstBlankLineIndex < lineIndex)) {
            listItem._spread = true;
          }

          // Fix position.
          listItem.end = Object.assign({}, lineIndex ? events[lineIndex][1].start : event[1].end);
          events.splice(lineIndex || index, 0, ['exit', listItem, event[2]]);
          index++;
          length++;
        }

        // Create a new list item.
        if (event[1].type === "listItemPrefix") {
          /** @type {Token} */
          const item = {
            type: 'listItem',
            _spread: false,
            start: Object.assign({}, event[1].start),
            // @ts-expect-error: weâ€™ll add `end` in a second.
            end: undefined
          };
          listItem = item;
          events.splice(index, 0, ['enter', item, event[2]]);
          index++;
          length++;
          firstBlankLineIndex = undefined;
          atMarker = true;
        }
      }
    }
    events[start][1]._spread = listSpread;
    return length;
  }

  /**
   * Create an opener handle.
   *
   * @param {(token: Token) => Nodes} create
   *   Create a node.
   * @param {Handle | undefined} [and]
   *   Optional function to also run.
   * @returns {Handle}
   *   Handle.
   */
  function opener(create, and) {
    return open;

    /**
     * @this {CompileContext}
     * @param {Token} token
     * @returns {undefined}
     */
    function open(token) {
      enter.call(this, create(token), token);
      if (and) and.call(this, token);
    }
  }

  /**
   * @type {CompileContext['buffer']}
   */
  function buffer() {
    this.stack.push({
      type: 'fragment',
      children: []
    });
  }

  /**
   * @type {CompileContext['enter']}
   */
  function enter(node, token, errorHandler) {
    const parent = this.stack[this.stack.length - 1];
    /** @type {Array<Nodes>} */
    const siblings = parent.children;
    siblings.push(node);
    this.stack.push(node);
    this.tokenStack.push([token, errorHandler || undefined]);
    node.position = {
      start: point(token.start),
      // @ts-expect-error: `end` will be patched later.
      end: undefined
    };
  }

  /**
   * Create a closer handle.
   *
   * @param {Handle | undefined} [and]
   *   Optional function to also run.
   * @returns {Handle}
   *   Handle.
   */
  function closer(and) {
    return close;

    /**
     * @this {CompileContext}
     * @param {Token} token
     * @returns {undefined}
     */
    function close(token) {
      if (and) and.call(this, token);
      exit.call(this, token);
    }
  }

  /**
   * @type {CompileContext['exit']}
   */
  function exit(token, onExitError) {
    const node = this.stack.pop();
    const open = this.tokenStack.pop();
    if (!open) {
      throw new Error('Cannot close `' + token.type + '` (' + stringifyPosition({
        start: token.start,
        end: token.end
      }) + '): itâ€™s not open');
    } else if (open[0].type !== token.type) {
      if (onExitError) {
        onExitError.call(this, token, open[0]);
      } else {
        const handler = open[1] || defaultOnError;
        handler.call(this, token, open[0]);
      }
    }
    node.position.end = point(token.end);
  }

  /**
   * @type {CompileContext['resume']}
   */
  function resume() {
    return toString(this.stack.pop());
  }

  //
  // Handlers.
  //

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onenterlistordered() {
    this.data.expectingFirstListItemValue = true;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onenterlistitemvalue(token) {
    if (this.data.expectingFirstListItemValue) {
      const ancestor = this.stack[this.stack.length - 2];
      ancestor.start = Number.parseInt(this.sliceSerialize(token), 10);
      this.data.expectingFirstListItemValue = undefined;
    }
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitcodefencedfenceinfo() {
    const data = this.resume();
    const node = this.stack[this.stack.length - 1];
    node.lang = data;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitcodefencedfencemeta() {
    const data = this.resume();
    const node = this.stack[this.stack.length - 1];
    node.meta = data;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitcodefencedfence() {
    // Exit if this is the closing fence.
    if (this.data.flowCodeInside) return;
    this.buffer();
    this.data.flowCodeInside = true;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitcodefenced() {
    const data = this.resume();
    const node = this.stack[this.stack.length - 1];
    node.value = data.replace(/^(\r?\n|\r)|(\r?\n|\r)$/g, '');
    this.data.flowCodeInside = undefined;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitcodeindented() {
    const data = this.resume();
    const node = this.stack[this.stack.length - 1];
    node.value = data.replace(/(\r?\n|\r)$/g, '');
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitdefinitionlabelstring(token) {
    const label = this.resume();
    const node = this.stack[this.stack.length - 1];
    node.label = label;
    node.identifier = normalizeIdentifier(this.sliceSerialize(token)).toLowerCase();
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitdefinitiontitlestring() {
    const data = this.resume();
    const node = this.stack[this.stack.length - 1];
    node.title = data;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitdefinitiondestinationstring() {
    const data = this.resume();
    const node = this.stack[this.stack.length - 1];
    node.url = data;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitatxheadingsequence(token) {
    const node = this.stack[this.stack.length - 1];
    if (!node.depth) {
      const depth = this.sliceSerialize(token).length;
      node.depth = depth;
    }
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitsetextheadingtext() {
    this.data.setextHeadingSlurpLineEnding = true;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitsetextheadinglinesequence(token) {
    const node = this.stack[this.stack.length - 1];
    node.depth = this.sliceSerialize(token).codePointAt(0) === 61 ? 1 : 2;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitsetextheading() {
    this.data.setextHeadingSlurpLineEnding = undefined;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onenterdata(token) {
    const node = this.stack[this.stack.length - 1];
    /** @type {Array<Nodes>} */
    const siblings = node.children;
    let tail = siblings[siblings.length - 1];
    if (!tail || tail.type !== 'text') {
      // Add a new text node.
      tail = text();
      tail.position = {
        start: point(token.start),
        // @ts-expect-error: weâ€™ll add `end` later.
        end: undefined
      };
      siblings.push(tail);
    }
    this.stack.push(tail);
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexitdata(token) {
    const tail = this.stack.pop();
    tail.value += this.sliceSerialize(token);
    tail.position.end = point(token.end);
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexitlineending(token) {
    const context = this.stack[this.stack.length - 1];
    // If weâ€™re at a hard break, include the line ending in there.
    if (this.data.atHardBreak) {
      const tail = context.children[context.children.length - 1];
      tail.position.end = point(token.end);
      this.data.atHardBreak = undefined;
      return;
    }
    if (!this.data.setextHeadingSlurpLineEnding && config.canContainEols.includes(context.type)) {
      onenterdata.call(this, token);
      onexitdata.call(this, token);
    }
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexithardbreak() {
    this.data.atHardBreak = true;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexithtmlflow() {
    const data = this.resume();
    const node = this.stack[this.stack.length - 1];
    node.value = data;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexithtmltext() {
    const data = this.resume();
    const node = this.stack[this.stack.length - 1];
    node.value = data;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexitcodetext() {
    const data = this.resume();
    const node = this.stack[this.stack.length - 1];
    node.value = data;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexitlink() {
    const node = this.stack[this.stack.length - 1];
    // Note: there are also `identifier` and `label` fields on this link node!
    // These are used / cleaned here.

    // To do: clean.
    if (this.data.inReference) {
      /** @type {ReferenceType} */
      const referenceType = this.data.referenceType || 'shortcut';
      node.type += 'Reference';
      // @ts-expect-error: mutate.
      node.referenceType = referenceType;
      // @ts-expect-error: mutate.
      delete node.url;
      delete node.title;
    } else {
      // @ts-expect-error: mutate.
      delete node.identifier;
      // @ts-expect-error: mutate.
      delete node.label;
    }
    this.data.referenceType = undefined;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexitimage() {
    const node = this.stack[this.stack.length - 1];
    // Note: there are also `identifier` and `label` fields on this link node!
    // These are used / cleaned here.

    // To do: clean.
    if (this.data.inReference) {
      /** @type {ReferenceType} */
      const referenceType = this.data.referenceType || 'shortcut';
      node.type += 'Reference';
      // @ts-expect-error: mutate.
      node.referenceType = referenceType;
      // @ts-expect-error: mutate.
      delete node.url;
      delete node.title;
    } else {
      // @ts-expect-error: mutate.
      delete node.identifier;
      // @ts-expect-error: mutate.
      delete node.label;
    }
    this.data.referenceType = undefined;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexitlabeltext(token) {
    const string = this.sliceSerialize(token);
    const ancestor = this.stack[this.stack.length - 2];
    // @ts-expect-error: stash this on the node, as it might become a reference
    // later.
    ancestor.label = decodeString(string);
    // @ts-expect-error: same as above.
    ancestor.identifier = normalizeIdentifier(string).toLowerCase();
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexitlabel() {
    const fragment = this.stack[this.stack.length - 1];
    const value = this.resume();
    const node = this.stack[this.stack.length - 1];
    // Assume a reference.
    this.data.inReference = true;
    if (node.type === 'link') {
      /** @type {Array<PhrasingContent>} */
      const children = fragment.children;
      node.children = children;
    } else {
      node.alt = value;
    }
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexitresourcedestinationstring() {
    const data = this.resume();
    const node = this.stack[this.stack.length - 1];
    node.url = data;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexitresourcetitlestring() {
    const data = this.resume();
    const node = this.stack[this.stack.length - 1];
    node.title = data;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexitresource() {
    this.data.inReference = undefined;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onenterreference() {
    this.data.referenceType = 'collapsed';
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexitreferencestring(token) {
    const label = this.resume();
    const node = this.stack[this.stack.length - 1];
    // @ts-expect-error: stash this on the node, as it might become a reference
    // later.
    node.label = label;
    // @ts-expect-error: same as above.
    node.identifier = normalizeIdentifier(this.sliceSerialize(token)).toLowerCase();
    this.data.referenceType = 'full';
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexitcharacterreferencemarker(token) {
    this.data.characterReferenceType = token.type;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitcharacterreferencevalue(token) {
    const data = this.sliceSerialize(token);
    const type = this.data.characterReferenceType;
    /** @type {string} */
    let value;
    if (type) {
      value = decodeNumericCharacterReference(data, type === "characterReferenceMarkerNumeric" ? 10 : 16);
      this.data.characterReferenceType = undefined;
    } else {
      const result = decodeNamedCharacterReference(data);
      value = result;
    }
    const tail = this.stack[this.stack.length - 1];
    tail.value += value;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitcharacterreference(token) {
    const tail = this.stack.pop();
    tail.position.end = point(token.end);
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitautolinkprotocol(token) {
    onexitdata.call(this, token);
    const node = this.stack[this.stack.length - 1];
    node.url = this.sliceSerialize(token);
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitautolinkemail(token) {
    onexitdata.call(this, token);
    const node = this.stack[this.stack.length - 1];
    node.url = 'mailto:' + this.sliceSerialize(token);
  }

  //
  // Creaters.
  //

  /** @returns {Blockquote} */
  function blockQuote() {
    return {
      type: 'blockquote',
      children: []
    };
  }

  /** @returns {Code} */
  function codeFlow() {
    return {
      type: 'code',
      lang: null,
      meta: null,
      value: ''
    };
  }

  /** @returns {InlineCode} */
  function codeText() {
    return {
      type: 'inlineCode',
      value: ''
    };
  }

  /** @returns {Definition} */
  function definition() {
    return {
      type: 'definition',
      identifier: '',
      label: null,
      title: null,
      url: ''
    };
  }

  /** @returns {Emphasis} */
  function emphasis() {
    return {
      type: 'emphasis',
      children: []
    };
  }

  /** @returns {Heading} */
  function heading() {
    return {
      type: 'heading',
      // @ts-expect-error `depth` will be set later.
      depth: 0,
      children: []
    };
  }

  /** @returns {Break} */
  function hardBreak() {
    return {
      type: 'break'
    };
  }

  /** @returns {Html} */
  function html() {
    return {
      type: 'html',
      value: ''
    };
  }

  /** @returns {Image} */
  function image() {
    return {
      type: 'image',
      title: null,
      url: '',
      alt: null
    };
  }

  /** @returns {Link} */
  function link() {
    return {
      type: 'link',
      title: null,
      url: '',
      children: []
    };
  }

  /**
   * @param {Token} token
   * @returns {List}
   */
  function list(token) {
    return {
      type: 'list',
      ordered: token.type === 'listOrdered',
      start: null,
      spread: token._spread,
      children: []
    };
  }

  /**
   * @param {Token} token
   * @returns {ListItem}
   */
  function listItem(token) {
    return {
      type: 'listItem',
      spread: token._spread,
      checked: null,
      children: []
    };
  }

  /** @returns {Paragraph} */
  function paragraph() {
    return {
      type: 'paragraph',
      children: []
    };
  }

  /** @returns {Strong} */
  function strong() {
    return {
      type: 'strong',
      children: []
    };
  }

  /** @returns {Text} */
  function text() {
    return {
      type: 'text',
      value: ''
    };
  }

  /** @returns {ThematicBreak} */
  function thematicBreak() {
    return {
      type: 'thematicBreak'
    };
  }
}

/**
 * Copy a point-like value.
 *
 * @param {Point} d
 *   Point-like value.
 * @returns {Point}
 *   unist point.
 */
function point(d) {
  return {
    line: d.line,
    column: d.column,
    offset: d.offset
  };
}

/**
 * @param {Config} combined
 * @param {Array<Array<Extension> | Extension>} extensions
 * @returns {undefined}
 */
function configure(combined, extensions) {
  let index = -1;
  while (++index < extensions.length) {
    const value = extensions[index];
    if (Array.isArray(value)) {
      configure(combined, value);
    } else {
      extension(combined, value);
    }
  }
}

/**
 * @param {Config} combined
 * @param {Extension} extension
 * @returns {undefined}
 */
function extension(combined, extension) {
  /** @type {keyof Extension} */
  let key;
  for (key in extension) {
    if (own$1.call(extension, key)) {
      switch (key) {
        case 'canContainEols':
          {
            const right = extension[key];
            if (right) {
              combined[key].push(...right);
            }
            break;
          }
        case 'transforms':
          {
            const right = extension[key];
            if (right) {
              combined[key].push(...right);
            }
            break;
          }
        case 'enter':
        case 'exit':
          {
            const right = extension[key];
            if (right) {
              Object.assign(combined[key], right);
            }
            break;
          }
        // No default
      }
    }
  }
}

/** @type {OnEnterError} */
function defaultOnError(left, right) {
  if (left) {
    throw new Error('Cannot close `' + left.type + '` (' + stringifyPosition({
      start: left.start,
      end: left.end
    }) + '): a different token (`' + right.type + '`, ' + stringifyPosition({
      start: right.start,
      end: right.end
    }) + ') is open');
  } else {
    throw new Error('Cannot close document, a token (`' + right.type + '`, ' + stringifyPosition({
      start: right.start,
      end: right.end
    }) + ') is still open');
  }
}

/**
 * @typedef {import('mdast').Root} Root
 * @typedef {import('mdast-util-from-markdown').Options} FromMarkdownOptions
 * @typedef {import('unified').Parser<Root>} Parser
 * @typedef {import('unified').Processor<Root>} Processor
 */


/**
 * Aadd support for parsing from markdown.
 *
 * @param {Readonly<Options> | null | undefined} [options]
 *   Configuration (optional).
 * @returns {undefined}
 *   Nothing.
 */
function remarkParse(options) {
  /** @type {Processor} */
  // @ts-expect-error: TS in JSDoc generates wrong types if `this` is typed regularly.
  const self = this;

  self.parser = parser;

  /**
   * @type {Parser}
   */
  function parser(doc) {
    return fromMarkdown(doc, {
      ...self.data('settings'),
      ...options,
      // Note: these options are not in the readme.
      // The goal is for them to be set by plugins on `data` instead of being
      // passed by users.
      extensions: self.data('micromarkExtensions') || [],
      mdastExtensions: self.data('fromMarkdownExtensions') || []
    })
  }
}

var e={d:(t,r)=>{for(var n in r)e.o(r,n)&&!e.o(t,n)&&Object.defineProperty(t,n,{enumerable:true,get:r[n]});},o:(e,t)=>Object.prototype.hasOwnProperty.call(e,t)},t={};e.d(t,{Z:()=>h,$:()=>k});var r={horizontalTab:-2,nul:0,eof:null,space:32};function n(e){return e<r.nul||e===r.space}function i(e){return e<r.horizontalTab}var a={553:e=>{e.exports=function(e){var t,r;return e._compiled||(t=e.before?"(?:"+e.before+")":"",r=e.after?"(?:"+e.after+")":"",e.atBreak&&(t="[\\r\\n][\\t ]*"+t),e._compiled=new RegExp((t?"("+t+")":"")+(/[|\\{}()[\]^$+*?.-]/.test(e.character)?"\\":"")+e.character+(r||""),"g")),e._compiled};},112:e=>{function t(e,t,r){var n;if(!t)return r;for("string"==typeof t&&(t=[t]),n=-1;++n<t.length;)if(-1!==e.indexOf(t[n]))return  true;return  false}e.exports=function(e,r){return t(e,r.inConstruct,true)&&!t(e,r.notInConstruct)};},113:(e,t,r)=>{e.exports=function(e,t,r){for(var s,u,l,c,f,k,h,p,d=(r.before||"")+(t||"")+(r.after||""),x=[],w=[],v={},g=-1;++g<e.unsafe.length;)if(c=e.unsafe[g],i(e.stack,c))for(f=n(c);k=f.exec(d);)s="before"in c||c.atBreak,u="after"in c,l=k.index+(s?k[1].length:0),-1===x.indexOf(l)?(x.push(l),v[l]={before:s,after:u}):(v[l].before&&!s&&(v[l].before=false),v[l].after&&!u&&(v[l].after=false));for(x.sort(a),h=r.before?r.before.length:0,p=d.length-(r.after?r.after.length:0),g=-1;++g<x.length;)(l=x[g])<h||l>=p||l+1<p&&x[g+1]===l+1&&v[l].after&&!v[l+1].before&&!v[l+1].after||(h!==l&&w.push(o(d.slice(h,l),"\\")),h=l,!/[!-/:-@[-`{-~]/.test(d.charAt(l))||r.encode&&-1!==r.encode.indexOf(d.charAt(l))?(w.push("&#x"+d.charCodeAt(l).toString(16).toUpperCase()+";"),h++):w.push("\\"));return w.push(o(d.slice(h,p),r.after)),w.join("")};var n=r(553),i=r(112);function a(e,t){return e-t}function o(e,t){for(var r,n=/\\(?=[!-/:-@[-`{-~])/g,i=[],a=[],o=-1,s=0,u=e+t;r=n.exec(u);)i.push(r.index);for(;++o<i.length;)s!==i[o]&&a.push(e.slice(s,i[o])),a.push("\\"),s=i[o];return a.push(e.slice(s)),a.join("")}}},o={};function s(e){var t=o[e];if(void 0!==t)return t.exports;var r=o[e]={exports:{}};return a[e](r,r.exports,s),r.exports}s.n=e=>{var t=e&&e.__esModule?()=>e.default:()=>e;return s.d(t,{a:t}),t},s.d=(e,t)=>{for(var r in t)s.o(t,r)&&!s.o(e,r)&&Object.defineProperty(e,r,{enumerable:true,get:t[r]});},s.o=(e,t)=>Object.prototype.hasOwnProperty.call(e,t);var u={};(()=>{function e(e={}){const t=e.permalinks||[],r=e.pageResolver||(e=>[e.replace(/ /g,"_").toLowerCase()]),n=e.newClassName||"new",i=e.wikiLinkClassName||"internal",a=e.hrefTemplate||(e=>`#/page/${e}`);let o;function s(e){return e[e.length-1]}return {enter:{wikiLink:function(e){o={type:"wikiLink",value:null,data:{alias:null,permalink:null,exists:null}},this.enter(o,e);}},exit:{wikiLinkTarget:function(e){const t=this.sliceSerialize(e);s(this.stack).value=t;},wikiLinkAlias:function(e){const t=this.sliceSerialize(e);s(this.stack).data.alias=t;},wikiLink:function(e){this.exit(e);const s=o,u=r(s.value),l=u.find((e=>-1!==t.indexOf(e))),c=void 0!==l;let f;f=c?l:u[0]||"";let k=s.value;s.data.alias&&(k=s.data.alias);let h=i;c||(h+=" "+n),s.data.alias=k,s.data.permalink=f,s.data.exists=c,s.data.hName="a",s.data.hProperties={className:h,href:a(f)},s.data.hChildren=[{type:"text",value:k}];}}}}s.d(u,{V:()=>e,x:()=>n});var t=s(113),r=s.n(t);function n(e={}){const t=e.aliasDivider||":";return {unsafe:[{character:"[",inConstruct:["phrasing","label","reference"]},{character:"]",inConstruct:["label","reference"]}],handlers:{wikiLink:function(e,n,i){const a=i.enter("wikiLink"),o=r()(i,e.value,{before:"[",after:"]"}),s=r()(i,e.data.alias,{before:"[",after:"]"});let u;return u=s!==o?`[[${o}${t}${s}]]`:`[[${o}]]`,a(),u}}}}})();var l=u.V,c=u.x;let f=false;function k(e={}){const t=this.data();function a(e,r){t[e]?t[e].push(r):t[e]=[r];}!f&&(this.Parser&&this.Parser.prototype&&this.Parser.prototype.blockTokenizers||this.Compiler&&this.Compiler.prototype&&this.Compiler.prototype.visitors)&&(f=true,console.warn("[remark-wiki-link] Warning: please upgrade to remark 13 to use this plugin")),a("micromarkExtensions",function(){var e=(arguments.length>0&&void 0!==arguments[0]?arguments[0]:{}).aliasDivider||":",t="]]";return {text:{91:{tokenize:function(a,o,s){var u,l,c=0,f=0,k=0;return function(e){return e!=="[[".charCodeAt(f)?s(e):(a.enter("wikiLink"),a.enter("wikiLinkMarker"),h(e))};function h(e){return 2===f?(a.exit("wikiLinkMarker"),function(e){return i(e)||e===r.eof?s(e):(a.enter("wikiLinkData"),a.enter("wikiLinkTarget"),p(e))}(e)):e!=="[[".charCodeAt(f)?s(e):(a.consume(e),f++,h)}function p(o){return o===e.charCodeAt(c)?u?(a.exit("wikiLinkTarget"),a.enter("wikiLinkAliasMarker"),d(o)):s(o):o===t.charCodeAt(k)?u?(a.exit("wikiLinkTarget"),a.exit("wikiLinkData"),a.enter("wikiLinkMarker"),w(o)):s(o):i(o)||o===r.eof?s(o):(n(o)||(u=true),a.consume(o),p)}function d(t){return c===e.length?(a.exit("wikiLinkAliasMarker"),a.enter("wikiLinkAlias"),x(t)):t!==e.charCodeAt(c)?s(t):(a.consume(t),c++,d)}function x(e){return e===t.charCodeAt(k)?l?(a.exit("wikiLinkAlias"),a.exit("wikiLinkData"),a.enter("wikiLinkMarker"),w(e)):s(e):i(e)||e===r.eof?s(e):(n(e)||(l=true),a.consume(e),x)}function w(e){return 2===k?(a.exit("wikiLinkMarker"),a.exit("wikiLink"),o(e)):e!==t.charCodeAt(k)?s(e):(a.consume(e),k++,w)}}}}}}(e)),a("fromMarkdownExtensions",l(e)),a("toMarkdownExtensions",c(e));}const h=k;var p=t.Z;t.$;

/**
 * Throw a given error.
 *
 * @param {Error|null|undefined} [error]
 *   Maybe error.
 * @returns {asserts error is null|undefined}
 */
function bail(error) {
  if (error) {
    throw error
  }
}

var extend$1;
var hasRequiredExtend;

function requireExtend () {
	if (hasRequiredExtend) return extend$1;
	hasRequiredExtend = 1;

	var hasOwn = Object.prototype.hasOwnProperty;
	var toStr = Object.prototype.toString;
	var defineProperty = Object.defineProperty;
	var gOPD = Object.getOwnPropertyDescriptor;

	var isArray = function isArray(arr) {
		if (typeof Array.isArray === 'function') {
			return Array.isArray(arr);
		}

		return toStr.call(arr) === '[object Array]';
	};

	var isPlainObject = function isPlainObject(obj) {
		if (!obj || toStr.call(obj) !== '[object Object]') {
			return false;
		}

		var hasOwnConstructor = hasOwn.call(obj, 'constructor');
		var hasIsPrototypeOf = obj.constructor && obj.constructor.prototype && hasOwn.call(obj.constructor.prototype, 'isPrototypeOf');
		// Not own constructor property must be Object
		if (obj.constructor && !hasOwnConstructor && !hasIsPrototypeOf) {
			return false;
		}

		// Own properties are enumerated firstly, so to speed up,
		// if last one is own, then all properties are own.
		var key;
		for (key in obj) { /**/ }

		return typeof key === 'undefined' || hasOwn.call(obj, key);
	};

	// If name is '__proto__', and Object.defineProperty is available, define __proto__ as an own property on target
	var setProperty = function setProperty(target, options) {
		if (defineProperty && options.name === '__proto__') {
			defineProperty(target, options.name, {
				enumerable: true,
				configurable: true,
				value: options.newValue,
				writable: true
			});
		} else {
			target[options.name] = options.newValue;
		}
	};

	// Return undefined instead of __proto__ if '__proto__' is not an own property
	var getProperty = function getProperty(obj, name) {
		if (name === '__proto__') {
			if (!hasOwn.call(obj, name)) {
				return void 0;
			} else if (gOPD) {
				// In early versions of node, obj['__proto__'] is buggy when obj has
				// __proto__ as an own property. Object.getOwnPropertyDescriptor() works.
				return gOPD(obj, name).value;
			}
		}

		return obj[name];
	};

	extend$1 = function extend() {
		var options, name, src, copy, copyIsArray, clone;
		var target = arguments[0];
		var i = 1;
		var length = arguments.length;
		var deep = false;

		// Handle a deep copy situation
		if (typeof target === 'boolean') {
			deep = target;
			target = arguments[1] || {};
			// skip the boolean and the target
			i = 2;
		}
		if (target == null || (typeof target !== 'object' && typeof target !== 'function')) {
			target = {};
		}

		for (; i < length; ++i) {
			options = arguments[i];
			// Only deal with non-null/undefined values
			if (options != null) {
				// Extend the base object
				for (name in options) {
					src = getProperty(target, name);
					copy = getProperty(options, name);

					// Prevent never-ending loop
					if (target !== copy) {
						// Recurse if we're merging plain objects or arrays
						if (deep && copy && (isPlainObject(copy) || (copyIsArray = isArray(copy)))) {
							if (copyIsArray) {
								copyIsArray = false;
								clone = src && isArray(src) ? src : [];
							} else {
								clone = src && isPlainObject(src) ? src : {};
							}

							// Never move original objects, clone them
							setProperty(target, { name: name, newValue: extend(deep, clone, copy) });

						// Don't bring in undefined values
						} else if (typeof copy !== 'undefined') {
							setProperty(target, { name: name, newValue: copy });
						}
					}
				}
			}
		}

		// Return the modified object
		return target;
	};
	return extend$1;
}

var extendExports = requireExtend();
var extend = /*@__PURE__*/getDefaultExportFromCjs(extendExports);

function isPlainObject$2(value) {
	if (typeof value !== 'object' || value === null) {
		return false;
	}

	const prototype = Object.getPrototypeOf(value);
	return (prototype === null || prototype === Object.prototype || Object.getPrototypeOf(prototype) === null) && !(Symbol.toStringTag in value) && !(Symbol.iterator in value);
}

// To do: remove `void`s
// To do: remove `null` from output of our APIs, allow it as user APIs.

/**
 * @typedef {(error?: Error | null | undefined, ...output: Array<any>) => void} Callback
 *   Callback.
 *
 * @typedef {(...input: Array<any>) => any} Middleware
 *   Ware.
 *
 * @typedef Pipeline
 *   Pipeline.
 * @property {Run} run
 *   Run the pipeline.
 * @property {Use} use
 *   Add middleware.
 *
 * @typedef {(...input: Array<any>) => void} Run
 *   Call all middleware.
 *
 *   Calls `done` on completion with either an error or the output of the
 *   last middleware.
 *
 *   > ðŸ‘‰ **Note**: as the length of input defines whether async functions get a
 *   > `next` function,
 *   > itâ€™s recommended to keep `input` at one value normally.

 *
 * @typedef {(fn: Middleware) => Pipeline} Use
 *   Add middleware.
 */

/**
 * Create new middleware.
 *
 * @returns {Pipeline}
 *   Pipeline.
 */
function trough() {
  /** @type {Array<Middleware>} */
  const fns = [];
  /** @type {Pipeline} */
  const pipeline = {run, use};

  return pipeline

  /** @type {Run} */
  function run(...values) {
    let middlewareIndex = -1;
    /** @type {Callback} */
    const callback = values.pop();

    if (typeof callback !== 'function') {
      throw new TypeError('Expected function as last argument, not ' + callback)
    }

    next(null, ...values);

    /**
     * Run the next `fn`, or weâ€™re done.
     *
     * @param {Error | null | undefined} error
     * @param {Array<any>} output
     */
    function next(error, ...output) {
      const fn = fns[++middlewareIndex];
      let index = -1;

      if (error) {
        callback(error);
        return
      }

      // Copy non-nullish input into values.
      while (++index < values.length) {
        if (output[index] === null || output[index] === undefined) {
          output[index] = values[index];
        }
      }

      // Save the newly created `output` for the next call.
      values = output;

      // Next or done.
      if (fn) {
        wrap(fn, next)(...output);
      } else {
        callback(null, ...output);
      }
    }
  }

  /** @type {Use} */
  function use(middelware) {
    if (typeof middelware !== 'function') {
      throw new TypeError(
        'Expected `middelware` to be a function, not ' + middelware
      )
    }

    fns.push(middelware);
    return pipeline
  }
}

/**
 * Wrap `middleware` into a uniform interface.
 *
 * You can pass all input to the resulting function.
 * `callback` is then called with the output of `middleware`.
 *
 * If `middleware` accepts more arguments than the later given in input,
 * an extra `done` function is passed to it after that input,
 * which must be called by `middleware`.
 *
 * The first value in `input` is the main input value.
 * All other input values are the rest input values.
 * The values given to `callback` are the input values,
 * merged with every non-nullish output value.
 *
 * * if `middleware` throws an error,
 *   returns a promise that is rejected,
 *   or calls the given `done` function with an error,
 *   `callback` is called with that error
 * * if `middleware` returns a value or returns a promise that is resolved,
 *   that value is the main output value
 * * if `middleware` calls `done`,
 *   all non-nullish values except for the first one (the error) overwrite the
 *   output values
 *
 * @param {Middleware} middleware
 *   Function to wrap.
 * @param {Callback} callback
 *   Callback called with the output of `middleware`.
 * @returns {Run}
 *   Wrapped middleware.
 */
function wrap(middleware, callback) {
  /** @type {boolean} */
  let called;

  return wrapped

  /**
   * Call `middleware`.
   * @this {any}
   * @param {Array<any>} parameters
   * @returns {void}
   */
  function wrapped(...parameters) {
    const fnExpectsCallback = middleware.length > parameters.length;
    /** @type {any} */
    let result;

    if (fnExpectsCallback) {
      parameters.push(done);
    }

    try {
      result = middleware.apply(this, parameters);
    } catch (error) {
      const exception = /** @type {Error} */ (error);

      // Well, this is quite the pickle.
      // `middleware` received a callback and called it synchronously, but that
      // threw an error.
      // The only thing left to do is to throw the thing instead.
      if (fnExpectsCallback && called) {
        throw exception
      }

      return done(exception)
    }

    if (!fnExpectsCallback) {
      if (result && result.then && typeof result.then === 'function') {
        result.then(then, done);
      } else if (result instanceof Error) {
        done(result);
      } else {
        then(result);
      }
    }
  }

  /**
   * Call `callback`, only once.
   *
   * @type {Callback}
   */
  function done(error, ...output) {
    if (!called) {
      called = true;
      callback(error, ...output);
    }
  }

  /**
   * Call `done` with one value.
   *
   * @param {any} [value]
   */
  function then(value) {
    done(null, value);
  }
}

/**
 * @typedef {import('unist').Node} Node
 * @typedef {import('unist').Point} Point
 * @typedef {import('unist').Position} Position
 */


/**
 * Message.
 */
class VFileMessage extends Error {
  /**
   * Create a message for `reason`.
   *
   * > ðŸª¦ **Note**: also has obsolete signatures.
   *
   * @overload
   * @param {string} reason
   * @param {Options | null | undefined} [options]
   * @returns
   *
   * @overload
   * @param {string} reason
   * @param {Node | NodeLike | null | undefined} parent
   * @param {string | null | undefined} [origin]
   * @returns
   *
   * @overload
   * @param {string} reason
   * @param {Point | Position | null | undefined} place
   * @param {string | null | undefined} [origin]
   * @returns
   *
   * @overload
   * @param {string} reason
   * @param {string | null | undefined} [origin]
   * @returns
   *
   * @overload
   * @param {Error | VFileMessage} cause
   * @param {Node | NodeLike | null | undefined} parent
   * @param {string | null | undefined} [origin]
   * @returns
   *
   * @overload
   * @param {Error | VFileMessage} cause
   * @param {Point | Position | null | undefined} place
   * @param {string | null | undefined} [origin]
   * @returns
   *
   * @overload
   * @param {Error | VFileMessage} cause
   * @param {string | null | undefined} [origin]
   * @returns
   *
   * @param {Error | VFileMessage | string} causeOrReason
   *   Reason for message, should use markdown.
   * @param {Node | NodeLike | Options | Point | Position | string | null | undefined} [optionsOrParentOrPlace]
   *   Configuration (optional).
   * @param {string | null | undefined} [origin]
   *   Place in code where the message originates (example:
   *   `'my-package:my-rule'` or `'my-rule'`).
   * @returns
   *   Instance of `VFileMessage`.
   */
  // eslint-disable-next-line complexity
  constructor(causeOrReason, optionsOrParentOrPlace, origin) {
    super();

    if (typeof optionsOrParentOrPlace === 'string') {
      origin = optionsOrParentOrPlace;
      optionsOrParentOrPlace = undefined;
    }

    /** @type {string} */
    let reason = '';
    /** @type {Options} */
    let options = {};
    let legacyCause = false;

    if (optionsOrParentOrPlace) {
      // Point.
      if (
        'line' in optionsOrParentOrPlace &&
        'column' in optionsOrParentOrPlace
      ) {
        options = {place: optionsOrParentOrPlace};
      }
      // Position.
      else if (
        'start' in optionsOrParentOrPlace &&
        'end' in optionsOrParentOrPlace
      ) {
        options = {place: optionsOrParentOrPlace};
      }
      // Node.
      else if ('type' in optionsOrParentOrPlace) {
        options = {
          ancestors: [optionsOrParentOrPlace],
          place: optionsOrParentOrPlace.position
        };
      }
      // Options.
      else {
        options = {...optionsOrParentOrPlace};
      }
    }

    if (typeof causeOrReason === 'string') {
      reason = causeOrReason;
    }
    // Error.
    else if (!options.cause && causeOrReason) {
      legacyCause = true;
      reason = causeOrReason.message;
      options.cause = causeOrReason;
    }

    if (!options.ruleId && !options.source && typeof origin === 'string') {
      const index = origin.indexOf(':');

      if (index === -1) {
        options.ruleId = origin;
      } else {
        options.source = origin.slice(0, index);
        options.ruleId = origin.slice(index + 1);
      }
    }

    if (!options.place && options.ancestors && options.ancestors) {
      const parent = options.ancestors[options.ancestors.length - 1];

      if (parent) {
        options.place = parent.position;
      }
    }

    const start =
      options.place && 'start' in options.place
        ? options.place.start
        : options.place;

    /* eslint-disable no-unused-expressions */
    /**
     * Stack of ancestor nodes surrounding the message.
     *
     * @type {Array<Node> | undefined}
     */
    this.ancestors = options.ancestors || undefined;

    /**
     * Original error cause of the message.
     *
     * @type {Error | undefined}
     */
    this.cause = options.cause || undefined;

    /**
     * Starting column of message.
     *
     * @type {number | undefined}
     */
    this.column = start ? start.column : undefined;

    /**
     * State of problem.
     *
     * * `true` â€” error, file not usable
     * * `false` â€” warning, change may be needed
     * * `undefined` â€” change likely not needed
     *
     * @type {boolean | null | undefined}
     */
    this.fatal = undefined;

    /**
     * Path of a file (used throughout the `VFile` ecosystem).
     *
     * @type {string | undefined}
     */
    this.file;

    // Field from `Error`.
    /**
     * Reason for message.
     *
     * @type {string}
     */
    this.message = reason;

    /**
     * Starting line of error.
     *
     * @type {number | undefined}
     */
    this.line = start ? start.line : undefined;

    // Field from `Error`.
    /**
     * Serialized positional info of message.
     *
     * On normal errors, this would be something like `ParseError`, buit in
     * `VFile` messages we use this space to show where an error happened.
     */
    this.name = stringifyPosition(options.place) || '1:1';

    /**
     * Place of message.
     *
     * @type {Point | Position | undefined}
     */
    this.place = options.place || undefined;

    /**
     * Reason for message, should use markdown.
     *
     * @type {string}
     */
    this.reason = this.message;

    /**
     * Category of message (example: `'my-rule'`).
     *
     * @type {string | undefined}
     */
    this.ruleId = options.ruleId || undefined;

    /**
     * Namespace of message (example: `'my-package'`).
     *
     * @type {string | undefined}
     */
    this.source = options.source || undefined;

    // Field from `Error`.
    /**
     * Stack of message.
     *
     * This is used by normal errors to show where something happened in
     * programming code, irrelevant for `VFile` messages,
     *
     * @type {string}
     */
    this.stack =
      legacyCause && options.cause && typeof options.cause.stack === 'string'
        ? options.cause.stack
        : '';

    // The following fields are â€œwell knownâ€.
    // Not standard.
    // Feel free to add other non-standard fields to your messages.

    /**
     * Specify the source value thatâ€™s being reported, which is deemed
     * incorrect.
     *
     * @type {string | undefined}
     */
    this.actual;

    /**
     * Suggest acceptable values that can be used instead of `actual`.
     *
     * @type {Array<string> | undefined}
     */
    this.expected;

    /**
     * Long form description of the message (you should use markdown).
     *
     * @type {string | undefined}
     */
    this.note;

    /**
     * Link to docs for the message.
     *
     * > ðŸ‘‰ **Note**: this must be an absolute URL that can be passed as `x`
     * > to `new URL(x)`.
     *
     * @type {string | undefined}
     */
    this.url;
    /* eslint-enable no-unused-expressions */
  }
}

VFileMessage.prototype.file = '';
VFileMessage.prototype.name = '';
VFileMessage.prototype.reason = '';
VFileMessage.prototype.message = '';
VFileMessage.prototype.stack = '';
VFileMessage.prototype.column = undefined;
VFileMessage.prototype.line = undefined;
VFileMessage.prototype.ancestors = undefined;
VFileMessage.prototype.cause = undefined;
VFileMessage.prototype.fatal = undefined;
VFileMessage.prototype.place = undefined;
VFileMessage.prototype.ruleId = undefined;
VFileMessage.prototype.source = undefined;

// A derivative work based on:
// <https://github.com/browserify/path-browserify>.
// Which is licensed:
//
// MIT License
//
// Copyright (c) 2013 James Halliday
//
// Permission is hereby granted, free of charge, to any person obtaining a copy of
// this software and associated documentation files (the "Software"), to deal in
// the Software without restriction, including without limitation the rights to
// use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
// the Software, and to permit persons to whom the Software is furnished to do so,
// subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in all
// copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
// FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
// COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
// IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
// CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
// A derivative work based on:
//
// Parts of that are extracted from Nodeâ€™s internal `path` module:
// <https://github.com/nodejs/node/blob/master/lib/path.js>.
// Which is licensed:
//
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.

const minpath = {basename, dirname, extname, join, sep: '/'};

/* eslint-disable max-depth, complexity */

/**
 * Get the basename from a path.
 *
 * @param {string} path
 *   File path.
 * @param {string | null | undefined} [extname]
 *   Extension to strip.
 * @returns {string}
 *   Stem or basename.
 */
function basename(path, extname) {
  if (extname !== undefined && typeof extname !== 'string') {
    throw new TypeError('"ext" argument must be a string')
  }

  assertPath$1(path);
  let start = 0;
  let end = -1;
  let index = path.length;
  /** @type {boolean | undefined} */
  let seenNonSlash;

  if (
    extname === undefined ||
    extname.length === 0 ||
    extname.length > path.length
  ) {
    while (index--) {
      if (path.codePointAt(index) === 47 /* `/` */) {
        // If we reached a path separator that was not part of a set of path
        // separators at the end of the string, stop now.
        if (seenNonSlash) {
          start = index + 1;
          break
        }
      } else if (end < 0) {
        // We saw the first non-path separator, mark this as the end of our
        // path component.
        seenNonSlash = true;
        end = index + 1;
      }
    }

    return end < 0 ? '' : path.slice(start, end)
  }

  if (extname === path) {
    return ''
  }

  let firstNonSlashEnd = -1;
  let extnameIndex = extname.length - 1;

  while (index--) {
    if (path.codePointAt(index) === 47 /* `/` */) {
      // If we reached a path separator that was not part of a set of path
      // separators at the end of the string, stop now.
      if (seenNonSlash) {
        start = index + 1;
        break
      }
    } else {
      if (firstNonSlashEnd < 0) {
        // We saw the first non-path separator, remember this index in case
        // we need it if the extension ends up not matching.
        seenNonSlash = true;
        firstNonSlashEnd = index + 1;
      }

      if (extnameIndex > -1) {
        // Try to match the explicit extension.
        if (path.codePointAt(index) === extname.codePointAt(extnameIndex--)) {
          if (extnameIndex < 0) {
            // We matched the extension, so mark this as the end of our path
            // component
            end = index;
          }
        } else {
          // Extension does not match, so our result is the entire path
          // component
          extnameIndex = -1;
          end = firstNonSlashEnd;
        }
      }
    }
  }

  if (start === end) {
    end = firstNonSlashEnd;
  } else if (end < 0) {
    end = path.length;
  }

  return path.slice(start, end)
}

/**
 * Get the dirname from a path.
 *
 * @param {string} path
 *   File path.
 * @returns {string}
 *   File path.
 */
function dirname(path) {
  assertPath$1(path);

  if (path.length === 0) {
    return '.'
  }

  let end = -1;
  let index = path.length;
  /** @type {boolean | undefined} */
  let unmatchedSlash;

  // Prefix `--` is important to not run on `0`.
  while (--index) {
    if (path.codePointAt(index) === 47 /* `/` */) {
      if (unmatchedSlash) {
        end = index;
        break
      }
    } else if (!unmatchedSlash) {
      // We saw the first non-path separator
      unmatchedSlash = true;
    }
  }

  return end < 0
    ? path.codePointAt(0) === 47 /* `/` */
      ? '/'
      : '.'
    : end === 1 && path.codePointAt(0) === 47 /* `/` */
      ? '//'
      : path.slice(0, end)
}

/**
 * Get an extname from a path.
 *
 * @param {string} path
 *   File path.
 * @returns {string}
 *   Extname.
 */
function extname(path) {
  assertPath$1(path);

  let index = path.length;

  let end = -1;
  let startPart = 0;
  let startDot = -1;
  // Track the state of characters (if any) we see before our first dot and
  // after any path separator we find.
  let preDotState = 0;
  /** @type {boolean | undefined} */
  let unmatchedSlash;

  while (index--) {
    const code = path.codePointAt(index);

    if (code === 47 /* `/` */) {
      // If we reached a path separator that was not part of a set of path
      // separators at the end of the string, stop now.
      if (unmatchedSlash) {
        startPart = index + 1;
        break
      }

      continue
    }

    if (end < 0) {
      // We saw the first non-path separator, mark this as the end of our
      // extension.
      unmatchedSlash = true;
      end = index + 1;
    }

    if (code === 46 /* `.` */) {
      // If this is our first dot, mark it as the start of our extension.
      if (startDot < 0) {
        startDot = index;
      } else if (preDotState !== 1) {
        preDotState = 1;
      }
    } else if (startDot > -1) {
      // We saw a non-dot and non-path separator before our dot, so we should
      // have a good chance at having a non-empty extension.
      preDotState = -1;
    }
  }

  if (
    startDot < 0 ||
    end < 0 ||
    // We saw a non-dot character immediately before the dot.
    preDotState === 0 ||
    // The (right-most) trimmed path component is exactly `..`.
    (preDotState === 1 && startDot === end - 1 && startDot === startPart + 1)
  ) {
    return ''
  }

  return path.slice(startDot, end)
}

/**
 * Join segments from a path.
 *
 * @param {Array<string>} segments
 *   Path segments.
 * @returns {string}
 *   File path.
 */
function join(...segments) {
  let index = -1;
  /** @type {string | undefined} */
  let joined;

  while (++index < segments.length) {
    assertPath$1(segments[index]);

    if (segments[index]) {
      joined =
        joined === undefined ? segments[index] : joined + '/' + segments[index];
    }
  }

  return joined === undefined ? '.' : normalize(joined)
}

/**
 * Normalize a basic file path.
 *
 * @param {string} path
 *   File path.
 * @returns {string}
 *   File path.
 */
// Note: `normalize` is not exposed as `path.normalize`, so some code is
// manually removed from it.
function normalize(path) {
  assertPath$1(path);

  const absolute = path.codePointAt(0) === 47; /* `/` */

  // Normalize the path according to POSIX rules.
  let value = normalizeString(path, !absolute);

  if (value.length === 0 && !absolute) {
    value = '.';
  }

  if (value.length > 0 && path.codePointAt(path.length - 1) === 47 /* / */) {
    value += '/';
  }

  return absolute ? '/' + value : value
}

/**
 * Resolve `.` and `..` elements in a path with directory names.
 *
 * @param {string} path
 *   File path.
 * @param {boolean} allowAboveRoot
 *   Whether `..` can move above root.
 * @returns {string}
 *   File path.
 */
function normalizeString(path, allowAboveRoot) {
  let result = '';
  let lastSegmentLength = 0;
  let lastSlash = -1;
  let dots = 0;
  let index = -1;
  /** @type {number | undefined} */
  let code;
  /** @type {number} */
  let lastSlashIndex;

  while (++index <= path.length) {
    if (index < path.length) {
      code = path.codePointAt(index);
    } else if (code === 47 /* `/` */) {
      break
    } else {
      code = 47; /* `/` */
    }

    if (code === 47 /* `/` */) {
      if (lastSlash === index - 1 || dots === 1) ; else if (lastSlash !== index - 1 && dots === 2) {
        if (
          result.length < 2 ||
          lastSegmentLength !== 2 ||
          result.codePointAt(result.length - 1) !== 46 /* `.` */ ||
          result.codePointAt(result.length - 2) !== 46 /* `.` */
        ) {
          if (result.length > 2) {
            lastSlashIndex = result.lastIndexOf('/');

            if (lastSlashIndex !== result.length - 1) {
              if (lastSlashIndex < 0) {
                result = '';
                lastSegmentLength = 0;
              } else {
                result = result.slice(0, lastSlashIndex);
                lastSegmentLength = result.length - 1 - result.lastIndexOf('/');
              }

              lastSlash = index;
              dots = 0;
              continue
            }
          } else if (result.length > 0) {
            result = '';
            lastSegmentLength = 0;
            lastSlash = index;
            dots = 0;
            continue
          }
        }

        if (allowAboveRoot) {
          result = result.length > 0 ? result + '/..' : '..';
          lastSegmentLength = 2;
        }
      } else {
        if (result.length > 0) {
          result += '/' + path.slice(lastSlash + 1, index);
        } else {
          result = path.slice(lastSlash + 1, index);
        }

        lastSegmentLength = index - lastSlash - 1;
      }

      lastSlash = index;
      dots = 0;
    } else if (code === 46 /* `.` */ && dots > -1) {
      dots++;
    } else {
      dots = -1;
    }
  }

  return result
}

/**
 * Make sure `path` is a string.
 *
 * @param {string} path
 *   File path.
 * @returns {asserts path is string}
 *   Nothing.
 */
function assertPath$1(path) {
  if (typeof path !== 'string') {
    throw new TypeError(
      'Path must be a string. Received ' + JSON.stringify(path)
    )
  }
}

/* eslint-enable max-depth, complexity */

// Somewhat based on:
// <https://github.com/defunctzombie/node-process/blob/master/browser.js>.
// But I donâ€™t think one tiny line of code can be copyrighted. ðŸ˜…
const minproc = {cwd};

function cwd() {
  return '/'
}

/**
 * Checks if a value has the shape of a WHATWG URL object.
 *
 * Using a symbol or instanceof would not be able to recognize URL objects
 * coming from other implementations (e.g. in Electron), so instead we are
 * checking some well known properties for a lack of a better test.
 *
 * We use `href` and `protocol` as they are the only properties that are
 * easy to retrieve and calculate due to the lazy nature of the getters.
 *
 * We check for auth attribute to distinguish legacy url instance with
 * WHATWG URL instance.
 *
 * @param {unknown} fileUrlOrPath
 *   File path or URL.
 * @returns {fileUrlOrPath is URL}
 *   Whether itâ€™s a URL.
 */
// From: <https://github.com/nodejs/node/blob/6a3403c/lib/internal/url.js#L720>
function isUrl(fileUrlOrPath) {
  return Boolean(
    fileUrlOrPath !== null &&
      typeof fileUrlOrPath === 'object' &&
      'href' in fileUrlOrPath &&
      fileUrlOrPath.href &&
      'protocol' in fileUrlOrPath &&
      fileUrlOrPath.protocol &&
      // @ts-expect-error: indexing is fine.
      fileUrlOrPath.auth === undefined
  )
}

// See: <https://github.com/nodejs/node/blob/6a3403c/lib/internal/url.js>

/**
 * @param {URL | string} path
 *   File URL.
 * @returns {string}
 *   File URL.
 */
function urlToPath(path) {
  if (typeof path === 'string') {
    path = new URL(path);
  } else if (!isUrl(path)) {
    /** @type {NodeJS.ErrnoException} */
    const error = new TypeError(
      'The "path" argument must be of type string or an instance of URL. Received `' +
        path +
        '`'
    );
    error.code = 'ERR_INVALID_ARG_TYPE';
    throw error
  }

  if (path.protocol !== 'file:') {
    /** @type {NodeJS.ErrnoException} */
    const error = new TypeError('The URL must be of scheme file');
    error.code = 'ERR_INVALID_URL_SCHEME';
    throw error
  }

  return getPathFromURLPosix(path)
}

/**
 * Get a path from a POSIX URL.
 *
 * @param {URL} url
 *   URL.
 * @returns {string}
 *   File path.
 */
function getPathFromURLPosix(url) {
  if (url.hostname !== '') {
    /** @type {NodeJS.ErrnoException} */
    const error = new TypeError(
      'File URL host must be "localhost" or empty on darwin'
    );
    error.code = 'ERR_INVALID_FILE_URL_HOST';
    throw error
  }

  const pathname = url.pathname;
  let index = -1;

  while (++index < pathname.length) {
    if (
      pathname.codePointAt(index) === 37 /* `%` */ &&
      pathname.codePointAt(index + 1) === 50 /* `2` */
    ) {
      const third = pathname.codePointAt(index + 2);
      if (third === 70 /* `F` */ || third === 102 /* `f` */) {
        /** @type {NodeJS.ErrnoException} */
        const error = new TypeError(
          'File URL path must not include encoded / characters'
        );
        error.code = 'ERR_INVALID_FILE_URL_PATH';
        throw error
      }
    }
  }

  return decodeURIComponent(pathname)
}

/**
 * @import {Node, Point, Position} from 'unist'
 * @import {Options as MessageOptions} from 'vfile-message'
 * @import {Compatible, Data, Map, Options, Value} from 'vfile'
 */


/**
 * Order of setting (least specific to most), we need this because otherwise
 * `{stem: 'a', path: '~/b.js'}` would throw, as a path is needed before a
 * stem can be set.
 */
const order = /** @type {const} */ ([
  'history',
  'path',
  'basename',
  'stem',
  'extname',
  'dirname'
]);

class VFile {
  /**
   * Create a new virtual file.
   *
   * `options` is treated as:
   *
   * *   `string` or `Uint8Array` â€” `{value: options}`
   * *   `URL` â€” `{path: options}`
   * *   `VFile` â€” shallow copies its data over to the new file
   * *   `object` â€” all fields are shallow copied over to the new file
   *
   * Path related fields are set in the following order (least specific to
   * most specific): `history`, `path`, `basename`, `stem`, `extname`,
   * `dirname`.
   *
   * You cannot set `dirname` or `extname` without setting either `history`,
   * `path`, `basename`, or `stem` too.
   *
   * @param {Compatible | null | undefined} [value]
   *   File value.
   * @returns
   *   New instance.
   */
  constructor(value) {
    /** @type {Options | VFile} */
    let options;

    if (!value) {
      options = {};
    } else if (isUrl(value)) {
      options = {path: value};
    } else if (typeof value === 'string' || isUint8Array$1(value)) {
      options = {value};
    } else {
      options = value;
    }

    /* eslint-disable no-unused-expressions */

    /**
     * Base of `path` (default: `process.cwd()` or `'/'` in browsers).
     *
     * @type {string}
     */
    // Prevent calling `cwd` (which could be expensive) if itâ€™s not needed;
    // the empty string will be overridden in the next block.
    this.cwd = 'cwd' in options ? '' : minproc.cwd();

    /**
     * Place to store custom info (default: `{}`).
     *
     * Itâ€™s OK to store custom data directly on the file but moving it to
     * `data` is recommended.
     *
     * @type {Data}
     */
    this.data = {};

    /**
     * List of file paths the file moved between.
     *
     * The first is the original path and the last is the current path.
     *
     * @type {Array<string>}
     */
    this.history = [];

    /**
     * List of messages associated with the file.
     *
     * @type {Array<VFileMessage>}
     */
    this.messages = [];

    /**
     * Raw value.
     *
     * @type {Value}
     */
    this.value;

    // The below are non-standard, they are â€œwell-knownâ€.
    // As in, used in several tools.
    /**
     * Source map.
     *
     * This type is equivalent to the `RawSourceMap` type from the `source-map`
     * module.
     *
     * @type {Map | null | undefined}
     */
    this.map;

    /**
     * Custom, non-string, compiled, representation.
     *
     * This is used by unified to store non-string results.
     * One example is when turning markdown into React nodes.
     *
     * @type {unknown}
     */
    this.result;

    /**
     * Whether a file was saved to disk.
     *
     * This is used by vfile reporters.
     *
     * @type {boolean}
     */
    this.stored;
    /* eslint-enable no-unused-expressions */

    // Set path related properties in the correct order.
    let index = -1;

    while (++index < order.length) {
      const field = order[index];

      // Note: we specifically use `in` instead of `hasOwnProperty` to accept
      // `vfile`s too.
      if (
        field in options &&
        options[field] !== undefined &&
        options[field] !== null
      ) {
        // @ts-expect-error: TS doesnâ€™t understand basic reality.
        this[field] = field === 'history' ? [...options[field]] : options[field];
      }
    }

    /** @type {string} */
    let field;

    // Set non-path related properties.
    for (field in options) {
      // @ts-expect-error: fine to set other things.
      if (!order.includes(field)) {
        // @ts-expect-error: fine to set other things.
        this[field] = options[field];
      }
    }
  }

  /**
   * Get the basename (including extname) (example: `'index.min.js'`).
   *
   * @returns {string | undefined}
   *   Basename.
   */
  get basename() {
    return typeof this.path === 'string'
      ? minpath.basename(this.path)
      : undefined
  }

  /**
   * Set basename (including extname) (`'index.min.js'`).
   *
   * Cannot contain path separators (`'/'` on unix, macOS, and browsers, `'\'`
   * on windows).
   * Cannot be nullified (use `file.path = file.dirname` instead).
   *
   * @param {string} basename
   *   Basename.
   * @returns {undefined}
   *   Nothing.
   */
  set basename(basename) {
    assertNonEmpty(basename, 'basename');
    assertPart(basename, 'basename');
    this.path = minpath.join(this.dirname || '', basename);
  }

  /**
   * Get the parent path (example: `'~'`).
   *
   * @returns {string | undefined}
   *   Dirname.
   */
  get dirname() {
    return typeof this.path === 'string'
      ? minpath.dirname(this.path)
      : undefined
  }

  /**
   * Set the parent path (example: `'~'`).
   *
   * Cannot be set if thereâ€™s no `path` yet.
   *
   * @param {string | undefined} dirname
   *   Dirname.
   * @returns {undefined}
   *   Nothing.
   */
  set dirname(dirname) {
    assertPath(this.basename, 'dirname');
    this.path = minpath.join(dirname || '', this.basename);
  }

  /**
   * Get the extname (including dot) (example: `'.js'`).
   *
   * @returns {string | undefined}
   *   Extname.
   */
  get extname() {
    return typeof this.path === 'string'
      ? minpath.extname(this.path)
      : undefined
  }

  /**
   * Set the extname (including dot) (example: `'.js'`).
   *
   * Cannot contain path separators (`'/'` on unix, macOS, and browsers, `'\'`
   * on windows).
   * Cannot be set if thereâ€™s no `path` yet.
   *
   * @param {string | undefined} extname
   *   Extname.
   * @returns {undefined}
   *   Nothing.
   */
  set extname(extname) {
    assertPart(extname, 'extname');
    assertPath(this.dirname, 'extname');

    if (extname) {
      if (extname.codePointAt(0) !== 46 /* `.` */) {
        throw new Error('`extname` must start with `.`')
      }

      if (extname.includes('.', 1)) {
        throw new Error('`extname` cannot contain multiple dots')
      }
    }

    this.path = minpath.join(this.dirname, this.stem + (extname || ''));
  }

  /**
   * Get the full path (example: `'~/index.min.js'`).
   *
   * @returns {string}
   *   Path.
   */
  get path() {
    return this.history[this.history.length - 1]
  }

  /**
   * Set the full path (example: `'~/index.min.js'`).
   *
   * Cannot be nullified.
   * You can set a file URL (a `URL` object with a `file:` protocol) which will
   * be turned into a path with `url.fileURLToPath`.
   *
   * @param {URL | string} path
   *   Path.
   * @returns {undefined}
   *   Nothing.
   */
  set path(path) {
    if (isUrl(path)) {
      path = urlToPath(path);
    }

    assertNonEmpty(path, 'path');

    if (this.path !== path) {
      this.history.push(path);
    }
  }

  /**
   * Get the stem (basename w/o extname) (example: `'index.min'`).
   *
   * @returns {string | undefined}
   *   Stem.
   */
  get stem() {
    return typeof this.path === 'string'
      ? minpath.basename(this.path, this.extname)
      : undefined
  }

  /**
   * Set the stem (basename w/o extname) (example: `'index.min'`).
   *
   * Cannot contain path separators (`'/'` on unix, macOS, and browsers, `'\'`
   * on windows).
   * Cannot be nullified (use `file.path = file.dirname` instead).
   *
   * @param {string} stem
   *   Stem.
   * @returns {undefined}
   *   Nothing.
   */
  set stem(stem) {
    assertNonEmpty(stem, 'stem');
    assertPart(stem, 'stem');
    this.path = minpath.join(this.dirname || '', stem + (this.extname || ''));
  }

  // Normal prototypal methods.
  /**
   * Create a fatal message for `reason` associated with the file.
   *
   * The `fatal` field of the message is set to `true` (error; file not usable)
   * and the `file` field is set to the current file path.
   * The message is added to the `messages` field on `file`.
   *
   * > ðŸª¦ **Note**: also has obsolete signatures.
   *
   * @overload
   * @param {string} reason
   * @param {MessageOptions | null | undefined} [options]
   * @returns {never}
   *
   * @overload
   * @param {string} reason
   * @param {Node | NodeLike | null | undefined} parent
   * @param {string | null | undefined} [origin]
   * @returns {never}
   *
   * @overload
   * @param {string} reason
   * @param {Point | Position | null | undefined} place
   * @param {string | null | undefined} [origin]
   * @returns {never}
   *
   * @overload
   * @param {string} reason
   * @param {string | null | undefined} [origin]
   * @returns {never}
   *
   * @overload
   * @param {Error | VFileMessage} cause
   * @param {Node | NodeLike | null | undefined} parent
   * @param {string | null | undefined} [origin]
   * @returns {never}
   *
   * @overload
   * @param {Error | VFileMessage} cause
   * @param {Point | Position | null | undefined} place
   * @param {string | null | undefined} [origin]
   * @returns {never}
   *
   * @overload
   * @param {Error | VFileMessage} cause
   * @param {string | null | undefined} [origin]
   * @returns {never}
   *
   * @param {Error | VFileMessage | string} causeOrReason
   *   Reason for message, should use markdown.
   * @param {Node | NodeLike | MessageOptions | Point | Position | string | null | undefined} [optionsOrParentOrPlace]
   *   Configuration (optional).
   * @param {string | null | undefined} [origin]
   *   Place in code where the message originates (example:
   *   `'my-package:my-rule'` or `'my-rule'`).
   * @returns {never}
   *   Never.
   * @throws {VFileMessage}
   *   Message.
   */
  fail(causeOrReason, optionsOrParentOrPlace, origin) {
    // @ts-expect-error: the overloads are fine.
    const message = this.message(causeOrReason, optionsOrParentOrPlace, origin);

    message.fatal = true;

    throw message
  }

  /**
   * Create an info message for `reason` associated with the file.
   *
   * The `fatal` field of the message is set to `undefined` (info; change
   * likely not needed) and the `file` field is set to the current file path.
   * The message is added to the `messages` field on `file`.
   *
   * > ðŸª¦ **Note**: also has obsolete signatures.
   *
   * @overload
   * @param {string} reason
   * @param {MessageOptions | null | undefined} [options]
   * @returns {VFileMessage}
   *
   * @overload
   * @param {string} reason
   * @param {Node | NodeLike | null | undefined} parent
   * @param {string | null | undefined} [origin]
   * @returns {VFileMessage}
   *
   * @overload
   * @param {string} reason
   * @param {Point | Position | null | undefined} place
   * @param {string | null | undefined} [origin]
   * @returns {VFileMessage}
   *
   * @overload
   * @param {string} reason
   * @param {string | null | undefined} [origin]
   * @returns {VFileMessage}
   *
   * @overload
   * @param {Error | VFileMessage} cause
   * @param {Node | NodeLike | null | undefined} parent
   * @param {string | null | undefined} [origin]
   * @returns {VFileMessage}
   *
   * @overload
   * @param {Error | VFileMessage} cause
   * @param {Point | Position | null | undefined} place
   * @param {string | null | undefined} [origin]
   * @returns {VFileMessage}
   *
   * @overload
   * @param {Error | VFileMessage} cause
   * @param {string | null | undefined} [origin]
   * @returns {VFileMessage}
   *
   * @param {Error | VFileMessage | string} causeOrReason
   *   Reason for message, should use markdown.
   * @param {Node | NodeLike | MessageOptions | Point | Position | string | null | undefined} [optionsOrParentOrPlace]
   *   Configuration (optional).
   * @param {string | null | undefined} [origin]
   *   Place in code where the message originates (example:
   *   `'my-package:my-rule'` or `'my-rule'`).
   * @returns {VFileMessage}
   *   Message.
   */
  info(causeOrReason, optionsOrParentOrPlace, origin) {
    // @ts-expect-error: the overloads are fine.
    const message = this.message(causeOrReason, optionsOrParentOrPlace, origin);

    message.fatal = undefined;

    return message
  }

  /**
   * Create a message for `reason` associated with the file.
   *
   * The `fatal` field of the message is set to `false` (warning; change may be
   * needed) and the `file` field is set to the current file path.
   * The message is added to the `messages` field on `file`.
   *
   * > ðŸª¦ **Note**: also has obsolete signatures.
   *
   * @overload
   * @param {string} reason
   * @param {MessageOptions | null | undefined} [options]
   * @returns {VFileMessage}
   *
   * @overload
   * @param {string} reason
   * @param {Node | NodeLike | null | undefined} parent
   * @param {string | null | undefined} [origin]
   * @returns {VFileMessage}
   *
   * @overload
   * @param {string} reason
   * @param {Point | Position | null | undefined} place
   * @param {string | null | undefined} [origin]
   * @returns {VFileMessage}
   *
   * @overload
   * @param {string} reason
   * @param {string | null | undefined} [origin]
   * @returns {VFileMessage}
   *
   * @overload
   * @param {Error | VFileMessage} cause
   * @param {Node | NodeLike | null | undefined} parent
   * @param {string | null | undefined} [origin]
   * @returns {VFileMessage}
   *
   * @overload
   * @param {Error | VFileMessage} cause
   * @param {Point | Position | null | undefined} place
   * @param {string | null | undefined} [origin]
   * @returns {VFileMessage}
   *
   * @overload
   * @param {Error | VFileMessage} cause
   * @param {string | null | undefined} [origin]
   * @returns {VFileMessage}
   *
   * @param {Error | VFileMessage | string} causeOrReason
   *   Reason for message, should use markdown.
   * @param {Node | NodeLike | MessageOptions | Point | Position | string | null | undefined} [optionsOrParentOrPlace]
   *   Configuration (optional).
   * @param {string | null | undefined} [origin]
   *   Place in code where the message originates (example:
   *   `'my-package:my-rule'` or `'my-rule'`).
   * @returns {VFileMessage}
   *   Message.
   */
  message(causeOrReason, optionsOrParentOrPlace, origin) {
    const message = new VFileMessage(
      // @ts-expect-error: the overloads are fine.
      causeOrReason,
      optionsOrParentOrPlace,
      origin
    );

    if (this.path) {
      message.name = this.path + ':' + message.name;
      message.file = this.path;
    }

    message.fatal = false;

    this.messages.push(message);

    return message
  }

  /**
   * Serialize the file.
   *
   * > **Note**: which encodings are supported depends on the engine.
   * > For info on Node.js, see:
   * > <https://nodejs.org/api/util.html#whatwg-supported-encodings>.
   *
   * @param {string | null | undefined} [encoding='utf8']
   *   Character encoding to understand `value` as when itâ€™s a `Uint8Array`
   *   (default: `'utf-8'`).
   * @returns {string}
   *   Serialized file.
   */
  toString(encoding) {
    if (this.value === undefined) {
      return ''
    }

    if (typeof this.value === 'string') {
      return this.value
    }

    const decoder = new TextDecoder(encoding || undefined);
    return decoder.decode(this.value)
  }
}

/**
 * Assert that `part` is not a path (as in, does not contain `path.sep`).
 *
 * @param {string | null | undefined} part
 *   File path part.
 * @param {string} name
 *   Part name.
 * @returns {undefined}
 *   Nothing.
 */
function assertPart(part, name) {
  if (part && part.includes(minpath.sep)) {
    throw new Error(
      '`' + name + '` cannot be a path: did not expect `' + minpath.sep + '`'
    )
  }
}

/**
 * Assert that `part` is not empty.
 *
 * @param {string | undefined} part
 *   Thing.
 * @param {string} name
 *   Part name.
 * @returns {asserts part is string}
 *   Nothing.
 */
function assertNonEmpty(part, name) {
  if (!part) {
    throw new Error('`' + name + '` cannot be empty')
  }
}

/**
 * Assert `path` exists.
 *
 * @param {string | undefined} path
 *   Path.
 * @param {string} name
 *   Dependency name.
 * @returns {asserts path is string}
 *   Nothing.
 */
function assertPath(path, name) {
  if (!path) {
    throw new Error('Setting `' + name + '` requires `path` to be set too')
  }
}

/**
 * Assert `value` is an `Uint8Array`.
 *
 * @param {unknown} value
 *   thing.
 * @returns {value is Uint8Array}
 *   Whether `value` is an `Uint8Array`.
 */
function isUint8Array$1(value) {
  return Boolean(
    value &&
      typeof value === 'object' &&
      'byteLength' in value &&
      'byteOffset' in value
  )
}

const CallableInstance =
  /**
   * @type {new <Parameters extends Array<unknown>, Result>(property: string | symbol) => (...parameters: Parameters) => Result}
   */
  (
    /** @type {unknown} */
    (
      /**
       * @this {Function}
       * @param {string | symbol} property
       * @returns {(...parameters: Array<unknown>) => unknown}
       */
      function (property) {
        const self = this;
        const constr = self.constructor;
        const proto = /** @type {Record<string | symbol, Function>} */ (
          // Prototypes do exist.
          // type-coverage:ignore-next-line
          constr.prototype
        );
        const value = proto[property];
        /** @type {(...parameters: Array<unknown>) => unknown} */
        const apply = function () {
          return value.apply(apply, arguments)
        };

        Object.setPrototypeOf(apply, proto);

        // Not needed for us in `unified`: we only call this on the `copy`
        // function,
        // and we don't need to add its fields (`length`, `name`)
        // over.
        // See also: GH-246.
        // const names = Object.getOwnPropertyNames(value)
        //
        // for (const p of names) {
        //   const descriptor = Object.getOwnPropertyDescriptor(value, p)
        //   if (descriptor) Object.defineProperty(apply, p, descriptor)
        // }

        return apply
      }
    )
  );

/**
 * @typedef {import('trough').Pipeline} Pipeline
 *
 * @typedef {import('unist').Node} Node
 *
 * @typedef {import('vfile').Compatible} Compatible
 * @typedef {import('vfile').Value} Value
 *
 * @typedef {import('../index.js').CompileResultMap} CompileResultMap
 * @typedef {import('../index.js').Data} Data
 * @typedef {import('../index.js').Settings} Settings
 */


// To do: next major: drop `Compiler`, `Parser`: prefer lowercase.

// To do: we could start yielding `never` in TS when a parser is missing and
// `parse` is called.
// Currently, we allow directly setting `processor.parser`, which is untyped.

const own = {}.hasOwnProperty;

/**
 * @template {Node | undefined} [ParseTree=undefined]
 *   Output of `parse` (optional).
 * @template {Node | undefined} [HeadTree=undefined]
 *   Input for `run` (optional).
 * @template {Node | undefined} [TailTree=undefined]
 *   Output for `run` (optional).
 * @template {Node | undefined} [CompileTree=undefined]
 *   Input of `stringify` (optional).
 * @template {CompileResults | undefined} [CompileResult=undefined]
 *   Output of `stringify` (optional).
 * @extends {CallableInstance<[], Processor<ParseTree, HeadTree, TailTree, CompileTree, CompileResult>>}
 */
class Processor extends CallableInstance {
  /**
   * Create a processor.
   */
  constructor() {
    // If `Processor()` is called (w/o new), `copy` is called instead.
    super('copy');

    /**
     * Compiler to use (deprecated).
     *
     * @deprecated
     *   Use `compiler` instead.
     * @type {(
     *   Compiler<
     *     CompileTree extends undefined ? Node : CompileTree,
     *     CompileResult extends undefined ? CompileResults : CompileResult
     *   > |
     *   undefined
     * )}
     */
    this.Compiler = undefined;

    /**
     * Parser to use (deprecated).
     *
     * @deprecated
     *   Use `parser` instead.
     * @type {(
     *   Parser<ParseTree extends undefined ? Node : ParseTree> |
     *   undefined
     * )}
     */
    this.Parser = undefined;

    // Note: the following fields are considered private.
    // However, they are needed for tests, and TSC generates an untyped
    // `private freezeIndex` field for, which trips `type-coverage` up.
    // Instead, we use `@deprecated` to visualize that they shouldnâ€™t be used.
    /**
     * Internal list of configured plugins.
     *
     * @deprecated
     *   This is a private internal property and should not be used.
     * @type {Array<PluginTuple<Array<unknown>>>}
     */
    this.attachers = [];

    /**
     * Compiler to use.
     *
     * @type {(
     *   Compiler<
     *     CompileTree extends undefined ? Node : CompileTree,
     *     CompileResult extends undefined ? CompileResults : CompileResult
     *   > |
     *   undefined
     * )}
     */
    this.compiler = undefined;

    /**
     * Internal state to track where we are while freezing.
     *
     * @deprecated
     *   This is a private internal property and should not be used.
     * @type {number}
     */
    this.freezeIndex = -1;

    /**
     * Internal state to track whether weâ€™re frozen.
     *
     * @deprecated
     *   This is a private internal property and should not be used.
     * @type {boolean | undefined}
     */
    this.frozen = undefined;

    /**
     * Internal state.
     *
     * @deprecated
     *   This is a private internal property and should not be used.
     * @type {Data}
     */
    this.namespace = {};

    /**
     * Parser to use.
     *
     * @type {(
     *   Parser<ParseTree extends undefined ? Node : ParseTree> |
     *   undefined
     * )}
     */
    this.parser = undefined;

    /**
     * Internal list of configured transformers.
     *
     * @deprecated
     *   This is a private internal property and should not be used.
     * @type {Pipeline}
     */
    this.transformers = trough();
  }

  /**
   * Copy a processor.
   *
   * @deprecated
   *   This is a private internal method and should not be used.
   * @returns {Processor<ParseTree, HeadTree, TailTree, CompileTree, CompileResult>}
   *   New *unfrozen* processor ({@linkcode Processor}) that is
   *   configured to work the same as its ancestor.
   *   When the descendant processor is configured in the future it does not
   *   affect the ancestral processor.
   */
  copy() {
    // Cast as the type parameters will be the same after attaching.
    const destination =
      /** @type {Processor<ParseTree, HeadTree, TailTree, CompileTree, CompileResult>} */ (
        new Processor()
      );
    let index = -1;

    while (++index < this.attachers.length) {
      const attacher = this.attachers[index];
      destination.use(...attacher);
    }

    destination.data(extend(true, {}, this.namespace));

    return destination
  }

  /**
   * Configure the processor with info available to all plugins.
   * Information is stored in an object.
   *
   * Typically, options can be given to a specific plugin, but sometimes it
   * makes sense to have information shared with several plugins.
   * For example, a list of HTML elements that are self-closing, which is
   * needed during all phases.
   *
   * > **Note**: setting information cannot occur on *frozen* processors.
   * > Call the processor first to create a new unfrozen processor.
   *
   * > **Note**: to register custom data in TypeScript, augment the
   * > {@linkcode Data} interface.
   *
   * @example
   *   This example show how to get and set info:
   *
   *   ```js
   *   import {unified} from 'unified'
   *
   *   const processor = unified().data('alpha', 'bravo')
   *
   *   processor.data('alpha') // => 'bravo'
   *
   *   processor.data() // => {alpha: 'bravo'}
   *
   *   processor.data({charlie: 'delta'})
   *
   *   processor.data() // => {charlie: 'delta'}
   *   ```
   *
   * @template {keyof Data} Key
   *
   * @overload
   * @returns {Data}
   *
   * @overload
   * @param {Data} dataset
   * @returns {Processor<ParseTree, HeadTree, TailTree, CompileTree, CompileResult>}
   *
   * @overload
   * @param {Key} key
   * @returns {Data[Key]}
   *
   * @overload
   * @param {Key} key
   * @param {Data[Key]} value
   * @returns {Processor<ParseTree, HeadTree, TailTree, CompileTree, CompileResult>}
   *
   * @param {Data | Key} [key]
   *   Key to get or set, or entire dataset to set, or nothing to get the
   *   entire dataset (optional).
   * @param {Data[Key]} [value]
   *   Value to set (optional).
   * @returns {unknown}
   *   The current processor when setting, the value at `key` when getting, or
   *   the entire dataset when getting without key.
   */
  data(key, value) {
    if (typeof key === 'string') {
      // Set `key`.
      if (arguments.length === 2) {
        assertUnfrozen('data', this.frozen);
        this.namespace[key] = value;
        return this
      }

      // Get `key`.
      return (own.call(this.namespace, key) && this.namespace[key]) || undefined
    }

    // Set space.
    if (key) {
      assertUnfrozen('data', this.frozen);
      this.namespace = key;
      return this
    }

    // Get space.
    return this.namespace
  }

  /**
   * Freeze a processor.
   *
   * Frozen processors are meant to be extended and not to be configured
   * directly.
   *
   * When a processor is frozen it cannot be unfrozen.
   * New processors working the same way can be created by calling the
   * processor.
   *
   * Itâ€™s possible to freeze processors explicitly by calling `.freeze()`.
   * Processors freeze automatically when `.parse()`, `.run()`, `.runSync()`,
   * `.stringify()`, `.process()`, or `.processSync()` are called.
   *
   * @returns {Processor<ParseTree, HeadTree, TailTree, CompileTree, CompileResult>}
   *   The current processor.
   */
  freeze() {
    if (this.frozen) {
      return this
    }

    // Cast so that we can type plugins easier.
    // Plugins are supposed to be usable on different processors, not just on
    // this exact processor.
    const self = /** @type {Processor} */ (/** @type {unknown} */ (this));

    while (++this.freezeIndex < this.attachers.length) {
      const [attacher, ...options] = this.attachers[this.freezeIndex];

      if (options[0] === false) {
        continue
      }

      if (options[0] === true) {
        options[0] = undefined;
      }

      const transformer = attacher.call(self, ...options);

      if (typeof transformer === 'function') {
        this.transformers.use(transformer);
      }
    }

    this.frozen = true;
    this.freezeIndex = Number.POSITIVE_INFINITY;

    return this
  }

  /**
   * Parse text to a syntax tree.
   *
   * > **Note**: `parse` freezes the processor if not already *frozen*.
   *
   * > **Note**: `parse` performs the parse phase, not the run phase or other
   * > phases.
   *
   * @param {Compatible | undefined} [file]
   *   file to parse (optional); typically `string` or `VFile`; any value
   *   accepted as `x` in `new VFile(x)`.
   * @returns {ParseTree extends undefined ? Node : ParseTree}
   *   Syntax tree representing `file`.
   */
  parse(file) {
    this.freeze();
    const realFile = vfile(file);
    const parser = this.parser || this.Parser;
    assertParser('parse', parser);
    return parser(String(realFile), realFile)
  }

  /**
   * Process the given file as configured on the processor.
   *
   * > **Note**: `process` freezes the processor if not already *frozen*.
   *
   * > **Note**: `process` performs the parse, run, and stringify phases.
   *
   * @overload
   * @param {Compatible | undefined} file
   * @param {ProcessCallback<VFileWithOutput<CompileResult>>} done
   * @returns {undefined}
   *
   * @overload
   * @param {Compatible | undefined} [file]
   * @returns {Promise<VFileWithOutput<CompileResult>>}
   *
   * @param {Compatible | undefined} [file]
   *   File (optional); typically `string` or `VFile`]; any value accepted as
   *   `x` in `new VFile(x)`.
   * @param {ProcessCallback<VFileWithOutput<CompileResult>> | undefined} [done]
   *   Callback (optional).
   * @returns {Promise<VFile> | undefined}
   *   Nothing if `done` is given.
   *   Otherwise a promise, rejected with a fatal error or resolved with the
   *   processed file.
   *
   *   The parsed, transformed, and compiled value is available at
   *   `file.value` (see note).
   *
   *   > **Note**: unified typically compiles by serializing: most
   *   > compilers return `string` (or `Uint8Array`).
   *   > Some compilers, such as the one configured with
   *   > [`rehype-react`][rehype-react], return other values (in this case, a
   *   > React tree).
   *   > If youâ€™re using a compiler that doesnâ€™t serialize, expect different
   *   > result values.
   *   >
   *   > To register custom results in TypeScript, add them to
   *   > {@linkcode CompileResultMap}.
   *
   *   [rehype-react]: https://github.com/rehypejs/rehype-react
   */
  process(file, done) {
    const self = this;

    this.freeze();
    assertParser('process', this.parser || this.Parser);
    assertCompiler('process', this.compiler || this.Compiler);

    return done ? executor(undefined, done) : new Promise(executor)

    // Note: `void`s needed for TS.
    /**
     * @param {((file: VFileWithOutput<CompileResult>) => undefined | void) | undefined} resolve
     * @param {(error: Error | undefined) => undefined | void} reject
     * @returns {undefined}
     */
    function executor(resolve, reject) {
      const realFile = vfile(file);
      // Assume `ParseTree` (the result of the parser) matches `HeadTree` (the
      // input of the first transform).
      const parseTree =
        /** @type {HeadTree extends undefined ? Node : HeadTree} */ (
          /** @type {unknown} */ (self.parse(realFile))
        );

      self.run(parseTree, realFile, function (error, tree, file) {
        if (error || !tree || !file) {
          return realDone(error)
        }

        // Assume `TailTree` (the output of the last transform) matches
        // `CompileTree` (the input of the compiler).
        const compileTree =
          /** @type {CompileTree extends undefined ? Node : CompileTree} */ (
            /** @type {unknown} */ (tree)
          );

        const compileResult = self.stringify(compileTree, file);

        if (looksLikeAValue(compileResult)) {
          file.value = compileResult;
        } else {
          file.result = compileResult;
        }

        realDone(error, /** @type {VFileWithOutput<CompileResult>} */ (file));
      });

      /**
       * @param {Error | undefined} error
       * @param {VFileWithOutput<CompileResult> | undefined} [file]
       * @returns {undefined}
       */
      function realDone(error, file) {
        if (error || !file) {
          reject(error);
        } else if (resolve) {
          resolve(file);
        } else {
          done(undefined, file);
        }
      }
    }
  }

  /**
   * Process the given file as configured on the processor.
   *
   * An error is thrown if asynchronous transforms are configured.
   *
   * > **Note**: `processSync` freezes the processor if not already *frozen*.
   *
   * > **Note**: `processSync` performs the parse, run, and stringify phases.
   *
   * @param {Compatible | undefined} [file]
   *   File (optional); typically `string` or `VFile`; any value accepted as
   *   `x` in `new VFile(x)`.
   * @returns {VFileWithOutput<CompileResult>}
   *   The processed file.
   *
   *   The parsed, transformed, and compiled value is available at
   *   `file.value` (see note).
   *
   *   > **Note**: unified typically compiles by serializing: most
   *   > compilers return `string` (or `Uint8Array`).
   *   > Some compilers, such as the one configured with
   *   > [`rehype-react`][rehype-react], return other values (in this case, a
   *   > React tree).
   *   > If youâ€™re using a compiler that doesnâ€™t serialize, expect different
   *   > result values.
   *   >
   *   > To register custom results in TypeScript, add them to
   *   > {@linkcode CompileResultMap}.
   *
   *   [rehype-react]: https://github.com/rehypejs/rehype-react
   */
  processSync(file) {
    /** @type {boolean} */
    let complete = false;
    /** @type {VFileWithOutput<CompileResult> | undefined} */
    let result;

    this.freeze();
    assertParser('processSync', this.parser || this.Parser);
    assertCompiler('processSync', this.compiler || this.Compiler);

    this.process(file, realDone);
    assertDone('processSync', 'process', complete);

    return result

    /**
     * @type {ProcessCallback<VFileWithOutput<CompileResult>>}
     */
    function realDone(error, file) {
      complete = true;
      bail(error);
      result = file;
    }
  }

  /**
   * Run *transformers* on a syntax tree.
   *
   * > **Note**: `run` freezes the processor if not already *frozen*.
   *
   * > **Note**: `run` performs the run phase, not other phases.
   *
   * @overload
   * @param {HeadTree extends undefined ? Node : HeadTree} tree
   * @param {RunCallback<TailTree extends undefined ? Node : TailTree>} done
   * @returns {undefined}
   *
   * @overload
   * @param {HeadTree extends undefined ? Node : HeadTree} tree
   * @param {Compatible | undefined} file
   * @param {RunCallback<TailTree extends undefined ? Node : TailTree>} done
   * @returns {undefined}
   *
   * @overload
   * @param {HeadTree extends undefined ? Node : HeadTree} tree
   * @param {Compatible | undefined} [file]
   * @returns {Promise<TailTree extends undefined ? Node : TailTree>}
   *
   * @param {HeadTree extends undefined ? Node : HeadTree} tree
   *   Tree to transform and inspect.
   * @param {(
   *   RunCallback<TailTree extends undefined ? Node : TailTree> |
   *   Compatible
   * )} [file]
   *   File associated with `node` (optional); any value accepted as `x` in
   *   `new VFile(x)`.
   * @param {RunCallback<TailTree extends undefined ? Node : TailTree>} [done]
   *   Callback (optional).
   * @returns {Promise<TailTree extends undefined ? Node : TailTree> | undefined}
   *   Nothing if `done` is given.
   *   Otherwise, a promise rejected with a fatal error or resolved with the
   *   transformed tree.
   */
  run(tree, file, done) {
    assertNode(tree);
    this.freeze();

    const transformers = this.transformers;

    if (!done && typeof file === 'function') {
      done = file;
      file = undefined;
    }

    return done ? executor(undefined, done) : new Promise(executor)

    // Note: `void`s needed for TS.
    /**
     * @param {(
     *   ((tree: TailTree extends undefined ? Node : TailTree) => undefined | void) |
     *   undefined
     * )} resolve
     * @param {(error: Error) => undefined | void} reject
     * @returns {undefined}
     */
    function executor(resolve, reject) {
      const realFile = vfile(file);
      transformers.run(tree, realFile, realDone);

      /**
       * @param {Error | undefined} error
       * @param {Node} outputTree
       * @param {VFile} file
       * @returns {undefined}
       */
      function realDone(error, outputTree, file) {
        const resultingTree =
          /** @type {TailTree extends undefined ? Node : TailTree} */ (
            outputTree || tree
          );

        if (error) {
          reject(error);
        } else if (resolve) {
          resolve(resultingTree);
        } else {
          done(undefined, resultingTree, file);
        }
      }
    }
  }

  /**
   * Run *transformers* on a syntax tree.
   *
   * An error is thrown if asynchronous transforms are configured.
   *
   * > **Note**: `runSync` freezes the processor if not already *frozen*.
   *
   * > **Note**: `runSync` performs the run phase, not other phases.
   *
   * @param {HeadTree extends undefined ? Node : HeadTree} tree
   *   Tree to transform and inspect.
   * @param {Compatible | undefined} [file]
   *   File associated with `node` (optional); any value accepted as `x` in
   *   `new VFile(x)`.
   * @returns {TailTree extends undefined ? Node : TailTree}
   *   Transformed tree.
   */
  runSync(tree, file) {
    /** @type {boolean} */
    let complete = false;
    /** @type {(TailTree extends undefined ? Node : TailTree) | undefined} */
    let result;

    this.run(tree, file, realDone);

    assertDone('runSync', 'run', complete);
    return result

    /**
     * @type {RunCallback<TailTree extends undefined ? Node : TailTree>}
     */
    function realDone(error, tree) {
      bail(error);
      result = tree;
      complete = true;
    }
  }

  /**
   * Compile a syntax tree.
   *
   * > **Note**: `stringify` freezes the processor if not already *frozen*.
   *
   * > **Note**: `stringify` performs the stringify phase, not the run phase
   * > or other phases.
   *
   * @param {CompileTree extends undefined ? Node : CompileTree} tree
   *   Tree to compile.
   * @param {Compatible | undefined} [file]
   *   File associated with `node` (optional); any value accepted as `x` in
   *   `new VFile(x)`.
   * @returns {CompileResult extends undefined ? Value : CompileResult}
   *   Textual representation of the tree (see note).
   *
   *   > **Note**: unified typically compiles by serializing: most compilers
   *   > return `string` (or `Uint8Array`).
   *   > Some compilers, such as the one configured with
   *   > [`rehype-react`][rehype-react], return other values (in this case, a
   *   > React tree).
   *   > If youâ€™re using a compiler that doesnâ€™t serialize, expect different
   *   > result values.
   *   >
   *   > To register custom results in TypeScript, add them to
   *   > {@linkcode CompileResultMap}.
   *
   *   [rehype-react]: https://github.com/rehypejs/rehype-react
   */
  stringify(tree, file) {
    this.freeze();
    const realFile = vfile(file);
    const compiler = this.compiler || this.Compiler;
    assertCompiler('stringify', compiler);
    assertNode(tree);

    return compiler(tree, realFile)
  }

  /**
   * Configure the processor to use a plugin, a list of usable values, or a
   * preset.
   *
   * If the processor is already using a plugin, the previous plugin
   * configuration is changed based on the options that are passed in.
   * In other words, the plugin is not added a second time.
   *
   * > **Note**: `use` cannot be called on *frozen* processors.
   * > Call the processor first to create a new unfrozen processor.
   *
   * @example
   *   There are many ways to pass plugins to `.use()`.
   *   This example gives an overview:
   *
   *   ```js
   *   import {unified} from 'unified'
   *
   *   unified()
   *     // Plugin with options:
   *     .use(pluginA, {x: true, y: true})
   *     // Passing the same plugin again merges configuration (to `{x: true, y: false, z: true}`):
   *     .use(pluginA, {y: false, z: true})
   *     // Plugins:
   *     .use([pluginB, pluginC])
   *     // Two plugins, the second with options:
   *     .use([pluginD, [pluginE, {}]])
   *     // Preset with plugins and settings:
   *     .use({plugins: [pluginF, [pluginG, {}]], settings: {position: false}})
   *     // Settings only:
   *     .use({settings: {position: false}})
   *   ```
   *
   * @template {Array<unknown>} [Parameters=[]]
   * @template {Node | string | undefined} [Input=undefined]
   * @template [Output=Input]
   *
   * @overload
   * @param {Preset | null | undefined} [preset]
   * @returns {Processor<ParseTree, HeadTree, TailTree, CompileTree, CompileResult>}
   *
   * @overload
   * @param {PluggableList} list
   * @returns {Processor<ParseTree, HeadTree, TailTree, CompileTree, CompileResult>}
   *
   * @overload
   * @param {Plugin<Parameters, Input, Output>} plugin
   * @param {...(Parameters | [boolean])} parameters
   * @returns {UsePlugin<ParseTree, HeadTree, TailTree, CompileTree, CompileResult, Input, Output>}
   *
   * @param {PluggableList | Plugin | Preset | null | undefined} value
   *   Usable value.
   * @param {...unknown} parameters
   *   Parameters, when a plugin is given as a usable value.
   * @returns {Processor<ParseTree, HeadTree, TailTree, CompileTree, CompileResult>}
   *   Current processor.
   */
  use(value, ...parameters) {
    const attachers = this.attachers;
    const namespace = this.namespace;

    assertUnfrozen('use', this.frozen);

    if (value === null || value === undefined) ; else if (typeof value === 'function') {
      addPlugin(value, parameters);
    } else if (typeof value === 'object') {
      if (Array.isArray(value)) {
        addList(value);
      } else {
        addPreset(value);
      }
    } else {
      throw new TypeError('Expected usable value, not `' + value + '`')
    }

    return this

    /**
     * @param {Pluggable} value
     * @returns {undefined}
     */
    function add(value) {
      if (typeof value === 'function') {
        addPlugin(value, []);
      } else if (typeof value === 'object') {
        if (Array.isArray(value)) {
          const [plugin, ...parameters] =
            /** @type {PluginTuple<Array<unknown>>} */ (value);
          addPlugin(plugin, parameters);
        } else {
          addPreset(value);
        }
      } else {
        throw new TypeError('Expected usable value, not `' + value + '`')
      }
    }

    /**
     * @param {Preset} result
     * @returns {undefined}
     */
    function addPreset(result) {
      if (!('plugins' in result) && !('settings' in result)) {
        throw new Error(
          'Expected usable value but received an empty preset, which is probably a mistake: presets typically come with `plugins` and sometimes with `settings`, but this has neither'
        )
      }

      addList(result.plugins);

      if (result.settings) {
        namespace.settings = extend(true, namespace.settings, result.settings);
      }
    }

    /**
     * @param {PluggableList | null | undefined} plugins
     * @returns {undefined}
     */
    function addList(plugins) {
      let index = -1;

      if (plugins === null || plugins === undefined) ; else if (Array.isArray(plugins)) {
        while (++index < plugins.length) {
          const thing = plugins[index];
          add(thing);
        }
      } else {
        throw new TypeError('Expected a list of plugins, not `' + plugins + '`')
      }
    }

    /**
     * @param {Plugin} plugin
     * @param {Array<unknown>} parameters
     * @returns {undefined}
     */
    function addPlugin(plugin, parameters) {
      let index = -1;
      let entryIndex = -1;

      while (++index < attachers.length) {
        if (attachers[index][0] === plugin) {
          entryIndex = index;
          break
        }
      }

      if (entryIndex === -1) {
        attachers.push([plugin, ...parameters]);
      }
      // Only set if there was at least a `primary` value, otherwise weâ€™d change
      // `arguments.length`.
      else if (parameters.length > 0) {
        let [primary, ...rest] = parameters;
        const currentPrimary = attachers[entryIndex][1];
        if (isPlainObject$2(currentPrimary) && isPlainObject$2(primary)) {
          primary = extend(true, currentPrimary, primary);
        }

        attachers[entryIndex] = [plugin, primary, ...rest];
      }
    }
  }
}

// Note: this returns a *callable* instance.
// Thatâ€™s why itâ€™s documented as a function.
/**
 * Create a new processor.
 *
 * @example
 *   This example shows how a new processor can be created (from `remark`) and linked
 *   to **stdin**(4) and **stdout**(4).
 *
 *   ```js
 *   import process from 'node:process'
 *   import concatStream from 'concat-stream'
 *   import {remark} from 'remark'
 *
 *   process.stdin.pipe(
 *     concatStream(function (buf) {
 *       process.stdout.write(String(remark().processSync(buf)))
 *     })
 *   )
 *   ```
 *
 * @returns
 *   New *unfrozen* processor (`processor`).
 *
 *   This processor is configured to work the same as its ancestor.
 *   When the descendant processor is configured in the future it does not
 *   affect the ancestral processor.
 */
const unified = new Processor().freeze();

/**
 * Assert a parser is available.
 *
 * @param {string} name
 * @param {unknown} value
 * @returns {asserts value is Parser}
 */
function assertParser(name, value) {
  if (typeof value !== 'function') {
    throw new TypeError('Cannot `' + name + '` without `parser`')
  }
}

/**
 * Assert a compiler is available.
 *
 * @param {string} name
 * @param {unknown} value
 * @returns {asserts value is Compiler}
 */
function assertCompiler(name, value) {
  if (typeof value !== 'function') {
    throw new TypeError('Cannot `' + name + '` without `compiler`')
  }
}

/**
 * Assert the processor is not frozen.
 *
 * @param {string} name
 * @param {unknown} frozen
 * @returns {asserts frozen is false}
 */
function assertUnfrozen(name, frozen) {
  if (frozen) {
    throw new Error(
      'Cannot call `' +
        name +
        '` on a frozen processor.\nCreate a new processor first, by calling it: use `processor()` instead of `processor`.'
    )
  }
}

/**
 * Assert `node` is a unist node.
 *
 * @param {unknown} node
 * @returns {asserts node is Node}
 */
function assertNode(node) {
  // `isPlainObj` unfortunately uses `any` instead of `unknown`.
  // type-coverage:ignore-next-line
  if (!isPlainObject$2(node) || typeof node.type !== 'string') {
    throw new TypeError('Expected node, got `' + node + '`')
    // Fine.
  }
}

/**
 * Assert that `complete` is `true`.
 *
 * @param {string} name
 * @param {string} asyncName
 * @param {unknown} complete
 * @returns {asserts complete is true}
 */
function assertDone(name, asyncName, complete) {
  if (!complete) {
    throw new Error(
      '`' + name + '` finished async. Use `' + asyncName + '` instead'
    )
  }
}

/**
 * @param {Compatible | undefined} [value]
 * @returns {VFile}
 */
function vfile(value) {
  return looksLikeAVFile(value) ? value : new VFile(value)
}

/**
 * @param {Compatible | undefined} [value]
 * @returns {value is VFile}
 */
function looksLikeAVFile(value) {
  return Boolean(
    value &&
      typeof value === 'object' &&
      'message' in value &&
      'messages' in value
  )
}

/**
 * @param {unknown} [value]
 * @returns {value is Value}
 */
function looksLikeAValue(value) {
  return typeof value === 'string' || isUint8Array(value)
}

/**
 * Assert `value` is an `Uint8Array`.
 *
 * @param {unknown} value
 *   thing.
 * @returns {value is Uint8Array}
 *   Whether `value` is an `Uint8Array`.
 */
function isUint8Array(value) {
  return Boolean(
    value &&
      typeof value === 'object' &&
      'byteLength' in value &&
      'byteOffset' in value
  )
}

// Autolink is like <https://foo.com> see
// https://daringfireball.net/projects/markdown/syntax#autolink
const isAutoLink = (node) => node.type === "link" &&
    node.url === node.children[0]?.value;
const isRegularTextNode = (node) => !!node && !isAutoLink(node);
const isWikiLink = (node) => node.type === "wikiLink";
const isTextNodeWithoutWikiLinks = (node) => !!node && !isWikiLink(node) && !isAutoLink(node);
const extractTextFromNode = (node, filter) => {
    return toString(node.children.filter(filter));
};
const extractTextFromFirstParagraph = (section, filter) => {
    const firstParagraph = section.children.find((node) => node.type === "paragraph");
    if (firstParagraph) {
        return extractTextFromNode(firstParagraph, filter);
    }
    return undefined;
};
const extractSectionTitle = (section) => {
    const firstHeading = section.children.find((node) => node.type === "heading");
    if (!firstHeading) {
        return (extractTextFromFirstParagraph(section, isRegularTextNode) ?? "no title");
    }
    return extractTextFromNode(firstHeading, isRegularTextNode);
};
// Markdown processing constants
const MAX_HEADING_DEPTH = 6;
const ROOT_SECTION_DEPTH = 1;
const ROOT_SECTION_INDEX = 0;
const INITIAL_SECTION_COUNT = 1;
const H1_HEADING_DEPTH = 1;
/**
 * Initialize the parsing state with a root section
 */
const initializeSectionParsingState = () => {
    const rootSection = {
        children: [],
        sections: [],
        depth: ROOT_SECTION_DEPTH,
        title: "title-not-set",
    };
    const nestedSectionStack = new Array(MAX_HEADING_DEPTH);
    nestedSectionStack[ROOT_SECTION_INDEX] = rootSection;
    return {
        sections: [rootSection],
        sectionCount: INITIAL_SECTION_COUNT,
        currentHeadingDepth: ROOT_SECTION_DEPTH,
        foundMainHeading: false,
        nestedSectionStack,
    };
};
/**
 * Check if a node is a heading and update parsing state accordingly
 */
const processHeadingNode = (node, state) => {
    if (!("depth" in node)) {
        return false; // Not skipping, process normally
    }
    const headingDepth = node.depth;
    if (headingDepth > H1_HEADING_DEPTH) {
        if (state.foundMainHeading) {
            state.sectionCount++;
            state.currentHeadingDepth = headingDepth;
            return false; // Don't skip
        }
        else {
            return true; // Skip this node - we haven't found main heading yet
        }
    }
    else {
        // This is an h1 heading
        state.currentHeadingDepth = H1_HEADING_DEPTH;
        state.foundMainHeading = true;
        return false; // Don't skip
    }
};
/**
 * Create new sections as needed to match the current section count
 */
const ensureSectionsExist = (state) => {
    while (state.sections.length < state.sectionCount) {
        const newSection = {
            children: [],
            sections: [],
            depth: state.currentHeadingDepth,
            title: "section-title-not-set",
        };
        state.sections.push(newSection);
        state.nestedSectionStack[state.currentHeadingDepth - 1] = newSection;
        // Link to parent section if this is a nested section
        if (state.currentHeadingDepth > H1_HEADING_DEPTH) {
            const parentSection = state.nestedSectionStack[state.currentHeadingDepth - 2];
            if (parentSection) {
                parentSection.sections.push(newSection);
            }
        }
    }
};
/**
 * Get the target section for adding the current node
 */
const getTargetSection = (state) => {
    return state.currentHeadingDepth === H1_HEADING_DEPTH
        ? state.sections[ROOT_SECTION_INDEX]
        : state.sections[state.sectionCount - 1];
};
/**
 * Extract sections from markdown syntax tree
 */
const toSections = (markdownSyntaxTree) => {
    const state = initializeSectionParsingState();
    markdownSyntaxTree.children.forEach((node) => {
        const shouldSkipNode = processHeadingNode(node, state);
        ensureSectionsExist(state);
        if (!shouldSkipNode) {
            const targetSection = getTargetSection(state);
            targetSection.children.push(node);
        }
    });
    // Set titles for all sections
    state.sections.forEach((section) => {
        section.title = extractSectionTitle(section);
    });
    return state.sections;
};
const getAllNodesFromSection = (section) => {
    // Optimized section node collection
    const collectedNodes = [];
    const nodeQueue = [...section.children];
    while (nodeQueue.length > 0) {
        const currentNode = nodeQueue.shift();
        collectedNodes.push(currentNode);
        if ("children" in currentNode && currentNode.children) {
            nodeQueue.push(...currentNode.children);
        }
    }
    return collectedNodes;
};
const extractFileNameFromUrl = (url) => {
    // Remove trailing slashes and .md extensions, then get the last path component
    let cleanUrl = url;
    while (cleanUrl.endsWith("/")) {
        cleanUrl = cleanUrl.slice(0, -1);
    }
    if (cleanUrl.endsWith(".md")) {
        cleanUrl = cleanUrl.slice(0, -3);
    }
    const lastSlashIndex = cleanUrl.lastIndexOf("/");
    return lastSlashIndex === -1
        ? cleanUrl
        : cleanUrl.substring(lastSlashIndex + 1);
};
const toMarkdownSection = (document, section) => {
    // Single-pass link extraction for better performance
    const extractedLinks = [];
    const nodes = getAllNodesFromSection(section);
    for (const node of nodes) {
        if (node.type === "wikiLink") {
            extractedLinks.push(linkResolver(node.value));
        }
        else if (node.type === "link" && node.url.startsWith("./")) {
            extractedLinks.push(extractFileNameFromUrl(node.url));
        }
    }
    return {
        title: section.title,
        hash: document.hash,
        links: extractedLinks,
        depth: section.depth,
        brief: extractTextFromFirstParagraph(section, isTextNodeWithoutWikiLinks),
    };
};
// Shared parser instance to avoid repeated instantiation overhead
const sharedParser = unified()
    .use(p, {
    hrefTemplate: (permalink) => `${permalink}`,
})
    .use(remarkParse);
const parseMarkdownDocument = (document) => {
    const markdownSyntaxTree = sharedParser.parse(document.content);
    return toSections(markdownSyntaxTree).map((section) => toMarkdownSection(document, section));
};

/**
 * Builder class for constructing graph structures from markdown documents
 *
 * The GraphBuilder follows the builder pattern, allowing incremental construction
 * of a graph by adding markdown documents one at a time. It handles the conversion
 * of markdown content into nodes and links in the graph structure.
 *
 * @example
 * ```typescript
 * const builder = new GraphBuilder();
 * builder.addDocument(document1)
 *        .addDocument(document2)
 *        .addDocument(document3);
 * const graph = builder.build();
 * ```
 */
class GraphBuilder {
    constructor(options) {
        this.graph = {
            nodes: {},
            links: [],
        };
        this.implicitLinks = [];
        this.justNodeNames = options?.justNodeNames ?? false;
        this.noSections = options?.noSections ?? false;
    }
    /**
     * Add a document reference to the graph without parsing content
     *
     * This is an optimized method for when we only need node names without
     * metadata or links. Creates empty nodes based on document ID only.
     *
     * @param reference - The document reference to add
     * @returns this - For method chaining
     */
    addDocumentReference(reference) {
        // Only add if we're in the optimized mode (both options enabled)
        if (this.noSections && this.justNodeNames) {
            // Create a single empty node for the document
            this.graph.nodes[reference.id] = {};
        }
        return this;
    }
    /**
     * Add a markdown document to the graph
     *
     * Parses the document content to extract sections and creates corresponding
     * nodes and links in the graph. Each section becomes a node, and wiki-style
     * links ([[target]]) become edges in the graph.
     *
     * @param document - The markdown document to add
     * @returns this - For method chaining
     */
    addDocument(document) {
        try {
            const allSections = parseMarkdownDocument(document);
            // Filter sections if noSections is enabled (only keep depth 1 sections)
            const sections = this.noSections
                ? allSections.filter((section) => section.depth === 1)
                : allSections;
            this.addNodes(document, sections);
            this.addLinks(document, sections);
        }
        catch (error) {
            // eslint-disable-next-line no-console
            console.error(`Ignoring ${document.filename} since error during parsing`, error);
        }
        return this;
    }
    /**
     * Add nodes for each section in the document
     */
    addNodes(document, sections) {
        if (this.justNodeNames) {
            // In justNodeNames mode, only create empty nodes with just the key
            sections.forEach((section) => {
                const { id } = createNode(document, section);
                this.graph.nodes[id] = {};
            });
        }
        else {
            // Normal mode: create nodes with full metadata
            sections.forEach((section) => {
                const { id, node } = createNode(document, section);
                this.graph.nodes[id] = node;
            });
        }
    }
    /**
     * Add links between sections
     */
    addLinks(document, sections) {
        if (this.justNodeNames) {
            // In justNodeNames mode, skip creating any links
            return;
        }
        sections.forEach((section) => {
            // Add explicit links
            const explicitLinks = createExplicitLinks(document, section);
            this.graph.links.push(...explicitLinks);
            // Add parent-child link for subsections
            const parentLink = createParentLink(document, section);
            if (parentLink) {
                this.graph.links.push(parentLink);
            }
            // Add implicit links from natural language processing
            if (section.brief) {
                const naturalLinks = naturalProcess(section.brief).links;
                for (const target of naturalLinks) {
                    if (target != document.id) {
                        this.implicitLinks.push({
                            source: document.id,
                            target: target,
                        });
                    }
                }
            }
        });
    }
    /**
     * Build and return the current graph state
     *
     * Returns a deep copy of the current graph to prevent external mutations.
     * The returned graph contains all nodes and links added through addDocument().
     *
     * @returns A copy of the current graph structure
     */
    build() {
        if (!this.justNodeNames) {
            // Only process implicit links in normal mode
            for (const implicitLink of this.implicitLinks) {
                if (implicitLink.target in this.graph.nodes) {
                    this.graph.links.push(implicitLink);
                }
            }
        }
        return {
            nodes: { ...this.graph.nodes },
            links: [...this.graph.links],
        };
    }
    /**
     * Reset the builder to start fresh
     *
     * Clears all nodes and links from the current graph, allowing the builder
     * to be reused for constructing a new graph from scratch.
     *
     * @returns this - For method chaining
     */
    reset() {
        this.graph = {
            nodes: {},
            links: [],
        };
        this.implicitLinks = [];
        return this;
    }
    /**
     * Get statistics about the current graph
     *
     * Returns count information about the current state of the graph,
     * useful for monitoring progress during graph construction.
     *
     * @returns Object containing node and link counts
     */
    getStats() {
        return getGraphStats(this.graph);
    }
}

/**
 * Manages incremental updates to a graph structure based on file changes
 *
 * This class maintains a mapping between files and the graph nodes they generate,
 * allowing for efficient updates when individual files change rather than
 * regenerating the entire graph.
 */
class GraphManager {
    constructor(repository, baseDirectory) {
        this.graph = { nodes: {}, links: [] };
        this.documentMappings = new Map();
        this.repository = repository;
        this.baseDirectory = baseDirectory;
    }
    /**
     * Initialize the graph by processing all documents in the repository
     */
    async initialize() {
        const builder = new GraphBuilder();
        this.documentMappings.clear();
        for await (const reference of this.repository.findAll()) {
            try {
                const document = await this.repository.loadDocument(reference);
                builder.addDocument(document);
                this.trackDocumentNodes(document, reference.id);
            }
            catch (error) {
                // eslint-disable-next-line no-console
                console.warn(`Failed to load document ${reference.id}:`, error);
            }
        }
        this.graph = builder.build();
        return this.getGraph();
    }
    /**
     * Update the graph for a specific file that has changed
     */
    async updateFile(filePath) {
        try {
            // Normalize the file path to get the document ID
            const relativePath = this.getRelativePathFromAbsolute(filePath);
            const documentRef = this.repository.toDocumentReference(relativePath);
            // Remove existing nodes for this document
            this.removeDocumentNodes(documentRef.id);
            // Load and add the updated document
            const document = await this.repository.loadDocument(documentRef);
            this.addDocumentToGraph(document);
            this.trackDocumentNodes(document, documentRef.id, filePath);
            return this.getGraph();
        }
        catch (error) {
            // eslint-disable-next-line no-console
            console.warn(`Failed to update file ${filePath}:`, error);
            return this.getGraph();
        }
    }
    /**
     * Remove a file from the graph
     */
    removeFile(filePath) {
        const relativePath = this.getRelativePathFromAbsolute(filePath);
        const documentRef = this.repository.toDocumentReference(relativePath);
        this.removeDocumentNodes(documentRef.id);
        return this.getGraph();
    }
    /**
     * Get the current graph state
     */
    getGraph() {
        return {
            nodes: { ...this.graph.nodes },
            links: [...this.graph.links],
        };
    }
    /**
     * Track which nodes belong to a document
     */
    trackDocumentNodes(document, documentId, filePath) {
        const sections = parseMarkdownDocument(document);
        const nodeIds = sections.map((section) => createNodeId(document, section));
        this.documentMappings.set(documentId, {
            documentId,
            nodeIds,
            filePath: filePath || documentId,
        });
    }
    /**
     * Add a document to the existing graph using GraphBuilder
     */
    addDocumentToGraph(document) {
        // Create a temporary builder to get the document's graph representation
        const tempBuilder = new GraphBuilder();
        tempBuilder.addDocument(document);
        const documentGraph = tempBuilder.build();
        // Merge the document's nodes and links into the main graph
        Object.assign(this.graph.nodes, documentGraph.nodes);
        this.graph.links.push(...documentGraph.links);
    }
    /**
     * Remove all nodes and links for a specific document
     */
    removeDocumentNodes(documentId) {
        const mapping = this.documentMappings.get(documentId);
        if (!mapping)
            return;
        // Remove nodes
        mapping.nodeIds.forEach((nodeId) => {
            delete this.graph.nodes[nodeId];
        });
        // Remove links where any of this document's nodes are source or target
        this.graph.links = this.graph.links.filter((link) => {
            const sourceIsFromDocument = mapping.nodeIds.includes(link.source);
            const targetIsFromDocument = mapping.nodeIds.includes(link.target);
            return !sourceIsFromDocument && !targetIsFromDocument;
        });
        // Remove the mapping
        this.documentMappings.delete(documentId);
    }
    /**
     * Convert absolute file path to relative path for document reference
     */
    getRelativePathFromAbsolute(filePath) {
        return sysPath__default.relative(this.baseDirectory, filePath);
    }
    /**
     * Get statistics about the current graph
     */
    getStats() {
        return getGraphStats(this.graph);
    }
}

const LogLevels = {
  fatal: 0,
  error: 0,
  warn: 1,
  log: 2,
  info: 3,
  success: 3,
  fail: 3,
  debug: 4,
  trace: 5,
  verbose: Number.POSITIVE_INFINITY
};
const LogTypes = {
  // Silent
  silent: {
    level: -1
  },
  // Level 0
  fatal: {
    level: LogLevels.fatal
  },
  error: {
    level: LogLevels.error
  },
  // Level 1
  warn: {
    level: LogLevels.warn
  },
  // Level 2
  log: {
    level: LogLevels.log
  },
  // Level 3
  info: {
    level: LogLevels.info
  },
  success: {
    level: LogLevels.success
  },
  fail: {
    level: LogLevels.fail
  },
  ready: {
    level: LogLevels.info
  },
  start: {
    level: LogLevels.info
  },
  box: {
    level: LogLevels.info
  },
  // Level 4
  debug: {
    level: LogLevels.debug
  },
  // Level 5
  trace: {
    level: LogLevels.trace
  },
  // Verbose
  verbose: {
    level: LogLevels.verbose
  }
};

function isPlainObject$1(value) {
  if (value === null || typeof value !== "object") {
    return false;
  }
  const prototype = Object.getPrototypeOf(value);
  if (prototype !== null && prototype !== Object.prototype && Object.getPrototypeOf(prototype) !== null) {
    return false;
  }
  if (Symbol.iterator in value) {
    return false;
  }
  if (Symbol.toStringTag in value) {
    return Object.prototype.toString.call(value) === "[object Module]";
  }
  return true;
}

function _defu(baseObject, defaults, namespace = ".", merger) {
  if (!isPlainObject$1(defaults)) {
    return _defu(baseObject, {}, namespace);
  }
  const object = Object.assign({}, defaults);
  for (const key in baseObject) {
    if (key === "__proto__" || key === "constructor") {
      continue;
    }
    const value = baseObject[key];
    if (value === null || value === void 0) {
      continue;
    }
    if (Array.isArray(value) && Array.isArray(object[key])) {
      object[key] = [...value, ...object[key]];
    } else if (isPlainObject$1(value) && isPlainObject$1(object[key])) {
      object[key] = _defu(
        value,
        object[key],
        (namespace ? `${namespace}.` : "") + key.toString());
    } else {
      object[key] = value;
    }
  }
  return object;
}
function createDefu(merger) {
  return (...arguments_) => (
    // eslint-disable-next-line unicorn/no-array-reduce
    arguments_.reduce((p, c) => _defu(p, c, ""), {})
  );
}
const defu = createDefu();

function isPlainObject(obj) {
  return Object.prototype.toString.call(obj) === "[object Object]";
}
function isLogObj(arg) {
  if (!isPlainObject(arg)) {
    return false;
  }
  if (!arg.message && !arg.args) {
    return false;
  }
  if (arg.stack) {
    return false;
  }
  return true;
}

let paused = false;
const queue = [];
class Consola {
  options;
  _lastLog;
  _mockFn;
  /**
   * Creates an instance of Consola with specified options or defaults.
   *
   * @param {Partial<ConsolaOptions>} [options={}] - Configuration options for the Consola instance.
   */
  constructor(options = {}) {
    const types = options.types || LogTypes;
    this.options = defu(
      {
        ...options,
        defaults: { ...options.defaults },
        level: _normalizeLogLevel(options.level, types),
        reporters: [...options.reporters || []]
      },
      {
        types: LogTypes,
        throttle: 1e3,
        throttleMin: 5,
        formatOptions: {
          date: true,
          colors: false,
          compact: true
        }
      }
    );
    for (const type in types) {
      const defaults = {
        type,
        ...this.options.defaults,
        ...types[type]
      };
      this[type] = this._wrapLogFn(defaults);
      this[type].raw = this._wrapLogFn(
        defaults,
        true
      );
    }
    if (this.options.mockFn) {
      this.mockTypes();
    }
    this._lastLog = {};
  }
  /**
   * Gets the current log level of the Consola instance.
   *
   * @returns {number} The current log level.
   */
  get level() {
    return this.options.level;
  }
  /**
   * Sets the minimum log level that will be output by the instance.
   *
   * @param {number} level - The new log level to set.
   */
  set level(level) {
    this.options.level = _normalizeLogLevel(
      level,
      this.options.types,
      this.options.level
    );
  }
  /**
   * Displays a prompt to the user and returns the response.
   * Throw an error if `prompt` is not supported by the current configuration.
   *
   * @template T
   * @param {string} message - The message to display in the prompt.
   * @param {T} [opts] - Optional options for the prompt. See {@link PromptOptions}.
   * @returns {promise<T>} A promise that infer with the prompt options. See {@link PromptOptions}.
   */
  prompt(message, opts) {
    if (!this.options.prompt) {
      throw new Error("prompt is not supported!");
    }
    return this.options.prompt(message, opts);
  }
  /**
   * Creates a new instance of Consola, inheriting options from the current instance, with possible overrides.
   *
   * @param {Partial<ConsolaOptions>} options - Optional overrides for the new instance. See {@link ConsolaOptions}.
   * @returns {ConsolaInstance} A new Consola instance. See {@link ConsolaInstance}.
   */
  create(options) {
    const instance = new Consola({
      ...this.options,
      ...options
    });
    if (this._mockFn) {
      instance.mockTypes(this._mockFn);
    }
    return instance;
  }
  /**
   * Creates a new Consola instance with the specified default log object properties.
   *
   * @param {InputLogObject} defaults - Default properties to include in any log from the new instance. See {@link InputLogObject}.
   * @returns {ConsolaInstance} A new Consola instance. See {@link ConsolaInstance}.
   */
  withDefaults(defaults) {
    return this.create({
      ...this.options,
      defaults: {
        ...this.options.defaults,
        ...defaults
      }
    });
  }
  /**
   * Creates a new Consola instance with a specified tag, which will be included in every log.
   *
   * @param {string} tag - The tag to include in each log of the new instance.
   * @returns {ConsolaInstance} A new Consola instance. See {@link ConsolaInstance}.
   */
  withTag(tag) {
    return this.withDefaults({
      tag: this.options.defaults.tag ? this.options.defaults.tag + ":" + tag : tag
    });
  }
  /**
   * Adds a custom reporter to the Consola instance.
   * Reporters will be called for each log message, depending on their implementation and log level.
   *
   * @param {ConsolaReporter} reporter - The reporter to add. See {@link ConsolaReporter}.
   * @returns {Consola} The current Consola instance.
   */
  addReporter(reporter) {
    this.options.reporters.push(reporter);
    return this;
  }
  /**
   * Removes a custom reporter from the Consola instance.
   * If no reporter is specified, all reporters will be removed.
   *
   * @param {ConsolaReporter} reporter - The reporter to remove. See {@link ConsolaReporter}.
   * @returns {Consola} The current Consola instance.
   */
  removeReporter(reporter) {
    if (reporter) {
      const i = this.options.reporters.indexOf(reporter);
      if (i !== -1) {
        return this.options.reporters.splice(i, 1);
      }
    } else {
      this.options.reporters.splice(0);
    }
    return this;
  }
  /**
   * Replaces all reporters of the Consola instance with the specified array of reporters.
   *
   * @param {ConsolaReporter[]} reporters - The new reporters to set. See {@link ConsolaReporter}.
   * @returns {Consola} The current Consola instance.
   */
  setReporters(reporters) {
    this.options.reporters = Array.isArray(reporters) ? reporters : [reporters];
    return this;
  }
  wrapAll() {
    this.wrapConsole();
    this.wrapStd();
  }
  restoreAll() {
    this.restoreConsole();
    this.restoreStd();
  }
  /**
   * Overrides console methods with Consola logging methods for consistent logging.
   */
  wrapConsole() {
    for (const type in this.options.types) {
      if (!console["__" + type]) {
        console["__" + type] = console[type];
      }
      console[type] = this[type].raw;
    }
  }
  /**
   * Restores the original console methods, removing Consola overrides.
   */
  restoreConsole() {
    for (const type in this.options.types) {
      if (console["__" + type]) {
        console[type] = console["__" + type];
        delete console["__" + type];
      }
    }
  }
  /**
   * Overrides standard output and error streams to redirect them through Consola.
   */
  wrapStd() {
    this._wrapStream(this.options.stdout, "log");
    this._wrapStream(this.options.stderr, "log");
  }
  _wrapStream(stream, type) {
    if (!stream) {
      return;
    }
    if (!stream.__write) {
      stream.__write = stream.write;
    }
    stream.write = (data) => {
      this[type].raw(String(data).trim());
    };
  }
  /**
   * Restores the original standard output and error streams, removing the Consola redirection.
   */
  restoreStd() {
    this._restoreStream(this.options.stdout);
    this._restoreStream(this.options.stderr);
  }
  _restoreStream(stream) {
    if (!stream) {
      return;
    }
    if (stream.__write) {
      stream.write = stream.__write;
      delete stream.__write;
    }
  }
  /**
   * Pauses logging, queues incoming logs until resumed.
   */
  pauseLogs() {
    paused = true;
  }
  /**
   * Resumes logging, processing any queued logs.
   */
  resumeLogs() {
    paused = false;
    const _queue = queue.splice(0);
    for (const item of _queue) {
      item[0]._logFn(item[1], item[2]);
    }
  }
  /**
   * Replaces logging methods with mocks if a mock function is provided.
   *
   * @param {ConsolaOptions["mockFn"]} mockFn - The function to use for mocking logging methods. See {@link ConsolaOptions["mockFn"]}.
   */
  mockTypes(mockFn) {
    const _mockFn = mockFn || this.options.mockFn;
    this._mockFn = _mockFn;
    if (typeof _mockFn !== "function") {
      return;
    }
    for (const type in this.options.types) {
      this[type] = _mockFn(type, this.options.types[type]) || this[type];
      this[type].raw = this[type];
    }
  }
  _wrapLogFn(defaults, isRaw) {
    return (...args) => {
      if (paused) {
        queue.push([this, defaults, args, isRaw]);
        return;
      }
      return this._logFn(defaults, args, isRaw);
    };
  }
  _logFn(defaults, args, isRaw) {
    if ((defaults.level || 0) > this.level) {
      return false;
    }
    const logObj = {
      date: /* @__PURE__ */ new Date(),
      args: [],
      ...defaults,
      level: _normalizeLogLevel(defaults.level, this.options.types)
    };
    if (!isRaw && args.length === 1 && isLogObj(args[0])) {
      Object.assign(logObj, args[0]);
    } else {
      logObj.args = [...args];
    }
    if (logObj.message) {
      logObj.args.unshift(logObj.message);
      delete logObj.message;
    }
    if (logObj.additional) {
      if (!Array.isArray(logObj.additional)) {
        logObj.additional = logObj.additional.split("\n");
      }
      logObj.args.push("\n" + logObj.additional.join("\n"));
      delete logObj.additional;
    }
    logObj.type = typeof logObj.type === "string" ? logObj.type.toLowerCase() : "log";
    logObj.tag = typeof logObj.tag === "string" ? logObj.tag : "";
    const resolveLog = (newLog = false) => {
      const repeated = (this._lastLog.count || 0) - this.options.throttleMin;
      if (this._lastLog.object && repeated > 0) {
        const args2 = [...this._lastLog.object.args];
        if (repeated > 1) {
          args2.push(`(repeated ${repeated} times)`);
        }
        this._log({ ...this._lastLog.object, args: args2 });
        this._lastLog.count = 1;
      }
      if (newLog) {
        this._lastLog.object = logObj;
        this._log(logObj);
      }
    };
    clearTimeout(this._lastLog.timeout);
    const diffTime = this._lastLog.time && logObj.date ? logObj.date.getTime() - this._lastLog.time.getTime() : 0;
    this._lastLog.time = logObj.date;
    if (diffTime < this.options.throttle) {
      try {
        const serializedLog = JSON.stringify([
          logObj.type,
          logObj.tag,
          logObj.args
        ]);
        const isSameLog = this._lastLog.serialized === serializedLog;
        this._lastLog.serialized = serializedLog;
        if (isSameLog) {
          this._lastLog.count = (this._lastLog.count || 0) + 1;
          if (this._lastLog.count > this.options.throttleMin) {
            this._lastLog.timeout = setTimeout(
              resolveLog,
              this.options.throttle
            );
            return;
          }
        }
      } catch {
      }
    }
    resolveLog(true);
  }
  _log(logObj) {
    for (const reporter of this.options.reporters) {
      reporter.log(logObj, {
        options: this.options
      });
    }
  }
}
function _normalizeLogLevel(input, types = {}, defaultLevel = 3) {
  if (input === void 0) {
    return defaultLevel;
  }
  if (typeof input === "number") {
    return input;
  }
  if (types[input] && types[input].level !== void 0) {
    return types[input].level;
  }
  return defaultLevel;
}
Consola.prototype.add = Consola.prototype.addReporter;
Consola.prototype.remove = Consola.prototype.removeReporter;
Consola.prototype.clear = Consola.prototype.removeReporter;
Consola.prototype.withScope = Consola.prototype.withTag;
Consola.prototype.mock = Consola.prototype.mockTypes;
Consola.prototype.pause = Consola.prototype.pauseLogs;
Consola.prototype.resume = Consola.prototype.resumeLogs;
function createConsola$1(options = {}) {
  return new Consola(options);
}

class BrowserReporter {
  options;
  defaultColor;
  levelColorMap;
  typeColorMap;
  constructor(options) {
    this.options = { ...options };
    this.defaultColor = "#7f8c8d";
    this.levelColorMap = {
      0: "#c0392b",
      // Red
      1: "#f39c12",
      // Yellow
      3: "#00BCD4"
      // Cyan
    };
    this.typeColorMap = {
      success: "#2ecc71"
      // Green
    };
  }
  _getLogFn(level) {
    if (level < 1) {
      return console.__error || console.error;
    }
    if (level === 1) {
      return console.__warn || console.warn;
    }
    return console.__log || console.log;
  }
  log(logObj) {
    const consoleLogFn = this._getLogFn(logObj.level);
    const type = logObj.type === "log" ? "" : logObj.type;
    const tag = logObj.tag || "";
    const color = this.typeColorMap[logObj.type] || this.levelColorMap[logObj.level] || this.defaultColor;
    const style = `
      background: ${color};
      border-radius: 0.5em;
      color: white;
      font-weight: bold;
      padding: 2px 0.5em;
    `;
    const badge = `%c${[tag, type].filter(Boolean).join(":")}`;
    if (typeof logObj.args[0] === "string") {
      consoleLogFn(
        `${badge}%c ${logObj.args[0]}`,
        style,
        // Empty string as style resets to default console style
        "",
        ...logObj.args.slice(1)
      );
    } else {
      consoleLogFn(badge, style, ...logObj.args);
    }
  }
}

function createConsola(options = {}) {
  const consola2 = createConsola$1({
    reporters: options.reporters || [new BrowserReporter({})],
    prompt(message, options2 = {}) {
      if (options2.type === "confirm") {
        return Promise.resolve(confirm(message));
      }
      return Promise.resolve(prompt(message));
    },
    ...options
  });
  return consola2;
}
const consola = createConsola();

function debounce(func, debounceMs, { signal, edges } = {}) {
    let pendingThis = undefined;
    let pendingArgs = null;
    const leading = edges != null && edges.includes('leading');
    const trailing = edges == null || edges.includes('trailing');
    const invoke = () => {
        if (pendingArgs !== null) {
            func.apply(pendingThis, pendingArgs);
            pendingThis = undefined;
            pendingArgs = null;
        }
    };
    const onTimerEnd = () => {
        if (trailing) {
            invoke();
        }
        cancel();
    };
    let timeoutId = null;
    const schedule = () => {
        if (timeoutId != null) {
            clearTimeout(timeoutId);
        }
        timeoutId = setTimeout(() => {
            timeoutId = null;
            onTimerEnd();
        }, debounceMs);
    };
    const cancelTimer = () => {
        if (timeoutId !== null) {
            clearTimeout(timeoutId);
            timeoutId = null;
        }
    };
    const cancel = () => {
        cancelTimer();
        pendingThis = undefined;
        pendingArgs = null;
    };
    const flush = () => {
        cancelTimer();
        invoke();
    };
    const debounced = function (...args) {
        if (signal?.aborted) {
            return;
        }
        pendingThis = this;
        pendingArgs = args;
        const isFirstCall = timeoutId == null;
        schedule();
        if (leading && isFirstCall) {
            invoke();
        }
    };
    debounced.schedule = schedule;
    debounced.cancel = cancel;
    debounced.flush = flush;
    signal?.addEventListener('abort', cancel, { once: true });
    return debounced;
}

// File watcher configuration constants
const DEFAULT_DEBOUNCE_MS = 300;
const FILE_STABILITY_THRESHOLD_MS = 100;
const POLL_INTERVAL_MS = 50;
const KEEPALIVE_INTERVAL_MS = 30000;
const JSON_INDENT_SPACES$1 = 2;
/**
 * File system watcher that efficiently updates graph JSON when markdown files change
 */
class GraphWatcher extends EventEmitter {
    constructor(options) {
        super();
        this.stats = {
            totalFiles: 0,
            nodeCount: 0,
            linkCount: 0,
            lastUpdate: new Date(),
        };
        this.options = {
            debounceMs: DEFAULT_DEBOUNCE_MS,
            excludes: ["node_modules", "dist", ".git"],
            includeHidden: false,
            verbose: false,
            ...options,
        };
        // Create repository and graph manager
        const repository = new FileRepository(this.options.targetDirectory, {
            excludes: this.options.excludes,
            includeHidden: this.options.includeHidden,
        });
        this.graphManager = new GraphManager(repository, this.options.targetDirectory);
        // Create debounced write function
        this.debouncedWriteGraph = debounce(() => {
            this.writeGraphToFile();
        }, this.options.debounceMs);
    }
    /**
     * Start watching for file changes
     * Returns a Promise that never resolves to keep the process alive
     */
    async start() {
        try {
            // Initialize the graph
            consola.start(`Initializing graph from ${this.options.targetDirectory}`);
            await this.graphManager.initialize();
            this.updateStats();
            // Emit initialization complete event
            this.emit("initialized", this.getStats());
            // Write initial graph and emit event
            this.writeGraphToFile();
            consola.success(`Initial graph created with ${this.stats.nodeCount} nodes and ${this.stats.linkCount} links`);
            this.watcher = watch(this.options.targetDirectory, {
                persistent: true,
                ignoreInitial: true,
                ignored: (path, stats) => !!stats?.isFile() && !path.endsWith(".md"),
                awaitWriteFinish: {
                    stabilityThreshold: FILE_STABILITY_THRESHOLD_MS,
                    pollInterval: POLL_INTERVAL_MS,
                },
                usePolling: false,
            });
            this.setupWatcherHandlers(this.watcher);
            consola.info(`Watching for changes in ${this.options.targetDirectory}`);
            consola.info("Press Ctrl+C to stop watching");
            // Return a promise that never resolves to keep the process alive
            return new Promise(() => {
                // Keep the event loop active with a timer to prevent process exit
                setInterval(() => {
                    // Do nothing, just keep the event loop busy
                }, KEEPALIVE_INTERVAL_MS); // Check every 30 seconds
            });
        }
        catch (error) {
            consola.error("Failed to start watcher:", error);
            throw error;
        }
    }
    /**
     * Stop watching for file changes
     */
    async stop() {
        if (this.watcher) {
            await this.watcher.close();
            this.watcher = undefined;
            consola.info("File watcher stopped");
        }
    }
    /**
     * Get current watch statistics
     */
    getStats() {
        return { ...this.stats };
    }
    /**
     * Set up event handlers for the file watcher
     */
    setupWatcherHandlers(watcher) {
        this.setupFileChangeHandlers(watcher);
        this.setupWatcherLifecycleHandlers(watcher);
    }
    /**
     * Set up handlers for file change events (add, change, unlink)
     */
    setupFileChangeHandlers(watcher) {
        watcher.on("add", (filePath) => {
            this.logFileEvent("File added", filePath);
            this.handleFileChange(filePath, "added");
        });
        watcher.on("change", (filePath) => {
            this.logFileEvent("File changed", filePath);
            this.handleFileChange(filePath, "changed");
        });
        watcher.on("unlink", (filePath) => {
            this.logFileEvent("File removed", filePath);
            this.handleFileRemoval(filePath);
        });
    }
    /**
     * Set up handlers for watcher lifecycle events (error, ready)
     */
    setupWatcherLifecycleHandlers(watcher) {
        watcher.on("error", (error) => {
            consola.error("Watcher error:", error);
        });
        watcher.on("ready", () => {
            if (this.options.verbose) {
                consola.debug("Initial scan complete. Ready for changes");
            }
            this.emit("ready");
        });
    }
    /**
     * Log file events if verbose logging is enabled
     */
    logFileEvent(eventType, filePath) {
        if (this.options.verbose) {
            consola.info(`${eventType}: ${filePath}`);
        }
    }
    /**
     * Handle file addition or modification
     */
    async handleFileChange(filePath, changeType) {
        try {
            await this.graphManager.updateFile(filePath);
            this.updateStats();
            this.debouncedWriteGraph();
            const fileName = sysPath__default.basename(filePath);
            if (this.options.verbose) {
                consola.info(`Graph updated: ${fileName} ${changeType} (${filePath})`);
            }
            else {
                consola.info(`Graph updated: ${fileName} ${changeType}`);
            }
            // Emit file change event
            this.emit("fileChanged", {
                filePath,
                changeType,
                stats: this.getStats(),
            });
        }
        catch (error) {
            consola.warn(`Failed to handle file ${changeType}: ${filePath}`, error);
        }
    }
    /**
     * Handle file removal
     */
    handleFileRemoval(filePath) {
        try {
            this.graphManager.removeFile(filePath);
            this.updateStats();
            this.debouncedWriteGraph();
            const fileName = sysPath__default.basename(filePath);
            if (this.options.verbose) {
                consola.info(`Graph updated: ${fileName} removed (${filePath})`);
            }
            else {
                consola.info(`Graph updated: ${fileName} removed`);
            }
            // Emit file removal event
            this.emit("fileChanged", {
                filePath,
                changeType: "removed",
                stats: this.getStats(),
            });
        }
        catch (error) {
            consola.warn(`Failed to handle file removal: ${filePath}`, error);
        }
    }
    /**
     * Update internal statistics
     */
    updateStats() {
        const graphStats = this.graphManager.getStats();
        this.stats = {
            totalFiles: this.stats.totalFiles, // This would need to be tracked separately
            nodeCount: graphStats.nodeCount,
            linkCount: graphStats.linkCount,
            lastUpdate: new Date(),
        };
    }
    /**
     * Write the current graph to the output file
     */
    writeGraphToFile() {
        try {
            const graph = this.graphManager.getGraph();
            const nodeCount = Object.keys(graph.nodes).length;
            const linkCount = graph.links.length;
            const jsonContent = JSON.stringify(graph, null, JSON_INDENT_SPACES$1);
            // Ensure output directory exists
            const outputDir = sysPath__default.dirname(this.options.outputFile);
            if (!fs.existsSync(outputDir)) {
                fs.mkdirSync(outputDir, { recursive: true });
            }
            fs.writeFileSync(this.options.outputFile, jsonContent);
            if (this.options.verbose) {
                consola.debug(`Graph written to ${this.options.outputFile} (${nodeCount} nodes, ${linkCount} links)`);
            }
            // Emit graph written event
            this.emit("graphWritten", {
                outputFile: this.options.outputFile,
                nodeCount,
                linkCount,
            });
        }
        catch (error) {
            consola.error("Failed to write graph file:", error);
        }
    }
    /**
     * Build ignore patterns for chokidar
     */
    buildIgnorePatterns(filePath) {
        // Return true to ignore the file, false to watch it
        // Check exclude patterns
        if (this.options.excludes) {
            for (const exclude of this.options.excludes) {
                if (filePath.includes(exclude)) {
                    return true;
                }
            }
        }
        // Check hidden files
        if (!this.options.includeHidden) {
            const fileName = sysPath__default.basename(filePath);
            if (fileName.startsWith(".")) {
                return true;
            }
        }
        // Don't ignore this file - watch it
        return false;
    }
}

function toRepository(config) {
    {
        if (!config.path) {
            throw new RepositoryConfigurationError("File repository requires a path to be specified");
        }
        return new FileRepository(config.path);
    }
}

const JSON_INDENT_SPACES = 2;
/**
 * Generate a graph from a markdown repository using the GraphBuilder
 * Optimized for concurrent file loading to improve performance
 */
async function generateGraph(repository, options) {
    const builder = new GraphBuilder(options);
    // Optimization: When both noSections and justNodeNames are true,
    // we only need document IDs and can skip file loading and parsing
    const canOptimize = options?.noSections && options?.justNodeNames;
    if (canOptimize) {
        // Fast path: only use document references (IDs) without loading content
        for await (const reference of repository.findAll()) {
            builder.addDocumentReference(reference);
        }
    }
    else {
        // Normal path: load and parse documents
        const promises = [];
        for await (const reference of repository.findAll())
            promises.push(repository.loadDocument(reference).then((document) => {
                builder.addDocument(document);
            }));
        await Promise.all(promises);
    }
    return builder.build();
}
async function save(graph, outputPath) {
    const jsonContent = JSON.stringify(graph, null, JSON_INDENT_SPACES);
    fs.writeFileSync(outputPath, jsonContent);
}
/**
 * Create a garden (graph) from repository options
 */
async function createGarden(options) {
    const repository = toRepository(options);
    const graph = await generateGraph(repository, {
        justNodeNames: options.justNodeNames,
        noSections: options.noSections,
    });
    // Determine the output path with default fallback
    const getOutputPath = () => {
        if (options.outputPath) {
            return options.outputPath;
        }
        // Default to .garden-graph.json in the garden directory
        const gardenDir = options.path || process.cwd();
        return sysPath__default.join(gardenDir, ".garden-graph.json");
    };
    const outputPath = getOutputPath();
    return {
        graph,
        repository,
        save: async () => save(graph, outputPath),
    };
}

/**
 * User-friendly error reporting with helpful suggestions
 *
 * This module provides enhanced error reporting capabilities with contextual
 * suggestions and recovery actions for common error scenarios.
 */
/**
 * Report an error with user-friendly message and suggestions
 */
function reportError(error) {
    if (error instanceof MarkdownGraphError) {
        reportMarkdownGraphError(error);
    }
    else {
        reportGenericError(error);
    }
}
/**
 * Report a markdown-graph specific error with context and suggestions
 */
function reportMarkdownGraphError(error) {
    const suggestions = getErrorSuggestions(error);
    consola.error(`${error.name}: ${error.message}`);
    if (suggestions.length > 0) {
        consola.info("Suggestions:");
        suggestions.forEach((suggestion, index) => {
            consola.info(`  ${index + 1}. ${suggestion.message}`);
            if (suggestion.action) {
                consola.info(`     â†’ ${suggestion.action}`);
            }
        });
    }
    if (error.cause) {
        consola.debug("Caused by:", error.cause.message);
    }
}
/**
 * Report a generic error
 */
function reportGenericError(error) {
    consola.error(`Unexpected error: ${error.message}`);
    consola.debug("Stack trace:", error.stack);
}
/**
 * Get helpful suggestions based on the error type
 */
function getErrorSuggestions(error) {
    if (error instanceof DirectoryNotFoundError) {
        return [
            {
                message: "Check that the directory path is correct",
                action: "Verify the path exists and you have read permissions",
            },
            {
                message: "Use an absolute path to avoid confusion",
                action: "Try using the full path like /Users/username/project",
            },
            {
                message: "Create the directory if it should exist",
                action: "mkdir -p <directory-path>",
            },
        ];
    }
    if (error instanceof FileNotFoundError) {
        return [
            {
                message: "Check that the file exists and you have read permissions",
            },
            {
                message: "Verify the file hasn't been moved or deleted",
            },
            {
                message: "Check if the file is in a hidden directory",
                action: "Use --include-hidden flag to scan hidden directories",
            },
        ];
    }
    if (error instanceof DocumentNotFoundError) {
        return [
            {
                message: "The document ID might be incorrect",
                action: "Check available document IDs in your repository",
            },
            {
                message: "The document might have been deleted or moved",
            },
        ];
    }
    if (error instanceof MarkdownParsingError) {
        return [
            {
                message: "Check the markdown file for syntax errors",
                action: "Review frontmatter YAML syntax",
            },
            {
                message: "Verify the file encoding is UTF-8",
            },
            {
                message: "Check for unsupported frontmatter syntax",
                action: "Ensure frontmatter uses valid YAML",
            },
        ];
    }
    if (error instanceof RepositoryConfigurationError) {
        return [
            {
                message: "Check your configuration file syntax",
                action: "Verify JSON syntax in .markdown-graph.json",
            },
            {
                message: "Review configuration options",
                action: "Run 'markdown-graph --help' for available options",
            },
            {
                message: "Check package.json for markdown-graph configuration",
                action: "Look for 'markdown-graph' section in package.json",
            },
        ];
    }
    return [
        {
            message: "Try running with verbose logging for more details",
            action: "Use -v or --verbose flag",
        },
        {
            message: "Check the documentation for troubleshooting tips",
        },
    ];
}

// CLI configuration constants
const SUCCESS_EXIT_CODE = 0;
const ERROR_EXIT_CODE = 1;
const DEFAULT_DEBOUNCE_STRING = "300";
const PARSE_BASE_10 = 10;
const UNEXPECTED_ERROR_MESSAGE = "Unexpected error:";
// Logging levels for different modes
const LOG_LEVELS = {
    QUIET: 0, // Only fatal errors
    DEFAULT: 3, // Info, warn, error, success
    VERBOSE: 4, // All logs including debug
};
// Default configuration values
const DEFAULT_CONFIG = {
    targetDirectory: () => process.cwd(),
    outputFileName: ".garden-graph.json",
};
/**
 * Merge CLI options with config file values, prioritizing CLI options
 */
function mergeOptionsWithConfig(options) {
    const config = loadConfig(options);
    validateConfig(config);
    return {
        targetDirectory: options.targetDirectory ||
            config.targetDirectory ||
            DEFAULT_CONFIG.targetDirectory(),
        providedOutputFile: options.outputFile,
        verbose: options.verbose !== undefined ? options.verbose : config.verbose || false,
        quiet: options.quiet !== undefined ? options.quiet : config.quiet || false,
    };
}
/**
 * Configure console logging level based on verbose and quiet flags
 */
function configureLogging(verbose, quiet) {
    if (quiet) {
        consola.level = LOG_LEVELS.QUIET;
    }
    else if (verbose) {
        consola.level = LOG_LEVELS.VERBOSE;
    }
    else {
        consola.level = LOG_LEVELS.DEFAULT;
    }
}
/**
 * Resolve the output file path from user input or generate default
 */
function resolveOutputFilePath(providedOutputFile, targetDirectory) {
    if (!providedOutputFile) {
        return sysPath__default.join(targetDirectory, DEFAULT_CONFIG.outputFileName);
    }
    return sysPath__default.isAbsolute(providedOutputFile)
        ? providedOutputFile
        : sysPath__default.join(process.cwd(), providedOutputFile);
}
/**
 * Validate target directory exists if checking is enabled
 */
function validateTargetDirectory(targetDirectory, checkDirectory) {
    if (checkDirectory && !fs.existsSync(targetDirectory)) {
        const message = `Directory does not exist: ${targetDirectory}`;
        consola.error(message);
        throw new Error(message);
    }
}
/**
 * Process and validate CLI options and configure logging
 */
function processCliOptions(options = {}, checkDirectory = true) {
    const mergedConfiguration = mergeOptionsWithConfig(options);
    const { targetDirectory, verbose, quiet, providedOutputFile } = mergedConfiguration;
    configureLogging(verbose, quiet);
    const outputFile = resolveOutputFilePath(providedOutputFile, targetDirectory);
    validateTargetDirectory(targetDirectory, checkDirectory);
    return {
        targetDirectory,
        outputFile,
        verbose,
        quiet,
        excludes: options.excludes,
        includeHidden: options.includeHidden,
        debounceMs: options.debounceMs,
    };
}
const runWatch = async (options = {}) => {
    try {
        const processedOptions = processCliOptions(options);
        // Create and start watcher
        const watcher = new GraphWatcher({
            targetDirectory: processedOptions.targetDirectory,
            outputFile: processedOptions.outputFile,
            verbose: processedOptions.verbose,
            excludes: processedOptions.excludes,
            includeHidden: processedOptions.includeHidden,
            debounceMs: processedOptions.debounceMs,
        });
        // Handle graceful shutdown
        const shutdown = async () => {
            consola.info("Shutting down watcher...");
            await watcher.stop();
            process.exit(SUCCESS_EXIT_CODE);
        };
        process.on("SIGINT", shutdown);
        process.on("SIGTERM", shutdown);
        // Start watcher - this will never return as it returns Promise<never>
        await watcher.start();
    }
    catch (error) {
        if (error instanceof Error) {
            reportError(error);
        }
        else {
            consola.error(UNEXPECTED_ERROR_MESSAGE, error);
        }
        process.exit(ERROR_EXIT_CODE);
    }
};
const runCli = async (options = {}) => {
    try {
        const processedOptions = processCliOptions(options, false);
        // Check if target directory exists and return error result if not
        if (!fs.existsSync(processedOptions.targetDirectory)) {
            const message = `Directory does not exist: ${processedOptions.targetDirectory}`;
            consola.error(message);
            return { success: false, message };
        }
        const startTime = performance.now();
        consola.start(`Scanning directory: ${processedOptions.targetDirectory}`);
        // Generate graph for target directory
        const garden = await createGarden({
            type: "file",
            path: processedOptions.targetDirectory,
            outputPath: processedOptions.outputFile,
        });
        const nodeCount = Object.keys(garden.graph.nodes).length;
        const linkCount = garden.graph.links.length;
        consola.info(`Found ${nodeCount} nodes and ${linkCount} links`);
        if (processedOptions.verbose) {
            consola.debug(`Target directory: ${processedOptions.targetDirectory}`);
            consola.debug(`Output file: ${processedOptions.outputFile}`);
            consola.debug(`Nodes: ${Object.keys(garden.graph.nodes).sort().join(", ")}`);
        }
        // Write graph to JSON file
        await garden.save();
        const endTime = performance.now();
        const duration = Math.round(endTime - startTime);
        const message = `Graph generated and written to ${processedOptions.outputFile} (${duration}ms)`;
        consola.success(message);
        return {
            success: true,
            message,
            outputFile: processedOptions.outputFile,
            nodeCount,
            linkCount,
        };
    }
    catch (error) {
        if (error instanceof Error) {
            reportError(error);
            return {
                success: false,
                message: error.message,
            };
        }
        const message = `Failed to generate graph: ${error}`;
        consola.error(message);
        return { success: false, message };
    }
};
/**
 * Add common options shared between generate and watch commands
 */
function addCommonOptions(command) {
    return command
        .argument("[directory]", "Directory to scan for markdown files", process.cwd())
        .option("-o, --output <file>", "Output file path (default: .garden-graph.json)")
        .option("-v, --verbose", "Enable verbose logging", false)
        .option("-q, --quiet", "Suppress all output except errors", false)
        .option("--exclude <patterns...>", "Patterns to exclude from scanning")
        .option("--include-hidden", "Include hidden files and directories", false);
}
/**
 * Convert command options to CliOptions format
 */
function buildCliOptions(directory, options, additionalOptions) {
    return {
        targetDirectory: sysPath__default.resolve(directory),
        outputFile: options.output,
        verbose: options.verbose,
        quiet: options.quiet,
        excludes: options.exclude,
        includeHidden: options.includeHidden,
        ...additionalOptions,
    };
}
const setupCliProgram = () => {
    const program = new Command();
    program
        .name("markdown-graph")
        .description("Generate a graph from markdown files")
        .version("0.0.1");
    // Generate command (default)
    addCommonOptions(program
        .command("generate")
        .alias("gen")
        .description("Generate a graph from markdown files once")).action(async (directory, options) => {
        const cliOptions = buildCliOptions(directory, options);
        const result = await runCli(cliOptions);
        if (!result.success) {
            process.exit(ERROR_EXIT_CODE);
        }
    });
    // Watch command
    addCommonOptions(program
        .command("watch")
        .description("Watch for file changes and update graph automatically"))
        .option("--debounce <ms>", "Debounce delay for file changes in milliseconds", DEFAULT_DEBOUNCE_STRING)
        .action(async (directory, options) => {
        const cliOptions = buildCliOptions(directory, options, {
            debounceMs: parseInt(options.debounce, PARSE_BASE_10),
        });
        await runWatch(cliOptions);
    });
    // Make generate the default command when no subcommand is provided
    program
        .argument("[directory]", "Directory to scan for markdown files (defaults to generate command)")
        .option("-o, --output <file>", "Output file path (default: .garden-graph.json)")
        .option("-v, --verbose", "Enable verbose logging", false)
        .option("-q, --quiet", "Suppress all output except errors", false)
        .option("--exclude <patterns...>", "Patterns to exclude from scanning")
        .option("--include-hidden", "Include hidden files and directories", false)
        .action(async (directory, options) => {
        const cliOptions = buildCliOptions(directory || process.cwd(), options);
        const result = await runCli(cliOptions);
        if (!result.success) {
            process.exit(1);
        }
    });
    return program;
};
const main = async () => {
    try {
        const program = setupCliProgram();
        await program.parseAsync(process.argv);
    }
    catch (error) {
        if (error instanceof Error) {
            reportError(error);
        }
        else {
            consola.error(UNEXPECTED_ERROR_MESSAGE, error);
        }
        process.exit(ERROR_EXIT_CODE);
    }
};
// Only run CLI if this file is being executed directly (not imported)
// Don't run during tests
if (process.env.NODE_ENV !== "test") {
    main().catch((error) => {
        consola.error(UNEXPECTED_ERROR_MESSAGE, error);
        process.exit(1);
    });
}

export { runCli, runWatch };
